# Comparing `tmp/csc_validator_be_cin-0.1.3.tar.gz` & `tmp/csc_validator_be_cin-0.1.4.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "csc_validator_be_cin-0.1.3.tar", max compression
+gzip compressed data, was "csc_validator_be_cin-0.1.4.tar", max compression
```

## Comparing `csc_validator_be_cin-0.1.3.tar` & `csc_validator_be_cin-0.1.4.tar`

### file list

```diff
@@ -1,125 +1,129 @@
--rw-r--r--   0        0        0        0 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/cin_validator/__init__.py
--rw-r--r--   0        0        0     6088 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/cin_validator/__main__.py
--rw-r--r--   0        0        0    18283 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/cin_validator/cin_validator.py
--rw-r--r--   0        0        0     1195 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/cin_validator/england_holidates.py
--rw-r--r--   0        0        0    18420 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/cin_validator/ingress.py
--rw-r--r--   0        0        0     4933 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__api.py
--rw-r--r--   0        0        0    11009 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__context.py
--rw-r--r--   0        0        0      317 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__init__.py
--rw-r--r--   0        0        0     1481 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__registry.py
--rw-r--r--   0        0        0        0 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/__init__.py
--rw-r--r--   0        0        0      222 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/__init__.py
--rw-r--r--   0        0        0     2422 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_100.py
--rw-r--r--   0        0        0     7376 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1103.py
--rw-r--r--   0        0        0     7090 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1104.py
--rw-r--r--   0        0        0     6581 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1105.py
--rw-r--r--   0        0        0     4153 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1510.py
--rw-r--r--   0        0        0     4167 2023-10-09 14:52:32.172906 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1520.py
--rw-r--r--   0        0        0     3893 2023-10-09 14:52:32.181699 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1530.py
--rw-r--r--   0        0        0     2014 2023-10-09 14:52:32.181699 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1540.py
--rw-r--r--   0        0        0     2081 2023-10-09 14:52:32.181699 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1550.py
--rw-r--r--   0        0        0     2825 2023-10-09 14:52:32.181699 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1560Q.py
--rw-r--r--   0        0        0     5352 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2883.py
--rw-r--r--   0        0        0     7244 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2884.py
--rw-r--r--   0        0        0    24750 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2885.py
--rw-r--r--   0        0        0     2556 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2886Q.py
--rw-r--r--   0        0        0     2541 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2887Q.py
--rw-r--r--   0        0        0     2576 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2888Q.py
--rw-r--r--   0        0        0     5475 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2889.py
--rw-r--r--   0        0        0    12572 2023-10-09 14:52:32.184202 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2990.py
--rw-r--r--   0        0        0     6033 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2991Q.py
--rw-r--r--   0        0        0     4498 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4000.py
--rw-r--r--   0        0        0     6448 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4001.py
--rw-r--r--   0        0        0     9244 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4003.py
--rw-r--r--   0        0        0     4756 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4004.py
--rw-r--r--   0        0        0     5724 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4008.py
--rw-r--r--   0        0        0     6737 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4009Q.py
--rw-r--r--   0        0        0     3765 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4010.py
--rw-r--r--   0        0        0     3857 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4011.py
--rw-r--r--   0        0        0     4346 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4012Q.py
--rw-r--r--   0        0        0     2693 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4013.py
--rw-r--r--   0        0        0     9363 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4014.py
--rw-r--r--   0        0        0     5734 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4015.py
--rw-r--r--   0        0        0     9246 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4016.py
--rw-r--r--   0        0        0     9997 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4017.py
--rw-r--r--   0        0        0     3224 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4180.py
--rw-r--r--   0        0        0     2181 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4220.py
--rw-r--r--   0        0        0     2945 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8500.py
--rw-r--r--   0        0        0     1804 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8510.py
--rw-r--r--   0        0        0     2272 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8520.py
--rw-r--r--   0        0        0     4902 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8525Q.py
--rw-r--r--   0        0        0     5139 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8530Q.py
--rw-r--r--   0        0        0     5162 2023-10-09 14:52:32.189377 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8535Q.py
--rw-r--r--   0        0        0     6583 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8540.py
--rw-r--r--   0        0        0     2822 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8545Q.py
--rw-r--r--   0        0        0     6245 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8555Q.py
--rw-r--r--   0        0        0    16210 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8565.py
--rw-r--r--   0        0        0     1595 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8568.py
--rw-r--r--   0        0        0     4726 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8569Q.py
--rw-r--r--   0        0        0     5025 2023-10-09 14:52:32.201023 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8585Q.py
--rw-r--r--   0        0        0     3270 2023-10-09 14:52:32.205151 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8590.py
--rw-r--r--   0        0        0     3159 2023-10-09 14:52:32.205151 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8600.py
--rw-r--r--   0        0        0     6792 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8606.py
--rw-r--r--   0        0        0     4573 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8608.py
--rw-r--r--   0        0        0     3199 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8610.py
--rw-r--r--   0        0        0     4179 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8614.py
--rw-r--r--   0        0        0     4607 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8615.py
--rw-r--r--   0        0        0     3970 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8620.py
--rw-r--r--   0        0        0     4111 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8630.py
--rw-r--r--   0        0        0     2780 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8640.py
--rw-r--r--   0        0        0     1760 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8650.py
--rw-r--r--   0        0        0     6769 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8670Q.py
--rw-r--r--   0        0        0     8274 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8675Q.py
--rw-r--r--   0        0        0     3117 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8696.py
--rw-r--r--   0        0        0     4146 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8715.py
--rw-r--r--   0        0        0     4515 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8720.py
--rw-r--r--   0        0        0     2933 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8730.py
--rw-r--r--   0        0        0     7978 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8736.py
--rw-r--r--   0        0        0     7546 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8740.py
--rw-r--r--   0        0        0     7481 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8750.py
--rw-r--r--   0        0        0    10148 2023-10-09 14:52:32.207252 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8770Q.py
--rw-r--r--   0        0        0     7646 2023-10-09 14:52:32.217880 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8772.py
--rw-r--r--   0        0        0     8823 2023-10-09 14:52:32.217880 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8775Q.py
--rw-r--r--   0        0        0     2239 2023-10-09 14:52:32.217880 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8790.py
--rw-r--r--   0        0        0     2911 2023-10-09 14:52:32.217880 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8794.py
--rw-r--r--   0        0        0     6196 2023-10-09 14:52:32.217880 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8805.py
--rw-r--r--   0        0        0     6235 2023-10-09 14:52:32.217880 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8810.py
--rw-r--r--   0        0        0     9357 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8815.py
--rw-r--r--   0        0        0    10238 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8816.py
--rw-r--r--   0        0        0    13127 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8820.py
--rw-r--r--   0        0        0     8906 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8825Q.py
--rw-r--r--   0        0        0    13904 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8831.py
--rw-r--r--   0        0        0     8936 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8832.py
--rw-r--r--   0        0        0     9648 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8839.py
--rw-r--r--   0        0        0     7125 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8840.py
--rw-r--r--   0        0        0    12099 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8841.py
--rw-r--r--   0        0        0     3102 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8842Q.py
--rw-r--r--   0        0        0    12268 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8863Q.py
--rw-r--r--   0        0        0     6051 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8866.py
--rw-r--r--   0        0        0    10170 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8867.py
--rw-r--r--   0        0        0    10979 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8868.py
--rw-r--r--   0        0        0     4159 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8869.py
--rw-r--r--   0        0        0     2904 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8870Q.py
--rw-r--r--   0        0        0    11749 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8873Q.py
--rw-r--r--   0        0        0     2809 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8875.py
--rw-r--r--   0        0        0    13026 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8890.py
--rw-r--r--   0        0        0     8213 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8896.py
--rw-r--r--   0        0        0     9178 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8897Q.py
--rw-r--r--   0        0        0     6262 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8898.py
--rw-r--r--   0        0        0     2108 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8905.py
--rw-r--r--   0        0        0     2087 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8910.py
--rw-r--r--   0        0        0     6743 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8915.py
--rw-r--r--   0        0        0    10862 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8920.py
--rw-r--r--   0        0        0     7485 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8925.py
--rw-r--r--   0        0        0     4370 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8930.py
--rw-r--r--   0        0        0     7938 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8935.py
--rw-r--r--   0        0        0    11173 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8940.py
--rw-r--r--   0        0        0      731 2023-10-09 14:52:32.220985 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2023_24/__init__.py
--rw-r--r--   0        0        0     4036 2023-10-09 14:52:32.234593 csc_validator_be_cin-0.1.3/cin_validator/rules/cin2023_24/rule_1530.py
--rw-r--r--   0        0        0     2844 2023-10-09 14:52:32.234593 csc_validator_be_cin-0.1.3/cin_validator/rules/ruleset_utils.py
--rw-r--r--   0        0        0      268 2023-10-09 14:52:32.237249 csc_validator_be_cin-0.1.3/cin_validator/test_engine/__init__.py
--rw-r--r--   0        0        0     5476 2023-10-09 14:52:32.237249 csc_validator_be_cin-0.1.3/cin_validator/utils.py
--rw-r--r--   0        0        0     1017 2023-10-09 15:18:42.192683 csc_validator_be_cin-0.1.3/pyproject.toml
--rw-r--r--   0        0        0     4548 2023-10-09 14:52:32.167390 csc_validator_be_cin-0.1.3/README.md
--rw-r--r--   0        0        0     3924 2023-10-09 14:52:32.237249 csc_validator_be_cin-0.1.3/rpc_main.py
--rw-r--r--   0        0        0     5657 1970-01-01 00:00:00.000000 csc_validator_be_cin-0.1.3/PKG-INFO
+-rw-r--r--   0        0        0     6608 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/README.md
+-rw-r--r--   0        0        0        0 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/__init__.py
+-rw-r--r--   0        0        0     5954 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/__main__.py
+-rw-r--r--   0        0        0    17910 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/cin_validator.py
+-rw-r--r--   0        0        0     1156 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/england_holidates.py
+-rw-r--r--   0        0        0    18964 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/ingress.py
+-rw-r--r--   0        0        0     5022 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__api.py
+-rw-r--r--   0        0        0    10717 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__context.py
+-rw-r--r--   0        0        0      304 2024-05-17 08:21:43.360221 csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__init__.py
+-rw-r--r--   0        0        0     1439 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__registry.py
+-rw-r--r--   0        0        0        0 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/__init__.py
+-rw-r--r--   0        0        0      214 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/__init__.py
+-rw-r--r--   0        0        0     2346 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_100.py
+-rw-r--r--   0        0        0     7160 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1103.py
+-rw-r--r--   0        0        0     6883 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1104.py
+-rw-r--r--   0        0        0     6366 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1105.py
+-rw-r--r--   0        0        0     4040 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1510.py
+-rw-r--r--   0        0        0     4038 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1520.py
+-rw-r--r--   0        0        0     3760 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1530.py
+-rw-r--r--   0        0        0     1953 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1540.py
+-rw-r--r--   0        0        0     1990 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1550.py
+-rw-r--r--   0        0        0     2746 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1560Q.py
+-rw-r--r--   0        0        0     5196 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2883.py
+-rw-r--r--   0        0        0     7017 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2884.py
+-rw-r--r--   0        0        0    24137 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2885.py
+-rw-r--r--   0        0        0     2489 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2886Q.py
+-rw-r--r--   0        0        0     2472 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2887Q.py
+-rw-r--r--   0        0        0     2511 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2888Q.py
+-rw-r--r--   0        0        0     5307 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2889.py
+-rw-r--r--   0        0        0    12183 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2990.py
+-rw-r--r--   0        0        0     5826 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2991Q.py
+-rw-r--r--   0        0        0     4335 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4000.py
+-rw-r--r--   0        0        0     6242 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4001.py
+-rw-r--r--   0        0        0     8958 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4003.py
+-rw-r--r--   0        0        0     4607 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4004.py
+-rw-r--r--   0        0        0     5530 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4008.py
+-rw-r--r--   0        0        0     6541 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4009Q.py
+-rw-r--r--   0        0        0     3665 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4010.py
+-rw-r--r--   0        0        0     3735 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4011.py
+-rw-r--r--   0        0        0     4200 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4012Q.py
+-rw-r--r--   0        0        0     2611 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4013.py
+-rw-r--r--   0        0        0     9107 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4014.py
+-rw-r--r--   0        0        0     5547 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4015.py
+-rw-r--r--   0        0        0     8962 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4016.py
+-rw-r--r--   0        0        0     9694 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4017.py
+-rw-r--r--   0        0        0     3144 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4180.py
+-rw-r--r--   0        0        0     2093 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4220.py
+-rw-r--r--   0        0        0     2874 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8500.py
+-rw-r--r--   0        0        0     1742 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8510.py
+-rw-r--r--   0        0        0     2197 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8520.py
+-rw-r--r--   0        0        0     4762 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8525Q.py
+-rw-r--r--   0        0        0     4979 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8530Q.py
+-rw-r--r--   0        0        0     5012 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8535Q.py
+-rw-r--r--   0        0        0     6356 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8540.py
+-rw-r--r--   0        0        0     2727 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8545Q.py
+-rw-r--r--   0        0        0     6046 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8555Q.py
+-rw-r--r--   0        0        0    15704 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8565.py
+-rw-r--r--   0        0        0     1539 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8568.py
+-rw-r--r--   0        0        0     4573 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8569Q.py
+-rw-r--r--   0        0        0     4855 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8585Q.py
+-rw-r--r--   0        0        0     3146 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8590.py
+-rw-r--r--   0        0        0     3072 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8600.py
+-rw-r--r--   0        0        0     6582 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8606.py
+-rw-r--r--   0        0        0     4437 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8608.py
+-rw-r--r--   0        0        0     3087 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8610.py
+-rw-r--r--   0        0        0     4049 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8614.py
+-rw-r--r--   0        0        0     4455 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8615.py
+-rw-r--r--   0        0        0     3867 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8620.py
+-rw-r--r--   0        0        0     3964 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8630.py
+-rw-r--r--   0        0        0     2704 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8640.py
+-rw-r--r--   0        0        0     1698 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8650.py
+-rw-r--r--   0        0        0     6599 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8670Q.py
+-rw-r--r--   0        0        0     8084 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8675Q.py
+-rw-r--r--   0        0        0     3026 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8696.py
+-rw-r--r--   0        0        0     4044 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8715.py
+-rw-r--r--   0        0        0     4405 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8720.py
+-rw-r--r--   0        0        0     2858 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8730.py
+-rw-r--r--   0        0        0     7779 2024-05-17 08:21:43.364221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8736.py
+-rw-r--r--   0        0        0     7362 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8740.py
+-rw-r--r--   0        0        0     7304 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8750.py
+-rw-r--r--   0        0        0     9897 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8770Q.py
+-rw-r--r--   0        0        0     7435 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8772.py
+-rw-r--r--   0        0        0     8592 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8775Q.py
+-rw-r--r--   0        0        0     2167 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8790.py
+-rw-r--r--   0        0        0     2820 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8794.py
+-rw-r--r--   0        0        0     6035 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8805.py
+-rw-r--r--   0        0        0     6076 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8810.py
+-rw-r--r--   0        0        0     9116 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8815.py
+-rw-r--r--   0        0        0     9973 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8816.py
+-rw-r--r--   0        0        0    12802 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8820.py
+-rw-r--r--   0        0        0     8684 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8825Q.py
+-rw-r--r--   0        0        0    13543 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8831.py
+-rw-r--r--   0        0        0     8713 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8832.py
+-rw-r--r--   0        0        0     9424 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8839.py
+-rw-r--r--   0        0        0     6963 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8840.py
+-rw-r--r--   0        0        0    11807 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8841.py
+-rw-r--r--   0        0        0     3023 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8842Q.py
+-rw-r--r--   0        0        0    11968 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8863Q.py
+-rw-r--r--   0        0        0     5877 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8866.py
+-rw-r--r--   0        0        0     9919 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8867.py
+-rw-r--r--   0        0        0    10703 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8868.py
+-rw-r--r--   0        0        0     4029 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8869.py
+-rw-r--r--   0        0        0     2823 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8870Q.py
+-rw-r--r--   0        0        0    12442 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8873Q.py
+-rw-r--r--   0        0        0     2729 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8875.py
+-rw-r--r--   0        0        0    12709 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8890.py
+-rw-r--r--   0        0        0     8031 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8896.py
+-rw-r--r--   0        0        0     9673 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8897Q.py
+-rw-r--r--   0        0        0     7176 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8898.py
+-rw-r--r--   0        0        0     2041 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8905.py
+-rw-r--r--   0        0        0     2021 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8910.py
+-rw-r--r--   0        0        0     6532 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8915.py
+-rw-r--r--   0        0        0    10605 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8920.py
+-rw-r--r--   0        0        0     7316 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8925.py
+-rw-r--r--   0        0        0     4263 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8930.py
+-rw-r--r--   0        0        0     7761 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8935.py
+-rw-r--r--   0        0        0    10893 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8940.py
+-rw-r--r--   0        0        0      710 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2023_24/__init__.py
+-rw-r--r--   0        0        0     3900 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2023_24/rule_1530.py
+-rw-r--r--   0        0        0      710 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2024_25/__init__.py
+-rw-r--r--   0        0        0     2465 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2024_25/rule_2886Q.py
+-rw-r--r--   0        0        0     2983 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2024_25/rule_4180.py
+-rw-r--r--   0        0        0     7150 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/cin2024_25/rule_8750.py
+-rw-r--r--   0        0        0     2768 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/rules/ruleset_utils.py
+-rw-r--r--   0        0        0      259 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/test_engine/__init__.py
+-rw-r--r--   0        0        0     5340 2024-05-17 08:21:43.368221 csc_validator_be_cin-0.1.4/cin_validator/utils.py
+-rw-r--r--   0        0        0      992 2024-05-17 08:21:43.372221 csc_validator_be_cin-0.1.4/pyproject.toml
+-rw-r--r--   0        0        0     3806 2024-05-17 08:21:43.372221 csc_validator_be_cin-0.1.4/rpc_main.py
+-rw-r--r--   0        0        0     7607 1970-01-01 00:00:00.000000 csc_validator_be_cin-0.1.4/PKG-INFO
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/__main__.py` & `csc_validator_be_cin-0.1.4/cin_validator/__main__.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,190 +1,191 @@
-import datetime
-import importlib
-import json
-import os
-import xml.etree.ElementTree as ET
-from pathlib import Path
-
-import click
-import pytest
-
-from cin_validator import cin_validator
-
-
-@click.group()
-def cli():
-    pass
-
-
-@cli.command(name="list")
-@click.option(
-    "--ruleset",
-    "-r",
-    default="cin2022_23",
-    help="Which ruleset to use, e.g. cin2022_23",
-)
-def list_cmd(ruleset):
-    """
-    List all rules in a ruleset.
-
-    Call using:
-    python -m cin_validator list
-
-    :param str ruleset: The name of a CIN validation ruleset, used to select rules for validating data.
-    :returns: A list of validation rules in the given ruleset.
-    :rtype: list
-    """
-    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
-    ruleset_registry = getattr(module, "registry")
-    for _, rule in ruleset_registry.items():
-        click.echo(f"{rule.code}\t{rule.message} ({rule.rule_type.name})")
-
-
-@cli.command(name="run")
-@click.argument("filename", type=click.File("rt"), required=True)
-@click.option(
-    "--ruleset",
-    "-r",
-    default="cin2022_23",
-    help="Which ruleset to use, e.g. cin2022_23",
-)
-@click.option("--select", "-s", default=None)
-@click.option("--output/--no_output", "-o/-no", default=False)
-def run_all(filename: str, ruleset, select, output):
-    """
-    Used to run all of a set of validation rules on input data.
-
-    CLI command:
-    python -m cin_validator run <filepath_to_data>
-
-    Can be used to validate data, via the command line interface, for a given rule set.
-    Runs with the cin2022_23 ruleset as standard.
-
-    :param str filename: Refers to the filepath of data to be validated.
-    :param str ruleset: The folder name of the validation rules to run input data against.
-    :param select: specify the rules that should be run. CLI works with a single string only.
-    :param bool output: If true, produces csv output of error report, if False (default)
-        does not.
-    :returns: DataFrame report of errors using selected validation rules, also output as
-        JSON when output is True.
-    :rtype: DataFrame, JSON
-    """
-
-    fulltree = ET.parse(filename)
-    root = fulltree.getroot()
-
-    raw_data = cin_validator.convert_data(root)
-    data_files = cin_validator.process_data(raw_data)
-
-    # get rules based on specified year.
-    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
-    ruleset_registry = getattr(module, "registry")
-
-    validator = cin_validator.CinValidator(
-        data_files, ruleset_registry, selected_rules=select
-    )
-
-    full_issue_df = validator.full_issue_df
-
-    if output:
-        validator.user_report.to_csv("user_report.csv")
-
-    click.echo(full_issue_df)
-    click.echo(validator.multichild_issues)
-
-
-@cli.command(name="test")
-@click.argument("rule", required=False)
-@click.option(
-    "--ruleset",
-    "-r",
-    default="cin2022_23",
-    help="Which ruleset to use, e.g. cin2022_23",
-)
-def test_cmd(rule, ruleset):
-    """
-    Test all (or individual) rules in a ruleset. Note: tests the code
-    for the rule, this is not used for validating data.
-
-    Allows use of the CLI to test a ruleset or individual rules against the
-    pytest written in each of their files. Useful for bugfixing. Defaults
-    to the cin2022_23 ruleset.
-
-    Can be called to test all rules using:
-    python -m cin_validator test
-    To test individual rules:
-    python -m cin_validator <rulecode>
-    For example:
-    python -m cin_validator test 8875
-
-    :param str rule: Used to specify an individual rule to test.
-    :param str ruleset: Use to give the name of a set of validation rules to test
-        (defaults to cin2022_23).
-    :returns: Pytest output in terminal of rules passing and failing.
-    :rtype: Pytest output in terminal.
-    """
-
-    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
-    module_folder = Path(module.__file__).parent
-
-    ruleset_registry = getattr(module, "registry")
-
-    if rule:
-        rule = str(rule)
-        # when rule code is specified, test specific rule.
-        rule_def = ruleset_registry.get(rule)
-        if not rule_def:
-            # if the get returns a <NoneType>
-            click.secho(f"Rule {rule} not found.", err=True, fg="red")
-            return 1
-        test_files = [os.path.join(module_folder, f"rule_{rule}.py")]
-    else:
-        # else test all rules.
-        test_files = [
-            str(p.absolute())
-            for p in module_folder.glob("*.py")
-            if p.stem != "__init__"
-        ]
-
-    pytest.main(test_files)
-
-
-@cli.command(name="xmltocsv")
-@click.argument("filename", type=click.Path(), required=True)
-def cli_converter(filename: str):
-    """
-    Converts XML to CSV at selected filepath. Does not require XML to be validated against validation rules and does not validate against rules.
-    Called using:
-    python -m cin_validator xmltocsv <filepath>
-
-    :param str filename: filename (or path) of XML file to convert to CSV.
-    :returns: CSV of XML input into output_csvs directory (which will be created
-        if it doesn't already exist).
-    :rtype: CSVs (multiple).
-
-    """
-    if Path(filename).exists():
-        fulltree = ET.parse(filename)
-        root = fulltree.getroot()
-
-        cin_tables_dict = cin_validator.convert_data(root)
-        for k, v in cin_tables_dict.items():
-            filepath = Path(f"output_csvs/{k}.csv")
-            filepath.parent.mkdir(parents=True, exist_ok=True)
-            v.to_csv(filepath)
-    else:
-        click.echo(f"{filename} can't be found, have you entered it correctly?")
-
-
-@cli.command(name="timer")
-@click.argument("filepath", type=str, required=True)
-def timer(filepath):
-    st = datetime.datetime.now()
-    os.system(f"python -m cin_validator run {filepath}")
-    et = datetime.datetime.now()
-    time_elapsed = et - st
-    click.echo(f"Time to run: {time_elapsed}")
-
-
-if __name__ == "__main__":
-    cli()
+import datetime
+import importlib
+import json
+import os
+import xml.etree.ElementTree as ET
+from pathlib import Path
+
+import click
+import pytest
+
+from cin_validator import cin_validator
+
+
+@click.group()
+def cli():
+    pass
+
+
+@cli.command(name="list")
+@click.option(
+    "--ruleset",
+    "-r",
+    default="cin2022_23",
+    help="Which ruleset to use, e.g. cin2022_23",
+)
+def list_cmd(ruleset):
+    """
+    List all rules in a ruleset.
+
+    Call using:
+    python -m cin_validator list
+
+    :param str ruleset: The name of a CIN validation ruleset, used to select rules for validating data.
+    :returns: A list of validation rules in the given ruleset.
+    :rtype: list
+    """
+    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
+    ruleset_registry = getattr(module, "registry")
+    for _, rule in ruleset_registry.items():
+        click.echo(f"{rule.code}\t{rule.message} ({rule.rule_type.name})")
+
+
+@cli.command(name="run")
+@click.argument("filename", type=click.File("rt"), required=True)
+@click.option(
+    "--ruleset",
+    "-r",
+    default="cin2022_23",
+    help="Which ruleset to use, e.g. cin2022_23",
+)
+@click.option("--select", "-s", default=None)
+@click.option("--output/--no_output", "-o/-no", default=False)
+def run_all(filename: str, ruleset, select, output):
+    """
+    Used to run all of a set of validation rules on input data.
+
+    CLI command:
+    python -m cin_validator run <filepath_to_data>
+
+    Can be used to validate data, via the command line interface, for a given rule set.
+    Runs with the cin2022_23 ruleset as standard.
+
+    :param str filename: Refers to the filepath of data to be validated.
+    :param str ruleset: The folder name of the validation rules to run input data against.
+    :param select: specify the rules that should be run. CLI works with a single string only.
+    :param bool output: If true, produces csv output of error report, if False (default)
+        does not.
+    :returns: DataFrame report of errors using selected validation rules, also output as
+        JSON when output is True.
+    :rtype: DataFrame, JSON
+    """
+
+    fulltree = ET.parse(filename)
+    root = fulltree.getroot()
+
+    raw_data = cin_validator.convert_data(root)
+    data_files = cin_validator.process_data(raw_data)
+
+    # get rules based on specified year.
+    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
+    ruleset_registry = getattr(module, "registry")
+
+    validator = cin_validator.CinValidator(
+        data_files, ruleset_registry, selected_rules=select
+    )
+
+    full_issue_df = validator.full_issue_df
+
+    if output:
+        validator.user_report.to_csv("user_report.csv")
+
+    # click.echo(full_issue_df)
+    # click.echo(validator.multichild_issues)
+    click.echo(validator.data_files["Assessments"])
+
+
+@cli.command(name="test")
+@click.argument("rule", required=False)
+@click.option(
+    "--ruleset",
+    "-r",
+    default="cin2022_23",
+    help="Which ruleset to use, e.g. cin2022_23",
+)
+def test_cmd(rule, ruleset):
+    """
+    Test all (or individual) rules in a ruleset. Note: tests the code
+    for the rule, this is not used for validating data.
+
+    Allows use of the CLI to test a ruleset or individual rules against the
+    pytest written in each of their files. Useful for bugfixing. Defaults
+    to the cin2022_23 ruleset.
+
+    Can be called to test all rules using:
+    python -m cin_validator test
+    To test individual rules:
+    python -m cin_validator <rulecode>
+    For example:
+    python -m cin_validator test 8875
+
+    :param str rule: Used to specify an individual rule to test.
+    :param str ruleset: Use to give the name of a set of validation rules to test
+        (defaults to cin2022_23).
+    :returns: Pytest output in terminal of rules passing and failing.
+    :rtype: Pytest output in terminal.
+    """
+
+    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
+    module_folder = Path(module.__file__).parent
+
+    ruleset_registry = getattr(module, "registry")
+
+    if rule:
+        rule = str(rule)
+        # when rule code is specified, test specific rule.
+        rule_def = ruleset_registry.get(rule)
+        if not rule_def:
+            # if the get returns a <NoneType>
+            click.secho(f"Rule {rule} not found.", err=True, fg="red")
+            return 1
+        test_files = [os.path.join(module_folder, f"rule_{rule}.py")]
+    else:
+        # else test all rules.
+        test_files = [
+            str(p.absolute())
+            for p in module_folder.glob("*.py")
+            if p.stem != "__init__"
+        ]
+
+    pytest.main(test_files)
+
+
+@cli.command(name="xmltocsv")
+@click.argument("filename", type=click.Path(), required=True)
+def cli_converter(filename: str):
+    """
+    Converts XML to CSV at selected filepath. Does not require XML to be validated against validation rules and does not validate against rules.
+    Called using:
+    python -m cin_validator xmltocsv <filepath>
+
+    :param str filename: filename (or path) of XML file to convert to CSV.
+    :returns: CSV of XML input into output_csvs directory (which will be created
+        if it doesn't already exist).
+    :rtype: CSVs (multiple).
+
+    """
+    if Path(filename).exists():
+        fulltree = ET.parse(filename)
+        root = fulltree.getroot()
+
+        cin_tables_dict = cin_validator.convert_data(root)
+        for k, v in cin_tables_dict.items():
+            filepath = Path(f"output_csvs/{k}.csv")
+            filepath.parent.mkdir(parents=True, exist_ok=True)
+            v.to_csv(filepath)
+    else:
+        click.echo(f"{filename} can't be found, have you entered it correctly?")
+
+
+@cli.command(name="timer")
+@click.argument("filepath", type=str, required=True)
+def timer(filepath):
+    st = datetime.datetime.now()
+    os.system(f"python -m cin_validator run {filepath}")
+    et = datetime.datetime.now()
+    time_elapsed = et - st
+    click.echo(f"Time to run: {time_elapsed}")
+
+
+if __name__ == "__main__":
+    cli()
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/cin_validator.py` & `csc_validator_be_cin-0.1.4/cin_validator/cin_validator.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,440 +1,441 @@
-import copy
-import xml.etree.ElementTree as ET
-from typing import Optional
-
-import pandas as pd
-
-from cin_validator.ingress import XMLtoCSV
-from cin_validator.rule_engine import CINTable, RuleContext, RuleDefinition
-from cin_validator.utils import process_date_columns
-
-pd.options.mode.chained_assignment = None
-# Suppresses false-positive SettingWithCopyError when column types are changes in the include_issue_child function.
-# https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas
-
-
-def enum_keys(dict_input: dict):
-    """
-    Convert keys of a dictionary to its corresponding CINTable format.
-    :param dict dict_input: dictionary of dataframes of CIN data
-    :return dict enumed_dict: same data content with keys replaced.
-    """
-    enumed_dict = {}
-    for enum_key in CINTable:
-        # if enum_key == CINTable.Header, then enum_key.name == Header
-        enumed_dict[enum_key] = dict_input[str(enum_key.name)]
-    return enumed_dict
-
-
-def convert_data(root: ET.Element):
-    """
-    Takes input data and processes it for validation.
-
-    This function takes input XML data, and uses ElementTree, and the custom class
-    XMLtoCSV to process the data into tables for validation.
-
-    :param XML root: root created by parsing the user's xml file.
-    :returns: dict of DataFrames - each representing a CIN table.
-    :rtype: Dictionary
-    """
-
-    # generate tables
-    data_files = XMLtoCSV(root)
-
-    # return tables
-    cin_tables = {
-        "Header": data_files.Header,
-        "ChildIdentifiers": data_files.ChildIdentifiers,
-        "ChildCharacteristics": data_files.ChildCharacteristics,
-        "ChildProtectionPlans": data_files.ChildProtectionPlans,
-        "CINdetails": data_files.CINdetails,
-        "CINplanDates": data_files.CINplanDates,
-        "Reviews": data_files.Reviews,
-        "Section47": data_files.Section47,
-        "Assessments": data_files.Assessments,
-        "Disabilities": data_files.Disabilities,
-    }
-    return cin_tables
-
-
-def process_data(cin_tables: dict):
-    """
-    formats date columns
-    :param dict cin_tables: data to be converted
-    :return dict cin_tables_dict: original dataframes where date columns have been formatted.
-    """
-
-    # format all date columns in tables
-    cin_tables_dict = {
-        name: process_date_columns(table) for name, table in cin_tables.items()
-    }
-
-    return cin_tables_dict
-
-
-def include_issue_child(issue_df: pd.DataFrame, cin_data: dict):
-    """
-    :param DataFrame issue_df: complete data about all issue locations.
-    :param dict cin_data: dictionary of dataframes generated when cin xml is converted to tabular format.
-    """
-
-    try:
-        la_level_issues = issue_df[issue_df["tables_affected"].isna()]
-    except:
-        # if no error locations were found, i.e issue_df doesn't exist, this allows an empty dataframe to be processed.
-        return issue_df
-
-    header_issues = issue_df[issue_df["tables_affected"] == "Header"]
-    tables_with_childid = [la_level_issues, header_issues]
-    for table in issue_df["tables_affected"].dropna().unique():
-        if table == "Header":
-            # the header table doesn't contain child id. It is like metadata
-            continue
-        table_df = issue_df[issue_df["tables_affected"] == table]
-
-        # get index values of the rows that fail.
-        # some ROW_ID values exist as ints and others as strs. Unify so that .unique() doesn't contain doubles.
-        table_rows = table_df["ROW_ID"].astype("int").unique()
-
-        # naming the index of the data allows it to be mapped back to the issue_df
-        table_data = cin_data[table]
-        table_data.index.name = "ROW_ID"
-        table_data.reset_index(inplace=True)
-        # select the data for the rows with appear in issue_df and get the child ids
-        linker_df = table_data.iloc[table_rows][["LAchildID", "ROW_ID"]]
-
-        # work around: ensure that columns from both sources have the same type to prevent merge error
-        table_df["ROW_ID"] = table_df["ROW_ID"].astype("int64")
-        linker_df["ROW_ID"] = linker_df["ROW_ID"].astype("int64")
-
-        if not linker_df.empty:
-            # if failing locations have been found, remove the dummy LAchildID column to make way for the real one.
-            table_df.drop(columns="LAchildID", inplace=True)
-
-        # map the child ids back to issue_df
-        table_df = table_df.merge(linker_df, on=["ROW_ID"], how="left")
-
-        # save the result
-        tables_with_childid.append(table_df)
-
-    # regenerate issue_df from its updated constituent tables
-    issue_df = pd.concat(tables_with_childid)
-
-    return issue_df
-
-
-def create_user_report(issue_df: pd.DataFrame, cin_data: dict):
-    """
-    A good report should tell the user what failed, where it failed and why it failed.
-    The report generated by this function contains table-column-value combinations to answer the former
-    and rule code-description combinations to answer the latter.
-
-    :param pd.DataFrame issue_df: in which child IDs have been added.
-    :param dict cin_data: dataframes of user's input data.
-    :return user_report: dataframe containing issue locations and specific values that fail in those locations.
-
-    """
-    try:
-        no_table = issue_df[issue_df["tables_affected"].isna()]
-    except:
-        # in the case where issue_df is empty, return an empty user report.
-        return pd.DataFrame()
-
-    reports = []
-    for table in issue_df["tables_affected"].dropna().unique():
-        table_issues = issue_df[issue_df["tables_affected"] == table]
-
-        table_reports = []
-        for column in table_issues["columns_affected"].unique():
-            only_column = table_issues[table_issues["columns_affected"] == column]
-            column_rows = only_column["ROW_ID"].unique().astype("int")
-
-            column_data = cin_data[table][column]
-            # fancy indexing. get all the values for a sequence of row positions in a column.
-            column_values = column_data[column_rows]
-            column_values.rename("value_flagged", inplace=True)
-            column_values.index.name = "ROW_ID"
-            values_df = column_values.reset_index()
-            values_df = values_df.assign(ROW_ID=values_df["ROW_ID"].astype("object"))
-
-            # work around: ensure that columns from both sources (user data and rule output) have the same type to prevent merge error
-            only_column["ROW_ID"] = only_column["ROW_ID"].astype("int64")
-            values_df["ROW_ID"] = values_df["ROW_ID"].astype("int64")
-            report_df = only_column.merge(values_df, on="ROW_ID")
-
-            table_reports.append(report_df)
-
-        reports.extend(table_reports)
-    # add in the la-level locations
-    reports.append(no_table)
-
-    # ensure that all required column names will be present in the result.
-    full_report_cols_df = pd.DataFrame(
-        columns=[
-            "ERROR_ID",
-            "LAchildID",
-            "rule_code",
-            "tables_affected",
-            "columns_affected",
-            "ROW_ID",
-            "value_flagged",
-            "rule_description",
-        ]
-    )
-    reports.append(full_report_cols_df)
-
-    full_report = pd.concat(reports, ignore_index=True)
-
-    # columns of interest are filtered and arranged in the desired order. values unified under str datatype.
-    user_report = full_report[
-        [
-            "ERROR_ID",
-            "LAchildID",
-            "rule_code",
-            "tables_affected",
-            "columns_affected",
-            "ROW_ID",
-            "value_flagged",
-            "rule_description",
-        ]
-    ]
-
-    def datetime_to_str(element):
-        if isinstance(element, pd.Timestamp):
-            # convert datetime elements to str date values
-            return str(element.strftime("%Y-%m-%d"))
-        elif isinstance(element, tuple):
-            # loop through tuples and convert each element accordingly. mostly in ERROR_ID column.
-            return tuple(map(datetime_to_str, element))
-        else:
-            # ensure all other elements are strings too.
-            return str(element)
-
-    user_report = user_report.applymap(datetime_to_str)
-
-    # Related issue locations should be displayed next to each other.
-    user_report.sort_values(
-        [
-            "LAchildID",
-            "ERROR_ID",
-            "tables_affected",
-            "columns_affected",
-        ],
-        inplace=True,
-        ignore_index=True,
-    )
-
-    user_report.drop_duplicates(
-        ["LAchildID", "rule_code", "columns_affected", "ROW_ID"], inplace=True
-    )
-
-    return user_report
-
-
-class CinValidator:
-    """
-    A class to contain the process of CIN validation. Generates error reports as dataframes.
-
-    :param any data_files: Data files for validation, either a DataContainerWrapper object, or a
-        dictionary of DataFrames.
-    :param dir ruleset: The directory containing the validation rules to be run according to the year in which they were published.
-    """
-
-    def __init__(
-        self,
-        data_files,
-        ruleset_registry,
-        selected_rules: Optional[list[str]] = None,
-    ) -> None:
-        """
-        Initialises CinValidator class.
-
-        Creates DataFrame containing error report, and allows selection of individual instances of error using ERROR_ID
-
-        :param list ruleset: The list of rules used in an individual validation session.
-            Refers to rules in particular subdirectories of the rules directory.
-        :param any data_files: The data extracted from input XML (or CSV) for validation.
-        :param str issue_id: Can be used to choose a particular instance of an error using ERROR_ID.
-        :param list selected_rules: array of rule codes (as strings) selected by the user. Determines what rules should be run.
-        :returns: DataFrame of error report which could be a filtered version if issue_id is input.
-        :rtype: DataFrame
-        """
-
-        self.data_files = data_files
-        self.ruleset_registry = ruleset_registry
-
-        # save independent version of data to be used in report.
-        raw_data = copy.deepcopy(self.data_files)
-
-        # run
-        self.create_issue_report_df(selected_rules)
-
-        # add child_id to issue location report.
-        self.full_issue_df: pd.DataFrame = include_issue_child(
-            self.full_issue_df, raw_data
-        )
-        self.user_report = create_user_report(self.full_issue_df, raw_data)
-
-        # regularise full_issue_df
-        self.full_issue_df.rename(columns={"ROW_ID": "row_id"}, inplace=True)
-        self.full_issue_df.rename(columns={"LAchildID": "child_id"}, inplace=True)
-        self.full_issue_df.drop(columns=["ERROR_ID"], inplace=True, errors="ignore")
-        self.full_issue_df.drop_duplicates(
-            ["child_id", "rule_code", "columns_affected", "row_id"], inplace=True
-        )
-        self.full_issue_df.reset_index(drop=True, inplace=True)
-
-        # remove header issues from main dataframe and transfer to no-child-id dataframe
-        header_issues = self.full_issue_df[
-            self.full_issue_df["tables_affected"] == "Header"
-        ]
-        self.full_issue_df = self.full_issue_df[
-            self.full_issue_df["tables_affected"] != "Header"
-        ]
-        # combine multichild issues
-        self.multichild_issues = pd.concat([header_issues, self.la_rule_issues])[
-            ["rule_code", "rule_description"]
-        ]
-
-    def get_rules_to_run(
-        self, registry, selected_rules: Optional[list[str]] = None
-    ) -> list[RuleDefinition]:
-        """
-        Filters rules to be run based on user's selection in the frontend.
-        :param Registry-class registry: record of all existing rules in rule pack
-        :param list selected_rules: array of rule codes as strings
-        """
-        if selected_rules:
-            rules_to_run = [
-                rule for _, rule in registry.items() if str(rule.code) in selected_rules
-            ]
-            return rules_to_run
-        else:
-            return registry.values()
-
-    def process_issues(self, rule: RuleDefinition, ctx: RuleContext):
-        """
-        process result of running a rule on the user's data.
-
-        :param RuleDefinition-class rule: the rule that was run on the data
-        :param RuleContext-object ctx: "manages state" per rule. contains updated issue_dfs if any were added when rule was run on the data.
-        :returns : None
-
-        """
-        issue_dfs_per_rule = pd.Series(
-            [
-                ctx.type_zero_issues,
-                ctx.type_one_issues,
-                ctx.type_two_issues,
-                ctx.type_three_issues,
-                ctx.la_level_issues,
-            ]
-        )
-        # error_df_lengths is a list of lengths of all elements in issue_dfs_per_rule respectively.
-        error_df_lengths = pd.Series([len(x) for x in issue_dfs_per_rule])
-        if error_df_lengths.max() == 0:
-            # if the rule didn't push to any of the issue accumulators, then it didn't find any issues in the file.
-            self.rules_passed.append(rule.code)
-        elif error_df_lengths.idxmax() == 4:
-            # If the maximum value is in position 4, this is a return level validation rule.
-            # It has no locations attached so it is only displayed in the rule descriptions.
-            self.la_rules_broken.append(issue_dfs_per_rule[4])
-        else:
-            # get the rule type based on which attribute had elements pushed to it (i.e non-zero length)
-            # its corresponding error_df can be found by issue_dfs_per_rule[ind]
-            ind = error_df_lengths.idxmax()
-
-            issue_dict = {
-                "code": rule.code,
-                "number": error_df_lengths[ind],
-                "type": ind,
-            }
-            issue_dict_df = pd.DataFrame([issue_dict])
-            self.issue_instances = pd.concat(
-                [self.issue_instances, issue_dict_df], ignore_index=True
-            )
-
-            # add the rule's code and description to it's error_df
-            issue_dfs_per_rule[ind]["rule_code"] = rule.code
-            issue_dfs_per_rule[ind]["rule_description"] = rule.message
-
-            # temporary: add rule type to track if all types are in df.
-            issue_dfs_per_rule[ind]["rule_type"] = ind
-
-            # combine this rule's error_df with the cummulative error_df
-            self.full_issue_df = pd.concat(
-                [self.full_issue_df, issue_dfs_per_rule[ind]],
-                ignore_index=True,
-            )
-
-            # Elements of the rule_descriptors df to explain error codes
-            self.rules_broken.append(rule.code)
-            self.rule_messages.append(f"{str(rule.code)} - {rule.message}")
-
-    def create_issue_report_df(self, selected_rules: Optional[list[str]] = None):
-        """
-        Creates report of errors found when validating CIN data input to
-        the tool.
-
-        This function takes the errors/rule violations reported by individual validation rule functions,
-        including table, field, and index locations of errors. It is important that it uses deepcopy
-        on the data per rule as some rules alter original data when only a standard .copy() function
-        is used. It runs through every rule in the registry and:
-
-        >Creates lists of rules passed, broken, and relevant messages.
-        >Returns a dataframe of issue instances for broken validation rules.
-        >Returns a dictionary of all rules codes and relevant messages.
-
-        :param DataFrame issue_instances: issues found in validation.
-        :param DataFrame all_rules_issue_locs: issue locations
-        :param list rules_broken: An empty list which is populated with the codes of the rules that trigger issues in the data during validation.
-        :param list la_rules_broken: An empty list which is populated with the list of LA rules that fail validation.
-        :param list rules_passed: An empty list of rules passed, populated with rules with no validation errors.
-        :returns: DataFrame of instances and locations of validation rule violations from data input via FE or CLI.
-        :rtype: DataFrame
-        :raises: Errors with rules that raise errors when validating data.
-        """
-
-        enum_data_files = enum_keys(self.data_files)
-        self.issue_instances = pd.DataFrame()
-        self.full_issue_df = pd.DataFrame(
-            columns=[
-                "tables_affected",
-                "columns_affected",
-                "ROW_ID",
-                "ERROR_ID",
-                "rule_code",
-                "rule_description",
-                "rule_type",
-                "la_level",
-                "LAchildID",
-            ]
-        )
-        self.rules_passed: list[str] = []
-
-        self.rules_broken: list[str] = []
-        self.rule_messages: list[str] = []
-        self.la_rules_broken: list[str] = []
-
-        registry = self.ruleset_registry
-
-        rules_to_run = self.get_rules_to_run(registry, selected_rules)
-        for rule in rules_to_run:
-            data_files = copy.deepcopy(enum_data_files)
-            ctx = RuleContext(rule)
-            try:
-                rule.func(data_files, ctx)
-            except Exception as e:
-                print(f"Error with rule {rule.code}: {type(e).__name__}, {e}")
-            self.process_issues(rule, ctx)
-
-        # df of all broken rule codes and related error messages.
-        child_level_rules = pd.DataFrame(
-            {"Rule code": self.rules_broken, "Rule Message": self.rule_messages}
-        )
-        # self.la_rules_broken is a list of issue_dfs, one per la-level rule that failed.
-        try:
-            self.la_rule_issues = pd.concat(self.la_rules_broken)
-        except:
-            # if la_rules_broken is still an empty list
-            self.la_rule_issues = pd.DataFrame()
+import copy
+import xml.etree.ElementTree as ET
+from typing import Optional
+
+import pandas as pd
+
+from cin_validator.ingress import XMLtoCSV
+from cin_validator.rule_engine import CINTable, RuleContext, RuleDefinition
+from cin_validator.utils import process_date_columns
+
+pd.options.mode.chained_assignment = None
+# Suppresses false-positive SettingWithCopyError when column types are changes in the include_issue_child function.
+# https://stackoverflow.com/questions/20625582/how-to-deal-with-settingwithcopywarning-in-pandas
+
+
+def enum_keys(dict_input: dict):
+    """
+    Convert keys of a dictionary to its corresponding CINTable format.
+    :param dict dict_input: dictionary of dataframes of CIN data
+    :return dict enumed_dict: same data content with keys replaced.
+    """
+    enumed_dict = {}
+    for enum_key in CINTable:
+        # if enum_key == CINTable.Header, then enum_key.name == Header
+        enumed_dict[enum_key] = dict_input[str(enum_key.name)]
+    return enumed_dict
+
+
+def convert_data(root: ET.Element):
+    """
+    Takes input data and processes it for validation.
+
+    This function takes input XML data, and uses ElementTree, and the custom class
+    XMLtoCSV to process the data into tables for validation.
+
+    :param XML root: root created by parsing the user's xml file.
+    :returns: dict of DataFrames - each representing a CIN table.
+    :rtype: Dictionary
+    """
+
+    # generate tables
+    data_files = XMLtoCSV(root)
+
+    # return tables
+    cin_tables = {
+        "Header": data_files.Header,
+        "ChildIdentifiers": data_files.ChildIdentifiers,
+        "ChildCharacteristics": data_files.ChildCharacteristics,
+        "ChildProtectionPlans": data_files.ChildProtectionPlans,
+        "CINdetails": data_files.CINdetails,
+        "CINplanDates": data_files.CINplanDates,
+        "Reviews": data_files.Reviews,
+        "Section47": data_files.Section47,
+        "Assessments": data_files.Assessments,
+        "AssessmentFactorsList": data_files.AssessmentFactorsList,
+        "Disabilities": data_files.Disabilities,
+    }
+    return cin_tables
+
+
+def process_data(cin_tables: dict):
+    """
+    formats date columns
+    :param dict cin_tables: data to be converted
+    :return dict cin_tables_dict: original dataframes where date columns have been formatted.
+    """
+
+    # format all date columns in tables
+    cin_tables_dict = {
+        name: process_date_columns(table) for name, table in cin_tables.items()
+    }
+
+    return cin_tables_dict
+
+
+def include_issue_child(issue_df: pd.DataFrame, cin_data: dict):
+    """
+    :param DataFrame issue_df: complete data about all issue locations.
+    :param dict cin_data: dictionary of dataframes generated when cin xml is converted to tabular format.
+    """
+
+    try:
+        la_level_issues = issue_df[issue_df["tables_affected"].isna()]
+    except:
+        # if no error locations were found, i.e issue_df doesn't exist, this allows an empty dataframe to be processed.
+        return issue_df
+
+    header_issues = issue_df[issue_df["tables_affected"] == "Header"]
+    tables_with_childid = [la_level_issues, header_issues]
+    for table in issue_df["tables_affected"].dropna().unique():
+        if table == "Header":
+            # the header table doesn't contain child id. It is like metadata
+            continue
+        table_df = issue_df[issue_df["tables_affected"] == table]
+
+        # get index values of the rows that fail.
+        # some ROW_ID values exist as ints and others as strs. Unify so that .unique() doesn't contain doubles.
+        table_rows = table_df["ROW_ID"].astype("int").unique()
+
+        # naming the index of the data allows it to be mapped back to the issue_df
+        table_data = cin_data[table]
+        table_data.index.name = "ROW_ID"
+        table_data.reset_index(inplace=True)
+        # select the data for the rows with appear in issue_df and get the child ids
+        linker_df = table_data.iloc[table_rows][["LAchildID", "ROW_ID"]]
+
+        # work around: ensure that columns from both sources have the same type to prevent merge error
+        table_df["ROW_ID"] = table_df["ROW_ID"].astype("int64")
+        linker_df["ROW_ID"] = linker_df["ROW_ID"].astype("int64")
+
+        if not linker_df.empty:
+            # if failing locations have been found, remove the dummy LAchildID column to make way for the real one.
+            table_df.drop(columns="LAchildID", inplace=True)
+
+        # map the child ids back to issue_df
+        table_df = table_df.merge(linker_df, on=["ROW_ID"], how="left")
+
+        # save the result
+        tables_with_childid.append(table_df)
+
+    # regenerate issue_df from its updated constituent tables
+    issue_df = pd.concat(tables_with_childid)
+
+    return issue_df
+
+
+def create_user_report(issue_df: pd.DataFrame, cin_data: dict):
+    """
+    A good report should tell the user what failed, where it failed and why it failed.
+    The report generated by this function contains table-column-value combinations to answer the former
+    and rule code-description combinations to answer the latter.
+
+    :param pd.DataFrame issue_df: in which child IDs have been added.
+    :param dict cin_data: dataframes of user's input data.
+    :return user_report: dataframe containing issue locations and specific values that fail in those locations.
+
+    """
+    try:
+        no_table = issue_df[issue_df["tables_affected"].isna()]
+    except:
+        # in the case where issue_df is empty, return an empty user report.
+        return pd.DataFrame()
+
+    reports = []
+    for table in issue_df["tables_affected"].dropna().unique():
+        table_issues = issue_df[issue_df["tables_affected"] == table]
+
+        table_reports = []
+        for column in table_issues["columns_affected"].unique():
+            only_column = table_issues[table_issues["columns_affected"] == column]
+            column_rows = only_column["ROW_ID"].unique().astype("int")
+
+            column_data = cin_data[table][column]
+            # fancy indexing. get all the values for a sequence of row positions in a column.
+            column_values = column_data[column_rows]
+            column_values.rename("value_flagged", inplace=True)
+            column_values.index.name = "ROW_ID"
+            values_df = column_values.reset_index()
+            values_df = values_df.assign(ROW_ID=values_df["ROW_ID"].astype("object"))
+
+            # work around: ensure that columns from both sources (user data and rule output) have the same type to prevent merge error
+            only_column["ROW_ID"] = only_column["ROW_ID"].astype("int64")
+            values_df["ROW_ID"] = values_df["ROW_ID"].astype("int64")
+            report_df = only_column.merge(values_df, on="ROW_ID")
+
+            table_reports.append(report_df)
+
+        reports.extend(table_reports)
+    # add in the la-level locations
+    reports.append(no_table)
+
+    # ensure that all required column names will be present in the result.
+    full_report_cols_df = pd.DataFrame(
+        columns=[
+            "ERROR_ID",
+            "LAchildID",
+            "rule_code",
+            "tables_affected",
+            "columns_affected",
+            "ROW_ID",
+            "value_flagged",
+            "rule_description",
+        ]
+    )
+    reports.append(full_report_cols_df)
+
+    full_report = pd.concat(reports, ignore_index=True)
+
+    # columns of interest are filtered and arranged in the desired order. values unified under str datatype.
+    user_report = full_report[
+        [
+            "ERROR_ID",
+            "LAchildID",
+            "rule_code",
+            "tables_affected",
+            "columns_affected",
+            "ROW_ID",
+            "value_flagged",
+            "rule_description",
+        ]
+    ]
+
+    def datetime_to_str(element):
+        if isinstance(element, pd.Timestamp):
+            # convert datetime elements to str date values
+            return str(element.strftime("%Y-%m-%d"))
+        elif isinstance(element, tuple):
+            # loop through tuples and convert each element accordingly. mostly in ERROR_ID column.
+            return tuple(map(datetime_to_str, element))
+        else:
+            # ensure all other elements are strings too.
+            return str(element)
+
+    user_report = user_report.applymap(datetime_to_str)
+
+    # Related issue locations should be displayed next to each other.
+    user_report.sort_values(
+        [
+            "LAchildID",
+            "ERROR_ID",
+            "tables_affected",
+            "columns_affected",
+        ],
+        inplace=True,
+        ignore_index=True,
+    )
+
+    user_report.drop_duplicates(
+        ["LAchildID", "rule_code", "columns_affected", "ROW_ID"], inplace=True
+    )
+
+    return user_report
+
+
+class CinValidator:
+    """
+    A class to contain the process of CIN validation. Generates error reports as dataframes.
+
+    :param any data_files: Data files for validation, either a DataContainerWrapper object, or a
+        dictionary of DataFrames.
+    :param dir ruleset: The directory containing the validation rules to be run according to the year in which they were published.
+    """
+
+    def __init__(
+        self,
+        data_files,
+        ruleset_registry,
+        selected_rules: Optional[list[str]] = None,
+    ) -> None:
+        """
+        Initialises CinValidator class.
+
+        Creates DataFrame containing error report, and allows selection of individual instances of error using ERROR_ID
+
+        :param list ruleset: The list of rules used in an individual validation session.
+            Refers to rules in particular subdirectories of the rules directory.
+        :param any data_files: The data extracted from input XML (or CSV) for validation.
+        :param str issue_id: Can be used to choose a particular instance of an error using ERROR_ID.
+        :param list selected_rules: array of rule codes (as strings) selected by the user. Determines what rules should be run.
+        :returns: DataFrame of error report which could be a filtered version if issue_id is input.
+        :rtype: DataFrame
+        """
+
+        self.data_files = data_files
+        self.ruleset_registry = ruleset_registry
+
+        # save independent version of data to be used in report.
+        raw_data = copy.deepcopy(self.data_files)
+
+        # run
+        self.create_issue_report_df(selected_rules)
+
+        # add child_id to issue location report.
+        self.full_issue_df: pd.DataFrame = include_issue_child(
+            self.full_issue_df, raw_data
+        )
+        self.user_report = create_user_report(self.full_issue_df, raw_data)
+
+        # regularise full_issue_df
+        self.full_issue_df.rename(columns={"ROW_ID": "row_id"}, inplace=True)
+        self.full_issue_df.rename(columns={"LAchildID": "child_id"}, inplace=True)
+        self.full_issue_df.drop(columns=["ERROR_ID"], inplace=True, errors="ignore")
+        self.full_issue_df.drop_duplicates(
+            ["child_id", "rule_code", "columns_affected", "row_id"], inplace=True
+        )
+        self.full_issue_df.reset_index(drop=True, inplace=True)
+
+        # remove header issues from main dataframe and transfer to no-child-id dataframe
+        header_issues = self.full_issue_df[
+            self.full_issue_df["tables_affected"] == "Header"
+        ]
+        self.full_issue_df = self.full_issue_df[
+            self.full_issue_df["tables_affected"] != "Header"
+        ]
+        # combine multichild issues
+        self.multichild_issues = pd.concat([header_issues, self.la_rule_issues])[
+            ["rule_code", "rule_description"]
+        ]
+
+    def get_rules_to_run(
+        self, registry, selected_rules: Optional[list[str]] = None
+    ) -> list[RuleDefinition]:
+        """
+        Filters rules to be run based on user's selection in the frontend.
+        :param Registry-class registry: record of all existing rules in rule pack
+        :param list selected_rules: array of rule codes as strings
+        """
+        if selected_rules:
+            rules_to_run = [
+                rule for _, rule in registry.items() if str(rule.code) in selected_rules
+            ]
+            return rules_to_run
+        else:
+            return registry.values()
+
+    def process_issues(self, rule: RuleDefinition, ctx: RuleContext):
+        """
+        process result of running a rule on the user's data.
+
+        :param RuleDefinition-class rule: the rule that was run on the data
+        :param RuleContext-object ctx: "manages state" per rule. contains updated issue_dfs if any were added when rule was run on the data.
+        :returns : None
+
+        """
+        issue_dfs_per_rule = pd.Series(
+            [
+                ctx.type_zero_issues,
+                ctx.type_one_issues,
+                ctx.type_two_issues,
+                ctx.type_three_issues,
+                ctx.la_level_issues,
+            ]
+        )
+        # error_df_lengths is a list of lengths of all elements in issue_dfs_per_rule respectively.
+        error_df_lengths = pd.Series([len(x) for x in issue_dfs_per_rule])
+        if error_df_lengths.max() == 0:
+            # if the rule didn't push to any of the issue accumulators, then it didn't find any issues in the file.
+            self.rules_passed.append(rule.code)
+        elif error_df_lengths.idxmax() == 4:
+            # If the maximum value is in position 4, this is a return level validation rule.
+            # It has no locations attached so it is only displayed in the rule descriptions.
+            self.la_rules_broken.append(issue_dfs_per_rule[4])
+        else:
+            # get the rule type based on which attribute had elements pushed to it (i.e non-zero length)
+            # its corresponding error_df can be found by issue_dfs_per_rule[ind]
+            ind = error_df_lengths.idxmax()
+
+            issue_dict = {
+                "code": rule.code,
+                "number": error_df_lengths[ind],
+                "type": ind,
+            }
+            issue_dict_df = pd.DataFrame([issue_dict])
+            self.issue_instances = pd.concat(
+                [self.issue_instances, issue_dict_df], ignore_index=True
+            )
+
+            # add the rule's code and description to it's error_df
+            issue_dfs_per_rule[ind]["rule_code"] = rule.code
+            issue_dfs_per_rule[ind]["rule_description"] = rule.message
+
+            # temporary: add rule type to track if all types are in df.
+            issue_dfs_per_rule[ind]["rule_type"] = ind
+
+            # combine this rule's error_df with the cummulative error_df
+            self.full_issue_df = pd.concat(
+                [self.full_issue_df, issue_dfs_per_rule[ind]],
+                ignore_index=True,
+            )
+
+            # Elements of the rule_descriptors df to explain error codes
+            self.rules_broken.append(rule.code)
+            self.rule_messages.append(f"{str(rule.code)} - {rule.message}")
+
+    def create_issue_report_df(self, selected_rules: Optional[list[str]] = None):
+        """
+        Creates report of errors found when validating CIN data input to
+        the tool.
+
+        This function takes the errors/rule violations reported by individual validation rule functions,
+        including table, field, and index locations of errors. It is important that it uses deepcopy
+        on the data per rule as some rules alter original data when only a standard .copy() function
+        is used. It runs through every rule in the registry and:
+
+        >Creates lists of rules passed, broken, and relevant messages.
+        >Returns a dataframe of issue instances for broken validation rules.
+        >Returns a dictionary of all rules codes and relevant messages.
+
+        :param DataFrame issue_instances: issues found in validation.
+        :param DataFrame all_rules_issue_locs: issue locations
+        :param list rules_broken: An empty list which is populated with the codes of the rules that trigger issues in the data during validation.
+        :param list la_rules_broken: An empty list which is populated with the list of LA rules that fail validation.
+        :param list rules_passed: An empty list of rules passed, populated with rules with no validation errors.
+        :returns: DataFrame of instances and locations of validation rule violations from data input via FE or CLI.
+        :rtype: DataFrame
+        :raises: Errors with rules that raise errors when validating data.
+        """
+
+        enum_data_files = enum_keys(self.data_files)
+        self.issue_instances = pd.DataFrame()
+        self.full_issue_df = pd.DataFrame(
+            columns=[
+                "tables_affected",
+                "columns_affected",
+                "ROW_ID",
+                "ERROR_ID",
+                "rule_code",
+                "rule_description",
+                "rule_type",
+                "la_level",
+                "LAchildID",
+            ]
+        )
+        self.rules_passed: list[str] = []
+
+        self.rules_broken: list[str] = []
+        self.rule_messages: list[str] = []
+        self.la_rules_broken: list[str] = []
+
+        registry = self.ruleset_registry
+
+        rules_to_run = self.get_rules_to_run(registry, selected_rules)
+        for rule in rules_to_run:
+            data_files = copy.deepcopy(enum_data_files)
+            ctx = RuleContext(rule)
+            try:
+                rule.func(data_files, ctx)
+            except Exception as e:
+                print(f"Error with rule {rule.code}: {type(e).__name__}, {e}")
+            self.process_issues(rule, ctx)
+
+        # df of all broken rule codes and related error messages.
+        child_level_rules = pd.DataFrame(
+            {"Rule code": self.rules_broken, "Rule Message": self.rule_messages}
+        )
+        # self.la_rules_broken is a list of issue_dfs, one per la-level rule that failed.
+        try:
+            self.la_rule_issues = pd.concat(self.la_rules_broken)
+        except:
+            # if la_rules_broken is still an empty list
+            self.la_rule_issues = pd.DataFrame()
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/england_holidates.py` & `csc_validator_be_cin-0.1.4/cin_validator/england_holidates.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,39 +1,39 @@
-import datetime
-
-england_holidates = [
-    datetime.date(2022, 1, 3),
-    datetime.date(2022, 4, 15),
-    datetime.date(2022, 4, 18),
-    datetime.date(2022, 5, 2),
-    datetime.date(2022, 6, 2),
-    datetime.date(2022, 6, 3),
-    datetime.date(2022, 8, 29),
-    datetime.date(2022, 9, 19),
-    datetime.date(2022, 12, 26),
-    datetime.date(2022, 12, 27),
-    datetime.date(2023, 1, 2),
-    datetime.date(2023, 4, 7),
-    datetime.date(2023, 4, 10),
-    datetime.date(2023, 5, 1),
-    datetime.date(2023, 5, 8),
-    datetime.date(2023, 5, 29),
-    datetime.date(2023, 8, 28),
-    datetime.date(2023, 12, 25),
-    datetime.date(2023, 12, 26),
-    datetime.date(2024, 1, 1),
-    datetime.date(2024, 3, 29),
-    datetime.date(2024, 4, 1),
-    datetime.date(2024, 5, 6),
-    datetime.date(2024, 5, 27),
-    datetime.date(2024, 8, 26),
-    datetime.date(2024, 12, 25),
-    datetime.date(2024, 12, 26),
-    datetime.date(2025, 1, 1),
-    datetime.date(2025, 4, 18),
-    datetime.date(2025, 4, 21),
-    datetime.date(2025, 5, 5),
-    datetime.date(2025, 5, 26),
-    datetime.date(2025, 8, 25),
-    datetime.date(2025, 12, 25),
-    datetime.date(2025, 12, 26),
-]
+import datetime
+
+england_holidates = [
+    datetime.date(2022, 1, 3),
+    datetime.date(2022, 4, 15),
+    datetime.date(2022, 4, 18),
+    datetime.date(2022, 5, 2),
+    datetime.date(2022, 6, 2),
+    datetime.date(2022, 6, 3),
+    datetime.date(2022, 8, 29),
+    datetime.date(2022, 9, 19),
+    datetime.date(2022, 12, 26),
+    datetime.date(2022, 12, 27),
+    datetime.date(2023, 1, 2),
+    datetime.date(2023, 4, 7),
+    datetime.date(2023, 4, 10),
+    datetime.date(2023, 5, 1),
+    datetime.date(2023, 5, 8),
+    datetime.date(2023, 5, 29),
+    datetime.date(2023, 8, 28),
+    datetime.date(2023, 12, 25),
+    datetime.date(2023, 12, 26),
+    datetime.date(2024, 1, 1),
+    datetime.date(2024, 3, 29),
+    datetime.date(2024, 4, 1),
+    datetime.date(2024, 5, 6),
+    datetime.date(2024, 5, 27),
+    datetime.date(2024, 8, 26),
+    datetime.date(2024, 12, 25),
+    datetime.date(2024, 12, 26),
+    datetime.date(2025, 1, 1),
+    datetime.date(2025, 4, 18),
+    datetime.date(2025, 4, 21),
+    datetime.date(2025, 5, 5),
+    datetime.date(2025, 5, 26),
+    datetime.date(2025, 8, 25),
+    datetime.date(2025, 12, 25),
+    datetime.date(2025, 12, 26),
+]
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/ingress.py` & `csc_validator_be_cin-0.1.4/cin_validator/ingress.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,471 +1,501 @@
-import pandas as pd
-
-from .utils import get_values
-
-
-# initialize all data sets as empty dataframes with columns names
-# whenever a child is created, it should add a row to each table where it exists.
-# tables should be attributes of a class that are accessible to the methods in create_child.
-class XMLtoCSV:
-    """
-    A class to convert data input as XML into CSV/DataFrame format for validation. Uses
-    ElementTree to parse the XML for each child, adding their data to relevant fields and tables.
-
-    :param DataFrame Header: DataFrame of fields for the Header table for validation,
-        to be populated with children's data from XML input.
-    :param DataFrame ChildIdentifiers: DataFrame of fields for the ChildIdentifiers table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame ChildCharacteristics: DataFrame of fields for the ChildCharacterisitcs table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame Disabilities: DataFrame of fields for the Disabilities table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame CINdetails: DataFrame of fields for the CINdetails table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame Assessments: DataFrame of fields for the Assessments table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame CINplanDates: DataFrame of fields for the CINplanDates table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame Section47: DataFrame of fields for the Section47 table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame ChildProtectionPlans: DataFrame of fields for the ChildProtectionPlans table for validation.
-        to be populated with children's data from XML input.
-    :param DataFrame Reviews: DataFrame of fields for the Reviews table for validation.
-        to be populated with children's data from XML input.
-    :param list id_cols: List of columns containing IDs that can be used to merge tables.
-    """
-
-    # define column names from CINTable object.
-    Header = pd.DataFrame(
-        columns=[
-            "Collection",
-            "Year",
-            "ReferenceDate",
-            "SourceLevel",
-            "LEA",
-            "SoftwareCode",
-            "Release",
-            "SerialNo",
-            "DateTime",
-        ]
-    )
-    ChildIdentifiers = pd.DataFrame(
-        columns=[
-            "LAchildID",
-            "UPN",
-            "FormerUPN",
-            "UPNunknown",
-            "PersonBirthDate",
-            "ExpectedPersonBirthDate",
-            "GenderCurrent",
-            "PersonDeathDate",
-        ]
-    )
-    ChildCharacteristics = pd.DataFrame(
-        columns=[
-            "LAchildID",
-            "Ethnicity",
-        ]
-    )
-    Disabilities = pd.DataFrame(columns=["LAchildID", "Disability"])
-
-    CINdetails = pd.DataFrame(
-        columns=[
-            "LAchildID",
-            "CINdetailsID",
-            "CINreferralDate",
-            "ReferralSource",
-            "PrimaryNeedCode",
-            "CINclosureDate",
-            "ReasonForClosure",
-            "DateOfInitialCPC",
-            "ReferralNFA",
-        ]
-    )
-    Assessments = pd.DataFrame(
-        columns=[
-            "LAchildID",
-            "CINdetailsID",
-            "AssessmentActualStartDate",
-            "AssessmentInternalReviewDate",
-            "AssessmentAuthorisationDate",
-            "AssessmentFactors",
-        ]
-    )
-    CINplanDates = pd.DataFrame(
-        columns=["LAchildID", "CINdetailsID", "CINPlanStartDate", "CINPlanEndDate"]
-    )
-    Section47 = pd.DataFrame(
-        columns=[
-            "LAchildID",
-            "CINdetailsID",
-            "S47ActualStartDate",
-            "InitialCPCtarget",
-            "DateOfInitialCPC",
-            "ICPCnotRequired",
-        ]
-    )
-    ChildProtectionPlans = pd.DataFrame(
-        columns=[
-            "LAchildID",
-            "CINdetailsID",
-            "CPPID",
-            "CPPstartDate",
-            "CPPendDate",
-            "InitialCategoryOfAbuse",
-            "LatestCategoryOfAbuse",
-            "NumberOfPreviousCPP",
-        ]
-    )
-    Reviews = pd.DataFrame(
-        columns=["LAchildID", "CINdetailsID", "CPPID", "CPPreviewDate"]
-    )
-
-    id_cols = ["LAchildID", "CINdetailsID", "CPPID"]
-
-    def __init__(self, root):
-        """
-        Initialises XMLtoCSV class, creates header, and iterates through input XML for every Child field
-        in the Children field.
-
-        :param xml root: root of the CIN XML data
-        :returns: Generates 10 dataframes containing the child info from the CIN XML fed into it.
-        """
-
-        header = root.find("Header")
-        self.Header = self.create_Header(header)
-
-        children = root.find("Children")
-        for child in children.findall("Child"):
-            self.create_child(child)
-
-    # for each table, column names should attempt to find their value in the child.
-    # if not found, they should assign themselves to NaN
-
-    def create_child(self, child):
-        """
-        For every child, use class methods to extract relevant fields from
-        input XML and append its data to appropriate DataFrames.
-        """
-
-        # at the start of every child, reset the value of LAchildID
-        self.LAchildID = None
-
-        self.create_ChildIdentifiers(child)
-        # LAchildID has been created. It can be used in the functions below.
-        self.create_ChildCharacteristics(child)
-
-        # CINdetailsID needed
-        self.create_CINdetails(child)
-
-        # CINdetails and CPPID needed
-        self.create_ChildProtectionPlans(child)
-        self.create_Reviews(child)
-
-    # TODO get column names from the CINTable object instead of writing them out as strings?
-    def create_Header(self, header):
-        """Extracts header data from XML, run once as only one row is needed for the header.
-        Exists once per census return.
-
-        :param object header: The element with the "Header" tag in the input XML
-        :returns: A DataFrame of the Header table extracted from input XML.
-        :rtype: DataFrame
-        """
-
-        header_dict = {}
-
-        collection_details = header.find("CollectionDetails")
-        collection_elements = ["Collection", "Year", "ReferenceDate"]
-        header_dict = get_values(collection_elements, header_dict, collection_details)
-
-        source = header.find("Source")
-        source_elements = [
-            "SourceLevel",
-            "LEA",
-            "SoftwareCode",
-            "Release",
-            "SerialNo",
-            "DateTime",
-        ]
-        header_dict = get_values(source_elements, header_dict, source)
-
-        header_df = pd.DataFrame.from_dict([header_dict])
-        return header_df
-
-    def create_ChildIdentifiers(self, child):
-        """
-        Populates the ChildIdentifiers table. One ChildIdentifiers block exists per child in CIN XML
-
-        :param xml child: 'child' element from the XML input. Each contains the full information per child.
-        :returns: DataFrame of data for an individual child for the ChildIdentifiers Table.
-        :rtype: DataFrame
-        """
-
-        # pick out the values of relevant columns
-        # add to the global attribute
-        identifiers_dict = {}
-
-        identifiers = child.find("ChildIdentifiers")
-        elements = self.ChildIdentifiers.columns
-        identifiers_dict = get_values(elements, identifiers_dict, identifiers)
-
-        self.LAchildID = identifiers_dict.get("LAchildID", pd.NA)
-
-        identifiers_df = pd.DataFrame.from_dict([identifiers_dict])
-        self.ChildIdentifiers = pd.concat(
-            [self.ChildIdentifiers, identifiers_df], ignore_index=True
-        )
-
-    def create_ChildCharacteristics(self, child):
-        """Populates the ChildCharacteristics table. One ChildCharacteristics block exists per child in CIN XML
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the ChildCharacteristics Table.
-        :rtype: DataFrame
-        """
-        # assign LAChild ID
-        characteristics_dict = {"LAchildID": self.LAchildID}
-
-        characteristics = child.find("ChildCharacteristics")
-        columns = self.ChildCharacteristics.columns
-        # select only columns whose values typically exist in this xml block.
-        # remove id_cols which tend to come from other blocks or get generated at runtime.
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        characteristics_dict = get_values(
-            elements, characteristics_dict, characteristics
-        )
-
-        characteristics_df = pd.DataFrame.from_dict([characteristics_dict])
-        self.ChildCharacteristics = pd.concat(
-            [self.ChildCharacteristics, characteristics_df], ignore_index=True
-        )
-
-        # The disabilities block for a child is found within a ChildCharacteristics block.
-        self.create_Disabilities(characteristics)
-
-    def create_Disabilities(self, characteristics):
-        """
-        Populates Disabilites table
-        """
-        disabilities_list = []
-        columns = self.Disabilities.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-        # get the Disabilities block
-        disabilities = characteristics.find("Disabilities")
-        if disabilities is not None:
-            # Only run this if a "Disabilities" xml block has been found
-            for disability in disabilities:
-                disability_dict = {
-                    "LAchildID": self.LAchildID,
-                }
-                disability_dict = get_values(elements, disability_dict, disability)
-                disability_dict["Disability"] = disability.text
-                disabilities_list.append(disability_dict)
-
-            disabilities_df = pd.DataFrame(disabilities_list)
-            self.Disabilities = pd.concat(
-                [self.Disabilities, disabilities_df], ignore_index=True
-            )
-
-    # CINdetailsID needed
-    def create_CINdetails(self, child):
-        """Populates the CINdetails table. Multiple CIN details blocks can exist in one child.
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the CINdetails Table.
-        :rtype: DataFrame
-        """
-
-        cin_details_list = []
-        columns = self.CINdetails.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        # TODO should we imitate DfE generator where the ID count for the first child is 1?
-        self.CINdetailsID = 0
-
-        cin_details = child.findall("CINdetails")
-        for cin_detail in cin_details:
-            self.CINdetailsID += 1
-            cin_detail_dict = {
-                "LAchildID": self.LAchildID,
-                "CINdetailsID": self.CINdetailsID,
-            }
-
-            cin_detail_dict = get_values(elements, cin_detail_dict, cin_detail)
-            cin_details_list.append(cin_detail_dict)
-
-            # functions that should use the CINdetailsID before it is incremented.
-            self.create_Assessments(cin_detail)
-            self.create_CINplanDates(cin_detail)
-            self.create_Section47(cin_detail)
-            self.create_ChildProtectionPlans(cin_detail)
-
-        cin_details_df = pd.DataFrame(cin_details_list)
-        self.CINdetails = pd.concat(
-            [self.CINdetails, cin_details_df], ignore_index=True
-        )
-
-    def create_Assessments(self, cin_detail):
-        """Populates the assessments table. Multiple Assessments blocks can exist in one CINdetails block.
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the Assessments Table.
-        :rtype: DataFrame
-        """
-
-        def assessment_block_maker(assmnt):
-            assessment_dict = {
-                "LAchildID": self.LAchildID,
-                "CINdetailsID": self.CINdetailsID,
-            }
-            assessment_dict = get_values(elements, assessment_dict, assessment)
-            # the get_values function will not find AssessmentFactors on that level so it'll assign it to NaN
-            assessment_dict["AssessmentFactors"] = assmnt.text
-            assessments_list.append(assessment_dict)
-            return assessment_dict
-
-        assessments_list = []
-        columns = self.Assessments.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        assessments = cin_detail.findall("Assessments")
-        for assessment in assessments:
-            # all the assessment descriptors repeat to create a row for each assessment factor.
-            assessment_factors = assessment.find("FactorsIdentifiedAtAssessment")
-            if assessment_factors is not None:
-                # if statement handles the non-iterable NoneType that .find produces if the element is not present.
-                for factor in assessment_factors:
-                    assessment_block_maker(factor)
-
-            # else needed to build blocks in instances where assessments aren't completed which means there's no assessment factors to build with.
-            else:
-                for assessment in assessments:
-                    assessment_block_maker(assessment)
-
-        assessments_df = pd.DataFrame(assessments_list)
-        self.Assessments = pd.concat(
-            [self.Assessments, assessments_df], ignore_index=True
-        )
-
-    def create_CINplanDates(self, cin_detail):
-        """
-        Populates the CINplanDates table. Multiple CINplanDates blocks can exist in one CINdetails block.
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the CINplanDates Table.
-        :rtype: DataFrame
-        """
-
-        dates_list = []
-        columns = self.CINplanDates.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        dates = cin_detail.findall("CINPlanDates")
-        for date in dates:
-            date_dict = {
-                "LAchildID": self.LAchildID,
-                "CINdetailsID": self.CINdetailsID,
-            }
-            date_dict = get_values(elements, date_dict, date)
-            dates_list.append(date_dict)
-
-        dates_df = pd.DataFrame(dates_list)
-        self.CINplanDates = pd.concat([self.CINplanDates, dates_df], ignore_index=True)
-
-    def create_Section47(self, cin_detail):
-        """
-        Populates the Section47 table. Multiple Section47 blocks can exist in one CINdetails block.
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the Section47 Table.
-        :rtype: DataFrame
-        """
-
-        sections_list = []
-        columns = self.Section47.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        sections = cin_detail.findall("Section47")
-        for section in sections:
-            section_dict = {
-                "LAchildID": self.LAchildID,
-                "CINdetailsID": self.CINdetailsID,
-            }
-            section_dict = get_values(elements, section_dict, section)
-            sections_list.append(section_dict)
-
-        sections_df = pd.DataFrame(sections_list)
-        self.Section47 = pd.concat([self.Section47, sections_df], ignore_index=True)
-
-    # CINdetails and CPPID needed
-    def create_ChildProtectionPlans(self, cin_detail):
-        """
-        Populates the ChildProtectionPlans table. Multiple ChildProtectionPlans blocks can exist in one CINdetails block.
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the ChildProtectionPlans Table.
-        :rtype: DataFrame
-        """
-
-        plans_list = []
-        columns = self.ChildProtectionPlans.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        # imitate DfE generator where the first counted thing starts from 1.
-        self.CPPID = 0
-
-        plans = cin_detail.findall("ChildProtectionPlans")
-        for plan in plans:
-            self.CPPID += 1
-            plan_dict = {
-                "LAchildID": self.LAchildID,
-                "CINdetailsID": self.CINdetailsID,
-                "CPPID": self.CPPID,
-            }
-            plan_dict = get_values(elements, plan_dict, plan)
-            plans_list.append(plan_dict)
-
-            # functions that should use CPPID before it is incremented
-            self.create_Reviews(plan)
-
-        plans_df = pd.DataFrame(plans_list)
-        self.ChildProtectionPlans = pd.concat(
-            [self.ChildProtectionPlans, plans_df], ignore_index=True
-        )
-
-    def create_Reviews(self, plan):
-        """
-        Populates the ChildIdentifiers table. Multiple Reviews blocks can exist in one Reviews block.
-
-        :param xml child: 'child' element from the XML input
-        :returns: DataFrame of data for an individual child for the Reviews Table.
-        :rtype: DataFrame
-        """
-
-        reviews_list = []
-        columns = self.Reviews.columns
-        elements = list(set(columns).difference(set(self.id_cols)))
-
-        reviews = plan.findall("Reviews[CPPreviewDate]")
-        for review in reviews:
-            review_dict = {
-                "LAchildID": self.LAchildID,
-                "CINdetailsID": self.CINdetailsID,
-                "CPPID": self.CPPID,
-            }
-            review_dict = get_values(elements, review_dict, review)
-
-            reviews_list.append(review_dict)
-
-        reviews_df = pd.DataFrame(reviews_list)
-        self.Reviews = pd.concat([self.Reviews, reviews_df], ignore_index=True)
-
-
-"""
-Sidenote: Fields absent from the fake_CIN_data.xml
-- Assessments
-- CINPlanDates
-- Section47
-- ChildProtectionPlans
-- Reviews
-"""
+import pandas as pd
+
+from .utils import get_values
+
+
+# initialize all data sets as empty dataframes with columns names
+# whenever a child is created, it should add a row to each table where it exists.
+# tables should be attributes of a class that are accessible to the methods in create_child.
+class XMLtoCSV:
+    """
+    A class to convert data input as XML into CSV/DataFrame format for validation. Uses
+    ElementTree to parse the XML for each child, adding their data to relevant fields and tables.
+
+    :param DataFrame Header: DataFrame of fields for the Header table for validation,
+        to be populated with children's data from XML input.
+    :param DataFrame ChildIdentifiers: DataFrame of fields for the ChildIdentifiers table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame ChildCharacteristics: DataFrame of fields for the ChildCharacterisitcs table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame Disabilities: DataFrame of fields for the Disabilities table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame CINdetails: DataFrame of fields for the CINdetails table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame Assessments: DataFrame of fields for the Assessments table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame CINplanDates: DataFrame of fields for the CINplanDates table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame Section47: DataFrame of fields for the Section47 table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame ChildProtectionPlans: DataFrame of fields for the ChildProtectionPlans table for validation.
+        to be populated with children's data from XML input.
+    :param DataFrame Reviews: DataFrame of fields for the Reviews table for validation.
+        to be populated with children's data from XML input.
+    :param list id_cols: List of columns containing IDs that can be used to merge tables.
+    """
+
+    # define column names from CINTable object.
+    Header = pd.DataFrame(
+        columns=[
+            "Collection",
+            "Year",
+            "ReferenceDate",
+            "SourceLevel",
+            "LEA",
+            "SoftwareCode",
+            "Release",
+            "SerialNo",
+            "DateTime",
+        ]
+    )
+    ChildIdentifiers = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "UPN",
+            "FormerUPN",
+            "UPNunknown",
+            "PersonBirthDate",
+            "ExpectedPersonBirthDate",
+            "GenderCurrent",
+            "Sex",
+            "PersonDeathDate",
+        ]
+    )
+    ChildCharacteristics = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "Ethnicity",
+        ]
+    )
+    Disabilities = pd.DataFrame(columns=["LAchildID", "Disability"])
+
+    CINdetails = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "CINdetailsID",
+            "CINreferralDate",
+            "ReferralSource",
+            "PrimaryNeedCode",
+            "CINclosureDate",
+            "ReasonForClosure",
+            "DateOfInitialCPC",
+            "ReferralNFA",
+        ]
+    )
+    Assessments = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "CINdetailsID",
+            "AssessmentID",
+            "AssessmentActualStartDate",
+            "AssessmentInternalReviewDate",
+            "AssessmentAuthorisationDate",
+            "AssessmentFactors",
+        ]
+    )
+    AssessmentFactorsList = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "CINdetailsID",
+            "AssessmentID",
+            "AssessmentFactor",
+        ]
+    )
+    CINplanDates = pd.DataFrame(
+        columns=["LAchildID", "CINdetailsID", "CINPlanStartDate", "CINPlanEndDate"]
+    )
+    Section47 = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "CINdetailsID",
+            "S47ActualStartDate",
+            "InitialCPCtarget",
+            "DateOfInitialCPC",
+            "ICPCnotRequired",
+        ]
+    )
+    ChildProtectionPlans = pd.DataFrame(
+        columns=[
+            "LAchildID",
+            "CINdetailsID",
+            "CPPID",
+            "CPPstartDate",
+            "CPPendDate",
+            "InitialCategoryOfAbuse",
+            "LatestCategoryOfAbuse",
+            "NumberOfPreviousCPP",
+        ]
+    )
+    Reviews = pd.DataFrame(
+        columns=["LAchildID", "CINdetailsID", "CPPID", "CPPreviewDate"]
+    )
+
+    id_cols = ["LAchildID", "CINdetailsID", "AssessmentID", "CPPID"]
+
+    def __init__(self, root):
+        """
+        Initialises XMLtoCSV class, creates header, and iterates through input XML for every Child field
+        in the Children field.
+
+        :param xml root: root of the CIN XML data
+        :returns: Generates 10 dataframes containing the child info from the CIN XML fed into it.
+        """
+
+        header = root.find("Header")
+        self.Header = self.create_Header(header)
+
+        children = root.find("Children")
+        for child in children.findall("Child"):
+            self.create_child(child)
+
+    # for each table, column names should attempt to find their value in the child.
+    # if not found, they should assign themselves to NaN
+
+    def create_child(self, child):
+        """
+        For every child, use class methods to extract relevant fields from
+        input XML and append its data to appropriate DataFrames.
+        """
+
+        # at the start of every child, reset the value of LAchildID
+        self.LAchildID = None
+
+        self.create_ChildIdentifiers(child)
+        # LAchildID has been created. It can be used in the functions below.
+        self.create_ChildCharacteristics(child)
+
+        # CINdetailsID needed
+        self.create_CINdetails(child)
+
+        # CINdetails and CPPID needed
+        self.create_ChildProtectionPlans(child)
+        self.create_Reviews(child)
+
+    # TODO get column names from the CINTable object instead of writing them out as strings?
+    def create_Header(self, header):
+        """Extracts header data from XML, run once as only one row is needed for the header.
+        Exists once per census return.
+
+        :param object header: The element with the "Header" tag in the input XML
+        :returns: A DataFrame of the Header table extracted from input XML.
+        :rtype: DataFrame
+        """
+
+        header_dict = {}
+
+        collection_details = header.find("CollectionDetails")
+        collection_elements = ["Collection", "Year", "ReferenceDate"]
+        header_dict = get_values(collection_elements, header_dict, collection_details)
+
+        source = header.find("Source")
+        source_elements = [
+            "SourceLevel",
+            "LEA",
+            "SoftwareCode",
+            "Release",
+            "SerialNo",
+            "DateTime",
+        ]
+        header_dict = get_values(source_elements, header_dict, source)
+
+        header_df = pd.DataFrame.from_dict([header_dict])
+        return header_df
+
+    def create_ChildIdentifiers(self, child):
+        """
+        Populates the ChildIdentifiers table. One ChildIdentifiers block exists per child in CIN XML
+
+        :param xml child: 'child' element from the XML input. Each contains the full information per child.
+        :returns: DataFrame of data for an individual child for the ChildIdentifiers Table.
+        :rtype: DataFrame
+        """
+
+        # pick out the values of relevant columns
+        # add to the global attribute
+        identifiers_dict = {}
+
+        identifiers = child.find("ChildIdentifiers")
+        elements = self.ChildIdentifiers.columns
+        identifiers_dict = get_values(elements, identifiers_dict, identifiers)
+
+        self.LAchildID = identifiers_dict.get("LAchildID", pd.NA)
+
+        identifiers_df = pd.DataFrame.from_dict([identifiers_dict])
+        self.ChildIdentifiers = pd.concat(
+            [self.ChildIdentifiers, identifiers_df], ignore_index=True
+        )
+
+    def create_ChildCharacteristics(self, child):
+        """Populates the ChildCharacteristics table. One ChildCharacteristics block exists per child in CIN XML
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the ChildCharacteristics Table.
+        :rtype: DataFrame
+        """
+        # assign LAChild ID
+        characteristics_dict = {"LAchildID": self.LAchildID}
+
+        characteristics = child.find("ChildCharacteristics")
+        columns = self.ChildCharacteristics.columns
+        # select only columns whose values typically exist in this xml block.
+        # remove id_cols which tend to come from other blocks or get generated at runtime.
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        characteristics_dict = get_values(
+            elements, characteristics_dict, characteristics
+        )
+
+        characteristics_df = pd.DataFrame.from_dict([characteristics_dict])
+        self.ChildCharacteristics = pd.concat(
+            [self.ChildCharacteristics, characteristics_df], ignore_index=True
+        )
+
+        # The disabilities block for a child is found within a ChildCharacteristics block.
+        self.create_Disabilities(characteristics)
+
+    def create_Disabilities(self, characteristics):
+        """
+        Populates Disabilites table
+        """
+        disabilities_list = []
+        columns = self.Disabilities.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+        # get the Disabilities block
+        disabilities = characteristics.find("Disabilities")
+        if disabilities is not None:
+            # Only run this if a "Disabilities" xml block has been found
+            for disability in disabilities:
+                disability_dict = {
+                    "LAchildID": self.LAchildID,
+                }
+                disability_dict = get_values(elements, disability_dict, disability)
+                disability_dict["Disability"] = disability.text
+                disabilities_list.append(disability_dict)
+
+            disabilities_df = pd.DataFrame(disabilities_list)
+            self.Disabilities = pd.concat(
+                [self.Disabilities, disabilities_df], ignore_index=True
+            )
+
+    # CINdetailsID needed
+    def create_CINdetails(self, child):
+        """Populates the CINdetails table. Multiple CIN details blocks can exist in one child.
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the CINdetails Table.
+        :rtype: DataFrame
+        """
+
+        cin_details_list = []
+        columns = self.CINdetails.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        # TODO should we imitate DfE generator where the ID count for the first child is 1?
+        self.CINdetailsID = 0
+
+        cin_details = child.findall("CINdetails")
+        for cin_detail in cin_details:
+            self.CINdetailsID += 1
+            cin_detail_dict = {
+                "LAchildID": self.LAchildID,
+                "CINdetailsID": self.CINdetailsID,
+            }
+
+            cin_detail_dict = get_values(elements, cin_detail_dict, cin_detail)
+            cin_details_list.append(cin_detail_dict)
+
+            # functions that should use the CINdetailsID before it is incremented.
+            self.create_Assessments(cin_detail)
+            self.create_CINplanDates(cin_detail)
+            self.create_Section47(cin_detail)
+            self.create_ChildProtectionPlans(cin_detail)
+
+        cin_details_df = pd.DataFrame(cin_details_list)
+        self.CINdetails = pd.concat(
+            [self.CINdetails, cin_details_df], ignore_index=True
+        )
+
+    def create_Assessments(self, cin_detail):
+        """Populates the assessments table. Multiple Assessments blocks can exist in one CINdetails block.
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the Assessments Table.
+        :rtype: DataFrame
+        """
+
+        assessments_list = []
+        columns = self.Assessments.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        self.AssessmentID = 0
+        assessments = cin_detail.findall("Assessments")
+
+        for assessment in assessments:
+            self.AssessmentID += 1
+            assessment_dict = {
+                "LAchildID": self.LAchildID,
+                "CINdetailsID": self.CINdetailsID,
+                "AssessmentID": self.AssessmentID,
+            }
+
+            assessment_dict = get_values(elements, assessment_dict, assessment)
+
+            # the get_values function will not find AssessmentFactors on that level so we retrieve these separately.
+            assessment_factors = assessment.find("FactorsIdentifiedAtAssessment")
+            assessment_factors_list = []
+            assessment_columns = self.AssessmentFactorsList.columns
+            assessment_elements = list(
+                set(assessment_columns).difference(set(self.id_cols))
+            )
+
+            if assessment_factors is not None:
+                # if statement handles the non-iterable NoneType that .find produces if the element is not present.
+                for factor in assessment_factors:
+                    assessment_factors_dict = {
+                        "LAchildID": self.LAchildID,
+                        "CINdetailsID": self.CINdetailsID,
+                        "AssessmentID": self.AssessmentID,
+                    }
+                    assessment_factors_dict = get_values(
+                        assessment_elements, assessment_factors_dict, factor
+                    )
+                    assessment_factors_dict["AssessmentFactor"] = factor.text
+                    assessment_factors_list.append(assessment_factors_dict)
+                assessment_factors_df = pd.DataFrame(assessment_factors_list)
+                self.AssessmentFactorsList = pd.concat(
+                    [self.AssessmentFactorsList, assessment_factors_df],
+                    ignore_index=True,
+                )
+                assessment_dict["AssessmentFactors"] = assessment_factors_df[
+                    "AssessmentFactor"
+                ].tolist()
+
+            assessments_list.append(assessment_dict)
+
+        assessments_df = pd.DataFrame(assessments_list)
+        self.Assessments = pd.concat(
+            [self.Assessments, assessments_df], ignore_index=True
+        )
+
+    def create_CINplanDates(self, cin_detail):
+        """
+        Populates the CINplanDates table. Multiple CINplanDates blocks can exist in one CINdetails block.
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the CINplanDates Table.
+        :rtype: DataFrame
+        """
+
+        dates_list = []
+        columns = self.CINplanDates.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        dates = cin_detail.findall("CINPlanDates")
+        for date in dates:
+            date_dict = {
+                "LAchildID": self.LAchildID,
+                "CINdetailsID": self.CINdetailsID,
+            }
+            date_dict = get_values(elements, date_dict, date)
+            dates_list.append(date_dict)
+
+        dates_df = pd.DataFrame(dates_list)
+        self.CINplanDates = pd.concat([self.CINplanDates, dates_df], ignore_index=True)
+
+    def create_Section47(self, cin_detail):
+        """
+        Populates the Section47 table. Multiple Section47 blocks can exist in one CINdetails block.
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the Section47 Table.
+        :rtype: DataFrame
+        """
+
+        sections_list = []
+        columns = self.Section47.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        sections = cin_detail.findall("Section47")
+        for section in sections:
+            section_dict = {
+                "LAchildID": self.LAchildID,
+                "CINdetailsID": self.CINdetailsID,
+            }
+            section_dict = get_values(elements, section_dict, section)
+            sections_list.append(section_dict)
+
+        sections_df = pd.DataFrame(sections_list)
+        self.Section47 = pd.concat([self.Section47, sections_df], ignore_index=True)
+
+    # CINdetails and CPPID needed
+    def create_ChildProtectionPlans(self, cin_detail):
+        """
+        Populates the ChildProtectionPlans table. Multiple ChildProtectionPlans blocks can exist in one CINdetails block.
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the ChildProtectionPlans Table.
+        :rtype: DataFrame
+        """
+
+        plans_list = []
+        columns = self.ChildProtectionPlans.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        # imitate DfE generator where the first counted thing starts from 1.
+        self.CPPID = 0
+
+        plans = cin_detail.findall("ChildProtectionPlans")
+        for plan in plans:
+            self.CPPID += 1
+            plan_dict = {
+                "LAchildID": self.LAchildID,
+                "CINdetailsID": self.CINdetailsID,
+                "CPPID": self.CPPID,
+            }
+            plan_dict = get_values(elements, plan_dict, plan)
+            plans_list.append(plan_dict)
+
+            # functions that should use CPPID before it is incremented
+            self.create_Reviews(plan)
+
+        plans_df = pd.DataFrame(plans_list)
+        self.ChildProtectionPlans = pd.concat(
+            [self.ChildProtectionPlans, plans_df], ignore_index=True
+        )
+
+    def create_Reviews(self, plan):
+        """
+        Populates the ChildIdentifiers table. Multiple Reviews blocks can exist in one Reviews block.
+
+        :param xml child: 'child' element from the XML input
+        :returns: DataFrame of data for an individual child for the Reviews Table.
+        :rtype: DataFrame
+        """
+
+        reviews_list = []
+        columns = self.Reviews.columns
+        elements = list(set(columns).difference(set(self.id_cols)))
+
+        reviews = plan.findall("Reviews[CPPreviewDate]")
+        for review in reviews:
+            review_dict = {
+                "LAchildID": self.LAchildID,
+                "CINdetailsID": self.CINdetailsID,
+                "CPPID": self.CPPID,
+            }
+            review_dict = get_values(elements, review_dict, review)
+
+            reviews_list.append(review_dict)
+
+        reviews_df = pd.DataFrame(reviews_list)
+        self.Reviews = pd.concat([self.Reviews, reviews_df], ignore_index=True)
+
+
+"""
+Sidenote: Fields absent from the fake_CIN_data.xml
+- Assessments
+- CINPlanDates
+- Section47
+- ChildProtectionPlans
+- Reviews
+"""
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__api.py` & `csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__api.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,165 +1,176 @@
-import importlib
-from dataclasses import dataclass
-from enum import Enum
-from typing import Callable, Iterable, Optional
-
-
-class CINTable(Enum):
-    """
-    An enumeration class (https://docs.python.org/3/library/enum.html).
-    Used in validation to select CIN data modules/tables and fields/columns
-    and assign them to variables. For practical reasons, this is done to
-    ensure consistent spelling.
-    """
-
-    Header = Enum(
-        "Header",
-        [
-            "Collection",
-            "Year",
-            "ReferenceDate",
-            "SourceLevel",
-            "LEA",
-            "SoftwareCode",
-            "Release",
-            "SerialNo",
-            "DateTime",
-        ],
-    )
-    ChildIdentifiers = Enum(
-        "ChildIdentifiers",
-        [
-            "LAchildID",
-            "UPN",
-            "FormerUPN",
-            "UPNunknown",
-            "PersonBirthDate",
-            "ExpectedPersonBirthDate",
-            "GenderCurrent",
-            "PersonDeathDate",
-        ],
-    )
-    ChildCharacteristics = Enum(
-        "ChildCharacteristics",
-        [
-            "LAchildID",
-            "Ethnicity",
-        ],
-    )
-    Disabilities = Enum("Disabilities", ["LAchildID", "Disability"])
-    CINdetails = Enum(
-        "CINdetails",
-        [
-            "LAchildID",
-            "CINdetailsID",
-            "CINreferralDate",
-            "ReferralSource",
-            "PrimaryNeedCode",
-            "CINclosureDate",
-            "ReasonForClosure",
-            "DateOfInitialCPC",
-            "ReferralNFA",
-        ],
-    )
-    Assessments = Enum(
-        "Assessments",
-        [
-            "LAchildID",
-            "CINdetailsID",
-            "AssessmentActualStartDate",
-            "AssessmentInternalReviewDate",
-            "AssessmentAuthorisationDate",
-            "AssessmentFactors",
-        ],
-    )
-    CINplanDates = Enum(
-        "CINplanDates",
-        ["LAchildID", "CINdetailsID", "CINPlanStartDate", "CINPlanEndDate"],
-    )
-    Section47 = Enum(
-        "Section47",
-        [
-            "LAchildID",
-            "CINdetailsID",
-            "S47ActualStartDate",
-            "InitialCPCtarget",
-            "DateOfInitialCPC",
-            "ICPCnotRequired",
-        ],
-    )
-    ChildProtectionPlans = Enum(
-        "ChildProtectionPlans",
-        [
-            "LAchildID",
-            "CINdetailsID",
-            "CPPID",
-            "CPPstartDate",
-            "CPPendDate",
-            "InitialCategoryOfAbuse",
-            "LatestCategoryOfAbuse",
-            "NumberOfPreviousCPP",
-        ],
-    )
-    Reviews = Enum("Reviews", ["LAchildID", "CINdetailsID", "CPPID", "CPPreviewDate"])
-
-    def __getattr__(self, item):
-        """
-        Used to get attributes within the CINtable class. Practically used to define
-        fields/column variables from within tables for use in validation rules.
-
-        :param variable item: The name of a module and field to be used for
-            a validation rule.
-        :returns: A variable containing a field/column for validation, or an error
-            (generally on misspelling).
-        :rtype: Variable, error.
-        """
-
-        if not item.startswith("_"):
-            try:
-                return self.value[item].name
-            except KeyError as kerr:
-                raise AttributeError(f"Table {self.name} has no field {item}") from kerr
-        else:
-            return super().__getattr__(item)
-
-
-class RuleType(Enum):
-    """
-    An enumeration type class that defines available rule types.
-    Used to assign 'Error' or 'Query' to each rule in validation.
-    """
-
-    ERROR = "Error"
-    QUERY = "Query"
-
-
-@dataclass(frozen=True, eq=True)
-class RuleDefinition:
-    """
-    A dataclass type class used in each validation to assign information about
-    each validation rule to the rule.
-
-    :param int code: The rule code for each rule.
-    :param function func: Used to import the validation rule function.
-    :param RuleType-class rule_type: A RuleType class object accepts a string denoting if
-        the rule is an error or a query.
-    :param CINtable-object module: Accepts a string denoting the module/table affected by a
-        validation rule.
-    :param str affected_fields: The fields/columns affected by a validation rule.
-    :param str message: The message to be displayed if rule is flagged.
-    :returns: RuleDefinition object containing information about validation rules.
-    :rtype: dataclass object.
-    """
-
-    code: str
-    func: Callable
-    rule_type: RuleType = RuleType.ERROR
-    module: Optional[CINTable] = None
-    affected_fields: Optional[Iterable[str]] = None
-    message: Optional[str] = None
-
-
-@dataclass(eq=True)
-class YearConfig:
-    deleted: list[str]
-    added_or_modified: dict[str, RuleDefinition]
+import importlib
+from dataclasses import dataclass
+from enum import Enum
+from typing import Callable, Iterable, Optional
+
+
+class CINTable(Enum):
+    """
+    An enumeration class (https://docs.python.org/3/library/enum.html).
+    Used in validation to select CIN data modules/tables and fields/columns
+    and assign them to variables. For practical reasons, this is done to
+    ensure consistent spelling.
+    """
+
+    Header = Enum(
+        "Header",
+        [
+            "Collection",
+            "Year",
+            "ReferenceDate",
+            "SourceLevel",
+            "LEA",
+            "SoftwareCode",
+            "Release",
+            "SerialNo",
+            "DateTime",
+        ],
+    )
+    ChildIdentifiers = Enum(
+        "ChildIdentifiers",
+        [
+            "LAchildID",
+            "UPN",
+            "FormerUPN",
+            "UPNunknown",
+            "PersonBirthDate",
+            "ExpectedPersonBirthDate",
+            "GenderCurrent",
+            "Sex",
+            "PersonDeathDate",
+        ],
+    )
+    ChildCharacteristics = Enum(
+        "ChildCharacteristics",
+        [
+            "LAchildID",
+            "Ethnicity",
+        ],
+    )
+    Disabilities = Enum("Disabilities", ["LAchildID", "Disability"])
+    CINdetails = Enum(
+        "CINdetails",
+        [
+            "LAchildID",
+            "CINdetailsID",
+            "CINreferralDate",
+            "ReferralSource",
+            "PrimaryNeedCode",
+            "CINclosureDate",
+            "ReasonForClosure",
+            "DateOfInitialCPC",
+            "ReferralNFA",
+        ],
+    )
+    Assessments = Enum(
+        "Assessments",
+        [
+            "LAchildID",
+            "CINdetailsID",
+            "AssessmentID",
+            "AssessmentActualStartDate",
+            "AssessmentInternalReviewDate",
+            "AssessmentAuthorisationDate",
+            "AssessmentFactors",
+        ],
+    )
+    AssessmentFactorsList = Enum(
+        "AssessmentFactorsList",
+        [
+            "LAchildID",
+            "CINdetailsID",
+            "AssessmentID",
+            "AssessmentFactor",
+        ],
+    )
+    CINplanDates = Enum(
+        "CINplanDates",
+        ["LAchildID", "CINdetailsID", "CINPlanStartDate", "CINPlanEndDate"],
+    )
+    Section47 = Enum(
+        "Section47",
+        [
+            "LAchildID",
+            "CINdetailsID",
+            "S47ActualStartDate",
+            "InitialCPCtarget",
+            "DateOfInitialCPC",
+            "ICPCnotRequired",
+        ],
+    )
+    ChildProtectionPlans = Enum(
+        "ChildProtectionPlans",
+        [
+            "LAchildID",
+            "CINdetailsID",
+            "CPPID",
+            "CPPstartDate",
+            "CPPendDate",
+            "InitialCategoryOfAbuse",
+            "LatestCategoryOfAbuse",
+            "NumberOfPreviousCPP",
+        ],
+    )
+    Reviews = Enum("Reviews", ["LAchildID", "CINdetailsID", "CPPID", "CPPreviewDate"])
+
+    def __getattr__(self, item):
+        """
+        Used to get attributes within the CINtable class. Practically used to define
+        fields/column variables from within tables for use in validation rules.
+
+        :param variable item: The name of a module and field to be used for
+            a validation rule.
+        :returns: A variable containing a field/column for validation, or an error
+            (generally on misspelling).
+        :rtype: Variable, error.
+        """
+
+        if not item.startswith("_"):
+            try:
+                return self.value[item].name
+            except KeyError as kerr:
+                raise AttributeError(f"Table {self.name} has no field {item}") from kerr
+        else:
+            return super().__getattr__(item)
+
+
+class RuleType(Enum):
+    """
+    An enumeration type class that defines available rule types.
+    Used to assign 'Error' or 'Query' to each rule in validation.
+    """
+
+    ERROR = "Error"
+    QUERY = "Query"
+
+
+@dataclass(frozen=True, eq=True)
+class RuleDefinition:
+    """
+    A dataclass type class used in each validation to assign information about
+    each validation rule to the rule.
+
+    :param int code: The rule code for each rule.
+    :param function func: Used to import the validation rule function.
+    :param RuleType-class rule_type: A RuleType class object accepts a string denoting if
+        the rule is an error or a query.
+    :param CINtable-object module: Accepts a string denoting the module/table affected by a
+        validation rule.
+    :param str affected_fields: The fields/columns affected by a validation rule.
+    :param str message: The message to be displayed if rule is flagged.
+    :returns: RuleDefinition object containing information about validation rules.
+    :rtype: dataclass object.
+    """
+
+    code: str
+    func: Callable
+    rule_type: RuleType = RuleType.ERROR
+    module: Optional[CINTable] = None
+    affected_fields: Optional[Iterable[str]] = None
+    message: Optional[str] = None
+
+
+@dataclass(eq=True)
+class YearConfig:
+    deleted: list[str]
+    added_or_modified: dict[str, RuleDefinition]
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__context.py` & `csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__context.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,292 +1,292 @@
-from dataclasses import dataclass
-from typing import List
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleDefinition
-from cin_validator.utils import create_issue_locs
-
-
-@dataclass(frozen=True, eq=True)
-class IssueLocator:
-    """
-    Dataclass used to specify definite locations of issues that should be highlighted in the user's data.
-
-    :param CINTable-object table: Contains the name of the module/table in erorr for
-        a validation rule.
-    :param str field: The name of the field/column of an error in validation.
-    :param int row: The index/row number of an error.
-    :returns: IssueLocator object containing table, field, and row of validation errors.
-    :rtype: IssueLocator object.
-    """
-
-    table: CINTable
-    field: str
-    row: int
-
-
-@dataclass(frozen=True, eq=True)
-class Type1:
-    """Dataclass to define issue locations when more than one column is involved."""
-
-    table: CINTable
-    columns: List[str]
-    row_df: pd.DataFrame
-
-
-class RuleContext:
-    """
-    The RuleContext class includes methods that define how error locations
-    should be stored per validation rule.
-
-    >Type 0 rules contain 1 table and 1 column.
-    >Type 1 rules contain multiple columns, but one table and no merges.
-    >Type 2 rules contain multiple tables and columns.
-    >Type 3 rules contain  one table but use merges to check values by group,
-        e.g. a CINplan group.
-    >LA level rules contain checks for a whole local authority.
-    """
-
-    def __init__(self, definition: RuleDefinition):
-        """
-        Initialises RuleContext class.
-
-        :param RuleDefinition-object definition: Member of the rule definition dataclass,
-            contains information about each validation rule.
-        :param list issues: Empty list to be populated with type 0 and 1 issues.
-        :param list type2_issues: Empty list to be populated with type 2 issues.
-        :param list type3_issues: Empty list to be populated with type 3 issues.
-        """
-
-        self.__definition = definition
-
-        self.__issues: list = []
-        self.__type1_issues: list = []
-        self.__type2_issues: list = []
-        self.__type3_issues: list = []
-        self.__la_issues: list = []
-
-    @property
-    def definition(self):
-        """
-        Used to call information about validation rules.
-
-        :returns: Object containing information about each validation rule.
-        :rtype: RuleDefinition object.
-        """
-
-        return self.__definition
-
-    # TODO create list of rules according to types to prevent checking all attributes each time a rule is run.
-    # Possibly classify rule code by adding it to a list of rules with a similar type, when push is done.
-
-    # METHODS THAT DEFINE HOW ERROR LOCATIONS SHOULD BE STORED PER RULE STRUCTURE
-    def push_issue(self, table, field, row):
-        """
-        For rules that check only a single column.
-
-        :param CINTable-object table: the table a validation error ocurred in.
-        :param CINTable-object column: the column a validation error ocurred in.
-        :param DataFrame row_df: errors for a validation rule by table.
-        :returns: information to locate validation errors in original data.
-        :rtype: list of IssueLocator objects.
-        """
-
-        for i in row:
-            self.__issues.append(IssueLocator(table, field, i))
-
-    def push_type_1(self, table, columns, row_df):
-        """
-        For rules that check multiple columns in a single table, no merge involved.
-
-        :param CINTable-object table: the table a validation error ocurred in.
-        :param CINTable-object column: the column a validation error ocurred in.
-        :param DataFrame row_df: the errors for a validation rule by table.
-        :returns: information to locate validation errors in original data.
-        :rtype: dataclass object
-        """
-
-        self.__type1_issues = Type1(table, columns, row_df)
-
-    def push_type_2(self, table, columns, row_df):
-        """
-        For rules that check multiple columns across multiple tables.
-
-        :param CINTable-object table: the table a validation error ocurred in.
-        :param CINTable-object column:the column a validation error ocurred in.
-        :param DataFrame row_df: the errors for a validation rule by table.
-        :returns: information to locate validation errors in original data.
-        :rtype: list of dataclass objects
-        """
-
-        table_tuple = Type1(table, columns, row_df)
-        self.__type2_issues.append(table_tuple)
-
-    def push_type_3(self, table, columns, row_df):
-        """
-        For rules that check values in a group with respect to each other.
-
-        :param CINTable-object table: the table a validation error ocurred in.
-        :param CINTable-object column: the column a validation error ocurred in.
-        :param DataFrame row_df: the errors for a validation rule by table.
-        :returns: information to locate validation errors in original data.
-        :rtype: list of dataclass objects
-        """
-
-        table_tuple = Type1(table, columns, row_df)
-        self.__type3_issues.append(table_tuple)
-
-    def push_la_level(self, rule_code, rule_description):
-        """
-        For rules that check relationships across the whole local authority
-
-        :param CINTable-object table: the table a validation error ocurred in.
-        :param CINTable-object column: the column a validation error ocurred in.
-        :param DataFrame row_df: the errors for a validation rule by table.
-        :returns: information to locate validation errors in original data.
-        :rtype: list of tuples
-        """
-
-        self.__la_issues = (rule_code, rule_description)
-
-    # PROPERTIES FOR TEST_VALIDATE FUNCTIONS
-    @property
-    def issues(self):
-        return self.__issues
-
-    @property
-    def type1_issues(self):
-        return self.__type1_issues
-
-    @property
-    def type2_issues(self):
-        return self.__type2_issues
-
-    @property
-    def type3_issues(self):
-        return self.__type3_issues
-
-    @property
-    def la_issues(self):
-        return self.__la_issues
-
-    # PROPERTIES FOR CREATING THE ERROR REPORT
-    @property
-    def type_zero_issues(self):
-        """
-        Expands issues object into a dataframe where each row represents a location in the data
-        by a unique table-column-index combination.
-
-        :returns: DataFrame that contains failing locations of rules that involve only 1 column
-        :rtype: DatFrame
-        """
-
-        if len(self.__issues) != 0:
-            locator_dicts = []
-            for locator in self.__issues:
-                # convert every IssueLocator object to a dictionary
-                locator_as_dict = {
-                    "tables_affected": str(locator.table)[9:],
-                    "columns_affected": str(locator.field),
-                    "ROW_ID": str(locator.row),
-                }
-                locator_dicts.append(locator_as_dict)
-            # create a df that contains data from all issue_locators generated by the rule.
-            df_issue_locs = pd.DataFrame(locator_dicts)
-            return df_issue_locs
-
-        else:
-            # for non-type0 rules, do this
-            return []
-
-    @property
-    def type_one_issues(self):
-        """
-        Expands type1 issue object into a dataframe where each row represents a location in the data
-        by a unique table-column-index combination.
-
-        :returns: DataFrame that contains failing locations of rules that involve only 1 table
-            and multiple columns.
-        :rtype: DatFrame
-        """
-        try:
-            # if it is a type1 rule i.e __type1_issues.row_df exists, do this.
-            issues = self.__type1_issues
-            df_issue_locs = create_issue_locs(issues)
-            return df_issue_locs
-
-        except:
-            # all non-type1 rules run this.
-            return []
-
-    # type_one_issues and type_two_issues, though similar, should be left apart for readability.
-    @property
-    def type_two_issues(self):
-        """
-        Expands type2 issue object into a dataframe where each row represents a location in the data
-        by a unique table-column-index combination
-
-        :returns: DataFrame that contains failing locations of rules that involve multiple tables.
-        :rtype: DataFrame
-        """
-
-        try:
-            # if it is a type2 rule i.e __type2_issues.row_df exists, do this.
-            issues_per_table = self.__type2_issues
-            df_issue_locs_lst = []
-            for issues in issues_per_table:
-                # create a dataframe of issue locations for each table.
-                df_issue_loc_table = create_issue_locs(issues)
-                # append all table dataframes to a list.
-                df_issue_locs_lst.append(df_issue_loc_table)
-            # generate a dataframe that contains that data of all tables involved.
-            df_issue_locs = pd.concat(df_issue_locs_lst, ignore_index=True)
-            return df_issue_locs
-
-        except:
-            # all non-type2 rules run this.
-            return []
-
-    @property
-    def type_three_issues(self):
-        """
-        Expands type3 issue object into a dataframe where each row represents a location in the data
-        by a unique table-column-index combination.
-
-        :returns: DataFrame that contains failing locations of rules that involve errors within groups.
-        :rtype: DataFrame
-        """
-
-        try:
-            # if it is a type3 rule i.e __type3_issues.row_df exists, do this.
-            issues_per_table = self.__type3_issues
-            df_issue_locs_lst = []
-            for issues in issues_per_table:
-                # create a dataframe of issue locations for each table.
-                df_issue_loc_table = create_issue_locs(issues)
-                # append all table dataframes to a list.
-                df_issue_locs_lst.append(df_issue_loc_table)
-            # generate a dataframe that contains that data of all tables involved.
-            df_issue_locs = pd.concat(df_issue_locs_lst, ignore_index=True)
-            return df_issue_locs
-
-        except:
-            # all non-type3 rules return this.
-            return []
-
-    @property
-    def la_level_issues(self):
-        """
-        Creates DataFrame of return level validation errors.
-
-        :returns: DataFrame containing rule code/description of la-level rules that the data failed.
-        :rtype: DataFrame
-        """
-        try:
-            code, desc = self.__la_issues
-            la_df = pd.DataFrame(
-                [{"rule_code": code, "rule_description": desc, "la_level": True}]
-            )
-            return la_df
-        except:
-            return []
+from dataclasses import dataclass
+from typing import List
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleDefinition
+from cin_validator.utils import create_issue_locs
+
+
+@dataclass(frozen=True, eq=True)
+class IssueLocator:
+    """
+    Dataclass used to specify definite locations of issues that should be highlighted in the user's data.
+
+    :param CINTable-object table: Contains the name of the module/table in erorr for
+        a validation rule.
+    :param str field: The name of the field/column of an error in validation.
+    :param int row: The index/row number of an error.
+    :returns: IssueLocator object containing table, field, and row of validation errors.
+    :rtype: IssueLocator object.
+    """
+
+    table: CINTable
+    field: str
+    row: int
+
+
+@dataclass(frozen=True, eq=True)
+class Type1:
+    """Dataclass to define issue locations when more than one column is involved."""
+
+    table: CINTable
+    columns: List[str]
+    row_df: pd.DataFrame
+
+
+class RuleContext:
+    """
+    The RuleContext class includes methods that define how error locations
+    should be stored per validation rule.
+
+    >Type 0 rules contain 1 table and 1 column.
+    >Type 1 rules contain multiple columns, but one table and no merges.
+    >Type 2 rules contain multiple tables and columns.
+    >Type 3 rules contain  one table but use merges to check values by group,
+        e.g. a CINplan group.
+    >LA level rules contain checks for a whole local authority.
+    """
+
+    def __init__(self, definition: RuleDefinition):
+        """
+        Initialises RuleContext class.
+
+        :param RuleDefinition-object definition: Member of the rule definition dataclass,
+            contains information about each validation rule.
+        :param list issues: Empty list to be populated with type 0 and 1 issues.
+        :param list type2_issues: Empty list to be populated with type 2 issues.
+        :param list type3_issues: Empty list to be populated with type 3 issues.
+        """
+
+        self.__definition = definition
+
+        self.__issues: list = []
+        self.__type1_issues: list = []
+        self.__type2_issues: list = []
+        self.__type3_issues: list = []
+        self.__la_issues: list = []
+
+    @property
+    def definition(self):
+        """
+        Used to call information about validation rules.
+
+        :returns: Object containing information about each validation rule.
+        :rtype: RuleDefinition object.
+        """
+
+        return self.__definition
+
+    # TODO create list of rules according to types to prevent checking all attributes each time a rule is run.
+    # Possibly classify rule code by adding it to a list of rules with a similar type, when push is done.
+
+    # METHODS THAT DEFINE HOW ERROR LOCATIONS SHOULD BE STORED PER RULE STRUCTURE
+    def push_issue(self, table, field, row):
+        """
+        For rules that check only a single column.
+
+        :param CINTable-object table: the table a validation error ocurred in.
+        :param CINTable-object column: the column a validation error ocurred in.
+        :param DataFrame row_df: errors for a validation rule by table.
+        :returns: information to locate validation errors in original data.
+        :rtype: list of IssueLocator objects.
+        """
+
+        for i in row:
+            self.__issues.append(IssueLocator(table, field, i))
+
+    def push_type_1(self, table, columns, row_df):
+        """
+        For rules that check multiple columns in a single table, no merge involved.
+
+        :param CINTable-object table: the table a validation error ocurred in.
+        :param CINTable-object column: the column a validation error ocurred in.
+        :param DataFrame row_df: the errors for a validation rule by table.
+        :returns: information to locate validation errors in original data.
+        :rtype: dataclass object
+        """
+
+        self.__type1_issues = Type1(table, columns, row_df)
+
+    def push_type_2(self, table, columns, row_df):
+        """
+        For rules that check multiple columns across multiple tables.
+
+        :param CINTable-object table: the table a validation error ocurred in.
+        :param CINTable-object column:the column a validation error ocurred in.
+        :param DataFrame row_df: the errors for a validation rule by table.
+        :returns: information to locate validation errors in original data.
+        :rtype: list of dataclass objects
+        """
+
+        table_tuple = Type1(table, columns, row_df)
+        self.__type2_issues.append(table_tuple)
+
+    def push_type_3(self, table, columns, row_df):
+        """
+        For rules that check values in a group with respect to each other.
+
+        :param CINTable-object table: the table a validation error ocurred in.
+        :param CINTable-object column: the column a validation error ocurred in.
+        :param DataFrame row_df: the errors for a validation rule by table.
+        :returns: information to locate validation errors in original data.
+        :rtype: list of dataclass objects
+        """
+
+        table_tuple = Type1(table, columns, row_df)
+        self.__type3_issues.append(table_tuple)
+
+    def push_la_level(self, rule_code, rule_description):
+        """
+        For rules that check relationships across the whole local authority
+
+        :param CINTable-object table: the table a validation error ocurred in.
+        :param CINTable-object column: the column a validation error ocurred in.
+        :param DataFrame row_df: the errors for a validation rule by table.
+        :returns: information to locate validation errors in original data.
+        :rtype: list of tuples
+        """
+
+        self.__la_issues = (rule_code, rule_description)
+
+    # PROPERTIES FOR TEST_VALIDATE FUNCTIONS
+    @property
+    def issues(self):
+        return self.__issues
+
+    @property
+    def type1_issues(self):
+        return self.__type1_issues
+
+    @property
+    def type2_issues(self):
+        return self.__type2_issues
+
+    @property
+    def type3_issues(self):
+        return self.__type3_issues
+
+    @property
+    def la_issues(self):
+        return self.__la_issues
+
+    # PROPERTIES FOR CREATING THE ERROR REPORT
+    @property
+    def type_zero_issues(self):
+        """
+        Expands issues object into a dataframe where each row represents a location in the data
+        by a unique table-column-index combination.
+
+        :returns: DataFrame that contains failing locations of rules that involve only 1 column
+        :rtype: DatFrame
+        """
+
+        if len(self.__issues) != 0:
+            locator_dicts = []
+            for locator in self.__issues:
+                # convert every IssueLocator object to a dictionary
+                locator_as_dict = {
+                    "tables_affected": str(locator.table)[9:],
+                    "columns_affected": str(locator.field),
+                    "ROW_ID": str(locator.row),
+                }
+                locator_dicts.append(locator_as_dict)
+            # create a df that contains data from all issue_locators generated by the rule.
+            df_issue_locs = pd.DataFrame(locator_dicts)
+            return df_issue_locs
+
+        else:
+            # for non-type0 rules, do this
+            return []
+
+    @property
+    def type_one_issues(self):
+        """
+        Expands type1 issue object into a dataframe where each row represents a location in the data
+        by a unique table-column-index combination.
+
+        :returns: DataFrame that contains failing locations of rules that involve only 1 table
+            and multiple columns.
+        :rtype: DatFrame
+        """
+        try:
+            # if it is a type1 rule i.e __type1_issues.row_df exists, do this.
+            issues = self.__type1_issues
+            df_issue_locs = create_issue_locs(issues)
+            return df_issue_locs
+
+        except:
+            # all non-type1 rules run this.
+            return []
+
+    # type_one_issues and type_two_issues, though similar, should be left apart for readability.
+    @property
+    def type_two_issues(self):
+        """
+        Expands type2 issue object into a dataframe where each row represents a location in the data
+        by a unique table-column-index combination
+
+        :returns: DataFrame that contains failing locations of rules that involve multiple tables.
+        :rtype: DataFrame
+        """
+
+        try:
+            # if it is a type2 rule i.e __type2_issues.row_df exists, do this.
+            issues_per_table = self.__type2_issues
+            df_issue_locs_lst = []
+            for issues in issues_per_table:
+                # create a dataframe of issue locations for each table.
+                df_issue_loc_table = create_issue_locs(issues)
+                # append all table dataframes to a list.
+                df_issue_locs_lst.append(df_issue_loc_table)
+            # generate a dataframe that contains that data of all tables involved.
+            df_issue_locs = pd.concat(df_issue_locs_lst, ignore_index=True)
+            return df_issue_locs
+
+        except:
+            # all non-type2 rules run this.
+            return []
+
+    @property
+    def type_three_issues(self):
+        """
+        Expands type3 issue object into a dataframe where each row represents a location in the data
+        by a unique table-column-index combination.
+
+        :returns: DataFrame that contains failing locations of rules that involve errors within groups.
+        :rtype: DataFrame
+        """
+
+        try:
+            # if it is a type3 rule i.e __type3_issues.row_df exists, do this.
+            issues_per_table = self.__type3_issues
+            df_issue_locs_lst = []
+            for issues in issues_per_table:
+                # create a dataframe of issue locations for each table.
+                df_issue_loc_table = create_issue_locs(issues)
+                # append all table dataframes to a list.
+                df_issue_locs_lst.append(df_issue_loc_table)
+            # generate a dataframe that contains that data of all tables involved.
+            df_issue_locs = pd.concat(df_issue_locs_lst, ignore_index=True)
+            return df_issue_locs
+
+        except:
+            # all non-type3 rules return this.
+            return []
+
+    @property
+    def la_level_issues(self):
+        """
+        Creates DataFrame of return level validation errors.
+
+        :returns: DataFrame containing rule code/description of la-level rules that the data failed.
+        :rtype: DataFrame
+        """
+        try:
+            code, desc = self.__la_issues
+            la_df = pd.DataFrame(
+                [{"rule_code": code, "rule_description": desc, "la_level": True}]
+            )
+            return la_df
+        except:
+            return []
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rule_engine/__registry.py` & `csc_validator_be_cin-0.1.4/cin_validator/rule_engine/__registry.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,42 +1,42 @@
-from functools import wraps
-from typing import Callable, Iterable, Optional
-
-from cin_validator.rule_engine.__api import CINTable, RuleDefinition, RuleType
-
-
-def rule_definition(
-    code: str,
-    module: CINTable,
-    rule_type: RuleType = RuleType.ERROR,
-    message: Optional[str] = None,
-    affected_fields: Optional[Iterable] = None,
-):
-    """
-    Creates the rule definition for validation rules using RuleDefinition class as a template.
-
-    :param int code: The rule code for each rule.
-    :param RuleType-class rule_type: object denoting if the rule is an error or a query.
-    :param CINtable-object module: string denoting the module/table affected by a validation rule.
-    :param str affected_fields: The fields/columns affected by a validation rule.
-    :param str message: The message displayed for each validation rule.
-    :returns: RuleDefinition object containing information about validation rules.
-    :rtype: RuleDefiniton class object.
-    """
-
-    def decorator(func: Callable) -> Callable:
-        @wraps(func)
-        def wrapper(*args, **kwargs):
-            return func(*args, **kwargs)
-
-        definition = RuleDefinition(
-            code=str(code),
-            func=func,
-            rule_type=rule_type,
-            module=module,
-            message=message,
-            affected_fields=affected_fields,
-        )
-        wrapper.__rule_def__ = definition
-        return wrapper
-
-    return decorator
+from functools import wraps
+from typing import Callable, Iterable, Optional
+
+from cin_validator.rule_engine.__api import CINTable, RuleDefinition, RuleType
+
+
+def rule_definition(
+    code: str,
+    module: CINTable,
+    rule_type: RuleType = RuleType.ERROR,
+    message: Optional[str] = None,
+    affected_fields: Optional[Iterable] = None,
+):
+    """
+    Creates the rule definition for validation rules using RuleDefinition class as a template.
+
+    :param int code: The rule code for each rule.
+    :param RuleType-class rule_type: object denoting if the rule is an error or a query.
+    :param CINtable-object module: string denoting the module/table affected by a validation rule.
+    :param str affected_fields: The fields/columns affected by a validation rule.
+    :param str message: The message displayed for each validation rule.
+    :returns: RuleDefinition object containing information about validation rules.
+    :rtype: RuleDefiniton class object.
+    """
+
+    def decorator(func: Callable) -> Callable:
+        @wraps(func)
+        def wrapper(*args, **kwargs):
+            return func(*args, **kwargs)
+
+        definition = RuleDefinition(
+            code=str(code),
+            func=func,
+            rule_type=rule_type,
+            module=module,
+            message=message,
+            affected_fields=affected_fields,
+        )
+        wrapper.__rule_def__ = definition
+        return wrapper
+
+    return decorator
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_100.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_100.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,76 +1,76 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-Year = Header.Year
-
-
-@rule_definition(
-    code="100",
-    module=CINTable.Header,
-    message="Reference Date is incorrect",
-    affected_fields=[ReferenceDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Header]
-
-    # <ReferenceDate> (N00603) must be present and must equal 2022-03-31
-
-    # ReferenceDate is expected to be the 31st of March in the collection year
-    df["expected_date"] = "31/03/" + df[Year]
-    df["expected_date"] = pd.to_datetime(
-        df["expected_date"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Checks that the reference date is present
-    is_present = df[ReferenceDate].isna()
-    # Checks the error date is equal to 31/03/[collection_year].
-    error_date = df[ReferenceDate] != df["expected_date"]
-    failing_indices = df[is_present | error_date].index
-
-    rule_context.push_issue(table=Header, field=ReferenceDate, row=failing_indices)
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    # Sidenote: a typical Header table will only have one row.
-    header = pd.DataFrame(
-        [
-            {Year: "2022", ReferenceDate: "31/03/2022"},
-            {Year: "2022", ReferenceDate: pd.NA},
-            {Year: "2022", ReferenceDate: pd.NA},
-            {Year: "2022", ReferenceDate: "30/11/2021"},
-        ]
-    )
-
-    header[ReferenceDate] = pd.to_datetime(
-        header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(validate, {Header: header})
-
-    issues = list(result.issues)
-    # Intended fail points in data.
-    assert len(issues) == 3
-    # Intended failures of test data by index.
-    assert issues == [
-        IssueLocator(CINTable.Header, ReferenceDate, 1),
-        IssueLocator(CINTable.Header, ReferenceDate, 2),
-        IssueLocator(CINTable.Header, ReferenceDate, 3),
-    ]
-
-    # Checks rule code and message are correct.
-    assert result.definition.code == "100"
-    assert result.definition.message == "Reference Date is incorrect"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+Year = Header.Year
+
+
+@rule_definition(
+    code="100",
+    module=CINTable.Header,
+    message="Reference Date is incorrect",
+    affected_fields=[ReferenceDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Header]
+
+    # <ReferenceDate> (N00603) must be present and must equal 2022-03-31
+
+    # ReferenceDate is expected to be the 31st of March in the collection year
+    df["expected_date"] = "31/03/" + df[Year]
+    df["expected_date"] = pd.to_datetime(
+        df["expected_date"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Checks that the reference date is present
+    is_present = df[ReferenceDate].isna()
+    # Checks the error date is equal to 31/03/[collection_year].
+    error_date = df[ReferenceDate] != df["expected_date"]
+    failing_indices = df[is_present | error_date].index
+
+    rule_context.push_issue(table=Header, field=ReferenceDate, row=failing_indices)
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    # Sidenote: a typical Header table will only have one row.
+    header = pd.DataFrame(
+        [
+            {Year: "2022", ReferenceDate: "31/03/2022"},
+            {Year: "2022", ReferenceDate: pd.NA},
+            {Year: "2022", ReferenceDate: pd.NA},
+            {Year: "2022", ReferenceDate: "30/11/2021"},
+        ]
+    )
+
+    header[ReferenceDate] = pd.to_datetime(
+        header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {Header: header})
+
+    issues = list(result.issues)
+    # Intended fail points in data.
+    assert len(issues) == 3
+    # Intended failures of test data by index.
+    assert issues == [
+        IssueLocator(CINTable.Header, ReferenceDate, 1),
+        IssueLocator(CINTable.Header, ReferenceDate, 2),
+        IssueLocator(CINTable.Header, ReferenceDate, 3),
+    ]
+
+    # Checks rule code and message are correct.
+    assert result.definition.code == "100"
+    assert result.definition.message == "Reference Date is incorrect"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1103.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1103.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,216 +1,216 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-Assessments = CINTable.Assessments
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-LAchildID = Assessments.LAchildID
-Assdetailsid = Assessments.CINdetailsID
-
-CINdetails = CINTable.CINdetails
-CINreferralDate = CINdetails.CINreferralDate
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-
-
-@rule_definition(
-    code="1103",
-    module=CINTable.Assessments,
-    message="The assessment start date cannot be before the referral date",
-    affected_fields=[
-        AssessmentActualStartDate,
-        CINreferralDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_ass = data_container[Assessments].copy()
-    df_refs = data_container[CINdetails].copy()
-
-    df_ass.index.name = "ROW_ID"
-    df_refs.index.name = "ROW_ID"
-
-    df_ass.reset_index(inplace=True)
-    df_refs.reset_index(inplace=True)
-
-    # Where present, the <AssessmentActualStartDate> (N00159) should be on or after the <CINReferralDate> (N00100)
-    # Issues dfs should return rows where Assessment Start Date is less than the Referral Start Date
-    df_ass = df_ass[df_ass[AssessmentActualStartDate].notna()]
-    df_refs = df_refs[df_refs[CINreferralDate].notna()]
-
-    #  Merge tables to get corresponding Assessment group and referrals
-    df_merged = df_ass.merge(
-        df_refs,
-        left_on=["LAchildID", "CINdetailsID"],
-        right_on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=("_ass", "_refs"),
-    )
-
-    #  Get rows where Assessment Start Date is less than the Referral Start Date
-    condition = df_merged[AssessmentActualStartDate] < df_merged[CINreferralDate]
-    df_merged = df_merged[condition].reset_index()
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[AssessmentActualStartDate],
-            df_merged[CINreferralDate],
-        )
-    )
-
-    # The merges were done on copies of fs_ass and df_refs so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_ass_issues = (
-        df_ass.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_refs_issues = (
-        df_refs.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_refs")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=Assessments, columns=[AssessmentActualStartDate], row_df=df_ass_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_refs_issues
-    )
-
-
-def test_validate():
-    sample_ass = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "AssessmentActualStartDate": "30/06/2021",  # Fails as referral date is after assessment start
-                "CINdetailsID": "CIN1",
-            },
-            {
-                "LAchildID": "child2",
-                "AssessmentActualStartDate": "10/09/2021",  #  Passes as assessment starts after referal start date
-                "CINdetailsID": "CIN2",
-            },
-            {
-                "LAchildID": "child3",
-                "AssessmentActualStartDate": pd.NA,  # Ignored as no Assessment Date recorded
-                "CINdetailsID": "CIN3",
-            },
-            {
-                "LAchildID": "child4",
-                "AssessmentActualStartDate": "01/12/2021",  # Fails as assessment starts after referral start date
-                "CINdetailsID": "CIN4",
-            },
-            {
-                "LAchildID": "child5",
-                "AssessmentActualStartDate": "10/02/2022",  # Fails as no Referral Start Date recorded
-                "CINdetailsID": "CIN5",
-            },
-        ]
-    )
-    sample_refs = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Fails
-                "CINreferralDate": "01/07/2021",
-                "CINdetailsID": "CIN1",
-            },
-            {
-                "LAchildID": "child2",  # Passes
-                "CINreferralDate": "01/09/2021",
-                "CINdetailsID": "CIN2",
-            },
-            {
-                "LAchildID": "child3",  # Ignored
-                "CINreferralDate": "26/05/2000",
-                "CINdetailsID": "CIN3",
-            },
-            {
-                "LAchildID": "child4",  # Fails
-                "CINreferralDate": "10/12/2021",
-                "CINdetailsID": "CIN4",
-            },
-            {
-                "LAchildID": "child5",  # Ignored
-                "CINreferralDate": pd.NA,
-                "CINdetailsID": "CIN5",
-            },
-        ]
-    )
-
-    sample_ass[AssessmentActualStartDate] = pd.to_datetime(
-        sample_ass[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_refs["CINreferralDate"] = pd.to_datetime(
-        sample_refs["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            Assessments: sample_ass,
-            CINdetails: sample_refs,
-        },
-    )
-
-    # Type 2 rule.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINreferralDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    # Assessment Date
-                    pd.to_datetime("30/06/2021", format="%d/%m/%Y", errors="coerce"),
-                    # Referral date
-                    pd.to_datetime("01/07/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",  # ChildID
-                    # Assessmwent date
-                    pd.to_datetime("01/12/2021", format="%d/%m/%Y", errors="coerce"),
-                    # Referral date
-                    pd.to_datetime("10/12/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "1103"
-    assert (
-        result.definition.message
-        == "The assessment start date cannot be before the referral date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+Assessments = CINTable.Assessments
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+LAchildID = Assessments.LAchildID
+Assdetailsid = Assessments.CINdetailsID
+
+CINdetails = CINTable.CINdetails
+CINreferralDate = CINdetails.CINreferralDate
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+
+
+@rule_definition(
+    code="1103",
+    module=CINTable.Assessments,
+    message="The assessment start date cannot be before the referral date",
+    affected_fields=[
+        AssessmentActualStartDate,
+        CINreferralDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_ass = data_container[Assessments].copy()
+    df_refs = data_container[CINdetails].copy()
+
+    df_ass.index.name = "ROW_ID"
+    df_refs.index.name = "ROW_ID"
+
+    df_ass.reset_index(inplace=True)
+    df_refs.reset_index(inplace=True)
+
+    # Where present, the <AssessmentActualStartDate> (N00159) should be on or after the <CINReferralDate> (N00100)
+    # Issues dfs should return rows where Assessment Start Date is less than the Referral Start Date
+    df_ass = df_ass[df_ass[AssessmentActualStartDate].notna()]
+    df_refs = df_refs[df_refs[CINreferralDate].notna()]
+
+    #  Merge tables to get corresponding Assessment group and referrals
+    df_merged = df_ass.merge(
+        df_refs,
+        left_on=["LAchildID", "CINdetailsID"],
+        right_on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=("_ass", "_refs"),
+    )
+
+    #  Get rows where Assessment Start Date is less than the Referral Start Date
+    condition = df_merged[AssessmentActualStartDate] < df_merged[CINreferralDate]
+    df_merged = df_merged[condition].reset_index()
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[AssessmentActualStartDate],
+            df_merged[CINreferralDate],
+        )
+    )
+
+    # The merges were done on copies of fs_ass and df_refs so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_ass_issues = (
+        df_ass.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_refs_issues = (
+        df_refs.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_refs")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=Assessments, columns=[AssessmentActualStartDate], row_df=df_ass_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_refs_issues
+    )
+
+
+def test_validate():
+    sample_ass = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "AssessmentActualStartDate": "30/06/2021",  # Fails as referral date is after assessment start
+                "CINdetailsID": "CIN1",
+            },
+            {
+                "LAchildID": "child2",
+                "AssessmentActualStartDate": "10/09/2021",  #  Passes as assessment starts after referal start date
+                "CINdetailsID": "CIN2",
+            },
+            {
+                "LAchildID": "child3",
+                "AssessmentActualStartDate": pd.NA,  # Ignored as no Assessment Date recorded
+                "CINdetailsID": "CIN3",
+            },
+            {
+                "LAchildID": "child4",
+                "AssessmentActualStartDate": "01/12/2021",  # Fails as assessment starts after referral start date
+                "CINdetailsID": "CIN4",
+            },
+            {
+                "LAchildID": "child5",
+                "AssessmentActualStartDate": "10/02/2022",  # Fails as no Referral Start Date recorded
+                "CINdetailsID": "CIN5",
+            },
+        ]
+    )
+    sample_refs = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Fails
+                "CINreferralDate": "01/07/2021",
+                "CINdetailsID": "CIN1",
+            },
+            {
+                "LAchildID": "child2",  # Passes
+                "CINreferralDate": "01/09/2021",
+                "CINdetailsID": "CIN2",
+            },
+            {
+                "LAchildID": "child3",  # Ignored
+                "CINreferralDate": "26/05/2000",
+                "CINdetailsID": "CIN3",
+            },
+            {
+                "LAchildID": "child4",  # Fails
+                "CINreferralDate": "10/12/2021",
+                "CINdetailsID": "CIN4",
+            },
+            {
+                "LAchildID": "child5",  # Ignored
+                "CINreferralDate": pd.NA,
+                "CINdetailsID": "CIN5",
+            },
+        ]
+    )
+
+    sample_ass[AssessmentActualStartDate] = pd.to_datetime(
+        sample_ass[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_refs["CINreferralDate"] = pd.to_datetime(
+        sample_refs["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            Assessments: sample_ass,
+            CINdetails: sample_refs,
+        },
+    )
+
+    # Type 2 rule.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINreferralDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    # Assessment Date
+                    pd.to_datetime("30/06/2021", format="%d/%m/%Y", errors="coerce"),
+                    # Referral date
+                    pd.to_datetime("01/07/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",  # ChildID
+                    # Assessmwent date
+                    pd.to_datetime("01/12/2021", format="%d/%m/%Y", errors="coerce"),
+                    # Referral date
+                    pd.to_datetime("10/12/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "1103"
+    assert (
+        result.definition.message
+        == "The assessment start date cannot be before the referral date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1104.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1104.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,207 +1,207 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-Section47 = CINTable.Section47
-DateOfInitialCPC = Section47.DateOfInitialCPC
-
-CINdetails = CINTable.CINdetails
-CINreferralDate = CINdetails.CINreferralDate
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-
-
-@rule_definition(
-    code="1104",
-    module=CINTable.Section47,
-    message="The date of the initial child protection conference cannot be before the referral date",
-    affected_fields=[
-        CINreferralDate,
-        DateOfInitialCPC,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cin = data_container[CINdetails]
-    df_47 = data_container[Section47]
-
-    df_cin.index.name = "ROW_ID"
-    df_47.index.name = "ROW_ID"
-
-    df_cin.reset_index(inplace=True)
-    df_47.reset_index(inplace=True)
-
-    # Where present, the <DateOfInitialCPC> (N00110) should be on or after <CINreferralDate> (N00100)
-    df_47 = df_47[df_47[DateOfInitialCPC].notna()]
-    # get only relevant rows in df_47 (line above) and relevant columns in CIN
-    # (line below: prevent the other DateOfInitialCPC from coming along in the merge else DateOfInitialCPC column name
-    # will depend on whether the same name in present in the CINdetails table and that is out of scope for this rule.)
-    df_cin_filtered = df_cin[["ROW_ID", LAchildID, CINdetailsID, CINreferralDate]]
-
-    merged_df = df_47.copy().merge(
-        df_cin_filtered,
-        on=[LAchildID, CINdetailsID],
-        how="left",
-        suffixes=["_47", "_cin"],
-    )
-
-    # check that the the dates being compared existed in the same CIN event period and belong to the same child.
-    condition = merged_df[DateOfInitialCPC] < merged_df[CINreferralDate]
-
-    merged_df = merged_df[condition].reset_index()
-
-    # create an identifier for each error instance.
-    merged_df["ERROR_ID"] = tuple(
-        zip(merged_df[LAchildID], merged_df[CINdetailsID], merged_df[DateOfInitialCPC])
-    )
-
-    # The merges were done on copies of df_47 and df_cin so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_47_issues = (
-        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=Section47, columns=[DateOfInitialCPC], row_df=df_47_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    sample_section47 = pd.DataFrame(
-        [
-            {  # 0 fail: before
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": "19/05/2000",
-            },
-            {  # 1 fail: before
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID2",
-                "DateOfInitialCPC": "26/05/2000",
-            },
-            {  # 2 ignore
-                "LAchildID": "child2",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": pd.NA,
-            },
-            {  # 3 pass: after
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": "31/05/2003",
-            },
-            {  # 4 ignore: CINreferralDate is null
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID2",
-                "DateOfInitialCPC": "26/05/2000",
-            },
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {  # 0 fail
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "CINreferralDate": "26/10/2001",
-            },
-            {  # 1 fail
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID2",
-                "CINreferralDate": "13/06/2002",
-            },
-            {  # 2 ignore
-                "LAchildID": "child2",
-                "CINdetailsID": "cinID1",
-                "CINreferralDate": "26/05/2000",
-            },
-            {  # 3 pass
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID1",
-                "CINreferralDate": "28/05/2000",
-            },
-            {  # 4 ignore
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID2",
-                "CINreferralDate": pd.NA,
-            },
-            {  # 5 ignore: doesn't match any ID when merged
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID4",
-                "CINreferralDate": "28/05/2000",
-            },
-        ]
-    )
-    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
-        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin_details["CINreferralDate"] = pd.to_datetime(
-        sample_cin_details["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            Section47: sample_section47,
-            CINdetails: sample_cin_details,
-        },
-    )
-
-    # Type 2 rule.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    issue_columns = issues.columns
-    assert issue_columns == [DateOfInitialCPC]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "cinID1",  # CINdetailsID
-                    # corresponding DateofInitialCPC
-                    pd.to_datetime("19/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID2",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "1104"
-    assert (
-        result.definition.message
-        == "The date of the initial child protection conference cannot be before the referral date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+Section47 = CINTable.Section47
+DateOfInitialCPC = Section47.DateOfInitialCPC
+
+CINdetails = CINTable.CINdetails
+CINreferralDate = CINdetails.CINreferralDate
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+
+
+@rule_definition(
+    code="1104",
+    module=CINTable.Section47,
+    message="The date of the initial child protection conference cannot be before the referral date",
+    affected_fields=[
+        CINreferralDate,
+        DateOfInitialCPC,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cin = data_container[CINdetails]
+    df_47 = data_container[Section47]
+
+    df_cin.index.name = "ROW_ID"
+    df_47.index.name = "ROW_ID"
+
+    df_cin.reset_index(inplace=True)
+    df_47.reset_index(inplace=True)
+
+    # Where present, the <DateOfInitialCPC> (N00110) should be on or after <CINreferralDate> (N00100)
+    df_47 = df_47[df_47[DateOfInitialCPC].notna()]
+    # get only relevant rows in df_47 (line above) and relevant columns in CIN
+    # (line below: prevent the other DateOfInitialCPC from coming along in the merge else DateOfInitialCPC column name
+    # will depend on whether the same name in present in the CINdetails table and that is out of scope for this rule.)
+    df_cin_filtered = df_cin[["ROW_ID", LAchildID, CINdetailsID, CINreferralDate]]
+
+    merged_df = df_47.copy().merge(
+        df_cin_filtered,
+        on=[LAchildID, CINdetailsID],
+        how="left",
+        suffixes=["_47", "_cin"],
+    )
+
+    # check that the the dates being compared existed in the same CIN event period and belong to the same child.
+    condition = merged_df[DateOfInitialCPC] < merged_df[CINreferralDate]
+
+    merged_df = merged_df[condition].reset_index()
+
+    # create an identifier for each error instance.
+    merged_df["ERROR_ID"] = tuple(
+        zip(merged_df[LAchildID], merged_df[CINdetailsID], merged_df[DateOfInitialCPC])
+    )
+
+    # The merges were done on copies of df_47 and df_cin so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_47_issues = (
+        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=Section47, columns=[DateOfInitialCPC], row_df=df_47_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    sample_section47 = pd.DataFrame(
+        [
+            {  # 0 fail: before
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": "19/05/2000",
+            },
+            {  # 1 fail: before
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID2",
+                "DateOfInitialCPC": "26/05/2000",
+            },
+            {  # 2 ignore
+                "LAchildID": "child2",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": pd.NA,
+            },
+            {  # 3 pass: after
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": "31/05/2003",
+            },
+            {  # 4 ignore: CINreferralDate is null
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID2",
+                "DateOfInitialCPC": "26/05/2000",
+            },
+        ]
+    )
+    sample_cin_details = pd.DataFrame(
+        [
+            {  # 0 fail
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "CINreferralDate": "26/10/2001",
+            },
+            {  # 1 fail
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID2",
+                "CINreferralDate": "13/06/2002",
+            },
+            {  # 2 ignore
+                "LAchildID": "child2",
+                "CINdetailsID": "cinID1",
+                "CINreferralDate": "26/05/2000",
+            },
+            {  # 3 pass
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID1",
+                "CINreferralDate": "28/05/2000",
+            },
+            {  # 4 ignore
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID2",
+                "CINreferralDate": pd.NA,
+            },
+            {  # 5 ignore: doesn't match any ID when merged
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID4",
+                "CINreferralDate": "28/05/2000",
+            },
+        ]
+    )
+    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
+        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin_details["CINreferralDate"] = pd.to_datetime(
+        sample_cin_details["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            Section47: sample_section47,
+            CINdetails: sample_cin_details,
+        },
+    )
+
+    # Type 2 rule.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    issue_columns = issues.columns
+    assert issue_columns == [DateOfInitialCPC]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "cinID1",  # CINdetailsID
+                    # corresponding DateofInitialCPC
+                    pd.to_datetime("19/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID2",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "1104"
+    assert (
+        result.definition.message
+        == "The date of the initial child protection conference cannot be before the referral date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1105.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1105.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,215 +1,215 @@
-"""
-Rule number: '1105'
-Module: Child protection plans
-Rule details: Where present, the <CPPStartDate> (N00105) must be on or after the <CINReferralDate> (N00100)
-Rule message: The child protection plan start date cannot be before the referral date
-
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-CPP_LAID = ChildProtectionPlans.LAchildID
-CPP_CINdetailsID = ChildProtectionPlans.CINdetailsID
-
-CINDetails = CINTable.CINdetails
-CINreferralDate = CINDetails.CINreferralDate
-CIN_LAID = CINDetails.LAchildID
-CIN_CINdetailsID = CINDetails.CINdetailsID
-
-
-@rule_definition(
-    code="1105",
-    module=CINTable.ChildProtectionPlans,
-    message="The child protection plan start date cannot be before the referral date",
-    affected_fields=[
-        CPPstartDate,
-        CINreferralDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_CPP = data_container[ChildProtectionPlans].copy()
-    df_CIN = data_container[CINDetails].copy()
-
-    df_CPP.index.name = "ROW_ID"
-    df_CIN.index.name = "ROW_ID"
-
-    df_CPP.reset_index(inplace=True)
-    df_CIN.reset_index(inplace=True)
-
-    # <CPPStartDate> (N00105) must be on or after the <CINReferralDate> (N00100)
-
-    # Remove rows without CPP start date
-    df_CPP = df_CPP[df_CPP[CPPstartDate].notna()]
-
-    df = df_CPP.merge(
-        df_CIN,
-        left_on=["LAchildID", "CINdetailsID"],
-        right_on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=("_CPP", "_CIN"),
-    )
-
-    # Return those where dates don't align
-    df = df[df["CINreferralDate"] > df["CPPstartDate"]].reset_index()
-
-    df["ERROR_ID"] = tuple(zip(df["LAchildID"], df[CPPstartDate], df[CINreferralDate]))
-
-    df_CPP_issues = (
-        df_CPP.merge(df, left_on="ROW_ID", right_on="ROW_ID_CPP")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_CIN_issues = (
-        df_CIN.merge(df, left_on="ROW_ID", right_on="ROW_ID_CIN")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_CPP_issues
-    )
-    rule_context.push_type_2(
-        table=CINDetails, columns=[CINreferralDate], row_df=df_CIN_issues
-    )
-
-
-def test_validate():
-    sample_CPP = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPstartDate": "26/05/2000",  # Pass, same date
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",
-                "CPPstartDate": "27/06/2002",  # Pass, after referall
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "07/02/1999",  # Fail, prior to referall
-                "CINdetailsID": "cinID6",
-            },
-            {
-                "LAchildID": "child2",
-                "CPPstartDate": "26/05/2000",  # Fail, prior to referral
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "26/05/2001",  # Pass, after referall
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-
-    sample_CIN = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass
-                "CINreferralDate": "26/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",  # Pass
-                "CINreferralDate": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",  # Fail
-                "CINreferralDate": "26/05/2000",
-                "CINdetailsID": "cinID6",
-            },
-            {
-                "LAchildID": "child2",  # Fail
-                "CINreferralDate": "30/05/2000",
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",  # Pass
-                "CINreferralDate": "27/05/2000",
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-
-    sample_CPP[CPPstartDate] = pd.to_datetime(
-        sample_CPP[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_CIN[CINreferralDate] = pd.to_datetime(
-        sample_CIN[CINreferralDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_CPP,
-            CINDetails: sample_CIN,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINDetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINreferralDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    # Start date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    # Referral date
-                    pd.to_datetime("30/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    # Start Date
-                    pd.to_datetime("07/02/1999", format="%d/%m/%Y", errors="coerce"),
-                    # Referral date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "1105"
-    assert (
-        result.definition.message
-        == "The child protection plan start date cannot be before the referral date"
-    )
+"""
+Rule number: '1105'
+Module: Child protection plans
+Rule details: Where present, the <CPPStartDate> (N00105) must be on or after the <CINReferralDate> (N00100)
+Rule message: The child protection plan start date cannot be before the referral date
+
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+CPP_LAID = ChildProtectionPlans.LAchildID
+CPP_CINdetailsID = ChildProtectionPlans.CINdetailsID
+
+CINDetails = CINTable.CINdetails
+CINreferralDate = CINDetails.CINreferralDate
+CIN_LAID = CINDetails.LAchildID
+CIN_CINdetailsID = CINDetails.CINdetailsID
+
+
+@rule_definition(
+    code="1105",
+    module=CINTable.ChildProtectionPlans,
+    message="The child protection plan start date cannot be before the referral date",
+    affected_fields=[
+        CPPstartDate,
+        CINreferralDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_CPP = data_container[ChildProtectionPlans].copy()
+    df_CIN = data_container[CINDetails].copy()
+
+    df_CPP.index.name = "ROW_ID"
+    df_CIN.index.name = "ROW_ID"
+
+    df_CPP.reset_index(inplace=True)
+    df_CIN.reset_index(inplace=True)
+
+    # <CPPStartDate> (N00105) must be on or after the <CINReferralDate> (N00100)
+
+    # Remove rows without CPP start date
+    df_CPP = df_CPP[df_CPP[CPPstartDate].notna()]
+
+    df = df_CPP.merge(
+        df_CIN,
+        left_on=["LAchildID", "CINdetailsID"],
+        right_on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=("_CPP", "_CIN"),
+    )
+
+    # Return those where dates don't align
+    df = df[df["CINreferralDate"] > df["CPPstartDate"]].reset_index()
+
+    df["ERROR_ID"] = tuple(zip(df["LAchildID"], df[CPPstartDate], df[CINreferralDate]))
+
+    df_CPP_issues = (
+        df_CPP.merge(df, left_on="ROW_ID", right_on="ROW_ID_CPP")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_CIN_issues = (
+        df_CIN.merge(df, left_on="ROW_ID", right_on="ROW_ID_CIN")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_CPP_issues
+    )
+    rule_context.push_type_2(
+        table=CINDetails, columns=[CINreferralDate], row_df=df_CIN_issues
+    )
+
+
+def test_validate():
+    sample_CPP = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPstartDate": "26/05/2000",  # Pass, same date
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",
+                "CPPstartDate": "27/06/2002",  # Pass, after referall
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "07/02/1999",  # Fail, prior to referall
+                "CINdetailsID": "cinID6",
+            },
+            {
+                "LAchildID": "child2",
+                "CPPstartDate": "26/05/2000",  # Fail, prior to referral
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "26/05/2001",  # Pass, after referall
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+
+    sample_CIN = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Pass
+                "CINreferralDate": "26/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",  # Pass
+                "CINreferralDate": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",  # Fail
+                "CINreferralDate": "26/05/2000",
+                "CINdetailsID": "cinID6",
+            },
+            {
+                "LAchildID": "child2",  # Fail
+                "CINreferralDate": "30/05/2000",
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",  # Pass
+                "CINreferralDate": "27/05/2000",
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+
+    sample_CPP[CPPstartDate] = pd.to_datetime(
+        sample_CPP[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_CIN[CINreferralDate] = pd.to_datetime(
+        sample_CIN[CINreferralDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_CPP,
+            CINDetails: sample_CIN,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == CINDetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINreferralDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    # Start date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    # Referral date
+                    pd.to_datetime("30/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    # Start Date
+                    pd.to_datetime("07/02/1999", format="%d/%m/%Y", errors="coerce"),
+                    # Referral date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "1105"
+    assert (
+        result.definition.message
+        == "The child protection plan start date cannot be before the referral date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1510.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1510.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,113 +1,113 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-UPN = ChildIdentifiers.UPN
-
-
-@rule_definition(
-    code="1510",
-    module=CINTable.ChildIdentifiers,
-    message="UPN invalid (wrong check letter at character 1)",
-    affected_fields=[UPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-
-    """
-    <UPN> (N00001) if present must contain the correct check letter
-
-    To calculate the check letter:
-
-    1. Multiply the individual digits by their weights as follows:
-
-    digit 2 by weight 2; digit 3 by weight 3; digit 4 by weight 4; digit 5 by weight 5; digit 6 by weight 6; digit 7 by weight 7; digit 8 by weight 8; digit 9 by weight 9; digit 10 by weight 10; digit 11 by weight 11; digit 12 by weight 12; digit 13 by weight 13.
-
-    2. Sum the individual results, divide the total by 23, and take the remainder.
-
-    3. Calculate the check letter from the result as follows:
-
-    0  = A;  1  = B;  2  = C;  3  = D;  4  = E;  5 = F;  6 = G;
-    7 = H;  8 = J;  9 = K;  10 = L;  11 = M;  12 = N;  13 = P;
-    14 = Q;  15 = R;  16 = T;  17 = U;  18 = V;  19 = W;  20 = X; Y = 21, Z = 22
-
-    Full list avaliable here https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/807381/UPN_Guide_1.2.pdf
-    """
-
-    df.reset_index(inplace=True)
-
-    df2 = df[["index", "UPN"]]
-    df2 = df2[(df2["UPN"].str.len() == 13) & df2["UPN"].notna()]
-
-    # the reference value is the first character of the UPN string.
-    df2["FIRST_CHAR"] = df2["UPN"].str[0]
-
-    # the last 12 characters have to be digits or else the UPN cannot be considered.
-    df2["LAST_C"] = df2["UPN"].str[1:]
-    df2["LAST_C"] = df2["LAST_C"].apply(lambda x: int(x) if str(x).isdigit() else pd.NA)
-    df2 = df2[df2["LAST_C"].notna()]
-
-    # calculate check value according to rule description.
-    df2["SUMMED"] = 0
-    for i in range(1, 13):
-        # previous check was important because non-digits cannot be converted to int and hence cannot be multiplied.
-        df2["SUMMED"] = (df2["SUMMED"] + (df2["UPN"].str[i].astype(int) * (i + 1))) % 23
-
-    # enumerate object yields (index_position, element) tuples for each element in the string.
-    check_map = enumerate(list("ABCDEFGHJKLMNPQRTUVWXYZ"))
-    check_map = dict((i, j) for i, j in check_map)
-
-    # Deduce the alphabet-letter representation of the calculated value based on rule description.
-    df2["CHECK_CHAR"] = df2["SUMMED"].map(check_map)
-    # select out all the rows where the calculated value does not match the expected value.
-    df2 = df2[df2["CHECK_CHAR"].astype(str) != df2["FIRST_CHAR"].astype(str)]
-    # restore the original index.
-    failing_indices = df2.set_index("index").index
-
-    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        {
-            "UPN": [
-                # These should pass
-                "A950000178301",  # 0 Valid format
-                pd.NA,  # 1
-                "H243278544154",  # 2 Valid format
-                "ASFFAGSVSV123",  # 3 Nonsense
-                "R325",  # 4 Nonsense
-                # These should fail
-                "R247962919251",  # 5 Wrong initial char
-                "X428558133462",  # 6 Wrong initial char
-                "X845212818005",
-            ]
-        }
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 2
-
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 5),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 6),
-    ]
-
-    assert result.definition.code == "1510"
-    assert (
-        result.definition.message == "UPN invalid (wrong check letter at character 1)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+UPN = ChildIdentifiers.UPN
+
+
+@rule_definition(
+    code="1510",
+    module=CINTable.ChildIdentifiers,
+    message="UPN invalid (wrong check letter at character 1)",
+    affected_fields=[UPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+
+    """
+    <UPN> (N00001) if present must contain the correct check letter
+
+    To calculate the check letter:
+
+    1. Multiply the individual digits by their weights as follows:
+
+    digit 2 by weight 2; digit 3 by weight 3; digit 4 by weight 4; digit 5 by weight 5; digit 6 by weight 6; digit 7 by weight 7; digit 8 by weight 8; digit 9 by weight 9; digit 10 by weight 10; digit 11 by weight 11; digit 12 by weight 12; digit 13 by weight 13.
+
+    2. Sum the individual results, divide the total by 23, and take the remainder.
+
+    3. Calculate the check letter from the result as follows:
+
+    0  = A;  1  = B;  2  = C;  3  = D;  4  = E;  5 = F;  6 = G;
+    7 = H;  8 = J;  9 = K;  10 = L;  11 = M;  12 = N;  13 = P;
+    14 = Q;  15 = R;  16 = T;  17 = U;  18 = V;  19 = W;  20 = X; Y = 21, Z = 22
+
+    Full list avaliable here https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/807381/UPN_Guide_1.2.pdf
+    """
+
+    df.reset_index(inplace=True)
+
+    df2 = df[["index", "UPN"]]
+    df2 = df2[(df2["UPN"].str.len() == 13) & df2["UPN"].notna()]
+
+    # the reference value is the first character of the UPN string.
+    df2["FIRST_CHAR"] = df2["UPN"].str[0]
+
+    # the last 12 characters have to be digits or else the UPN cannot be considered.
+    df2["LAST_C"] = df2["UPN"].str[1:]
+    df2["LAST_C"] = df2["LAST_C"].apply(lambda x: int(x) if str(x).isdigit() else pd.NA)
+    df2 = df2[df2["LAST_C"].notna()]
+
+    # calculate check value according to rule description.
+    df2["SUMMED"] = 0
+    for i in range(1, 13):
+        # previous check was important because non-digits cannot be converted to int and hence cannot be multiplied.
+        df2["SUMMED"] = (df2["SUMMED"] + (df2["UPN"].str[i].astype(int) * (i + 1))) % 23
+
+    # enumerate object yields (index_position, element) tuples for each element in the string.
+    check_map = enumerate(list("ABCDEFGHJKLMNPQRTUVWXYZ"))
+    check_map = dict((i, j) for i, j in check_map)
+
+    # Deduce the alphabet-letter representation of the calculated value based on rule description.
+    df2["CHECK_CHAR"] = df2["SUMMED"].map(check_map)
+    # select out all the rows where the calculated value does not match the expected value.
+    df2 = df2[df2["CHECK_CHAR"].astype(str) != df2["FIRST_CHAR"].astype(str)]
+    # restore the original index.
+    failing_indices = df2.set_index("index").index
+
+    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        {
+            "UPN": [
+                # These should pass
+                "A950000178301",  # 0 Valid format
+                pd.NA,  # 1
+                "H243278544154",  # 2 Valid format
+                "ASFFAGSVSV123",  # 3 Nonsense
+                "R325",  # 4 Nonsense
+                # These should fail
+                "R247962919251",  # 5 Wrong initial char
+                "X428558133462",  # 6 Wrong initial char
+                "X845212818005",
+            ]
+        }
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 2
+
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 5),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 6),
+    ]
+
+    assert result.definition.code == "1510"
+    assert (
+        result.definition.message == "UPN invalid (wrong check letter at character 1)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1520.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1520.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,129 +1,129 @@
-"""
-Rule number: '1520'
-Module: Child idenitifiers
-Rule details: Each pupil <UPN> (N00001) must be unique across all pupils in the extract. 
-Note: This rule should be evaluated at LA-level for imported data                                                                     
-Rule message: More than one record with the same UPN
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-UPN = ChildIdentifiers.UPN
-
-
-@rule_definition(
-    code="1520",
-    module=CINTable.ChildIdentifiers,
-    message="More than one record with the same UPN.",
-    affected_fields=[UPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-    df.index.name = "ROW_ID"
-
-    # Each pupil <UPN> (N00001) must be unique across all pupils in the extract
-
-    df = df[df[UPN].notna()]
-    df_issues = df[df.duplicated(subset=[UPN], keep=False)].reset_index()
-
-    link_id = tuple(
-        zip(
-            df_issues["LAchildID"],
-            df_issues[UPN],
-        )
-    )
-
-    df_issues["ERROR_ID"] = link_id
-
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_1(table=ChildIdentifiers, columns=[UPN], row_df=df_issues)
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "UPN": "1234",
-            },
-            {
-                "LAchildID": "child2",
-                "UPN": "1234",
-            },
-            {
-                "LAchildID": "child3",
-                "UPN": "12345",
-            },
-            {
-                "LAchildID": "child4",
-                "UPN": pd.NA,
-            },
-            {
-                "LAchildID": "child4",
-                "UPN": pd.NA,
-            },
-        ]
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    # The result contains a NamedTuple of issues encountered
-    issues = result.type1_issues
-
-    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [UPN]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "1234",
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    "1234",
-                ),
-                "ROW_ID": [1],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8840 with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "1520"
-    assert result.definition.message == "More than one record with the same UPN."
+"""
+Rule number: '1520'
+Module: Child idenitifiers
+Rule details: Each pupil <UPN> (N00001) must be unique across all pupils in the extract. 
+Note: This rule should be evaluated at LA-level for imported data                                                                     
+Rule message: More than one record with the same UPN
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+UPN = ChildIdentifiers.UPN
+
+
+@rule_definition(
+    code="1520",
+    module=CINTable.ChildIdentifiers,
+    message="More than one record with the same UPN.",
+    affected_fields=[UPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+    df.index.name = "ROW_ID"
+
+    # Each pupil <UPN> (N00001) must be unique across all pupils in the extract
+
+    df = df[df[UPN].notna()]
+    df_issues = df[df.duplicated(subset=[UPN], keep=False)].reset_index()
+
+    link_id = tuple(
+        zip(
+            df_issues["LAchildID"],
+            df_issues[UPN],
+        )
+    )
+
+    df_issues["ERROR_ID"] = link_id
+
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_1(table=ChildIdentifiers, columns=[UPN], row_df=df_issues)
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "UPN": "1234",
+            },
+            {
+                "LAchildID": "child2",
+                "UPN": "1234",
+            },
+            {
+                "LAchildID": "child3",
+                "UPN": "12345",
+            },
+            {
+                "LAchildID": "child4",
+                "UPN": pd.NA,
+            },
+            {
+                "LAchildID": "child4",
+                "UPN": pd.NA,
+            },
+        ]
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    # The result contains a NamedTuple of issues encountered
+    issues = result.type1_issues
+
+    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [UPN]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "1234",
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "1234",
+                ),
+                "ROW_ID": [1],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8840 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "1520"
+    assert result.definition.message == "More than one record with the same UPN."
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1530.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2023_24/rule_1530.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,133 +1,136 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-UPN = ChildIdentifiers.UPN
-
-
-@rule_definition(
-    code="1530",
-    module=CINTable.ChildIdentifiers,
-    message="UPN invalid (characters 2-4 not a recognised LA code)",
-    affected_fields=[UPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-    """
-    If <UPN> (N00001) present then characters 2-4 of <UPN> must be a valid post April 1998 LA code 
-    or a recognised ‘pseudo LA’ code 
-
-    001-005, 201-213, 301-320, 330-336, 340-344, 350-359, 370-373, 380-384, 390-394, 420, 660-681, 
-    701-708, 800-803, 805-808, 810-813, 815, 816, 820- 823, 825, 826, 830, 831, 835-837, 838-839, 
-    840, 841, 845, 846, 850-852, 855-857, 860, 861, 865-896, 908, 909, 916, 919, 921, 925, 
-    926, 928, 929, 931, 933, 935-938, 940-941
-    """
-    LA_list = []
-    LA_list.extend("00" + str(x) for x in range(1, 6))
-    LA_list.extend(range(201, 214))
-    LA_list.extend(range(301, 321))
-    LA_list.extend(range(330, 337))
-    LA_list.extend(range(340, 345))
-    LA_list.extend(range(350, 360))
-    LA_list.extend(range(370, 374))
-    LA_list.extend(range(380, 385))
-    LA_list.extend(range(390, 395))
-    LA_list.extend(range(660, 682))
-    LA_list.extend(range(701, 709))
-    LA_list.extend(range(800, 804))
-    LA_list.extend(range(805, 809))
-    LA_list.extend(range(810, 814))
-    LA_list.extend(range(820, 824))
-    LA_list.extend(range(835, 840))
-    LA_list.extend(range(850, 853))
-    LA_list.extend(range(855, 858))
-    LA_list.extend(range(865, 897))
-    LA_list.extend(range(935, 939))
-    LA_list.extend(range(940, 942))
-    LA_list.extend(
-        [
-            420,
-            815,
-            816,
-            825,
-            826,
-            830,
-            831,
-            840,
-            841,
-            845,
-            846,
-            860,
-            861,
-            908,
-            909,
-            916,
-            919,
-            921,
-            925,
-            926,
-            928,
-            929,
-            931,
-            933,
-        ]
-    )
-
-    LA_list = [str(x) for x in LA_list]
-
-    df.reset_index(inplace=True)
-    df2 = df[["index", "UPN"]]
-    df2 = df2[(df2["UPN"].str.len() == 13) & df2["UPN"].notna()]
-    df2["C2_to_C4"] = df2["UPN"].str[1:4]
-    df2 = df2[~df2["C2_to_C4"].isin(LA_list)]
-
-    failing_indices = df2.set_index("index").index
-
-    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        {
-            "UPN": [
-                # These should pass
-                "A38100178301",  # 0 In LA list
-                pd.NA,  # 1
-                "H003278544154",  # 2 In LA list
-                "R34",  # 3 Nonsense
-                # These should fail
-                "R421962919251",  # 4 Not in LA list
-                "X817558133462",  # 5 Not in LA list
-                "ASFFAGSVSV123",  # 6 Not in LA list, not numeric.
-            ]
-        }
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 4),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 5),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 6),
-    ]
-
-    assert result.definition.code == "1530"
-    assert (
-        result.definition.message
-        == "UPN invalid (characters 2-4 not a recognised LA code)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+UPN = ChildIdentifiers.UPN
+
+
+@rule_definition(
+    code=1530,
+    module=CINTable.ChildIdentifiers,
+    message="UPN invalid (characters 2-4 not a recognised LA code)",
+    affected_fields=[UPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+    """
+    If <UPN> (N00001) present then characters 2-4 of <UPN> must be a valid post April 1998 LA code 
+    or a recognised ‘pseudo LA’ code 
+
+    001-005, 201-213, 301-320, 330-336, 340-344, 350-359, 370-373, 380-384, 390-394, 420, 660-681, 
+    701-708, 800-803, 805-808, 810-813, 815, 816, 820- 823, 825, 826, 830, 831, 835-837, 838-839, 
+    840, 841, 845, 846, 850-852, 855-857, 860, 861, 865-896, 908, 909, 916, 919, 921, 925, 
+    926, 928, 929, 931, 933, 935-938, 940-941
+    """
+    LA_list = []
+    LA_list.extend("00" + str(x) for x in range(1, 6))
+    LA_list.extend(range(201, 214))
+    LA_list.extend(range(301, 321))
+    LA_list.extend(range(330, 337))
+    LA_list.extend(range(340, 345))
+    LA_list.extend(range(350, 360))
+    LA_list.extend(range(370, 374))
+    LA_list.extend(range(380, 385))
+    LA_list.extend(range(390, 395))
+    LA_list.extend(range(660, 682))
+    LA_list.extend(range(701, 709))
+    LA_list.extend(range(800, 804))
+    LA_list.extend(range(805, 809))
+    LA_list.extend(range(810, 814))
+    LA_list.extend(range(820, 824))
+    LA_list.extend(range(835, 840))
+    LA_list.extend(range(850, 853))
+    LA_list.extend(range(855, 858))
+    LA_list.extend(range(865, 897))
+    LA_list.extend(range(935, 939))
+    LA_list.extend(range(940, 942))
+    LA_list.extend(
+        [
+            420,
+            815,
+            816,
+            825,
+            826,
+            830,
+            831,
+            840,
+            841,
+            845,
+            846,
+            860,
+            861,
+            908,
+            909,
+            916,
+            919,
+            921,
+            925,
+            926,
+            928,
+            929,
+            931,
+            933,
+            942,
+            943,
+        ]
+    )
+
+    LA_list = [str(x) for x in LA_list]
+
+    df.reset_index(inplace=True)
+    df2 = df[["index", "UPN"]]
+    df2 = df2[(df2["UPN"].str.len() == 13) & df2["UPN"].notna()]
+    df2["C2_to_C4"] = df2["UPN"].str[1:4]
+    df2 = df2[~df2["C2_to_C4"].isin(LA_list)]
+
+    failing_indices = df2.set_index("index").index
+
+    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        {
+            "UPN": [
+                # These should pass
+                "A38100178301",  # 0 In LA list
+                pd.NA,  # 1
+                "H003278544154",  # 2 In LA list
+                "R34",  # 3 Nonsense
+                # These should fail
+                "R421962919251",  # 4 Not in LA list
+                "X817558133462",  # 5 Not in LA list
+                "ASFFAGSVSV123",  # 6 Not in LA list, not numeric.
+                "A94300178301",  # 942/3 added in 23/24 ruleset, data added to check correct addition to rule
+            ]
+        }
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 4),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 5),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 6),
+    ]
+
+    assert result.definition.code == 1530
+    assert (
+        result.definition.message
+        == "UPN invalid (characters 2-4 not a recognised LA code)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1540.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1540.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,61 +1,61 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-UPN = ChildIdentifiers.UPN
-
-
-@rule_definition(
-    code="1540",
-    module=CINTable.ChildIdentifiers,
-    message="UPN invalid (characters 5-12 not all numeric)",
-    affected_fields=[UPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    """
-    Returns indices of rows where character 5:12 of UPN contains non numerical characters.
-    Does this by:
-    Returning a boolean for the logic check to see is characters 5:12 contain only numerical characters.
-    Using the not operator (~) to return values as false where the logic returns true (and true if there are non-numeric characters).
-    Slicing df according to this criteria.
-    Returns indices of the rows of this df to failing_indices."""
-
-    df = data_container[ChildIdentifiers]
-
-    # If <UPN> (N00001) present Characters 5-12 of <UPN> must be numeric
-
-    #  df takes a slice of rows of df where the UPN column doesn't have Na/NaN values
-    df = df.loc[df["UPN"].notna()]
-
-    failing_indices = df[~df["UPN"].str[4:12].str.isdigit()].index
-
-    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        {"UPN": [pd.NA, "X000000000000", "X0000y0000000", "x0000000er00e0"]}
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-    assert len(issues) == 2
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 2),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 3),
-    ]
-
-    assert result.definition.code == "1540"
-    assert result.definition.message == "UPN invalid (characters 5-12 not all numeric)"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+UPN = ChildIdentifiers.UPN
+
+
+@rule_definition(
+    code="1540",
+    module=CINTable.ChildIdentifiers,
+    message="UPN invalid (characters 5-12 not all numeric)",
+    affected_fields=[UPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    """
+    Returns indices of rows where character 5:12 of UPN contains non numerical characters.
+    Does this by:
+    Returning a boolean for the logic check to see is characters 5:12 contain only numerical characters.
+    Using the not operator (~) to return values as false where the logic returns true (and true if there are non-numeric characters).
+    Slicing df according to this criteria.
+    Returns indices of the rows of this df to failing_indices."""
+
+    df = data_container[ChildIdentifiers]
+
+    # If <UPN> (N00001) present Characters 5-12 of <UPN> must be numeric
+
+    #  df takes a slice of rows of df where the UPN column doesn't have Na/NaN values
+    df = df.loc[df["UPN"].notna()]
+
+    failing_indices = df[~df["UPN"].str[4:12].str.isdigit()].index
+
+    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        {"UPN": [pd.NA, "X000000000000", "X0000y0000000", "x0000000er00e0"]}
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+    assert len(issues) == 2
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 2),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 3),
+    ]
+
+    assert result.definition.code == "1540"
+    assert result.definition.message == "UPN invalid (characters 5-12 not all numeric)"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1550.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1550.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,91 +1,91 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-UPN = ChildIdentifiers.UPN
-
-
-@rule_definition(
-    code="1550",
-    module=CINTable.ChildIdentifiers,
-    message="UPN invalid (character 13 not a recognised value)",
-    affected_fields=[UPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-
-    # if <UPN> (N00001)) present Character 13 of <UPN> must be numeric or A-Z omitting I, O and S
-    # Confirm length and value present
-    df2 = df[(df["UPN"].str.len() == 13) & df["UPN"].notna()]
-
-    # Valid characters
-    valid = [
-        "A",
-        "B",
-        "C",
-        "D",
-        "E",
-        "F",
-        "G",
-        "H",
-        "J",
-        "K",
-        "L",
-        "M",
-        "N",
-        "P",
-        "Q",
-        "R",
-        "T",
-        "U",
-        "V",
-        "W",
-        "Y",
-        "X",
-        "Z",
-        "0",
-        "1",
-        "2",
-        "3",
-        "4",
-        "5",
-        "6",
-        "7",
-        "8",
-        "9",
-    ]
-
-    failing_indices = df2[~df2["UPN"].str[12].isin(valid)].index
-
-    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        [["1234567891234"], ["123456789123I"], ["123456789123O"]], columns=[UPN]
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-    assert len(issues) == 2
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 1),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 2),
-    ]
-
-    assert result.definition.code == "1550"
-    assert (
-        result.definition.message == "UPN invalid (character 13 not a recognised value)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+UPN = ChildIdentifiers.UPN
+
+
+@rule_definition(
+    code="1550",
+    module=CINTable.ChildIdentifiers,
+    message="UPN invalid (character 13 not a recognised value)",
+    affected_fields=[UPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+
+    # if <UPN> (N00001)) present Character 13 of <UPN> must be numeric or A-Z omitting I, O and S
+    # Confirm length and value present
+    df2 = df[(df["UPN"].str.len() == 13) & df["UPN"].notna()]
+
+    # Valid characters
+    valid = [
+        "A",
+        "B",
+        "C",
+        "D",
+        "E",
+        "F",
+        "G",
+        "H",
+        "J",
+        "K",
+        "L",
+        "M",
+        "N",
+        "P",
+        "Q",
+        "R",
+        "T",
+        "U",
+        "V",
+        "W",
+        "Y",
+        "X",
+        "Z",
+        "0",
+        "1",
+        "2",
+        "3",
+        "4",
+        "5",
+        "6",
+        "7",
+        "8",
+        "9",
+    ]
+
+    failing_indices = df2[~df2["UPN"].str[12].isin(valid)].index
+
+    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        [["1234567891234"], ["123456789123I"], ["123456789123O"]], columns=[UPN]
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+    assert len(issues) == 2
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 1),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 2),
+    ]
+
+    assert result.definition.code == "1550"
+    assert (
+        result.definition.message == "UPN invalid (character 13 not a recognised value)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_1560Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1560Q.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,79 +1,79 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    RuleType,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-FormerUPN = ChildIdentifiers.FormerUPN
-
-
-@rule_definition(
-    code="1560Q",
-    module=CINTable.ChildIdentifiers,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend or provide a reason: Former UPN wrongly formatted",
-    affected_fields=[FormerUPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-
-    # <FormerUPN> (N00002) where present should be in the correct format, as specified in the data table
-
-    # Note, there are multiple types of former UPN, there are Temporary UPNs which end in a letter, and
-    # those where a child is assigned a UPN but then another is identified for them having been used previously.
-    # If this was only a check for temporary UPNs, it would check that the last character was a letter. However, it checks more generally.
-
-    #  filter rows of df where the UPN column doesn't have Na/NaN values
-    df = df.loc[df[FormerUPN].notna()]
-
-    # Flag locations where FormerUPN is not 13 characters long
-    check_length = df[FormerUPN].str.len() != 13
-    # Flag locations where FormerUPN's last twelve characters do not form a full digit
-    digit_within = ~df[FormerUPN].str[1:].str.isdigit()
-    # Flag locations where FormerUPN's first character is not a letter
-    check_edges = ~df[FormerUPN].str[0].str.isalpha()
-
-    failing_indices = df[check_length | digit_within | check_edges].index
-
-    rule_context.push_issue(
-        table=ChildIdentifiers, field=FormerUPN, row=failing_indices
-    )
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        [
-            {FormerUPN: pd.NA},  # 0 ignore
-            {FormerUPN: "X987654321231"},  # 1 pass
-            {FormerUPN: "X0000y0000007"},  # 2 fail non-alphabet within
-            {FormerUPN: "X98721238"},  # 3 wrong length
-            {FormerUPN: "E000215119000"},
-            {FormerUPN: "X987654321231"},  # 1 pass
-            {FormerUPN: "E000215119000"},
-        ]
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-    assert len(issues) == 2
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, FormerUPN, 2),
-        IssueLocator(CINTable.ChildIdentifiers, FormerUPN, 3),
-    ]
-
-    assert result.definition.code == "1560Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend or provide a reason: Former UPN wrongly formatted"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    RuleType,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+FormerUPN = ChildIdentifiers.FormerUPN
+
+
+@rule_definition(
+    code="1560Q",
+    module=CINTable.ChildIdentifiers,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend or provide a reason: Former UPN wrongly formatted",
+    affected_fields=[FormerUPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+
+    # <FormerUPN> (N00002) where present should be in the correct format, as specified in the data table
+
+    # Note, there are multiple types of former UPN, there are Temporary UPNs which end in a letter, and
+    # those where a child is assigned a UPN but then another is identified for them having been used previously.
+    # If this was only a check for temporary UPNs, it would check that the last character was a letter. However, it checks more generally.
+
+    #  filter rows of df where the UPN column doesn't have Na/NaN values
+    df = df.loc[df[FormerUPN].notna()]
+
+    # Flag locations where FormerUPN is not 13 characters long
+    check_length = df[FormerUPN].str.len() != 13
+    # Flag locations where FormerUPN's last twelve characters do not form a full digit
+    digit_within = ~df[FormerUPN].str[1:].str.isdigit()
+    # Flag locations where FormerUPN's first character is not a letter
+    check_edges = ~df[FormerUPN].str[0].str.isalpha()
+
+    failing_indices = df[check_length | digit_within | check_edges].index
+
+    rule_context.push_issue(
+        table=ChildIdentifiers, field=FormerUPN, row=failing_indices
+    )
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        [
+            {FormerUPN: pd.NA},  # 0 ignore
+            {FormerUPN: "X987654321231"},  # 1 pass
+            {FormerUPN: "X0000y0000007"},  # 2 fail non-alphabet within
+            {FormerUPN: "X98721238"},  # 3 wrong length
+            {FormerUPN: "E000215119000"},
+            {FormerUPN: "X987654321231"},  # 1 pass
+            {FormerUPN: "E000215119000"},
+        ]
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+    assert len(issues) == 2
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, FormerUPN, 2),
+        IssueLocator(CINTable.ChildIdentifiers, FormerUPN, 3),
+    ]
+
+    assert result.definition.code == "1560Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend or provide a reason: Former UPN wrongly formatted"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2883.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2883.py`

 * *Ordering differences only*

 * *Files 26% similar despite different names*

```diff
@@ -1,156 +1,156 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-LAchildID = ChildProtectionPlans.LAchildID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-CINdetails = CINTable.CINdetails
-DateOfInitialCPC = CINdetails.DateOfInitialCPC
-
-Section47 = CINTable.Section47
-
-
-# define characteristics of rule
-@rule_definition(
-    code="2883",
-    # module is table that seems central to the condition.
-    module=CINTable.ChildProtectionPlans,
-    message="There are more child protection plans starting than initial conferences taking place",
-    affected_fields=[CPPstartDate, DateOfInitialCPC],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cpp = data_container[ChildProtectionPlans]
-    df_cin = data_container[CINdetails]
-    df_47 = data_container[Section47]
-
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # Within a Local Authority, count the number of <CPPStartDate> (N00105) where a date is present and within [Period_of_Census]. This value should be less than or equal to the sum of:
-    # a) the count of <DateOfInitialCPC> (N00110) on CIN Details module where a date is present and within [Period_of_Census], plus
-    # b) the count of <DateOfInitialCPC> on the S47 module where a date is present and within [Period_of_Census].
-
-    # filter and count CPPstartDate
-    present_cpp = df_cpp[CPPstartDate].notna()
-    within_census_cpp = (df_cpp[CPPstartDate] >= collection_start) & (
-        df_cpp[CPPstartDate] <= collection_end
-    )
-    df_cpp = df_cpp[present_cpp & within_census_cpp]
-    num_cpp = len(df_cpp)
-
-    # filter and count DateOfInitialCPC in CINdetails
-    present_cin = df_cin[DateOfInitialCPC].notna()
-    within_census_cin = (df_cin[DateOfInitialCPC] >= collection_start) & (
-        df_cin[DateOfInitialCPC] <= collection_end
-    )
-    df_cin = df_cin[present_cin & within_census_cin]
-    num_cin = len(df_cin)
-
-    # filter and count DateOfInitialCPC in Section47
-    present_47 = df_47[DateOfInitialCPC].notna()
-    within_census_47 = (df_47[DateOfInitialCPC] >= collection_start) & (
-        df_47[DateOfInitialCPC] <= collection_end
-    )
-    df_47 = df_47[present_47 & within_census_47]
-    num_47 = len(df_47)
-
-    if num_cpp > (num_cin + num_47):
-        rule_context.push_la_level(
-            rule_context.definition.code, rule_context.definition.message
-        )
-    else:
-        pass
-
-
-def test_validate():
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # collection_start is 01/04/2000
-    )
-    sample_cpp = pd.DataFrame(
-        [  # num_cpp = 3
-            {
-                LAchildID: "child1",
-                CPPstartDate: "26/05/2000",
-            },
-            {
-                LAchildID: "child1",  # checks that values are considered independently and no grouping is done.
-                CPPstartDate: "27/06/2000",
-            },
-            {
-                LAchildID: "child2",
-                CPPstartDate: "26/05/2004",  # not considered: out of period of census
-            },
-            {
-                LAchildID: "child3",
-                CPPstartDate: "26/05/2000",
-            },
-            {
-                LAchildID: "child1",
-                CPPstartDate: pd.NA,  # ignore: absent
-            },
-        ]
-    )
-
-    sample_cin = pd.DataFrame(
-        [  # num_cin = 0
-            {
-                LAchildID: "child2",
-                DateOfInitialCPC: "26/05/2004",  # not considered: out of period of census
-            },
-            {
-                LAchildID: "child1",
-                DateOfInitialCPC: pd.NA,  # ignore: absent
-            },
-        ]
-    )
-
-    sample_section47 = pd.DataFrame(
-        [  # num_47 = 2
-            {
-                LAchildID: "child1",
-                DateOfInitialCPC: "26/05/2000",
-            },
-            {
-                LAchildID: "child1",  # checks that values are considered independently and no grouping is done.
-                DateOfInitialCPC: "27/06/2000",
-            },
-        ]
-    )
-
-    sample_cpp[CPPstartDate] = pd.to_datetime(
-        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin[DateOfInitialCPC] = pd.to_datetime(
-        sample_cin[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_section47[DateOfInitialCPC] = pd.to_datetime(
-        sample_section47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            CINdetails: sample_cin,
-            Section47: sample_section47,
-            Header: sample_header,
-        },
-    )
-
-    issues = result.la_issues
-    assert issues == (
-        "2883",
-        "There are more child protection plans starting than initial conferences taking place",
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+LAchildID = ChildProtectionPlans.LAchildID
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+CINdetails = CINTable.CINdetails
+DateOfInitialCPC = CINdetails.DateOfInitialCPC
+
+Section47 = CINTable.Section47
+
+
+# define characteristics of rule
+@rule_definition(
+    code="2883",
+    # module is table that seems central to the condition.
+    module=CINTable.ChildProtectionPlans,
+    message="There are more child protection plans starting than initial conferences taking place",
+    affected_fields=[CPPstartDate, DateOfInitialCPC],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cpp = data_container[ChildProtectionPlans]
+    df_cin = data_container[CINdetails]
+    df_47 = data_container[Section47]
+
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # Within a Local Authority, count the number of <CPPStartDate> (N00105) where a date is present and within [Period_of_Census]. This value should be less than or equal to the sum of:
+    # a) the count of <DateOfInitialCPC> (N00110) on CIN Details module where a date is present and within [Period_of_Census], plus
+    # b) the count of <DateOfInitialCPC> on the S47 module where a date is present and within [Period_of_Census].
+
+    # filter and count CPPstartDate
+    present_cpp = df_cpp[CPPstartDate].notna()
+    within_census_cpp = (df_cpp[CPPstartDate] >= collection_start) & (
+        df_cpp[CPPstartDate] <= collection_end
+    )
+    df_cpp = df_cpp[present_cpp & within_census_cpp]
+    num_cpp = len(df_cpp)
+
+    # filter and count DateOfInitialCPC in CINdetails
+    present_cin = df_cin[DateOfInitialCPC].notna()
+    within_census_cin = (df_cin[DateOfInitialCPC] >= collection_start) & (
+        df_cin[DateOfInitialCPC] <= collection_end
+    )
+    df_cin = df_cin[present_cin & within_census_cin]
+    num_cin = len(df_cin)
+
+    # filter and count DateOfInitialCPC in Section47
+    present_47 = df_47[DateOfInitialCPC].notna()
+    within_census_47 = (df_47[DateOfInitialCPC] >= collection_start) & (
+        df_47[DateOfInitialCPC] <= collection_end
+    )
+    df_47 = df_47[present_47 & within_census_47]
+    num_47 = len(df_47)
+
+    if num_cpp > (num_cin + num_47):
+        rule_context.push_la_level(
+            rule_context.definition.code, rule_context.definition.message
+        )
+    else:
+        pass
+
+
+def test_validate():
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2001"}]  # collection_start is 01/04/2000
+    )
+    sample_cpp = pd.DataFrame(
+        [  # num_cpp = 3
+            {
+                LAchildID: "child1",
+                CPPstartDate: "26/05/2000",
+            },
+            {
+                LAchildID: "child1",  # checks that values are considered independently and no grouping is done.
+                CPPstartDate: "27/06/2000",
+            },
+            {
+                LAchildID: "child2",
+                CPPstartDate: "26/05/2004",  # not considered: out of period of census
+            },
+            {
+                LAchildID: "child3",
+                CPPstartDate: "26/05/2000",
+            },
+            {
+                LAchildID: "child1",
+                CPPstartDate: pd.NA,  # ignore: absent
+            },
+        ]
+    )
+
+    sample_cin = pd.DataFrame(
+        [  # num_cin = 0
+            {
+                LAchildID: "child2",
+                DateOfInitialCPC: "26/05/2004",  # not considered: out of period of census
+            },
+            {
+                LAchildID: "child1",
+                DateOfInitialCPC: pd.NA,  # ignore: absent
+            },
+        ]
+    )
+
+    sample_section47 = pd.DataFrame(
+        [  # num_47 = 2
+            {
+                LAchildID: "child1",
+                DateOfInitialCPC: "26/05/2000",
+            },
+            {
+                LAchildID: "child1",  # checks that values are considered independently and no grouping is done.
+                DateOfInitialCPC: "27/06/2000",
+            },
+        ]
+    )
+
+    sample_cpp[CPPstartDate] = pd.to_datetime(
+        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin[DateOfInitialCPC] = pd.to_datetime(
+        sample_cin[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_section47[DateOfInitialCPC] = pd.to_datetime(
+        sample_section47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            CINdetails: sample_cin,
+            Section47: sample_section47,
+            Header: sample_header,
+        },
+    )
+
+    issues = result.la_issues
+    assert issues == (
+        "2883",
+        "There are more child protection plans starting than initial conferences taking place",
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2884.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2884.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,227 +1,227 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-CINdetails = CINTable.CINdetails
-Section47 = CINTable.Section47
-
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-DateOfInitialCPC = Section47.DateOfInitialCPC
-DateOfInitialCPC = CINdetails.DateOfInitialCPC
-
-
-@rule_definition(
-    code="2884",
-    module=CINTable.Section47,
-    message="An initial child protection conference is recorded at both the S47 and CIN Details level and it should only be recorded in one",
-    affected_fields=[
-        DateOfInitialCPC,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_47 = data_container[Section47].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    df_47.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_47.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    merged_df = df_cin.merge(
-        df_47,
-        on=[LAchildID],
-        suffixes=["_cin", "_47"],
-    )
-
-    condition = merged_df["DateOfInitialCPC_cin"] == merged_df["DateOfInitialCPC_47"]
-    merged_df = merged_df[condition].reset_index()
-
-    merged_df["ERROR_ID"] = tuple(
-        zip(
-            merged_df[LAchildID],
-            merged_df["CINdetailsID_47"],
-            merged_df["DateOfInitialCPC_cin"],
-        )
-    )
-
-    df_47_issues = (
-        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=Section47, columns=[DateOfInitialCPC], row_df=df_47_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[DateOfInitialCPC], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    sample_section47 = pd.DataFrame(
-        [
-            {  # 0 fail: datecpc == (child1, cinID2)'s datecpc in cindetails table
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 1 fail: datecpc == (child1, cinID2)'s datecpc in cindetails table
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {  # 2
-                "LAchildID": "child2",
-                "DateOfInitialCPC": "30/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 3
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "27/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 4 fail: datecpc == (child3, cinID2)'s datecpc in cindetails table
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {  # 5 fail: datecpc == (child3, cinID2)'s datecpc in cindetails table
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID3",
-            },
-            {  # 6
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {  # 0
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/10/1999",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 1 fail
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {  # 2
-                "LAchildID": "child2",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 3
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "28/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 4 fail
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {  # 5
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2003",
-                "CINdetailsID": "cinID3",
-            },
-            {  # 6
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "14/03/2001",
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
-        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin_details["DateOfInitialCPC"] = pd.to_datetime(
-        sample_cin_details["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            Section47: sample_section47,
-            CINdetails: sample_cin_details,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    issue_columns = issues.columns
-    assert issue_columns == [DateOfInitialCPC]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 4
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID1",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID2",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID2",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID3",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "2884"
-    assert (
-        result.definition.message
-        == "An initial child protection conference is recorded at both the S47 and CIN Details level and it should only be recorded in one"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+CINdetails = CINTable.CINdetails
+Section47 = CINTable.Section47
+
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+DateOfInitialCPC = Section47.DateOfInitialCPC
+DateOfInitialCPC = CINdetails.DateOfInitialCPC
+
+
+@rule_definition(
+    code="2884",
+    module=CINTable.Section47,
+    message="An initial child protection conference is recorded at both the S47 and CIN Details level and it should only be recorded in one",
+    affected_fields=[
+        DateOfInitialCPC,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_47 = data_container[Section47].copy()
+    df_cin = data_container[CINdetails].copy()
+
+    df_47.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    df_47.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    merged_df = df_cin.merge(
+        df_47,
+        on=[LAchildID],
+        suffixes=["_cin", "_47"],
+    )
+
+    condition = merged_df["DateOfInitialCPC_cin"] == merged_df["DateOfInitialCPC_47"]
+    merged_df = merged_df[condition].reset_index()
+
+    merged_df["ERROR_ID"] = tuple(
+        zip(
+            merged_df[LAchildID],
+            merged_df["CINdetailsID_47"],
+            merged_df["DateOfInitialCPC_cin"],
+        )
+    )
+
+    df_47_issues = (
+        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_cin_issues = (
+        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=Section47, columns=[DateOfInitialCPC], row_df=df_47_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[DateOfInitialCPC], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    sample_section47 = pd.DataFrame(
+        [
+            {  # 0 fail: datecpc == (child1, cinID2)'s datecpc in cindetails table
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 1 fail: datecpc == (child1, cinID2)'s datecpc in cindetails table
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {  # 2
+                "LAchildID": "child2",
+                "DateOfInitialCPC": "30/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 3
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "27/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 4 fail: datecpc == (child3, cinID2)'s datecpc in cindetails table
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {  # 5 fail: datecpc == (child3, cinID2)'s datecpc in cindetails table
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID3",
+            },
+            {  # 6
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+    sample_cin_details = pd.DataFrame(
+        [
+            {  # 0
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/10/1999",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 1 fail
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {  # 2
+                "LAchildID": "child2",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 3
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "28/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 4 fail
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {  # 5
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2003",
+                "CINdetailsID": "cinID3",
+            },
+            {  # 6
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "14/03/2001",
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
+        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin_details["DateOfInitialCPC"] = pd.to_datetime(
+        sample_cin_details["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            Section47: sample_section47,
+            CINdetails: sample_cin_details,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    issue_columns = issues.columns
+    assert issue_columns == [DateOfInitialCPC]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 4
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID2",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID2",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID3",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "2884"
+    assert (
+        result.definition.message
+        == "An initial child protection conference is recorded at both the S47 and CIN Details level and it should only be recorded in one"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2885.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2885.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,613 +1,613 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CINdetails = CINTable.CINdetails
-Section47 = CINTable.Section47
-
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-LAchildID = ChildProtectionPlans.LAchildID
-CINdetailsID = ChildProtectionPlans.CINdetailsID
-DateOfInitialCPC = Section47.DateOfInitialCPC
-
-# Reference date in header is needed to define the period of census.
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '2885'
-    code="2885",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child protection plan shown as starting a different day to the initial child protection conference.",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        CPPstartDate,
-        DateOfInitialCPC,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Replace ChildProtectionPlans with the name of the table you need.
-    df_cpp = data_container[ChildProtectionPlans]
-    df_47 = data_container[Section47]
-    df_cin = data_container[CINdetails]
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cpp.index.name = "ROW_ID"
-    df_47.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-
-    df_cpp.reset_index(inplace=True)
-    df_47.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # get collection period
-    header = data_container[Header]
-    ref_date_series = header[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If present and if <CPPStartDate> (N00105) falls within [Period_Of_Census], then the <CPPStartDate> (N00105) should equal either:
-    # a) a Section47 module <DateOfInitialCPC> (N00110), or
-    # b) a CINDetails module <DateOfInitialCPC> (N00110) if there is no associated Section 47 record.
-
-    start_date_present = df_cpp[CPPstartDate].notna()
-    within_period = (df_cpp[CPPstartDate] >= collection_start) & (
-        df_cpp[CPPstartDate] <= collection_end
-    )
-    df_cpp = df_cpp[start_date_present & within_period]
-
-    # left merge means that only the filtered cpp children will be considered and there is no possibility of additonal children coming in from other tables.
-
-    # get only the section47 rows where cppstartdate exists and is within period.
-    df_cpp_47 = df_cpp.merge(
-        df_47, on=[LAchildID, CINdetailsID], how="inner", suffixes=["_cpp", "_47"]
-    )
-
-    # FIND LOCATIONS THAT FAIL THE RULE
-
-    # Section47 table: if CPPstartDate matches any DateOfInitialCPC within its CIN module, all DateOfInitialCPCs should pass in that CIN module.
-
-    # locations with equal dates surely pass.
-    df_cpp_47_pass = df_cpp_47[df_cpp_47[CPPstartDate] == df_cpp_47[DateOfInitialCPC]]
-    # locations with unequal dates could fail.
-    df_cpp_47_failable = df_cpp_47[
-        df_cpp_47[CPPstartDate] != df_cpp_47[DateOfInitialCPC]
-    ]
-    # the failable locations that are not found in a CIN module where a DateOfInitialCPC passes, surely fail.
-    df_cpp_47_failable["ERROR_ID"] = tuple(
-        zip(df_cpp_47_failable[LAchildID], df_cpp_47_failable[CINdetailsID])
-    )
-    df_cpp_47_pass["ERROR_ID"] = tuple(
-        zip(df_cpp_47_pass[LAchildID], df_cpp_47_pass[CINdetailsID])
-    )
-    df_cpp_47_fail = df_cpp_47_failable[
-        ~(df_cpp_47_failable["ERROR_ID"].isin(df_cpp_47_pass["ERROR_ID"]))
-    ]
-
-    # One CPPstartDate's pass should not affect the other. Create a separate reference dataset for CPPstartDate failing locations.
-    # Redo the above steps to create a dataset where a CPPstartDate is only removed from failable if its LAchildID-CINdetails-CPPstartDate is found to pass.
-    df_cpp_47_failable["ERROR_startdate"] = tuple(
-        zip(
-            df_cpp_47_failable[LAchildID],
-            df_cpp_47_failable[CINdetailsID],
-            df_cpp_47_failable[CPPstartDate],
-        )
-    )
-    df_cpp_47_pass["ERROR_startdate"] = tuple(
-        zip(
-            df_cpp_47_pass[LAchildID],
-            df_cpp_47_pass[CINdetailsID],
-            df_cpp_47_pass[CPPstartDate],
-        )
-    )
-    df_cpp_47_startdate_fail = df_cpp_47_failable[
-        ~(df_cpp_47_failable["ERROR_startdate"].isin(df_cpp_47_pass["ERROR_startdate"]))
-    ]
-
-    # CIN table: if CPPstartDate matches any DateOfInitialCPC within its CIN module, all DateOfInitialCPCs should pass in that CIN module.
-
-    df_cpp_cin = df_cpp.merge(
-        df_cin, on=[LAchildID, CINdetailsID], how="left", suffixes=["_cpp", "_cin"]
-    )
-    df_cpp_cin_pass = df_cpp_cin[
-        df_cpp_cin[CPPstartDate] == df_cpp_cin[DateOfInitialCPC]
-    ]
-    df_cpp_cin_failable = df_cpp_cin[
-        df_cpp_cin[CPPstartDate] != df_cpp_cin[DateOfInitialCPC]
-    ]
-
-    df_cpp_cin_failable["ERROR_ID"] = tuple(
-        zip(df_cpp_cin_failable[LAchildID], df_cpp_cin_failable[CINdetailsID])
-    )
-    df_cpp_cin_pass["ERROR_ID"] = tuple(
-        zip(df_cpp_cin_pass[LAchildID], df_cpp_cin_pass[CINdetailsID])
-    )
-    df_cpp_cin_fail = df_cpp_cin_failable[
-        ~(df_cpp_cin_failable["ERROR_ID"].isin(df_cpp_cin_pass["ERROR_ID"]))
-    ]
-
-    df_cpp_cin_failable["ERROR_startdate"] = tuple(
-        zip(
-            df_cpp_cin_failable[LAchildID],
-            df_cpp_cin_failable[CINdetailsID],
-            df_cpp_cin_failable[CPPstartDate],
-        )
-    )
-    df_cpp_cin_pass["ERROR_startdate"] = tuple(
-        zip(
-            df_cpp_cin_pass[LAchildID],
-            df_cpp_cin_pass[CINdetailsID],
-            df_cpp_cin_pass[CPPstartDate],
-        )
-    )
-    df_cpp_cin_startdate_fail = df_cpp_cin_failable[
-        ~(
-            df_cpp_cin_failable["ERROR_startdate"].isin(
-                df_cpp_cin_pass["ERROR_startdate"]
-            )
-        )
-    ]
-
-    # Since the condition is to check the CIN table only if the LAchildID-CINdetailID is absent in Section47,
-    # only those failing locations that are absent in section47 table should be flagged in the cindetails table. Locations that are flagged in section47 don't need to re-flag here.
-
-    # create an ID that cin groups can be identified by.
-    df_47["ERROR_ID"] = tuple(zip(df_47[LAchildID], df_47[CINdetailsID]))
-    df_cpp_cin_fail_no_47 = df_cpp_cin_fail[
-        ~(df_cpp_cin_fail["ERROR_ID"].isin(df_47["ERROR_ID"]))
-    ]
-    # do same for the cppstartdate identifier table.
-    df_cpp_cin_startdate_fail_no47 = df_cpp_cin_startdate_fail[
-        ~(df_cpp_cin_startdate_fail["ERROR_ID"].isin(df_47["ERROR_ID"]))
-    ]
-
-    # MAP FAILING LOCATIONS TO THEIR ORIGINAL TABLES.
-    df_47_issues = df_47[df_47["ROW_ID"].isin(df_cpp_47_fail["ROW_ID_47"])]
-    df_47_issues = (
-        df_47_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cin["ERROR_ID"] = tuple(zip(df_cin[LAchildID], df_cin[CINdetailsID]))
-    df_cin_issues = df_cin[df_cin["ROW_ID"].isin(df_cpp_cin_fail_no_47["ROW_ID_cin"])]
-    df_cin_issues = (
-        df_cin_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cpp["ERROR_ID"] = tuple(
-        zip(df_cpp[LAchildID], df_cpp[CINdetailsID], df_cpp[CPPstartDate])
-    )
-    df_cpp_issues = df_cpp[
-        (df_cpp["ROW_ID"].isin(df_cpp_47_startdate_fail["ROW_ID_cpp"]))
-        | (df_cpp["ROW_ID"].isin(df_cpp_cin_startdate_fail_no47["ROW_ID_cpp"]))
-    ]
-    df_cpp_issues = (
-        df_cpp_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # In this case, the rule is checked for each CPPstartDate, in each CINplanDates group (differentiated by CINdetailsID), in each child (differentiated by LAchildID)
-    # However, the cin and section47 locations fail/pass per group so LAchildID-CINdetailsID is used to identify them.
-    # On the other hand, CPPstartDate locations fail/pass independently so a combination of LAchildID, CINdetailsID and CPPstartDate identifies a cpp error instance.
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=Section47, columns=[DateOfInitialCPC], row_df=df_47_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[DateOfInitialCPC], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_cpp = pd.DataFrame(
-        [  # child1: Simulates multiple cin modules with one out of census period, and multiple CPPs within the same CIN.
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "CPPstartDate": "26/05/2021",  #  passes in section47
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",  # simulates multiple CPPs with same LAchildID-CINdetailsID where some fail, some pass.
-                "CPPstartDate": "26/06/2021",  #  # fail. fails both section47 and cin
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID2",
-                "CPPstartDate": "27/06/2002",  # ignore. would've failed but ignored. Not in period of census
-            },
-            # child2: fail in section47, pass in cin
-            {
-                "LAchildID": "child2",
-                "CINdetailsID": "cinID1",
-                "CPPstartDate": "26/05/2021",  # fail. fails in section47, pass in cin not considered.
-            },
-            # child3: multiple cin details modules.
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID1",
-                "CPPstartDate": "26/05/2021",  # fail. fails in both section47 and cin
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID2",
-                "CPPstartDate": pd.NA,  # ignore. cppstartdate is absent
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID3",
-                "CPPstartDate": "07/02/2022",  # fail. fails both section47 and cin
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID4",
-                "CPPstartDate": "14/03/2022",  # fail. fails in section47, pass in cin not considered.
-            },
-            # child 5: date present in section47 and absent in cin
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "cinID4",
-                "CPPstartDate": "19/07/2021",  # passes in section47
-            },
-            # child 6: no DateOfInitialCPC recorded in cin or section47 table
-            {
-                "LAchildID": "child6",
-                "CINdetailsID": "cinID4",
-                "CPPstartDate": "19/07/2021",  # fail
-            },
-            # child 8: multiple section47s in the same cin module where some pass and others fail.
-            {
-                "LAchildID": "child8",
-                "CINdetailsID": "cinID1",
-                "CPPstartDate": "20/10/2021",  # passes in section_47
-            },
-            # child 9: present in cin, absent in section47
-            {
-                "LAchildID": "child9",
-                "CINdetailsID": "cinID1",
-                "CPPstartDate": "20/10/2021",  # passes in cin
-            },
-        ]
-    )
-    sample_section47 = pd.DataFrame(
-        [
-            {  # 0 pass
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2021",  # pass. same as cppstartdate
-                "CINdetailsID": "cinID1",
-            },
-            {  # 1 ignored
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate not in period of census
-                "CINdetailsID": "cinID2",
-            },
-            {  # 2 pass
-                "LAchildID": "child2",
-                "DateOfInitialCPC": "30/05/2021",  # fail. not the same
-                "CINdetailsID": "cinID1",
-            },
-            {  # 4 absent, ignored
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate is absent.
-                "CINdetailsID": "cinID2",
-            },
-            {  # 5 fail
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2021",  # fail. not the same
-                "CINdetailsID": "cinID3",
-            },
-            {  # 6 pass
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,  # fail. not the same
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child5",
-                "DateOfInitialCPC": "19/07/2021",  # pass. same as cppstartdate
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child5",
-                "DateOfInitialCPC": pd.NA,  # pass since other section47 in same modeule passes.
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child6",
-                "DateOfInitialCPC": pd.NA,  # fail. not the same
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child8",
-                "DateOfInitialCPC": "20/10/2021",  # pass. same as cpp_start_date
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child8",
-                "DateOfInitialCPC": "22/07/2021",  # pass since other section47 in the same CINmodule passes.
-                "CINdetailsID": "cinID1",
-            },
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {  # 0 pass
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/10/2020",  # ignore fail. not the same but present in section47 table
-                "CINdetailsID": "cinID1",
-            },
-            {  # 1 ignore
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate not in period of census
-                "CINdetailsID": "cinID2",
-            },
-            {  # 2 pass
-                "LAchildID": "child2",
-                "DateOfInitialCPC": "26/05/2021",  # ignore fail. could've passed but present in section47
-                "CINdetailsID": "cinID1",
-            },
-            {  # 3 fail
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "28/05/2021",  # fail. not the same and no corresponding section47
-                "CINdetailsID": "cinID1",
-            },
-            {  # 4 ignore
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate is absent
-                "CINdetailsID": "cinID2",
-            },
-            {  # 5 fail
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2003",  # ignore fail. not the same and has corresponding section47.
-                "CINdetailsID": "cinID3",
-            },
-            {  # 6 pass
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "14/03/2022",  # ignore fail. could've passed but present in section47
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child5",
-                "DateOfInitialCPC": pd.NA,  # ignore fail. not the same  and has corresponding section47.
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child6",
-                "DateOfInitialCPC": pd.NA,  # ignore fail. not the same and has corresponding section47
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child7",
-                "DateOfInitialCPC": pd.NA,  # ignore. not present in cpp table.
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child8",
-                "DateOfInitialCPC": pd.NA,  # passes in section47
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child9",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": "20/10/2021",  # passes in cin
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cpp[CPPstartDate] = pd.to_datetime(
-        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_section47[DateOfInitialCPC] = pd.to_datetime(
-        sample_section47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin_details[DateOfInitialCPC] = pd.to_datetime(
-        sample_cin_details[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            Section47: sample_section47,
-            CINdetails: sample_cin_details,
-            Header: sample_header,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 3
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-
-    # pick any table and check it's values. the tuple in location 1 will contain the Section47 columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Section47 with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [DateOfInitialCPC]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 4
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    "cinID1",  # CINdetailsID,
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID3",
-                ),
-                "ROW_ID": [4],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID4",
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "child6",
-                    "cinID4",
-                ),
-                "ROW_ID": [8],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # check table 2
-    issues2 = issues_list[2]
-    issue_table2 = issues2.table
-    assert issue_table2 == CINdetails
-
-    issue_columns2 = issues2.columns
-    assert issue_columns2 == [DateOfInitialCPC]
-
-    issue_rows2 = issues2.row_df
-    assert len(issue_rows2) == 1
-    assert isinstance(issue_rows2, pd.DataFrame)
-    assert issue_rows2.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df2 = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID1",  # CINdetailsID,
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-    assert issue_rows2.equals(expected_df2)
-
-    # check table 0
-    issues0 = issues_list[0]
-    issue_table0 = issues0.table
-    assert issue_table0 == ChildProtectionPlans
-
-    issue_columns0 = issues0.columns
-    assert issue_columns0 == [CPPstartDate]
-
-    issue_rows0 = issues0.row_df
-    assert len(issue_rows0) == 6
-    assert isinstance(issue_rows0, pd.DataFrame)
-    assert issue_rows0.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df0 = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "cinID1",  # CINdetailsID,
-                    pd.to_datetime("26/06/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    "cinID1",  # CINdetailsID,
-                    pd.to_datetime("26/05/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID1",  # CINdetailsID,
-                    pd.to_datetime("26/05/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID3",  # CINdetailsID,
-                    pd.to_datetime("07/02/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [6],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID4",  # CINdetailsID,
-                    pd.to_datetime("14/03/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [7],
-            },
-            {
-                "ERROR_ID": (
-                    "child6",  # ChildID
-                    "cinID4",  # CINdetailsID,
-                    pd.to_datetime("19/07/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [9],
-            },
-        ]
-    )
-    assert issue_rows0.equals(expected_df0)
-
-    # Confirm that the rule details were properly pushed through.
-    assert result.definition.code == "2885"
-    assert (
-        result.definition.message
-        == "Child protection plan shown as starting a different day to the initial child protection conference."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CINdetails = CINTable.CINdetails
+Section47 = CINTable.Section47
+
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+LAchildID = ChildProtectionPlans.LAchildID
+CINdetailsID = ChildProtectionPlans.CINdetailsID
+DateOfInitialCPC = Section47.DateOfInitialCPC
+
+# Reference date in header is needed to define the period of census.
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '2885'
+    code="2885",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child protection plan shown as starting a different day to the initial child protection conference.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        CPPstartDate,
+        DateOfInitialCPC,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace ChildProtectionPlans with the name of the table you need.
+    df_cpp = data_container[ChildProtectionPlans]
+    df_47 = data_container[Section47]
+    df_cin = data_container[CINdetails]
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cpp.index.name = "ROW_ID"
+    df_47.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+
+    df_cpp.reset_index(inplace=True)
+    df_47.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # get collection period
+    header = data_container[Header]
+    ref_date_series = header[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If present and if <CPPStartDate> (N00105) falls within [Period_Of_Census], then the <CPPStartDate> (N00105) should equal either:
+    # a) a Section47 module <DateOfInitialCPC> (N00110), or
+    # b) a CINDetails module <DateOfInitialCPC> (N00110) if there is no associated Section 47 record.
+
+    start_date_present = df_cpp[CPPstartDate].notna()
+    within_period = (df_cpp[CPPstartDate] >= collection_start) & (
+        df_cpp[CPPstartDate] <= collection_end
+    )
+    df_cpp = df_cpp[start_date_present & within_period]
+
+    # left merge means that only the filtered cpp children will be considered and there is no possibility of additonal children coming in from other tables.
+
+    # get only the section47 rows where cppstartdate exists and is within period.
+    df_cpp_47 = df_cpp.merge(
+        df_47, on=[LAchildID, CINdetailsID], how="inner", suffixes=["_cpp", "_47"]
+    )
+
+    # FIND LOCATIONS THAT FAIL THE RULE
+
+    # Section47 table: if CPPstartDate matches any DateOfInitialCPC within its CIN module, all DateOfInitialCPCs should pass in that CIN module.
+
+    # locations with equal dates surely pass.
+    df_cpp_47_pass = df_cpp_47[df_cpp_47[CPPstartDate] == df_cpp_47[DateOfInitialCPC]]
+    # locations with unequal dates could fail.
+    df_cpp_47_failable = df_cpp_47[
+        df_cpp_47[CPPstartDate] != df_cpp_47[DateOfInitialCPC]
+    ]
+    # the failable locations that are not found in a CIN module where a DateOfInitialCPC passes, surely fail.
+    df_cpp_47_failable["ERROR_ID"] = tuple(
+        zip(df_cpp_47_failable[LAchildID], df_cpp_47_failable[CINdetailsID])
+    )
+    df_cpp_47_pass["ERROR_ID"] = tuple(
+        zip(df_cpp_47_pass[LAchildID], df_cpp_47_pass[CINdetailsID])
+    )
+    df_cpp_47_fail = df_cpp_47_failable[
+        ~(df_cpp_47_failable["ERROR_ID"].isin(df_cpp_47_pass["ERROR_ID"]))
+    ]
+
+    # One CPPstartDate's pass should not affect the other. Create a separate reference dataset for CPPstartDate failing locations.
+    # Redo the above steps to create a dataset where a CPPstartDate is only removed from failable if its LAchildID-CINdetails-CPPstartDate is found to pass.
+    df_cpp_47_failable["ERROR_startdate"] = tuple(
+        zip(
+            df_cpp_47_failable[LAchildID],
+            df_cpp_47_failable[CINdetailsID],
+            df_cpp_47_failable[CPPstartDate],
+        )
+    )
+    df_cpp_47_pass["ERROR_startdate"] = tuple(
+        zip(
+            df_cpp_47_pass[LAchildID],
+            df_cpp_47_pass[CINdetailsID],
+            df_cpp_47_pass[CPPstartDate],
+        )
+    )
+    df_cpp_47_startdate_fail = df_cpp_47_failable[
+        ~(df_cpp_47_failable["ERROR_startdate"].isin(df_cpp_47_pass["ERROR_startdate"]))
+    ]
+
+    # CIN table: if CPPstartDate matches any DateOfInitialCPC within its CIN module, all DateOfInitialCPCs should pass in that CIN module.
+
+    df_cpp_cin = df_cpp.merge(
+        df_cin, on=[LAchildID, CINdetailsID], how="left", suffixes=["_cpp", "_cin"]
+    )
+    df_cpp_cin_pass = df_cpp_cin[
+        df_cpp_cin[CPPstartDate] == df_cpp_cin[DateOfInitialCPC]
+    ]
+    df_cpp_cin_failable = df_cpp_cin[
+        df_cpp_cin[CPPstartDate] != df_cpp_cin[DateOfInitialCPC]
+    ]
+
+    df_cpp_cin_failable["ERROR_ID"] = tuple(
+        zip(df_cpp_cin_failable[LAchildID], df_cpp_cin_failable[CINdetailsID])
+    )
+    df_cpp_cin_pass["ERROR_ID"] = tuple(
+        zip(df_cpp_cin_pass[LAchildID], df_cpp_cin_pass[CINdetailsID])
+    )
+    df_cpp_cin_fail = df_cpp_cin_failable[
+        ~(df_cpp_cin_failable["ERROR_ID"].isin(df_cpp_cin_pass["ERROR_ID"]))
+    ]
+
+    df_cpp_cin_failable["ERROR_startdate"] = tuple(
+        zip(
+            df_cpp_cin_failable[LAchildID],
+            df_cpp_cin_failable[CINdetailsID],
+            df_cpp_cin_failable[CPPstartDate],
+        )
+    )
+    df_cpp_cin_pass["ERROR_startdate"] = tuple(
+        zip(
+            df_cpp_cin_pass[LAchildID],
+            df_cpp_cin_pass[CINdetailsID],
+            df_cpp_cin_pass[CPPstartDate],
+        )
+    )
+    df_cpp_cin_startdate_fail = df_cpp_cin_failable[
+        ~(
+            df_cpp_cin_failable["ERROR_startdate"].isin(
+                df_cpp_cin_pass["ERROR_startdate"]
+            )
+        )
+    ]
+
+    # Since the condition is to check the CIN table only if the LAchildID-CINdetailID is absent in Section47,
+    # only those failing locations that are absent in section47 table should be flagged in the cindetails table. Locations that are flagged in section47 don't need to re-flag here.
+
+    # create an ID that cin groups can be identified by.
+    df_47["ERROR_ID"] = tuple(zip(df_47[LAchildID], df_47[CINdetailsID]))
+    df_cpp_cin_fail_no_47 = df_cpp_cin_fail[
+        ~(df_cpp_cin_fail["ERROR_ID"].isin(df_47["ERROR_ID"]))
+    ]
+    # do same for the cppstartdate identifier table.
+    df_cpp_cin_startdate_fail_no47 = df_cpp_cin_startdate_fail[
+        ~(df_cpp_cin_startdate_fail["ERROR_ID"].isin(df_47["ERROR_ID"]))
+    ]
+
+    # MAP FAILING LOCATIONS TO THEIR ORIGINAL TABLES.
+    df_47_issues = df_47[df_47["ROW_ID"].isin(df_cpp_47_fail["ROW_ID_47"])]
+    df_47_issues = (
+        df_47_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_cin["ERROR_ID"] = tuple(zip(df_cin[LAchildID], df_cin[CINdetailsID]))
+    df_cin_issues = df_cin[df_cin["ROW_ID"].isin(df_cpp_cin_fail_no_47["ROW_ID_cin"])]
+    df_cin_issues = (
+        df_cin_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_cpp["ERROR_ID"] = tuple(
+        zip(df_cpp[LAchildID], df_cpp[CINdetailsID], df_cpp[CPPstartDate])
+    )
+    df_cpp_issues = df_cpp[
+        (df_cpp["ROW_ID"].isin(df_cpp_47_startdate_fail["ROW_ID_cpp"]))
+        | (df_cpp["ROW_ID"].isin(df_cpp_cin_startdate_fail_no47["ROW_ID_cpp"]))
+    ]
+    df_cpp_issues = (
+        df_cpp_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # In this case, the rule is checked for each CPPstartDate, in each CINplanDates group (differentiated by CINdetailsID), in each child (differentiated by LAchildID)
+    # However, the cin and section47 locations fail/pass per group so LAchildID-CINdetailsID is used to identify them.
+    # On the other hand, CPPstartDate locations fail/pass independently so a combination of LAchildID, CINdetailsID and CPPstartDate identifies a cpp error instance.
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=Section47, columns=[DateOfInitialCPC], row_df=df_47_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[DateOfInitialCPC], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_cpp = pd.DataFrame(
+        [  # child1: Simulates multiple cin modules with one out of census period, and multiple CPPs within the same CIN.
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "CPPstartDate": "26/05/2021",  #  passes in section47
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",  # simulates multiple CPPs with same LAchildID-CINdetailsID where some fail, some pass.
+                "CPPstartDate": "26/06/2021",  #  # fail. fails both section47 and cin
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID2",
+                "CPPstartDate": "27/06/2002",  # ignore. would've failed but ignored. Not in period of census
+            },
+            # child2: fail in section47, pass in cin
+            {
+                "LAchildID": "child2",
+                "CINdetailsID": "cinID1",
+                "CPPstartDate": "26/05/2021",  # fail. fails in section47, pass in cin not considered.
+            },
+            # child3: multiple cin details modules.
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID1",
+                "CPPstartDate": "26/05/2021",  # fail. fails in both section47 and cin
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID2",
+                "CPPstartDate": pd.NA,  # ignore. cppstartdate is absent
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID3",
+                "CPPstartDate": "07/02/2022",  # fail. fails both section47 and cin
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID4",
+                "CPPstartDate": "14/03/2022",  # fail. fails in section47, pass in cin not considered.
+            },
+            # child 5: date present in section47 and absent in cin
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "cinID4",
+                "CPPstartDate": "19/07/2021",  # passes in section47
+            },
+            # child 6: no DateOfInitialCPC recorded in cin or section47 table
+            {
+                "LAchildID": "child6",
+                "CINdetailsID": "cinID4",
+                "CPPstartDate": "19/07/2021",  # fail
+            },
+            # child 8: multiple section47s in the same cin module where some pass and others fail.
+            {
+                "LAchildID": "child8",
+                "CINdetailsID": "cinID1",
+                "CPPstartDate": "20/10/2021",  # passes in section_47
+            },
+            # child 9: present in cin, absent in section47
+            {
+                "LAchildID": "child9",
+                "CINdetailsID": "cinID1",
+                "CPPstartDate": "20/10/2021",  # passes in cin
+            },
+        ]
+    )
+    sample_section47 = pd.DataFrame(
+        [
+            {  # 0 pass
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2021",  # pass. same as cppstartdate
+                "CINdetailsID": "cinID1",
+            },
+            {  # 1 ignored
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate not in period of census
+                "CINdetailsID": "cinID2",
+            },
+            {  # 2 pass
+                "LAchildID": "child2",
+                "DateOfInitialCPC": "30/05/2021",  # fail. not the same
+                "CINdetailsID": "cinID1",
+            },
+            {  # 4 absent, ignored
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate is absent.
+                "CINdetailsID": "cinID2",
+            },
+            {  # 5 fail
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2021",  # fail. not the same
+                "CINdetailsID": "cinID3",
+            },
+            {  # 6 pass
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,  # fail. not the same
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child5",
+                "DateOfInitialCPC": "19/07/2021",  # pass. same as cppstartdate
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child5",
+                "DateOfInitialCPC": pd.NA,  # pass since other section47 in same modeule passes.
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child6",
+                "DateOfInitialCPC": pd.NA,  # fail. not the same
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child8",
+                "DateOfInitialCPC": "20/10/2021",  # pass. same as cpp_start_date
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child8",
+                "DateOfInitialCPC": "22/07/2021",  # pass since other section47 in the same CINmodule passes.
+                "CINdetailsID": "cinID1",
+            },
+        ]
+    )
+    sample_cin_details = pd.DataFrame(
+        [
+            {  # 0 pass
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/10/2020",  # ignore fail. not the same but present in section47 table
+                "CINdetailsID": "cinID1",
+            },
+            {  # 1 ignore
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate not in period of census
+                "CINdetailsID": "cinID2",
+            },
+            {  # 2 pass
+                "LAchildID": "child2",
+                "DateOfInitialCPC": "26/05/2021",  # ignore fail. could've passed but present in section47
+                "CINdetailsID": "cinID1",
+            },
+            {  # 3 fail
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "28/05/2021",  # fail. not the same and no corresponding section47
+                "CINdetailsID": "cinID1",
+            },
+            {  # 4 ignore
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2021",  # ignore. cppstartdate is absent
+                "CINdetailsID": "cinID2",
+            },
+            {  # 5 fail
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2003",  # ignore fail. not the same and has corresponding section47.
+                "CINdetailsID": "cinID3",
+            },
+            {  # 6 pass
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "14/03/2022",  # ignore fail. could've passed but present in section47
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child5",
+                "DateOfInitialCPC": pd.NA,  # ignore fail. not the same  and has corresponding section47.
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child6",
+                "DateOfInitialCPC": pd.NA,  # ignore fail. not the same and has corresponding section47
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child7",
+                "DateOfInitialCPC": pd.NA,  # ignore. not present in cpp table.
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child8",
+                "DateOfInitialCPC": pd.NA,  # passes in section47
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child9",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": "20/10/2021",  # passes in cin
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
+    )
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cpp[CPPstartDate] = pd.to_datetime(
+        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_section47[DateOfInitialCPC] = pd.to_datetime(
+        sample_section47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin_details[DateOfInitialCPC] = pd.to_datetime(
+        sample_cin_details[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            Section47: sample_section47,
+            CINdetails: sample_cin_details,
+            Header: sample_header,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 3
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+
+    # pick any table and check it's values. the tuple in location 1 will contain the Section47 columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace Section47 with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [DateOfInitialCPC]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 4
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    "cinID1",  # CINdetailsID,
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID3",
+                ),
+                "ROW_ID": [4],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID4",
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child6",
+                    "cinID4",
+                ),
+                "ROW_ID": [8],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # check table 2
+    issues2 = issues_list[2]
+    issue_table2 = issues2.table
+    assert issue_table2 == CINdetails
+
+    issue_columns2 = issues2.columns
+    assert issue_columns2 == [DateOfInitialCPC]
+
+    issue_rows2 = issues2.row_df
+    assert len(issue_rows2) == 1
+    assert isinstance(issue_rows2, pd.DataFrame)
+    assert issue_rows2.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df2 = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID1",  # CINdetailsID,
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+    assert issue_rows2.equals(expected_df2)
+
+    # check table 0
+    issues0 = issues_list[0]
+    issue_table0 = issues0.table
+    assert issue_table0 == ChildProtectionPlans
+
+    issue_columns0 = issues0.columns
+    assert issue_columns0 == [CPPstartDate]
+
+    issue_rows0 = issues0.row_df
+    assert len(issue_rows0) == 6
+    assert isinstance(issue_rows0, pd.DataFrame)
+    assert issue_rows0.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df0 = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "cinID1",  # CINdetailsID,
+                    pd.to_datetime("26/06/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    "cinID1",  # CINdetailsID,
+                    pd.to_datetime("26/05/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID1",  # CINdetailsID,
+                    pd.to_datetime("26/05/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID3",  # CINdetailsID,
+                    pd.to_datetime("07/02/2022", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [6],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID4",  # CINdetailsID,
+                    pd.to_datetime("14/03/2022", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [7],
+            },
+            {
+                "ERROR_ID": (
+                    "child6",  # ChildID
+                    "cinID4",  # CINdetailsID,
+                    pd.to_datetime("19/07/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [9],
+            },
+        ]
+    )
+    assert issue_rows0.equals(expected_df0)
+
+    # Confirm that the rule details were properly pushed through.
+    assert result.definition.code == "2885"
+    assert (
+        result.definition.message
+        == "Child protection plan shown as starting a different day to the initial child protection conference."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2886Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2886Q.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,67 +1,67 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-GenderCurrent = ChildIdentifiers.GenderCurrent
-ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="2886Q",
-    rule_type=RuleType.QUERY,
-    module=CINTable.ChildIdentifiers,
-    message="Please check and either amend or provide a reason: Percentage of children with no gender recorded is more than 2% (excluding unborns)",
-    affected_fields=[ExpectedPersonBirthDate, ChildIdentifiers],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-
-    # The sum of: the number of child records where <GenderCurrent> (N00065) is equal to zero or missing,
-    # and the <ExpectedPersonBirthDate> (N00098) is equal to missing, divided by the total number of
-    # child records should be less than or equal to 0.02. Validation should be triggered at LA level.
-
-    # get the total number of child records
-    num_records = len(df)
-
-    # get the number of child records that fit the specified condition.
-    missing_gender = df[GenderCurrent].isna() | df[GenderCurrent] == 0
-    missing_date = df[ExpectedPersonBirthDate].isna()
-    condition = missing_gender & missing_date
-    # since the filtered number has to be compared to the original, make a copy of the data.
-    df_issues = df.copy()
-    df_issues = df_issues[condition]
-    num_issues = len(df_issues)
-
-    # calculate
-    missing_ratio = num_issues / num_records
-    if missing_ratio > 0.02:
-        rule_context.push_la_level(
-            rule_context.definition.code, rule_context.definition.message
-        )
-    else:
-        pass
-
-
-def test_validate():
-    sample_child_ids = pd.DataFrame(
-        [
-            {GenderCurrent: 0, ExpectedPersonBirthDate: pd.NA},
-            {GenderCurrent: 1, ExpectedPersonBirthDate: pd.NA},
-            {GenderCurrent: pd.NA, ExpectedPersonBirthDate: pd.NA},
-        ]
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildIdentifiers: sample_child_ids})
-
-    assert result.la_issues == (
-        "2886Q",
-        "Please check and either amend or provide a reason: Percentage of children with no gender recorded is more than 2% (excluding unborns)",
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+GenderCurrent = ChildIdentifiers.GenderCurrent
+ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="2886Q",
+    rule_type=RuleType.QUERY,
+    module=CINTable.ChildIdentifiers,
+    message="Please check and either amend or provide a reason: Percentage of children with no gender recorded is more than 2% (excluding unborns)",
+    affected_fields=[ExpectedPersonBirthDate, ChildIdentifiers],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+
+    # The sum of: the number of child records where <GenderCurrent> (N00065) is equal to zero or missing,
+    # and the <ExpectedPersonBirthDate> (N00098) is equal to missing, divided by the total number of
+    # child records should be less than or equal to 0.02. Validation should be triggered at LA level.
+
+    # get the total number of child records
+    num_records = len(df)
+
+    # get the number of child records that fit the specified condition.
+    missing_gender = df[GenderCurrent].isna() | df[GenderCurrent] == 0
+    missing_date = df[ExpectedPersonBirthDate].isna()
+    condition = missing_gender & missing_date
+    # since the filtered number has to be compared to the original, make a copy of the data.
+    df_issues = df.copy()
+    df_issues = df_issues[condition]
+    num_issues = len(df_issues)
+
+    # calculate
+    missing_ratio = num_issues / num_records
+    if missing_ratio > 0.02:
+        rule_context.push_la_level(
+            rule_context.definition.code, rule_context.definition.message
+        )
+    else:
+        pass
+
+
+def test_validate():
+    sample_child_ids = pd.DataFrame(
+        [
+            {GenderCurrent: 0, ExpectedPersonBirthDate: pd.NA},
+            {GenderCurrent: 1, ExpectedPersonBirthDate: pd.NA},
+            {GenderCurrent: pd.NA, ExpectedPersonBirthDate: pd.NA},
+        ]
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildIdentifiers: sample_child_ids})
+
+    assert result.la_issues == (
+        "2886Q",
+        "Please check and either amend or provide a reason: Percentage of children with no gender recorded is more than 2% (excluding unborns)",
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2887Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2887Q.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,69 +1,69 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-Disabilities = CINTable.Disabilities
-Disability = Disabilities.Disability
-LAchildID = Disabilities.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    code="2887Q",
-    rule_type=RuleType.QUERY,
-    module=CINTable.Disabilities,
-    message="Please check and either amend or provide a reason: Less than 8 disability codes have been used in your return",
-    affected_fields=[Disability],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Disabilities]
-
-    # LOGIC
-    # Excluding children where <Disability> (N00099) is ‘NONE’, the number of different disability codes used by a LA should be more than 7.
-    # Validation should be triggered at LA level, not child level, if the LA has only used 7 or fewer different disability codes in their return.
-
-    # remove "NONE" values
-    condition = df[Disability] == "NONE"
-    df = df[condition]
-
-    # .nunique() will include NaN values so .count() is used instead which excludes NaNs.
-    num_disabilities = df[Disability].count()
-    if num_disabilities <= 7:
-        rule_context.push_la_level(
-            rule_context.definition.code, rule_context.definition.message
-        )
-    else:
-        pass
-
-
-def test_validate():
-    sample_disabilities = pd.DataFrame(
-        [
-            {
-                LAchildID: "child1",
-                Disability: 0,
-            },
-            {LAchildID: "child1", Disability: "aaaa"},
-            {LAchildID: "child2", Disability: "bbbb"},
-            {LAchildID: "child3", Disability: "aaaa"},  # duplicate
-            {LAchildID: "child4", Disability: "cc"},
-            {LAchildID: "child5", Disability: "d"},
-            {LAchildID: "child6", Disability: pd.NA},  # not counted
-            {LAchildID: "child7", Disability: "f"},
-            {LAchildID: "child8", Disability: "NONE"},  # ignored: Disability is NONE
-            {LAchildID: "child9", Disability: "aaaa"},  # duplicate
-        ]
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Disabilities: sample_disabilities})
-
-    assert result.la_issues == (
-        "2887Q",
-        "Please check and either amend or provide a reason: Less than 8 disability codes have been used in your return",
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+Disabilities = CINTable.Disabilities
+Disability = Disabilities.Disability
+LAchildID = Disabilities.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="2887Q",
+    rule_type=RuleType.QUERY,
+    module=CINTable.Disabilities,
+    message="Please check and either amend or provide a reason: Less than 8 disability codes have been used in your return",
+    affected_fields=[Disability],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Disabilities]
+
+    # LOGIC
+    # Excluding children where <Disability> (N00099) is ‘NONE’, the number of different disability codes used by a LA should be more than 7.
+    # Validation should be triggered at LA level, not child level, if the LA has only used 7 or fewer different disability codes in their return.
+
+    # remove "NONE" values
+    condition = df[Disability] == "NONE"
+    df = df[condition]
+
+    # .nunique() will include NaN values so .count() is used instead which excludes NaNs.
+    num_disabilities = df[Disability].count()
+    if num_disabilities <= 7:
+        rule_context.push_la_level(
+            rule_context.definition.code, rule_context.definition.message
+        )
+    else:
+        pass
+
+
+def test_validate():
+    sample_disabilities = pd.DataFrame(
+        [
+            {
+                LAchildID: "child1",
+                Disability: 0,
+            },
+            {LAchildID: "child1", Disability: "aaaa"},
+            {LAchildID: "child2", Disability: "bbbb"},
+            {LAchildID: "child3", Disability: "aaaa"},  # duplicate
+            {LAchildID: "child4", Disability: "cc"},
+            {LAchildID: "child5", Disability: "d"},
+            {LAchildID: "child6", Disability: pd.NA},  # not counted
+            {LAchildID: "child7", Disability: "f"},
+            {LAchildID: "child8", Disability: "NONE"},  # ignored: Disability is NONE
+            {LAchildID: "child9", Disability: "aaaa"},  # duplicate
+        ]
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Disabilities: sample_disabilities})
+
+    assert result.la_issues == (
+        "2887Q",
+        "Please check and either amend or provide a reason: Less than 8 disability codes have been used in your return",
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2888Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2888Q.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,65 +1,65 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-Disabilities = CINTable.Disabilities
-Disability = Disabilities.Disability
-LAchildID = Disabilities.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    code="2888Q",
-    rule_type=RuleType.QUERY,
-    module=CINTable.Disabilities,
-    message="Please check and either amend or provide a reason: Only one disability code is recorded per child and multiple disabilities should be recorded where possible.",
-    affected_fields=[Disability],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Disabilities]
-
-    # LOGIC
-    # Excluding children where <Disability> (N00099) is ‘NONE’, within a local authority, one or more children should have more than one disability recorded.
-    # Validation should be triggered at LA level, not child level, if all children who are recorded as having a disability have only 1 disability code recorded.
-
-    # remove "NONE" values
-    df = df[df[Disability] != "NONE"]
-
-    disability_count = df.groupby(LAchildID)[Disability].count()
-    # maximum number of disabilities recorded per child should be > 1
-
-    if disability_count.max() <= 1:
-        rule_context.push_la_level(
-            rule_context.definition.code, rule_context.definition.message
-        )
-    else:
-        pass
-
-
-def test_validate():
-    sample_disabilities = pd.DataFrame(
-        [
-            {
-                LAchildID: "child0",
-                Disability: "NONE",
-            },  # child0 : disability_count would have been 2 and rule would have not been flagged if NONE was considered.
-            {LAchildID: "child0", Disability: "NONE"},
-            {LAchildID: "child1", Disability: "aaaa"},  # child1 : disability_count == 1
-            {LAchildID: "child2", Disability: "bbbb"},  # child2 : disability_count == 1
-            {LAchildID: "child2", Disability: pd.NA},
-            {LAchildID: "child4", Disability: "cc"},  # child4 : disability_count == 1
-        ]
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Disabilities: sample_disabilities})
-
-    assert result.la_issues == (
-        "2888Q",
-        "Please check and either amend or provide a reason: Only one disability code is recorded per child and multiple disabilities should be recorded where possible.",
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+Disabilities = CINTable.Disabilities
+Disability = Disabilities.Disability
+LAchildID = Disabilities.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="2888Q",
+    rule_type=RuleType.QUERY,
+    module=CINTable.Disabilities,
+    message="Please check and either amend or provide a reason: Only one disability code is recorded per child and multiple disabilities should be recorded where possible.",
+    affected_fields=[Disability],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Disabilities]
+
+    # LOGIC
+    # Excluding children where <Disability> (N00099) is ‘NONE’, within a local authority, one or more children should have more than one disability recorded.
+    # Validation should be triggered at LA level, not child level, if all children who are recorded as having a disability have only 1 disability code recorded.
+
+    # remove "NONE" values
+    df = df[df[Disability] != "NONE"]
+
+    disability_count = df.groupby(LAchildID)[Disability].count()
+    # maximum number of disabilities recorded per child should be > 1
+
+    if disability_count.max() <= 1:
+        rule_context.push_la_level(
+            rule_context.definition.code, rule_context.definition.message
+        )
+    else:
+        pass
+
+
+def test_validate():
+    sample_disabilities = pd.DataFrame(
+        [
+            {
+                LAchildID: "child0",
+                Disability: "NONE",
+            },  # child0 : disability_count would have been 2 and rule would have not been flagged if NONE was considered.
+            {LAchildID: "child0", Disability: "NONE"},
+            {LAchildID: "child1", Disability: "aaaa"},  # child1 : disability_count == 1
+            {LAchildID: "child2", Disability: "bbbb"},  # child2 : disability_count == 1
+            {LAchildID: "child2", Disability: pd.NA},
+            {LAchildID: "child4", Disability: "cc"},  # child4 : disability_count == 1
+        ]
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Disabilities: sample_disabilities})
+
+    assert result.la_issues == (
+        "2888Q",
+        "Please check and either amend or provide a reason: Only one disability code is recorded per child and multiple disabilities should be recorded where possible.",
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2889.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2889.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,168 +1,168 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-Section47 = CINTable.Section47
-S47ActualStartDate = Section47.S47ActualStartDate
-
-CINdetails = CINTable.CINdetails
-CINreferralDate = CINdetails.CINreferralDate
-LAchildID = CINdetails.LAchildID
-
-
-@rule_definition(
-    code="2889",
-    module=CINTable.Section47,
-    message="The S47 start date cannot be before the referral date.",
-    affected_fields=[S47ActualStartDate, CINreferralDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_s47 = data_container[Section47]
-    df_cin = data_container[CINdetails]
-
-    df_s47.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_s47.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # Where present, the <S47ActualStartDate> (N00148) should be on or after the <CINReferralDate> (N00100)
-    # Remove null S47Starts
-    df_s47 = df_s47[df_s47[S47ActualStartDate].notna()]
-
-    # Merge tables via LAchildID and CINdetailsID.
-    df_merged = df_s47.merge(
-        df_cin, how="left", on=["LAchildID", "CINdetailsID"], suffixes=["_47", "_cin"]
-    )
-
-    # Check for S47 Start < Cin Ref date which are the error rows
-    condition = df_merged[S47ActualStartDate] < df_merged[CINreferralDate]
-    df_merged = df_merged[condition].reset_index()
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[S47ActualStartDate],
-            df_merged[CINreferralDate],
-        )
-    )
-
-    df_47_issues = (
-        df_s47.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_cin_issues
-    )
-    rule_context.push_type_2(
-        table=Section47, columns=[S47ActualStartDate], row_df=df_47_issues
-    )
-
-
-def test_validate():
-    s47_data = (
-        # ID     #CINID    #S47 Date
-        ("1", "45", "2020-05-05"),  # 0
-        ("4", "55", "2019-04-20"),  # 1
-        ("67", "66", "2014-03-21"),  # 2 fail: preceeds 2016-03-21 in #C
-        ("69", "67", "2018-04-20"),  # 3
-        ("69", "67", pd.NA),  # 4
-        ("167", "166", "2014-03-21"),  # 5 fail: preceeds 2015-02-21 in #G
-    )
-
-    cin_data = (
-        # ID     #CINID   #CIN Ref Date
-        ("1", "44", "2017-05-05"),  # A
-        ("4", "55", "2019-04-20"),  # B
-        ("67", "66", "2016-03-21"),  # C fail
-        ("67", "67", "2015-03-21"),  # D
-        ("69", "67", "2018-04-20"),  # E
-        ("70", "69", "2015-04-20"),  # F
-        ("167", "166", "2015-02-21"),  # G fail
-    )
-
-    fake_s47 = pd.DataFrame(
-        {
-            "LAchildID": [x[0] for x in s47_data],
-            "CINdetailsID": [x[1] for x in s47_data],
-            S47ActualStartDate: [x[2] for x in s47_data],
-        }
-    )
-    fake_cin = pd.DataFrame(
-        {
-            "LAchildID": [x[0] for x in cin_data],
-            "CINdetailsID": [x[1] for x in cin_data],
-            CINreferralDate: [x[2] for x in cin_data],
-        }
-    )
-
-    fake_s47[S47ActualStartDate] = pd.to_datetime(
-        fake_s47[S47ActualStartDate], format=r"%Y-%m-%d", errors="coerce"
-    )
-    fake_cin[CINreferralDate] = pd.to_datetime(
-        fake_cin[CINreferralDate], format=r"%Y-%m-%d", errors="coerce"
-    )
-
-    result = run_rule(validate, {Section47: fake_s47, CINdetails: fake_cin})
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-
-    issues = issues_list[1]
-    assert issues.table == Section47
-    assert issues.columns == [S47ActualStartDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "167",  # ChildID
-                    pd.to_datetime(
-                        "2014-03-21", format=r"%Y-%m-%d", errors="coerce"
-                    ),  # S47ActualStartDate
-                    pd.to_datetime(
-                        "2015-02-21", format=r"%Y-%m-%d", errors="coerce"
-                    ),  # CINreferralDate
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "67",  # ChildID
-                    pd.to_datetime(
-                        "2014-03-21", format=r"%Y-%m-%d", errors="coerce"
-                    ),  # S47ActualStartDate
-                    pd.to_datetime(
-                        "2016-03-21", format=r"%Y-%m-%d", errors="coerce"
-                    ),  # CINreferralDate
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "2889"
-    assert (
-        result.definition.message
-        == "The S47 start date cannot be before the referral date."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+Section47 = CINTable.Section47
+S47ActualStartDate = Section47.S47ActualStartDate
+
+CINdetails = CINTable.CINdetails
+CINreferralDate = CINdetails.CINreferralDate
+LAchildID = CINdetails.LAchildID
+
+
+@rule_definition(
+    code="2889",
+    module=CINTable.Section47,
+    message="The S47 start date cannot be before the referral date.",
+    affected_fields=[S47ActualStartDate, CINreferralDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_s47 = data_container[Section47]
+    df_cin = data_container[CINdetails]
+
+    df_s47.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    df_s47.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # Where present, the <S47ActualStartDate> (N00148) should be on or after the <CINReferralDate> (N00100)
+    # Remove null S47Starts
+    df_s47 = df_s47[df_s47[S47ActualStartDate].notna()]
+
+    # Merge tables via LAchildID and CINdetailsID.
+    df_merged = df_s47.merge(
+        df_cin, how="left", on=["LAchildID", "CINdetailsID"], suffixes=["_47", "_cin"]
+    )
+
+    # Check for S47 Start < Cin Ref date which are the error rows
+    condition = df_merged[S47ActualStartDate] < df_merged[CINreferralDate]
+    df_merged = df_merged[condition].reset_index()
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[S47ActualStartDate],
+            df_merged[CINreferralDate],
+        )
+    )
+
+    df_47_issues = (
+        df_s47.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_cin_issues
+    )
+    rule_context.push_type_2(
+        table=Section47, columns=[S47ActualStartDate], row_df=df_47_issues
+    )
+
+
+def test_validate():
+    s47_data = (
+        # ID     #CINID    #S47 Date
+        ("1", "45", "2020-05-05"),  # 0
+        ("4", "55", "2019-04-20"),  # 1
+        ("67", "66", "2014-03-21"),  # 2 fail: preceeds 2016-03-21 in #C
+        ("69", "67", "2018-04-20"),  # 3
+        ("69", "67", pd.NA),  # 4
+        ("167", "166", "2014-03-21"),  # 5 fail: preceeds 2015-02-21 in #G
+    )
+
+    cin_data = (
+        # ID     #CINID   #CIN Ref Date
+        ("1", "44", "2017-05-05"),  # A
+        ("4", "55", "2019-04-20"),  # B
+        ("67", "66", "2016-03-21"),  # C fail
+        ("67", "67", "2015-03-21"),  # D
+        ("69", "67", "2018-04-20"),  # E
+        ("70", "69", "2015-04-20"),  # F
+        ("167", "166", "2015-02-21"),  # G fail
+    )
+
+    fake_s47 = pd.DataFrame(
+        {
+            "LAchildID": [x[0] for x in s47_data],
+            "CINdetailsID": [x[1] for x in s47_data],
+            S47ActualStartDate: [x[2] for x in s47_data],
+        }
+    )
+    fake_cin = pd.DataFrame(
+        {
+            "LAchildID": [x[0] for x in cin_data],
+            "CINdetailsID": [x[1] for x in cin_data],
+            CINreferralDate: [x[2] for x in cin_data],
+        }
+    )
+
+    fake_s47[S47ActualStartDate] = pd.to_datetime(
+        fake_s47[S47ActualStartDate], format=r"%Y-%m-%d", errors="coerce"
+    )
+    fake_cin[CINreferralDate] = pd.to_datetime(
+        fake_cin[CINreferralDate], format=r"%Y-%m-%d", errors="coerce"
+    )
+
+    result = run_rule(validate, {Section47: fake_s47, CINdetails: fake_cin})
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+
+    issues = issues_list[1]
+    assert issues.table == Section47
+    assert issues.columns == [S47ActualStartDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "167",  # ChildID
+                    pd.to_datetime(
+                        "2014-03-21", format=r"%Y-%m-%d", errors="coerce"
+                    ),  # S47ActualStartDate
+                    pd.to_datetime(
+                        "2015-02-21", format=r"%Y-%m-%d", errors="coerce"
+                    ),  # CINreferralDate
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "67",  # ChildID
+                    pd.to_datetime(
+                        "2014-03-21", format=r"%Y-%m-%d", errors="coerce"
+                    ),  # S47ActualStartDate
+                    pd.to_datetime(
+                        "2016-03-21", format=r"%Y-%m-%d", errors="coerce"
+                    ),  # CINreferralDate
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "2889"
+    assert (
+        result.definition.message
+        == "The S47 start date cannot be before the referral date."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_2991Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8555Q.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,207 +1,199 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-Assessments = CINTable.Assessments
-Section47 = CINTable.Section47
-
-
-LAchildID = Assessments.LAchildID
-CINdetailsID = Assessments.CINdetailsID
-
-
-@rule_definition(
-    code="2991Q",
-    module=CINTable.CINdetails,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend data or provide a reason: A Section 47 module is recorded and there is no assessment on the episode",
-    affected_fields=[
-        CINdetailsID,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_ass = data_container[Assessments].copy()
-    df_47 = data_container[Section47].copy()
-
-    df_ass.index.name = "ROW_ID"
-    df_47.index.name = "ROW_ID"
-
-    df_ass.reset_index(inplace=True)
-    df_47.reset_index(inplace=True)
-
-    #  If <Section47> module is present then <Assessment> module should be present.
-    merged_df = df_47.merge(
-        df_ass,
-        on=[LAchildID, CINdetailsID],
-        suffixes=["_47", "_ass"],
-        how="outer",
-        indicator=True,
-    )
-    merged_df = merged_df[merged_df["_merge"] == "left_only"]
-
-    merged_df["ERROR_ID"] = tuple(
-        zip(
-            merged_df[LAchildID],
-            merged_df[CINdetailsID],
-        )
-    )
-    df_ass_issues = (
-        df_ass.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_47_issues = (
-        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=Assessments, columns=[LAchildID], row_df=df_ass_issues
-    )
-    rule_context.push_type_2(table=Section47, columns=[LAchildID], row_df=df_47_issues)
-
-
-def test_validate():
-    sample_ass = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPstartDate": "26/05/2000",
-                "CINdetailsID": pd.NA,
-            },
-            {
-                "LAchildID": "child1",
-                "CPPstartDate": "27/06/2002",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "26/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": pd.NA,
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "07/02/2001",
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "14/03/2001",
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child4",
-                "CPPstartDate": "14/03/2001",
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-    sample_section47 = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 fail. No assessment
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child2",  # 2 fail. No assessment
-                "DateOfInitialCPC": "30/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "27/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",  # 6 fail. No assessment
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": pd.NA,
-            },
-        ]
-    )
-
-    result = run_rule(
-        validate,
-        {
-            Assessments: sample_ass,
-            Section47: sample_section47,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    issue_columns = issues.columns
-    assert issue_columns == [LAchildID]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 3
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID1",
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    "cinID1",
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    pd.NA,
-                ),
-                "ROW_ID": [6],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "2991Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: A Section 47 module is recorded and there is no assessment on the episode"
-    )
+"""
+Rule number: 8555Q
+Module: CIN details
+Rule details: If <PersonDeathDate> (N00108) is present, then the <CINreferralDate> (N00100) must be on or before the <PersonDeathDate> (N00108)
+Rule message: Child cannot be referred after its recorded date of death
+
+"""
+
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+LAchildID = ChildIdentifiers.LAchildID
+
+CINdetails = CINTable.CINdetails
+CINreferralDate = CINdetails.CINreferralDate
+LAchildID = CINdetails.LAchildID
+
+
+@rule_definition(
+    code="8555Q",
+    module=CINTable.CINdetails,
+    rule_type=RuleType.QUERY,
+    message="Child cannot be referred after its recorded date of death",
+    affected_fields=[
+        PersonDeathDate,
+        CINreferralDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_CINDetails = data_container[CINdetails].copy()
+    df_ChildIdentifiers = data_container[ChildIdentifiers].copy()
+
+    df_CINDetails.index.name = "ROW_ID"
+    df_ChildIdentifiers.index.name = "ROW_ID"
+
+    df_CINDetails.reset_index(inplace=True)
+    df_ChildIdentifiers.reset_index(inplace=True)
+
+    # <CINreferralDate> (N00100) must be on or before the <PersonDeathDate> (N00108)
+
+    # Remove rows with no death date
+    df_ChildIdentifiers = df_ChildIdentifiers[
+        df_ChildIdentifiers[PersonDeathDate].notna()
+    ]
+
+    #  Join tables
+    df_merged = df_CINDetails.merge(
+        df_ChildIdentifiers,
+        left_on=["LAchildID"],
+        right_on=["LAchildID"],
+        how="left",
+        suffixes=("_CINDetails", "_ChildIdentifiers"),
+    )
+
+    #  Get rows where PersonDeathDate is less than  CINreferralDate
+    condition = df_merged[PersonDeathDate] < df_merged[CINreferralDate]
+    df_merged = df_merged[condition].reset_index()
+
+    # Error identifier
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID], df_merged[CINreferralDate], df_merged[PersonDeathDate]
+        )
+    )
+    df_CINDetails_issues = (
+        df_CINDetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_CINDetails")
+        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_ChildIdentifiers_issues = (
+        df_ChildIdentifiers.merge(
+            df_merged, left_on="ROW_ID", right_on="ROW_ID_ChildIdentifiers"
+        )
+        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_CINDetails_issues
+    )
+    rule_context.push_type_2(
+        table=ChildIdentifiers,
+        columns=[PersonDeathDate],
+        row_df=df_ChildIdentifiers_issues,
+    )
+
+
+def test_validate():
+    sample_CINDetails = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINreferralDate": "26/05/2000",  # Pass as dates are the same
+            },
+            {
+                "LAchildID": "child2",
+                "CINreferralDate": "27/06/2002",  # Fails, referral after death
+            },
+            {
+                "LAchildID": "child3",
+                "CINreferralDate": "07/02/1999",  # Pass, pre death
+            },
+            {
+                "LAchildID": "child4",
+                "CINreferralDate": pd.NA,  # Ignored, no referral date
+            },
+            {
+                "LAchildID": "child5",
+                "CINreferralDate": "14/03/2001",  # Pass, dropped due to no death date
+            },
+        ]
+    )
+    sample_ChildIdentifiers = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Pass
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",  # Fails
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",  # Pass
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child4",  # Pass
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child5",  # Pass
+                "PersonDeathDate": pd.NA,
+            },
+        ]
+    )
+
+    sample_CINDetails[CINreferralDate] = pd.to_datetime(
+        sample_CINDetails[CINreferralDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_ChildIdentifiers["PersonDeathDate"] = pd.to_datetime(
+        sample_ChildIdentifiers["PersonDeathDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINdetails: sample_CINDetails,
+            ChildIdentifiers: sample_ChildIdentifiers,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    issue_columns = issues.columns
+    assert issue_columns == [PersonDeathDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    # Start Date
+                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
+                    # Review date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8555Q"
+    assert (
+        result.definition.message
+        == "Child cannot be referred after its recorded date of death"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4000.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4000.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,163 +1,163 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-CINplanDates = CINTable.CINplanDates
-LAchildID = CINplanDates.LAchildID
-
-CINdetails = CINTable.CINdetails
-ReferralNFA = CINdetails.ReferralNFA
-CINdetailsID_details = CINdetails.CINdetailsID
-
-
-@rule_definition(
-    code="4000",
-    module=CINTable.CINplanDates,
-    message="CIN Plan details provided for a referral with no further action",
-    affected_fields=[
-        ReferralNFA,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cpd = data_container[CINplanDates].copy()
-    df_CINdetails = data_container[CINdetails].copy()
-
-    df_cpd.index.name = "ROW_ID"
-    df_CINdetails.index.name = "ROW_ID"
-
-    df_cpd.reset_index(inplace=True)
-    df_CINdetails.reset_index(inplace=True)
-
-    df_CINdetails = df_CINdetails[
-        (df_CINdetails[ReferralNFA] == "true")
-        | (df_CINdetails[ReferralNFA] == 1)
-        | (df_CINdetails[ReferralNFA] == "1")
-        | (df_CINdetails[ReferralNFA] == True)
-    ]
-
-    df_merged = df_CINdetails.merge(
-        df_cpd,
-        left_on=["LAchildID", "CINdetailsID"],
-        right_on=["LAchildID", "CINdetailsID"],
-        how="inner",
-        suffixes=("_cin", "_cpd"),
-    )
-
-    df_merged = df_merged.reset_index()
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged["LAchildID"],
-            df_merged["CINdetailsID"],
-        )
-    )
-
-    df_cpp_issues = (
-        df_cpd.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpd")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_CINdetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=CINplanDates, columns=[LAchildID], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[ReferralNFA], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    sample_cpd = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID1",
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID2",
-            },
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "CDID6",
-            },
-        ]
-    )
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Fail, module present
-                "CINdetailsID": "CDID1",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child1",  # Pass, no referralNFA
-                "CINdetailsID": "CDID2",
-                "ReferralNFA": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # Pass, no module
-                "CINdetailsID": "CDID6",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child4",  # Pass, referral NFA is false
-                "CINdetailsID": "CDID6",
-                "ReferralNFA": "false",
-            },
-        ]
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINplanDates: sample_cpd,
-            CINdetails: sample_cin,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [ReferralNFA]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "CDID1",
-                ),
-                "ROW_ID": [0],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4000"
-    assert (
-        result.definition.message
-        == "CIN Plan details provided for a referral with no further action"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+CINplanDates = CINTable.CINplanDates
+LAchildID = CINplanDates.LAchildID
+
+CINdetails = CINTable.CINdetails
+ReferralNFA = CINdetails.ReferralNFA
+CINdetailsID_details = CINdetails.CINdetailsID
+
+
+@rule_definition(
+    code="4000",
+    module=CINTable.CINplanDates,
+    message="CIN Plan details provided for a referral with no further action",
+    affected_fields=[
+        ReferralNFA,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cpd = data_container[CINplanDates].copy()
+    df_CINdetails = data_container[CINdetails].copy()
+
+    df_cpd.index.name = "ROW_ID"
+    df_CINdetails.index.name = "ROW_ID"
+
+    df_cpd.reset_index(inplace=True)
+    df_CINdetails.reset_index(inplace=True)
+
+    df_CINdetails = df_CINdetails[
+        (df_CINdetails[ReferralNFA] == "true")
+        | (df_CINdetails[ReferralNFA] == 1)
+        | (df_CINdetails[ReferralNFA] == "1")
+        | (df_CINdetails[ReferralNFA] == True)
+    ]
+
+    df_merged = df_CINdetails.merge(
+        df_cpd,
+        left_on=["LAchildID", "CINdetailsID"],
+        right_on=["LAchildID", "CINdetailsID"],
+        how="inner",
+        suffixes=("_cin", "_cpd"),
+    )
+
+    df_merged = df_merged.reset_index()
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged["LAchildID"],
+            df_merged["CINdetailsID"],
+        )
+    )
+
+    df_cpp_issues = (
+        df_cpd.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpd")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_CINdetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=CINplanDates, columns=[LAchildID], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReferralNFA], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    sample_cpd = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID1",
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID2",
+            },
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "CDID6",
+            },
+        ]
+    )
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Fail, module present
+                "CINdetailsID": "CDID1",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child1",  # Pass, no referralNFA
+                "CINdetailsID": "CDID2",
+                "ReferralNFA": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # Pass, no module
+                "CINdetailsID": "CDID6",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child4",  # Pass, referral NFA is false
+                "CINdetailsID": "CDID6",
+                "ReferralNFA": "false",
+            },
+        ]
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINplanDates: sample_cpd,
+            CINdetails: sample_cin,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [ReferralNFA]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "CDID1",
+                ),
+                "ROW_ID": [0],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "4000"
+    assert (
+        result.definition.message
+        == "CIN Plan details provided for a referral with no further action"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4001.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_2991Q.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,206 +1,207 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LAchildID = ChildProtectionPlans.LAchildID
-CINdetailsID = ChildProtectionPlans.CINdetailsID
-CPPID = ChildProtectionPlans.CPPID
-CPPendDate = ChildProtectionPlans.CPPendDate
-
-CINplanDates = CINTable.CINplanDates
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-
-
-@rule_definition(
-    code="4001",
-    module=CINTable.CINplanDates,
-    message="A CIN Plan cannot run concurrently with a Child Protection Plan",
-    affected_fields=[
-        CINPlanEndDate,
-        CPPendDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cpp = data_container[ChildProtectionPlans]
-    df_plan = data_container[CINplanDates]
-
-    df_cpp.index.name = "ROW_ID"
-    df_plan.index.name = "ROW_ID"
-
-    df_cpp.reset_index(inplace=True)
-    df_plan.reset_index(inplace=True)
-
-    # If a <CINDetails> module has a <ChildProtectionPlan> module present with no <CPPendDate> (N00115)
-    # - then a <CINPlanDates> module with no <CINPlanEndDate> (N00690) must not be present
-    df_merged = df_cpp.merge(
-        df_plan,
-        on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=("_cpp", "_cin"),
-    )
-
-    #  Get rows where CPPendDate is null and CINPlanEndDate is null
-    condition = df_merged[CPPendDate].isna() & (
-        df_merged[CINPlanStartDate].notna() & df_merged[CINPlanEndDate].isna()
-    )
-    df_merged = df_merged[condition].reset_index()
-
-    df_merged["ERROR_ID"] = tuple(zip(df_merged[LAchildID], df_merged[CINdetailsID]))
-
-    df_cpp_issues = (
-        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_plan.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    rule_context.push_type_2(
-        table=ChildProtectionPlans,
-        columns=[CPPendDate],
-        row_df=df_cpp_issues,
-    )
-    rule_context.push_type_2(
-        table=CINplanDates, columns=[CINPlanEndDate], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    sample_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 Pass
-                "CPPendDate": "30/05/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",  # 1 Pass
-                "CPPendDate": pd.NA,
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child2",  # 2 Fail
-                "CPPendDate": pd.NA,
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",  # 3 Pass
-                "CPPendDate": "30/10/2001",
-                "CINdetailsID": "cinID5",
-            },
-            {
-                "LAchildID": "child5",  # 4 Pass
-                "CPPendDate": pd.NA,
-                "CINdetailsID": "cinID7",
-            },
-            {
-                "LAchildID": "child6",  # 4 Pass
-                "CPPendDate": pd.NA,
-                "CINdetailsID": "cinID8",
-            },
-        ]
-    )
-    sample_plan = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 Pass
-                "CINPlanEndDate": "04/04/2000",
-                "CINPlanStartDate": "04/04/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",  # 1 Pass
-                "CINPlanEndDate": "28/05/2000",
-                "CINPlanStartDate": "04/04/2000",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child2",  # 2 Fail
-                "CINPlanStartDate": "04/04/2000",
-                "CINPlanEndDate": pd.NA,
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child2",  # 3 Pass
-                "CINPlanStartDate": "04/04/2000",
-                "CINPlanEndDate": pd.NA,
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child3",  # 4 Pass
-                "CINPlanStartDate": "04/04/2000",
-                "CINPlanEndDate": "30/10/2001",
-                "CINdetailsID": "cinID5",
-            },
-            {
-                "LAchildID": "child4",  # 5 Pass
-                "CINPlanStartDate": "04/04/2000",
-                "CINPlanEndDate": pd.NA,
-                "CINdetailsID": "cinID6",
-            },
-            {
-                "LAchildID": "child6",  # 6 Pass
-                "CINPlanEndDate": pd.NA,
-                "CINdetailsID": "cinID9",
-            },
-        ]
-    )
-
-    sample_cpp[CPPendDate] = pd.to_datetime(
-        sample_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_plan[CINPlanEndDate] = pd.to_datetime(
-        sample_plan[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            CINplanDates: sample_plan,
-        },
-    )
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINplanDates
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINPlanEndDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",
-                    "cinID3",
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4001"
-    assert (
-        result.definition.message
-        == "A CIN Plan cannot run concurrently with a Child Protection Plan"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+Assessments = CINTable.Assessments
+Section47 = CINTable.Section47
+
+
+LAchildID = Assessments.LAchildID
+CINdetailsID = Assessments.CINdetailsID
+
+
+@rule_definition(
+    code="2991Q",
+    module=CINTable.CINdetails,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend data or provide a reason: A Section 47 module is recorded and there is no assessment on the episode",
+    affected_fields=[
+        CINdetailsID,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_ass = data_container[Assessments].copy()
+    df_47 = data_container[Section47].copy()
+
+    df_ass.index.name = "ROW_ID"
+    df_47.index.name = "ROW_ID"
+
+    df_ass.reset_index(inplace=True)
+    df_47.reset_index(inplace=True)
+
+    #  If <Section47> module is present then <Assessment> module should be present.
+    merged_df = df_47.merge(
+        df_ass,
+        on=[LAchildID, CINdetailsID],
+        suffixes=["_47", "_ass"],
+        how="outer",
+        indicator=True,
+    )
+    merged_df = merged_df[merged_df["_merge"] == "left_only"]
+
+    merged_df["ERROR_ID"] = tuple(
+        zip(
+            merged_df[LAchildID],
+            merged_df[CINdetailsID],
+        )
+    )
+    df_ass_issues = (
+        df_ass.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_47_issues = (
+        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=Assessments, columns=[LAchildID], row_df=df_ass_issues
+    )
+    rule_context.push_type_2(table=Section47, columns=[LAchildID], row_df=df_47_issues)
+
+
+def test_validate():
+    sample_ass = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPstartDate": "26/05/2000",
+                "CINdetailsID": pd.NA,
+            },
+            {
+                "LAchildID": "child1",
+                "CPPstartDate": "27/06/2002",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "26/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": pd.NA,
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "07/02/2001",
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "14/03/2001",
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child4",
+                "CPPstartDate": "14/03/2001",
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+    sample_section47 = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # 0 fail. No assessment
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child2",  # 2 fail. No assessment
+                "DateOfInitialCPC": "30/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "27/05/2000",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",  # 6 fail. No assessment
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": pd.NA,
+            },
+        ]
+    )
+
+    result = run_rule(
+        validate,
+        {
+            Assessments: sample_ass,
+            Section47: sample_section47,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    issue_columns = issues.columns
+    assert issue_columns == [LAchildID]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 3
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "cinID1",
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    pd.NA,
+                ),
+                "ROW_ID": [6],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "2991Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: A Section 47 module is recorded and there is no assessment on the episode"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4003.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4003.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,286 +1,286 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-CINplanDates = CINTable.CINplanDates
-Reviews = CINTable.Reviews
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPendDate = ChildProtectionPlans.CPPendDate
-LAchildID = CINplanDates.LAchildID
-CPPreviewDate = Reviews.CPPreviewDate
-CPPID = Reviews.CPPID
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-CPPendDate = ChildProtectionPlans.CPPendDate
-
-
-@rule_definition(
-    code="4003",
-    module=CINTable.Reviews,
-    message="A CPP review date is shown as being held at the same time as an open CIN Plan.",
-    affected_fields=[
-        CINPlanStartDate,
-        CINPlanEndDate,
-        CPPreviewDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cpp = data_container[ChildProtectionPlans].copy()
-    df_cin = data_container[CINplanDates].copy()
-    df_reviews = data_container[Reviews].copy()
-
-    df_reviews.index.name = "ROW_ID"
-    df_cpp.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_reviews.reset_index(inplace=True)
-    df_cpp.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # Within a <CINDetails> module, no <CPPReviewDate> (N00116) can fall between any
-    # <CINPlanStartdate> (N00689) or <CINPlanEndDate> (N00690) unless <CPPReviewDate> is equal to <CPPendDate> (N00115)
-    df_cpp = df_cpp.merge(
-        df_reviews, on=["LAchildID", "CPPID"], how="left", suffixes=("", "_reviews")
-    )
-
-    df_merged = df_cin.merge(
-        df_cpp,
-        on=["LAchildID"],
-        how="left",
-        suffixes=("_cin", "_cpp"),
-    )
-
-    cin_start_after_cin_start = df_merged[CPPreviewDate] >= df_merged[CINPlanStartDate]
-    cin_start_before_cin_end = (
-        df_merged[CPPreviewDate] < df_merged[CINPlanEndDate]
-    ) & df_merged[CPPendDate].notna()
-    cp_review_is_end = (df_merged[CPPreviewDate] == df_merged[CPPendDate]) & df_merged[
-        CPPendDate
-    ].notna()
-
-    df_merged = df_merged[
-        (cin_start_after_cin_start & cin_start_before_cin_end) & (~cp_review_is_end)
-    ].reset_index()
-
-    df_merged["ERROR_ID"] = tuple(zip(df_merged[LAchildID], df_merged[CPPreviewDate]))
-    df_cpp_issues = (
-        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_reviews_issues = (
-        df_reviews.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_reviews")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildProtectionPlans,
-        columns=[CPPendDate],
-        row_df=df_cpp_issues,
-    )
-    rule_context.push_type_2(
-        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_cin_issues
-    )
-    rule_context.push_type_2(
-        table=Reviews, columns=[CPPreviewDate], row_df=df_reviews_issues
-    )
-
-
-def test_validate():
-    sample_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPendDate": "30/05/2001",  # Fail
-                "CPPID": "cinID1",
-            },
-            {
-                "LAchildID": "child2",
-                "CPPendDate": pd.NA,
-                "CPPID": "cinID1",
-            },
-            {
-                "LAchildID": "child2",
-                "CPPendDate": "29/05/2001",  # ignore: CPPReviewDate == CPPendDate
-                "CPPID": "cinID2",
-            },
-            {
-                "LAchildID": "child2",
-                "CPPendDate": pd.NA,
-                "CPPID": "cinID4",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPendDate": "30/10/2001",
-                "CPPID": "cinID5",
-            },
-            {
-                "LAchildID": "child5",
-                "CPPendDate": pd.NA,
-                "CPPID": "cinID6",
-            },
-        ]
-    )
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINPlanStartDate": "04/04/2000",  # fail: 29/05/2001
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanStartDate": "28/05/2000",  # ignore: CPPReviewDate == CPPendDate 29/05/2001
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child3",
-                "CINPlanStartDate": "30/05/2000",  # pass: "29/05/2004"
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child4",
-                "CINPlanStartDate": "04/06/2000",  # pass: "29/05/2004"
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child5",
-                "CINPlanStartDate": "30/06/2000",
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanStartDate": "26/10/2000",
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanStartDate": "26/02/2001",
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanStartDate": "26/03/2001",
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child3",
-                "CINPlanStartDate": "30/10/2001",
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child4",
-                "CINPlanStartDate": "04/06/2000",
-                "CINPlanEndDate": "01/06/2002",
-            },
-            {
-                "LAchildID": "child5",
-                "CINPlanStartDate": "31/03/2001",
-                "CINPlanEndDate": "01/06/2002",
-            },
-        ]
-    )
-    sample_reviews = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPID": "cinID1",
-                "CPPreviewDate": "29/05/2001",
-            },  # fail
-            {
-                "LAchildID": "child2",
-                "CPPID": "cinID2",
-                "CPPreviewDate": "29/05/2001",
-            },  # ignore
-            {
-                "LAchildID": "child3",
-                "CPPID": "cinID3",
-                "CPPreviewDate": "29/05/2004",
-            },  # pass
-            {
-                "LAchildID": "child4",
-                "CPPID": "cinID4",
-                "CPPreviewDate": "29/05/2004",
-            },  # pass
-            {
-                "LAchildID": "child5",
-                "CPPID": "cinID5",
-                "CPPreviewDate": "29/05/2004",
-            },  # pass
-            {
-                "LAchildID": "child6",
-                "CPPID": "cinID6",
-                "CPPreviewDate": "29/05/2004",
-            },  # ignore: not present in cin table
-        ]
-    )
-
-    sample_reviews[CPPreviewDate] = pd.to_datetime(
-        sample_reviews[CPPreviewDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cpp[CPPendDate] = pd.to_datetime(
-        sample_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin[CINPlanStartDate] = pd.to_datetime(
-        sample_cin[CINPlanStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin[CINPlanEndDate] = pd.to_datetime(
-        sample_cin[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            CINplanDates: sample_cin,
-            Reviews: sample_reviews,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 3
-    issues = issues_list[2]
-
-    issue_table = issues.table
-    assert issue_table == Reviews
-
-    issue_columns = issues.columns
-    assert issue_columns == [CPPreviewDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("29/05/2001", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            }
-        ]
-    )
-
-    assert issue_rows.equals(expected_df)
-    assert result.definition.code == "4003"
-    assert (
-        result.definition.message
-        == "A CPP review date is shown as being held at the same time as an open CIN Plan."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+CINplanDates = CINTable.CINplanDates
+Reviews = CINTable.Reviews
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPendDate = ChildProtectionPlans.CPPendDate
+LAchildID = CINplanDates.LAchildID
+CPPreviewDate = Reviews.CPPreviewDate
+CPPID = Reviews.CPPID
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+CINPlanEndDate = CINplanDates.CINPlanEndDate
+CPPendDate = ChildProtectionPlans.CPPendDate
+
+
+@rule_definition(
+    code="4003",
+    module=CINTable.Reviews,
+    message="A CPP review date is shown as being held at the same time as an open CIN Plan.",
+    affected_fields=[
+        CINPlanStartDate,
+        CINPlanEndDate,
+        CPPreviewDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cpp = data_container[ChildProtectionPlans].copy()
+    df_cin = data_container[CINplanDates].copy()
+    df_reviews = data_container[Reviews].copy()
+
+    df_reviews.index.name = "ROW_ID"
+    df_cpp.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    df_reviews.reset_index(inplace=True)
+    df_cpp.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # Within a <CINDetails> module, no <CPPReviewDate> (N00116) can fall between any
+    # <CINPlanStartdate> (N00689) or <CINPlanEndDate> (N00690) unless <CPPReviewDate> is equal to <CPPendDate> (N00115)
+    df_cpp = df_cpp.merge(
+        df_reviews, on=["LAchildID", "CPPID"], how="left", suffixes=("", "_reviews")
+    )
+
+    df_merged = df_cin.merge(
+        df_cpp,
+        on=["LAchildID"],
+        how="left",
+        suffixes=("_cin", "_cpp"),
+    )
+
+    cin_start_after_cin_start = df_merged[CPPreviewDate] >= df_merged[CINPlanStartDate]
+    cin_start_before_cin_end = (
+        df_merged[CPPreviewDate] < df_merged[CINPlanEndDate]
+    ) & df_merged[CPPendDate].notna()
+    cp_review_is_end = (df_merged[CPPreviewDate] == df_merged[CPPendDate]) & df_merged[
+        CPPendDate
+    ].notna()
+
+    df_merged = df_merged[
+        (cin_start_after_cin_start & cin_start_before_cin_end) & (~cp_review_is_end)
+    ].reset_index()
+
+    df_merged["ERROR_ID"] = tuple(zip(df_merged[LAchildID], df_merged[CPPreviewDate]))
+    df_cpp_issues = (
+        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_reviews_issues = (
+        df_reviews.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_reviews")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildProtectionPlans,
+        columns=[CPPendDate],
+        row_df=df_cpp_issues,
+    )
+    rule_context.push_type_2(
+        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_cin_issues
+    )
+    rule_context.push_type_2(
+        table=Reviews, columns=[CPPreviewDate], row_df=df_reviews_issues
+    )
+
+
+def test_validate():
+    sample_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPendDate": "30/05/2001",  # Fail
+                "CPPID": "cinID1",
+            },
+            {
+                "LAchildID": "child2",
+                "CPPendDate": pd.NA,
+                "CPPID": "cinID1",
+            },
+            {
+                "LAchildID": "child2",
+                "CPPendDate": "29/05/2001",  # ignore: CPPReviewDate == CPPendDate
+                "CPPID": "cinID2",
+            },
+            {
+                "LAchildID": "child2",
+                "CPPendDate": pd.NA,
+                "CPPID": "cinID4",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPendDate": "30/10/2001",
+                "CPPID": "cinID5",
+            },
+            {
+                "LAchildID": "child5",
+                "CPPendDate": pd.NA,
+                "CPPID": "cinID6",
+            },
+        ]
+    )
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINPlanStartDate": "04/04/2000",  # fail: 29/05/2001
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child2",
+                "CINPlanStartDate": "28/05/2000",  # ignore: CPPReviewDate == CPPendDate 29/05/2001
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child3",
+                "CINPlanStartDate": "30/05/2000",  # pass: "29/05/2004"
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child4",
+                "CINPlanStartDate": "04/06/2000",  # pass: "29/05/2004"
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child5",
+                "CINPlanStartDate": "30/06/2000",
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child2",
+                "CINPlanStartDate": "26/10/2000",
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child2",
+                "CINPlanStartDate": "26/02/2001",
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child2",
+                "CINPlanStartDate": "26/03/2001",
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child3",
+                "CINPlanStartDate": "30/10/2001",
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child4",
+                "CINPlanStartDate": "04/06/2000",
+                "CINPlanEndDate": "01/06/2002",
+            },
+            {
+                "LAchildID": "child5",
+                "CINPlanStartDate": "31/03/2001",
+                "CINPlanEndDate": "01/06/2002",
+            },
+        ]
+    )
+    sample_reviews = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPID": "cinID1",
+                "CPPreviewDate": "29/05/2001",
+            },  # fail
+            {
+                "LAchildID": "child2",
+                "CPPID": "cinID2",
+                "CPPreviewDate": "29/05/2001",
+            },  # ignore
+            {
+                "LAchildID": "child3",
+                "CPPID": "cinID3",
+                "CPPreviewDate": "29/05/2004",
+            },  # pass
+            {
+                "LAchildID": "child4",
+                "CPPID": "cinID4",
+                "CPPreviewDate": "29/05/2004",
+            },  # pass
+            {
+                "LAchildID": "child5",
+                "CPPID": "cinID5",
+                "CPPreviewDate": "29/05/2004",
+            },  # pass
+            {
+                "LAchildID": "child6",
+                "CPPID": "cinID6",
+                "CPPreviewDate": "29/05/2004",
+            },  # ignore: not present in cin table
+        ]
+    )
+
+    sample_reviews[CPPreviewDate] = pd.to_datetime(
+        sample_reviews[CPPreviewDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cpp[CPPendDate] = pd.to_datetime(
+        sample_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin[CINPlanStartDate] = pd.to_datetime(
+        sample_cin[CINPlanStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin[CINPlanEndDate] = pd.to_datetime(
+        sample_cin[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            CINplanDates: sample_cin,
+            Reviews: sample_reviews,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 3
+    issues = issues_list[2]
+
+    issue_table = issues.table
+    assert issue_table == Reviews
+
+    issue_columns = issues.columns
+    assert issue_columns == [CPPreviewDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    pd.to_datetime("29/05/2001", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            }
+        ]
+    )
+
+    assert issue_rows.equals(expected_df)
+    assert result.definition.code == "4003"
+    assert (
+        result.definition.message
+        == "A CPP review date is shown as being held at the same time as an open CIN Plan."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4008.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4008.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,194 +1,194 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-LAchildID = ChildIdentifiers.LAchildID
-
-CINplanDates = CINTable.CINplanDates
-LAchildID = CINplanDates.LAchildID
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-
-
-@rule_definition(
-    code="4008",
-    module=CINTable.ChildIdentifiers,
-    message="CIN Plan shown as starting after the child’s Date of Death.",
-    affected_fields=[
-        PersonDeathDate,
-        CINPlanStartDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_ci = data_container[ChildIdentifiers].copy()
-    df_cpd = data_container[CINplanDates].copy()
-
-    df_ci.index.name = "ROW_ID"
-    df_cpd.index.name = "ROW_ID"
-
-    df_ci.reset_index(inplace=True)
-    df_cpd.reset_index(inplace=True)
-
-    # If <PersonDeathDate> (N00108) is present, then <CINPlanStartDate> (N00689) must be on or before <PersonDeathDate> (N00108)
-    df_ci = df_ci[df_ci[PersonDeathDate].notna()]
-    df_cpd = df_cpd[df_cpd[CINPlanStartDate].notna()]
-
-    df_merged = df_ci.merge(
-        df_cpd,
-        left_on=["LAchildID"],
-        right_on=["LAchildID"],
-        how="left",
-        suffixes=("_ci", "_cpd"),
-    )
-
-    condition = df_merged[PersonDeathDate] < df_merged[CINPlanStartDate]
-    df_merged = df_merged[condition].reset_index()
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[PersonDeathDate],
-        )
-    )
-
-    df_cpp_issues = (
-        df_ci.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ci")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_reviews_issues = (
-        df_cpd.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpd")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_reviews_issues
-    )
-
-
-def test_validate():
-    sample_ci = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "PersonDeathDate": "26/05/2000",  # Passes same date
-            },
-            {
-                "LAchildID": "child2",
-                "PersonDeathDate": "27/06/2002",  # Passes
-            },
-            {
-                "LAchildID": "child3",
-                "PersonDeathDate": "07/02/2001",  # Passes
-            },
-            {
-                "LAchildID": "child4",
-                "PersonDeathDate": "26/05/2000",  # Passes
-            },
-            {
-                "LAchildID": "child5",
-                "PersonDeathDate": "26/05/2000",  # Fails, death before CIN plan starts
-            },
-            {
-                "LAchildID": "child6",
-                "PersonDeathDate": pd.NA,  # Passes
-            },
-            {
-                "LAchildID": "child7",
-                "PersonDeathDate": "14/03/2001",  # Passes
-            },
-        ]
-    )
-    sample_cpd = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINPlanStartDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanStartDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child3",
-                "CINPlanStartDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child4",
-                "CINPlanStartDate": "25/05/2000",
-            },
-            {
-                "LAchildID": "child5",
-                "CINPlanStartDate": "27/05/2000",
-            },
-            {
-                "LAchildID": "child6",
-                "CINPlanStartDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child7",
-                "CINPlanStartDate": pd.NA,
-            },
-        ]
-    )
-
-    sample_ci["PersonDeathDate"] = pd.to_datetime(
-        sample_ci["PersonDeathDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cpd["CINPlanStartDate"] = pd.to_datetime(
-        sample_cpd["CINPlanStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_ci,
-            CINplanDates: sample_cpd,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINplanDates
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINPlanStartDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child5",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4008"
-    assert (
-        result.definition.message
-        == "CIN Plan shown as starting after the child’s Date of Death."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+LAchildID = ChildIdentifiers.LAchildID
+
+CINplanDates = CINTable.CINplanDates
+LAchildID = CINplanDates.LAchildID
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+
+
+@rule_definition(
+    code="4008",
+    module=CINTable.ChildIdentifiers,
+    message="CIN Plan shown as starting after the child’s Date of Death.",
+    affected_fields=[
+        PersonDeathDate,
+        CINPlanStartDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_ci = data_container[ChildIdentifiers].copy()
+    df_cpd = data_container[CINplanDates].copy()
+
+    df_ci.index.name = "ROW_ID"
+    df_cpd.index.name = "ROW_ID"
+
+    df_ci.reset_index(inplace=True)
+    df_cpd.reset_index(inplace=True)
+
+    # If <PersonDeathDate> (N00108) is present, then <CINPlanStartDate> (N00689) must be on or before <PersonDeathDate> (N00108)
+    df_ci = df_ci[df_ci[PersonDeathDate].notna()]
+    df_cpd = df_cpd[df_cpd[CINPlanStartDate].notna()]
+
+    df_merged = df_ci.merge(
+        df_cpd,
+        left_on=["LAchildID"],
+        right_on=["LAchildID"],
+        how="left",
+        suffixes=("_ci", "_cpd"),
+    )
+
+    condition = df_merged[PersonDeathDate] < df_merged[CINPlanStartDate]
+    df_merged = df_merged[condition].reset_index()
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[PersonDeathDate],
+        )
+    )
+
+    df_cpp_issues = (
+        df_ci.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ci")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_reviews_issues = (
+        df_cpd.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpd")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_reviews_issues
+    )
+
+
+def test_validate():
+    sample_ci = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "PersonDeathDate": "26/05/2000",  # Passes same date
+            },
+            {
+                "LAchildID": "child2",
+                "PersonDeathDate": "27/06/2002",  # Passes
+            },
+            {
+                "LAchildID": "child3",
+                "PersonDeathDate": "07/02/2001",  # Passes
+            },
+            {
+                "LAchildID": "child4",
+                "PersonDeathDate": "26/05/2000",  # Passes
+            },
+            {
+                "LAchildID": "child5",
+                "PersonDeathDate": "26/05/2000",  # Fails, death before CIN plan starts
+            },
+            {
+                "LAchildID": "child6",
+                "PersonDeathDate": pd.NA,  # Passes
+            },
+            {
+                "LAchildID": "child7",
+                "PersonDeathDate": "14/03/2001",  # Passes
+            },
+        ]
+    )
+    sample_cpd = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINPlanStartDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "CINPlanStartDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",
+                "CINPlanStartDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child4",
+                "CINPlanStartDate": "25/05/2000",
+            },
+            {
+                "LAchildID": "child5",
+                "CINPlanStartDate": "27/05/2000",
+            },
+            {
+                "LAchildID": "child6",
+                "CINPlanStartDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child7",
+                "CINPlanStartDate": pd.NA,
+            },
+        ]
+    )
+
+    sample_ci["PersonDeathDate"] = pd.to_datetime(
+        sample_ci["PersonDeathDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cpd["CINPlanStartDate"] = pd.to_datetime(
+        sample_cpd["CINPlanStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildIdentifiers: sample_ci,
+            CINplanDates: sample_cpd,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == CINplanDates
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINPlanStartDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child5",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "4008"
+    assert (
+        result.definition.message
+        == "CIN Plan shown as starting after the child’s Date of Death."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4009Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8810.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,196 +1,159 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-CINplanDates = CINTable.CINplanDates
-
-LAchildID = ChildIdentifiers.LAchildID
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-
-
-@rule_definition(
-    code="4009Q",
-    module=CINTable.ChildIdentifiers,
-    rule_type=RuleType.QUERY,
-    message="CIN Plan cannot end after the child’s Date of Death",
-    affected_fields=[
-        PersonDeathDate,
-        CINPlanEndDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_ci = data_container[ChildIdentifiers].copy()
-    df_cin = data_container[CINplanDates].copy()
-
-    df_ci.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_ci.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # If <PersonDeathDate> (N00108) is present, then <CINPlanEndDate> (N00690) must be on or before <PersonDeathDate> (N00108)
-    df_ci = df_ci[df_ci["PersonDeathDate"].notna()]
-
-    merged_df = df_ci.merge(
-        df_cin,
-        on=[
-            LAchildID,
-        ],
-        suffixes=["_ci", "_cin"],
-    )
-
-    condition = merged_df[PersonDeathDate] < merged_df[CINPlanEndDate]
-
-    merged_df = merged_df[condition].reset_index()
-
-    merged_df["ERROR_ID"] = tuple(
-        zip(
-            merged_df[LAchildID],
-            merged_df[PersonDeathDate],
-        )
-    )
-
-    df_ci_issues = (
-        df_ci.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ci")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_ci_issues
-    )
-    rule_context.push_type_2(
-        table=CINplanDates, columns=[CINPlanEndDate], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    sample_ci = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Fail
-                "PersonDeathDate": "01/01/2000",
-            },
-            {
-                "LAchildID": "child2",  # Pass
-                "PersonDeathDate": "01/01/2000",
-            },
-            {
-                "LAchildID": "child3",  # Pass
-                "PersonDeathDate": pd.NA,
-            },
-            {
-                "LAchildID": "child4",  # Fail
-                "PersonDeathDate": "01/01/2000",
-            },
-        ]
-    )
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINPlanEndDate": "01/01/2001",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanEndDate": pd.NA,
-            },
-            {
-                "LAchildID": "child3",
-                "CINPlanEndDate": "01/01/2000",
-            },
-            {
-                "LAchildID": "child4",
-                "CINPlanEndDate": "01/01/2001",
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_ci[PersonDeathDate] = pd.to_datetime(
-        sample_ci[PersonDeathDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    sample_cin["CINPlanEndDate"] = pd.to_datetime(
-        sample_cin["CINPlanEndDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_ci,
-            CINplanDates: sample_cin,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Section47 columns because that's the second thing pushed above.
-    issues = issues_list[0]
-
-    # get table name and check it. Replace Section47 with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [PersonDeathDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("01/01/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    pd.to_datetime("01/01/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 4009Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "4009Q"
-    assert (
-        result.definition.message
-        == "CIN Plan cannot end after the child’s Date of Death"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+ReasonForClosure = CINdetails.ReasonForClosure
+CINclosureDate = CINdetails.CINclosureDate
+CINdetailsID = CINdetails.CINdetailsID
+LAchildID = CINdetails.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8810",
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="A CIN case cannot have a Reason for Closure without a CIN Closure Date",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[ReasonForClosure, CINclosureDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df = data_container[CINdetails]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <ReasonForClosure> (N00103) is present then <CINclosureDate> (N00102) must also be present
+    # Return rows where there is a Reason for closure and no CINclosureDate
+    condition = df[ReasonForClosure].notna() & df[CINclosureDate].isna()
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    link_id = tuple(
+        zip(df_issues[LAchildID], df_issues[ReasonForClosure], df_issues[CINdetailsID])
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=CINdetails, columns=[ReasonForClosure, CINclosureDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_data_frame = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "ReasonForClosure": "aaa",
+                "CINclosureDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "CINdetailsID": "CINID2",
+                "ReasonForClosure": "aaa",
+                "CINclosureDate": "26/05/2001",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CINID3",
+                "ReasonForClosure": "aaa",
+                "CINclosureDate": pd.NA,
+            },  #  Fails because there is a ReasonForClosure and no CINclosureDate
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "CINID4",
+                "ReasonForClosure": "aaa",
+                "CINclosureDate": pd.NA,
+            },  #  Fails because there is a ReasonForClosure and no CINclosureDate
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "CINID5",
+                "ReasonForClosure": pd.NA,
+                "CINclosureDate": "25/05/2000",
+            },
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "CINID6",
+                "ReasonForClosure": pd.NA,
+                "CINclosureDate": pd.NA,
+            },
+        ]
+    )
+    #  Date values not checked so no datetime conversion.
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {CINdetails: fake_data_frame})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    # check that the right columns were returned.
+    issue_columns = issues.columns
+    assert issue_columns == [ReasonForClosure, CINclosureDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "aaa",
+                    "CINID3",
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "aaa",
+                    "CINID4",
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8810' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8810"
+    assert (
+        result.definition.message
+        == "A CIN case cannot have a Reason for Closure without a CIN Closure Date"
+    )
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4010.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4010.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,100 +1,100 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-CINplanDates = CINTable.CINplanDates
-LAchildID = CINplanDates.LAchildID
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="4010",
-    module=CINTable.CINplanDates,
-    message="CIN Plan start date is missing or out of data collection period",
-    affected_fields=[CINPlanStartDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINplanDates]
-    df_ref = data_container[Header]
-
-    ref_data_series = df_ref[ReferenceDate]
-    collection_start, reference_date = make_census_period(ref_data_series)
-
-    # Where a <CINPlanDates> module is present, <CINPlanStartDate> (N00689) must be present and on or before the <ReferenceDate> (N00603)
-    # condition states that there must be a value in CINPlanStartDate and that value must be after the reference_date.
-    # As such any NULL values for CINPlanStartDate wil be flagged with the error message
-    df = df[(df[CINPlanStartDate].isna() | (df[CINPlanStartDate] > reference_date))]
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=CINplanDates, field=CINPlanStartDate, row=failing_indices
-    )
-
-
-def test_validate():
-    cin_start = pd.to_datetime(
-        # Create some sample data such that some values pass the validation and some fail.
-        [
-            "2022-04-25",  # Fail - CINPlanStartDate is after the reference_date of 31st March 2022
-            "2022-03-01",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
-            "2022-12-25",  # Fail - CINPlanStartDate is after the reference_date of 31st March 2022
-            "2021-04-27",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
-            "2021-11-21",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
-            "2021-08-20",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
-            "2020-04-17",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
-            "1999-01-30",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
-            pd.NA,  # Fail - CINPlanStartDate is blank and is therefore missing.
-        ],
-        format="%Y/%m/%d",
-        errors="coerce",
-    )
-    CINids = [
-        "CINID1",
-        "CINID2",
-        "CINID3",
-        "CINID4",
-        "CINID5",
-        "CINID6",
-        "CINID7",
-        "CINID8",
-        "CINID9",
-    ]
-
-    fake_cin_start = pd.DataFrame({CINPlanStartDate: cin_start, "CINdetailsID": CINids})
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]
-    )  # the reference date will be 31/03/2022
-
-    fake_header["ReferenceDate"] = pd.to_datetime(
-        fake_header["ReferenceDate"], format="%d/%m/%Y"
-    )
-
-    result = run_rule(validate, {CINplanDates: fake_cin_start, Header: fake_header})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-    assert issues == [
-        IssueLocator(CINTable.CINplanDates, CINPlanStartDate, 0),
-        IssueLocator(CINTable.CINplanDates, CINPlanStartDate, 2),
-        IssueLocator(CINTable.CINplanDates, CINPlanStartDate, 8),
-    ]
-
-    assert result.definition.code == "4010"
-    assert (
-        result.definition.message
-        == "CIN Plan start date is missing or out of data collection period"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+CINplanDates = CINTable.CINplanDates
+LAchildID = CINplanDates.LAchildID
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="4010",
+    module=CINTable.CINplanDates,
+    message="CIN Plan start date is missing or out of data collection period",
+    affected_fields=[CINPlanStartDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINplanDates]
+    df_ref = data_container[Header]
+
+    ref_data_series = df_ref[ReferenceDate]
+    collection_start, reference_date = make_census_period(ref_data_series)
+
+    # Where a <CINPlanDates> module is present, <CINPlanStartDate> (N00689) must be present and on or before the <ReferenceDate> (N00603)
+    # condition states that there must be a value in CINPlanStartDate and that value must be after the reference_date.
+    # As such any NULL values for CINPlanStartDate wil be flagged with the error message
+    df = df[(df[CINPlanStartDate].isna() | (df[CINPlanStartDate] > reference_date))]
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=CINplanDates, field=CINPlanStartDate, row=failing_indices
+    )
+
+
+def test_validate():
+    cin_start = pd.to_datetime(
+        # Create some sample data such that some values pass the validation and some fail.
+        [
+            "2022-04-25",  # Fail - CINPlanStartDate is after the reference_date of 31st March 2022
+            "2022-03-01",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
+            "2022-12-25",  # Fail - CINPlanStartDate is after the reference_date of 31st March 2022
+            "2021-04-27",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
+            "2021-11-21",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
+            "2021-08-20",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
+            "2020-04-17",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
+            "1999-01-30",  # Pass - CINPlanStartDate is before the reference_date of 31st March 2022
+            pd.NA,  # Fail - CINPlanStartDate is blank and is therefore missing.
+        ],
+        format="%Y/%m/%d",
+        errors="coerce",
+    )
+    CINids = [
+        "CINID1",
+        "CINID2",
+        "CINID3",
+        "CINID4",
+        "CINID5",
+        "CINID6",
+        "CINID7",
+        "CINID8",
+        "CINID9",
+    ]
+
+    fake_cin_start = pd.DataFrame({CINPlanStartDate: cin_start, "CINdetailsID": CINids})
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]
+    )  # the reference date will be 31/03/2022
+
+    fake_header["ReferenceDate"] = pd.to_datetime(
+        fake_header["ReferenceDate"], format="%d/%m/%Y"
+    )
+
+    result = run_rule(validate, {CINplanDates: fake_cin_start, Header: fake_header})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+    assert issues == [
+        IssueLocator(CINTable.CINplanDates, CINPlanStartDate, 0),
+        IssueLocator(CINTable.CINplanDates, CINPlanStartDate, 2),
+        IssueLocator(CINTable.CINplanDates, CINPlanStartDate, 8),
+    ]
+
+    assert result.definition.code == "4010"
+    assert (
+        result.definition.message
+        == "CIN Plan start date is missing or out of data collection period"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4011.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4011.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,122 +1,122 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-CINplanDates = CINTable.CINplanDates
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-LAchildID = CINplanDates.LAchildID
-
-
-@rule_definition(
-    code="4011",
-    module=CINTable.CINplanDates,
-    message="CIN Plan End Date earlier than Start Date",
-    affected_fields=[CINPlanEndDate, CINPlanStartDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINplanDates]
-    df.index.name = "ROW_ID"
-
-    # <If present <CINPlanEndDate> (N00690) must be on or after the <CINPlanStartDate> (N00689)
-    # Remove all rows with no end date
-    df = df[~df[CINPlanEndDate].isna()]
-
-    # Return rows where end date is prior to start dat
-    condition1 = df[CINPlanEndDate] < df[CINPlanStartDate]
-
-    # df with all rows meeting the conditions
-    df_issues = df[condition1].reset_index()
-
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID], df_issues[CINPlanEndDate], df_issues[CINPlanStartDate]
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_1(
-        table=CINplanDates, columns=[CINPlanEndDate, CINPlanStartDate], row_df=df_issues
-    )
-
-
-def test_validate():
-    cin_plan = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINPlanEndDate": "26/05/2000",
-                "CINPlanStartDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",
-                "CINPlanEndDate": "26/05/2000",
-                "CINPlanStartDate": "26/05/2001",
-                # fails, start after end
-            },
-            {
-                "LAchildID": "child3",
-                "CINPlanEndDate": "26/05/2000",
-                "CINPlanStartDate": "26/05/1999",
-            },
-            {
-                "LAchildID": "child4",
-                "CINPlanEndDate": "26/05/2000",
-                "CINPlanStartDate": pd.NA,
-                # pass, no requirement in this rule for a start date
-            },
-            {
-                "LAchildID": "child6",
-                "CINPlanEndDate": pd.NA,
-                "CINPlanStartDate": pd.NA,
-            },
-        ]
-    )
-    cin_plan[CINPlanEndDate] = pd.to_datetime(
-        cin_plan[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
-    )
-    cin_plan[CINPlanStartDate] = pd.to_datetime(
-        cin_plan[CINPlanStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(validate, {CINplanDates: cin_plan})
-
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == CINplanDates
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINPlanEndDate, CINPlanStartDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("26/05/2001", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4011"
-    assert result.definition.message == "CIN Plan End Date earlier than Start Date"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+CINplanDates = CINTable.CINplanDates
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+CINPlanEndDate = CINplanDates.CINPlanEndDate
+LAchildID = CINplanDates.LAchildID
+
+
+@rule_definition(
+    code="4011",
+    module=CINTable.CINplanDates,
+    message="CIN Plan End Date earlier than Start Date",
+    affected_fields=[CINPlanEndDate, CINPlanStartDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINplanDates]
+    df.index.name = "ROW_ID"
+
+    # <If present <CINPlanEndDate> (N00690) must be on or after the <CINPlanStartDate> (N00689)
+    # Remove all rows with no end date
+    df = df[~df[CINPlanEndDate].isna()]
+
+    # Return rows where end date is prior to start dat
+    condition1 = df[CINPlanEndDate] < df[CINPlanStartDate]
+
+    # df with all rows meeting the conditions
+    df_issues = df[condition1].reset_index()
+
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID], df_issues[CINPlanEndDate], df_issues[CINPlanStartDate]
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_1(
+        table=CINplanDates, columns=[CINPlanEndDate, CINPlanStartDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    cin_plan = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINPlanEndDate": "26/05/2000",
+                "CINPlanStartDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "CINPlanEndDate": "26/05/2000",
+                "CINPlanStartDate": "26/05/2001",
+                # fails, start after end
+            },
+            {
+                "LAchildID": "child3",
+                "CINPlanEndDate": "26/05/2000",
+                "CINPlanStartDate": "26/05/1999",
+            },
+            {
+                "LAchildID": "child4",
+                "CINPlanEndDate": "26/05/2000",
+                "CINPlanStartDate": pd.NA,
+                # pass, no requirement in this rule for a start date
+            },
+            {
+                "LAchildID": "child6",
+                "CINPlanEndDate": pd.NA,
+                "CINPlanStartDate": pd.NA,
+            },
+        ]
+    )
+    cin_plan[CINPlanEndDate] = pd.to_datetime(
+        cin_plan[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
+    )
+    cin_plan[CINPlanStartDate] = pd.to_datetime(
+        cin_plan[CINPlanStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {CINplanDates: cin_plan})
+
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == CINplanDates
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINPlanEndDate, CINPlanStartDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/2001", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "4011"
+    assert result.definition.message == "CIN Plan End Date earlier than Start Date"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4012Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4012Q.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,146 +1,146 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    RuleType,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-CINplanDates = CINTable.CINplanDates
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-LAchildID = CINplanDates.LAchildID
-
-
-@rule_definition(
-    code="4012Q",
-    rule_type=RuleType.QUERY,
-    module=CINTable.CINplanDates,
-    message="Please check and either amend or provide a reason: CIN Plan shown as starting and ending on the same day",
-    affected_fields=[CINPlanStartDate, CINPlanEndDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINplanDates]
-
-    # Within a <CINPlanDates> group, <CINPlanStartDate> (N00689) should not be the same as the <CINPlanEndDate> (N00690)
-    df.index.name = "ROW_ID"
-    df = df[df["CINPlanStartDate"] == df["CINPlanEndDate"]]
-
-    df_issues = df.reset_index()
-
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID], df_issues[CINPlanStartDate], df_issues[CINPlanEndDate]
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    rule_context.push_type_1(
-        table=CINplanDates, columns=[CINPlanStartDate, CINPlanEndDate], row_df=df_issues
-    )
-
-
-def test_validate():
-    IDS_are = [
-        "AAAAAAAA",
-        "BBBBBBBBB",
-        "CCCCCCCCCCC",
-        "DDDDDDDDD",
-        "EEEE",
-        "FFFFFFFFF",
-        "GGGGGGGGGG",
-        "HHHH",
-    ]
-    starts = [
-        "01-01-2020",
-        "01-02-2020",
-        "01-03-2020",
-        "15-01-2020",
-        pd.NA,
-        "01-07-2020",
-        "15-01-2020",
-        pd.NA,
-    ]
-    ends = [
-        "01-01-2020",
-        "01-01-2020",
-        "01-03-2020",
-        "17-01-2020",
-        pd.NA,
-        "01-01-2020",
-        "15-01-2020",
-        "01-01-2020",
-    ]
-    #  Fails rows 0, 2, 6.
-    fake_dataframe = pd.DataFrame(
-        {"LAchildID": IDS_are, "CINPlanStartDate": starts, "CINPlanEndDate": ends}
-    )
-
-    fake_dataframe[CINPlanStartDate] = pd.to_datetime(
-        fake_dataframe[CINPlanStartDate], format=r"%d-%m-%Y", errors="coerce"
-    )
-    fake_dataframe[CINPlanEndDate] = pd.to_datetime(
-        fake_dataframe[CINPlanEndDate], format=r"%d-%m-%Y", errors="coerce"
-    )
-
-    result = run_rule(validate, {CINplanDates: fake_dataframe})
-
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == CINplanDates
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINPlanStartDate, CINPlanEndDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 3
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "AAAAAAAA",
-                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "CCCCCCCCCCC",
-                    pd.to_datetime("01-03-2020", format=r"%d-%m-%Y", errors="coerce"),
-                    pd.to_datetime("01-03-2020", format=r"%d-%m-%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "GGGGGGGGGG",
-                    pd.to_datetime("15-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                    pd.to_datetime("15-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                ),
-                "ROW_ID": [6],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4012Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend or provide a reason: CIN Plan shown as starting and ending on the same day"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    RuleType,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+CINplanDates = CINTable.CINplanDates
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+CINPlanEndDate = CINplanDates.CINPlanEndDate
+LAchildID = CINplanDates.LAchildID
+
+
+@rule_definition(
+    code="4012Q",
+    rule_type=RuleType.QUERY,
+    module=CINTable.CINplanDates,
+    message="Please check and either amend or provide a reason: CIN Plan shown as starting and ending on the same day",
+    affected_fields=[CINPlanStartDate, CINPlanEndDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINplanDates]
+
+    # Within a <CINPlanDates> group, <CINPlanStartDate> (N00689) should not be the same as the <CINPlanEndDate> (N00690)
+    df.index.name = "ROW_ID"
+    df = df[df["CINPlanStartDate"] == df["CINPlanEndDate"]]
+
+    df_issues = df.reset_index()
+
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID], df_issues[CINPlanStartDate], df_issues[CINPlanEndDate]
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    rule_context.push_type_1(
+        table=CINplanDates, columns=[CINPlanStartDate, CINPlanEndDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    IDS_are = [
+        "AAAAAAAA",
+        "BBBBBBBBB",
+        "CCCCCCCCCCC",
+        "DDDDDDDDD",
+        "EEEE",
+        "FFFFFFFFF",
+        "GGGGGGGGGG",
+        "HHHH",
+    ]
+    starts = [
+        "01-01-2020",
+        "01-02-2020",
+        "01-03-2020",
+        "15-01-2020",
+        pd.NA,
+        "01-07-2020",
+        "15-01-2020",
+        pd.NA,
+    ]
+    ends = [
+        "01-01-2020",
+        "01-01-2020",
+        "01-03-2020",
+        "17-01-2020",
+        pd.NA,
+        "01-01-2020",
+        "15-01-2020",
+        "01-01-2020",
+    ]
+    #  Fails rows 0, 2, 6.
+    fake_dataframe = pd.DataFrame(
+        {"LAchildID": IDS_are, "CINPlanStartDate": starts, "CINPlanEndDate": ends}
+    )
+
+    fake_dataframe[CINPlanStartDate] = pd.to_datetime(
+        fake_dataframe[CINPlanStartDate], format=r"%d-%m-%Y", errors="coerce"
+    )
+    fake_dataframe[CINPlanEndDate] = pd.to_datetime(
+        fake_dataframe[CINPlanEndDate], format=r"%d-%m-%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {CINplanDates: fake_dataframe})
+
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == CINplanDates
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINPlanStartDate, CINPlanEndDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 3
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "AAAAAAAA",
+                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "CCCCCCCCCCC",
+                    pd.to_datetime("01-03-2020", format=r"%d-%m-%Y", errors="coerce"),
+                    pd.to_datetime("01-03-2020", format=r"%d-%m-%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "GGGGGGGGGG",
+                    pd.to_datetime("15-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                    pd.to_datetime("15-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                ),
+                "ROW_ID": [6],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "4012Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend or provide a reason: CIN Plan shown as starting and ending on the same day"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4013.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4013.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,82 +1,82 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-CINPlanDates = CINTable.CINplanDates
-CINPlanEndDate = CINPlanDates.CINPlanEndDate
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="4013",
-    module=CINTable.CINplanDates,
-    message="CIN Plan end date must fall within the census year",
-    affected_fields=[CINPlanEndDate, ReferenceDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINPlanDates]
-
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # If <CINPlanEndDate> (N00690) is present, then<CINPlanEndDate> (N00690) must fall within [Period_of_Census] inclusive
-    # A value is out of range if it is before the start or after the end.
-    failing_indices = df[
-        (df[CINPlanEndDate] < collection_start) | (df[CINPlanEndDate] > reference_date)
-    ].index
-
-    rule_context.push_issue(
-        table=CINPlanDates, field=CINPlanEndDate, row=failing_indices
-    )
-
-
-def test_validate():
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-    fake_CINEndDate = pd.DataFrame(
-        [
-            {
-                CINPlanEndDate: "01/03/2019"
-            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
-            {
-                CINPlanEndDate: "01/04/2021"
-            },  # 1 pass: April 1st is within April 1st, 2021 to March 31st, 2022.
-            {
-                CINPlanEndDate: "01/10/2022"
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-        ]
-    )
-
-    fake_CINEndDate[CINPlanEndDate] = pd.to_datetime(
-        fake_CINEndDate[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(validate, {CINPlanDates: fake_CINEndDate, Header: fake_header})
-
-    issues = list(result.issues)
-    assert len(issues) == 2
-    assert issues == [
-        # from above, index positions 0 and 2 fail.
-        IssueLocator(CINTable.CINplanDates, CINPlanEndDate, 0),
-        IssueLocator(CINTable.CINplanDates, CINPlanEndDate, 2),
-    ]
-
-    assert result.definition.code == "4013"
-    assert (
-        result.definition.message
-        == "CIN Plan end date must fall within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+CINPlanDates = CINTable.CINplanDates
+CINPlanEndDate = CINPlanDates.CINPlanEndDate
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="4013",
+    module=CINTable.CINplanDates,
+    message="CIN Plan end date must fall within the census year",
+    affected_fields=[CINPlanEndDate, ReferenceDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINPlanDates]
+
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # If <CINPlanEndDate> (N00690) is present, then<CINPlanEndDate> (N00690) must fall within [Period_of_Census] inclusive
+    # A value is out of range if it is before the start or after the end.
+    failing_indices = df[
+        (df[CINPlanEndDate] < collection_start) | (df[CINPlanEndDate] > reference_date)
+    ].index
+
+    rule_context.push_issue(
+        table=CINPlanDates, field=CINPlanEndDate, row=failing_indices
+    )
+
+
+def test_validate():
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
+    )
+    fake_CINEndDate = pd.DataFrame(
+        [
+            {
+                CINPlanEndDate: "01/03/2019"
+            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
+            {
+                CINPlanEndDate: "01/04/2021"
+            },  # 1 pass: April 1st is within April 1st, 2021 to March 31st, 2022.
+            {
+                CINPlanEndDate: "01/10/2022"
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+        ]
+    )
+
+    fake_CINEndDate[CINPlanEndDate] = pd.to_datetime(
+        fake_CINEndDate[CINPlanEndDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {CINPlanDates: fake_CINEndDate, Header: fake_header})
+
+    issues = list(result.issues)
+    assert len(issues) == 2
+    assert issues == [
+        # from above, index positions 0 and 2 fail.
+        IssueLocator(CINTable.CINplanDates, CINPlanEndDate, 0),
+        IssueLocator(CINTable.CINplanDates, CINPlanEndDate, 2),
+    ]
+
+    assert result.definition.code == "4013"
+    assert (
+        result.definition.message
+        == "CIN Plan end date must fall within the census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4014.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4014.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,256 +1,256 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-CINplanDates = CINTable.CINplanDates
-LAchildID = CINplanDates.LAchildID
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="4014",
-    module=CINTable.CINplanDates,
-    message="CIN Plan data contains overlapping dates",
-    affected_fields=[
-        CINPlanStartDate,
-        CINPlanEndDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cinp = data_container[CINplanDates].copy()
-    df_cinp2 = data_container[CINplanDates].copy()
-
-    df_cinp.index.name = "ROW_ID"
-    df_cinp2.index.name = "ROW_ID"
-
-    df_cinp.reset_index(inplace=True)
-    df_cinp2.reset_index(inplace=True)
-
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # Where more than one <CINplanDates> group is included,
-    # the <CINPlanStartDate> (N00105) of each group cannot fall within either:
-    #   a) <CINPlanStartDate> (N00105) to <CINPlanEndDate> (N00115), or
-    #   b) <CINPlanStartDate> (N00105) and <ReferenceDate> if <CINPlanEndDate> (N00115) is not present
-    # of any other group
-    #
-    # Issues dfs should return rows where CINPlanStartDate is between another CINPlanStartDate and CINPlanEndDate (or ReferenceDate)
-
-    #  Create dataframes which only have rows with CIN plans, and which should have one plan per row.
-    df_cinp = df_cinp[df_cinp[CINPlanStartDate].notna()]
-    df_cinp2 = df_cinp2[df_cinp2[CINPlanStartDate].notna()]
-
-    #  Merge tables to test for overlaps
-    df_merged = df_cinp.merge(
-        df_cinp2,
-        on=["LAchildID"],
-        how="left",
-        suffixes=("_cinp", "_cinp2"),
-    )
-
-    # Use CINPlanStartDate to identify a CIN plan. Exclude rows where the ROW_ID is the same on both sides to prevent a plan from being compared with itself.
-    df_merged = df_merged[df_merged["ROW_ID_cinp"] != df_merged["ROW_ID_cinp2"]]
-
-    # Determine whether CINplanStart overlaps with another CINplan period of the same child.
-    cinp_started_after_start = (
-        df_merged["CINPlanStartDate_cinp"] >= df_merged["CINPlanStartDate_cinp2"]
-    )
-    cinp_started_before_end = (
-        df_merged["CINPlanStartDate_cinp"] <= df_merged["CINPlanEndDate_cinp2"]
-    ) & df_merged["CINPlanEndDate_cinp2"].notna()
-    cinp_started_before_refdate = (
-        df_merged["CINPlanStartDate_cinp"] <= reference_date
-    ) & df_merged["CINPlanEndDate_cinp2"].isna()
-
-    df_merged = df_merged[
-        cinp_started_after_start
-        & (cinp_started_before_end | cinp_started_before_refdate)
-    ].reset_index()
-
-    # create an identifier for each error instance.
-    # In this case, the rule is checked for each CINPlanStartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged["CINPlanStartDate_cinp"],
-            df_merged["CINPlanStartDate_cinp2"],
-        )
-    )
-
-    # The merges were done on copies of cinp_df so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cinp_issues = (
-        df_cinp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cinp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cinp2_issues = (
-        df_cinp2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cinp2")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_3(
-        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_cinp_issues
-    )
-    rule_context.push_type_3(
-        table=CINplanDates,
-        columns=[CINPlanStartDate, CINPlanEndDate],
-        row_df=df_cinp2_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
-    )
-
-    sample_cinp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 Pass
-                "CINPlanStartDate": "26/05/2000",
-                "CINPlanEndDate": "26/10/2000",
-            },
-            {
-                "LAchildID": "child1",  # 1 Fail because of 0
-                "CINPlanStartDate": "26/08/2000",
-                "CINPlanEndDate": "26/12/2000",
-            },
-            {
-                "LAchildID": "child2",  # 2 Pass
-                "CINPlanStartDate": "26/05/2000",
-                "CINPlanEndDate": "25/10/2000",
-            },
-            {
-                "LAchildID": "child2",  # 3 Pass
-                "CINPlanStartDate": "26/10/2000",
-                "CINPlanEndDate": "26/12/2000",
-            },
-            {
-                "LAchildID": "child3",  # 4 Pass
-                "CINPlanStartDate": "26/05/2000",
-                "CINPlanEndDate": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # 5 Fail
-                "CINPlanStartDate": "26/08/2000",
-                "CINPlanEndDate": "26/10/2000",
-            },
-            {
-                "LAchildID": "child4",  # 6 Pass
-                "CINPlanStartDate": "26/10/2000",
-                "CINPlanEndDate": "31/03/2001",
-            },
-            {
-                "LAchildID": "child4",  # 7 Fail
-                "CINPlanStartDate": "31/03/2001",
-                "CINPlanEndDate": pd.NA,
-            },
-            {
-                "LAchildID": "child5",  # 8 Fail
-                "CINPlanStartDate": "31/03/2001",
-                "CINPlanEndDate": "31/04/2001",
-            },
-            {
-                "LAchildID": "child5",  # 9 Fail
-                "CINPlanStartDate": "31/03/2001",
-                "CINPlanEndDate": "31/04/2001",
-            },
-        ]
-    )
-
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cinp[CINPlanStartDate] = pd.to_datetime(
-        sample_cinp[CINPlanStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cinp["CINPlanEndDate"] = pd.to_datetime(
-        sample_cinp["CINPlanEndDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINplanDates: sample_cinp,
-            Header: sample_header,
-        },
-    )
-
-    issues_list = result.type3_issues
-    assert len(issues_list) == 2
-
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == CINplanDates
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINPlanStartDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 4
-
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    pd.to_datetime("31/03/2001", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("26/10/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [7],
-            },
-            {
-                "ERROR_ID": (
-                    "child5",
-                    pd.to_datetime("31/03/2001", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("31/03/2001", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [8, 9],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4014"
-    assert result.definition.message == "CIN Plan data contains overlapping dates"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+CINplanDates = CINTable.CINplanDates
+LAchildID = CINplanDates.LAchildID
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+CINPlanEndDate = CINplanDates.CINPlanEndDate
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="4014",
+    module=CINTable.CINplanDates,
+    message="CIN Plan data contains overlapping dates",
+    affected_fields=[
+        CINPlanStartDate,
+        CINPlanEndDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cinp = data_container[CINplanDates].copy()
+    df_cinp2 = data_container[CINplanDates].copy()
+
+    df_cinp.index.name = "ROW_ID"
+    df_cinp2.index.name = "ROW_ID"
+
+    df_cinp.reset_index(inplace=True)
+    df_cinp2.reset_index(inplace=True)
+
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # Where more than one <CINplanDates> group is included,
+    # the <CINPlanStartDate> (N00105) of each group cannot fall within either:
+    #   a) <CINPlanStartDate> (N00105) to <CINPlanEndDate> (N00115), or
+    #   b) <CINPlanStartDate> (N00105) and <ReferenceDate> if <CINPlanEndDate> (N00115) is not present
+    # of any other group
+    #
+    # Issues dfs should return rows where CINPlanStartDate is between another CINPlanStartDate and CINPlanEndDate (or ReferenceDate)
+
+    #  Create dataframes which only have rows with CIN plans, and which should have one plan per row.
+    df_cinp = df_cinp[df_cinp[CINPlanStartDate].notna()]
+    df_cinp2 = df_cinp2[df_cinp2[CINPlanStartDate].notna()]
+
+    #  Merge tables to test for overlaps
+    df_merged = df_cinp.merge(
+        df_cinp2,
+        on=["LAchildID"],
+        how="left",
+        suffixes=("_cinp", "_cinp2"),
+    )
+
+    # Use CINPlanStartDate to identify a CIN plan. Exclude rows where the ROW_ID is the same on both sides to prevent a plan from being compared with itself.
+    df_merged = df_merged[df_merged["ROW_ID_cinp"] != df_merged["ROW_ID_cinp2"]]
+
+    # Determine whether CINplanStart overlaps with another CINplan period of the same child.
+    cinp_started_after_start = (
+        df_merged["CINPlanStartDate_cinp"] >= df_merged["CINPlanStartDate_cinp2"]
+    )
+    cinp_started_before_end = (
+        df_merged["CINPlanStartDate_cinp"] <= df_merged["CINPlanEndDate_cinp2"]
+    ) & df_merged["CINPlanEndDate_cinp2"].notna()
+    cinp_started_before_refdate = (
+        df_merged["CINPlanStartDate_cinp"] <= reference_date
+    ) & df_merged["CINPlanEndDate_cinp2"].isna()
+
+    df_merged = df_merged[
+        cinp_started_after_start
+        & (cinp_started_before_end | cinp_started_before_refdate)
+    ].reset_index()
+
+    # create an identifier for each error instance.
+    # In this case, the rule is checked for each CINPlanStartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged["CINPlanStartDate_cinp"],
+            df_merged["CINPlanStartDate_cinp2"],
+        )
+    )
+
+    # The merges were done on copies of cinp_df so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_cinp_issues = (
+        df_cinp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cinp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_cinp2_issues = (
+        df_cinp2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cinp2")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_cinp_issues
+    )
+    rule_context.push_type_3(
+        table=CINplanDates,
+        columns=[CINPlanStartDate, CINPlanEndDate],
+        row_df=df_cinp2_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
+    )
+
+    sample_cinp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # 0 Pass
+                "CINPlanStartDate": "26/05/2000",
+                "CINPlanEndDate": "26/10/2000",
+            },
+            {
+                "LAchildID": "child1",  # 1 Fail because of 0
+                "CINPlanStartDate": "26/08/2000",
+                "CINPlanEndDate": "26/12/2000",
+            },
+            {
+                "LAchildID": "child2",  # 2 Pass
+                "CINPlanStartDate": "26/05/2000",
+                "CINPlanEndDate": "25/10/2000",
+            },
+            {
+                "LAchildID": "child2",  # 3 Pass
+                "CINPlanStartDate": "26/10/2000",
+                "CINPlanEndDate": "26/12/2000",
+            },
+            {
+                "LAchildID": "child3",  # 4 Pass
+                "CINPlanStartDate": "26/05/2000",
+                "CINPlanEndDate": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # 5 Fail
+                "CINPlanStartDate": "26/08/2000",
+                "CINPlanEndDate": "26/10/2000",
+            },
+            {
+                "LAchildID": "child4",  # 6 Pass
+                "CINPlanStartDate": "26/10/2000",
+                "CINPlanEndDate": "31/03/2001",
+            },
+            {
+                "LAchildID": "child4",  # 7 Fail
+                "CINPlanStartDate": "31/03/2001",
+                "CINPlanEndDate": pd.NA,
+            },
+            {
+                "LAchildID": "child5",  # 8 Fail
+                "CINPlanStartDate": "31/03/2001",
+                "CINPlanEndDate": "31/04/2001",
+            },
+            {
+                "LAchildID": "child5",  # 9 Fail
+                "CINPlanStartDate": "31/03/2001",
+                "CINPlanEndDate": "31/04/2001",
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cinp[CINPlanStartDate] = pd.to_datetime(
+        sample_cinp[CINPlanStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cinp["CINPlanEndDate"] = pd.to_datetime(
+        sample_cinp["CINPlanEndDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINplanDates: sample_cinp,
+            Header: sample_header,
+        },
+    )
+
+    issues_list = result.type3_issues
+    assert len(issues_list) == 2
+
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == CINplanDates
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINPlanStartDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 4
+
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    pd.to_datetime("31/03/2001", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/10/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [7],
+            },
+            {
+                "ERROR_ID": (
+                    "child5",
+                    pd.to_datetime("31/03/2001", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("31/03/2001", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [8, 9],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "4014"
+    assert result.definition.message == "CIN Plan data contains overlapping dates"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4015.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4015.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,187 +1,187 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-CINplanDates = CINTable.CINplanDates
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-LAchildID = CINplanDates.LAchildID
-
-CINdetails = CINTable.CINdetails
-CINreferralDate = CINdetails.CINreferralDate
-
-
-@rule_definition(
-    code="4015",
-    module=CINTable.CINplanDates,
-    message="The CIN Plan start date cannot be before the referral date",
-    affected_fields=[
-        CINPlanStartDate,
-        CINreferralDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    """
-    Where present, the <CINPlanStartDate> (N00689) must be on or after the <CINReferralDate> (N00100)
-    """
-    df_cindetail = data_container[CINdetails].copy()
-    df_cinplan = data_container[CINplanDates].copy()
-
-    df_cindetail.index.name = "ROW_ID"
-    df_cinplan.index.name = "ROW_ID"
-
-    df_cindetail.reset_index(inplace=True)
-    df_cinplan.reset_index(inplace=True)
-
-    # Where present, the <CINPlanStartDate> (N00689) must be on or after the <CINReferralDate> (N00100)
-    df_cinplan = df_cinplan[df_cinplan[CINPlanStartDate].notna()]
-
-    df_merged = df_cindetail.merge(
-        df_cinplan,
-        how="inner",
-        on=["LAchildID", "CINdetailsID"],
-        suffixes=["_det", "_plan"],
-    )
-
-    df_merged.query(r"CINPlanStartDate < CINreferralDate", inplace=True)
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[CINPlanStartDate],
-            df_merged[CINreferralDate],
-        )
-    )
-
-    df_cindet_issues = (
-        df_cinplan.merge(
-            df_merged, how="inner", left_on="ROW_ID", right_on="ROW_ID_plan"
-        )
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cinplan_issues = (
-        df_cindetail.merge(
-            df_merged, how="inner", left_on="ROW_ID", right_on="ROW_ID_det"
-        )
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_cindet_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_cinplan_issues
-    )
-
-
-def test_validate():
-    plan_is = (
-        # ID     #CINID   #PlanStartDate
-        ("1", "45", "2020-05-05"),  # 0
-        ("4", "55", "2019-04-20"),  # 1
-        ("67", "66", "2014-03-21"),  # 2
-        ("69", "67", "2018-04-20"),  # 3
-        ("69", "67", pd.NA),  # 4
-        ("167", "166", "2014-03-21"),  # 5
-    )
-
-    cin_is = (
-        # ID     #CINID   #CIN Ref Date
-        ("1", "44", "2017-05-05"),  # A  0
-        ("4", "55", "2019-04-20"),  # B  1
-        ("67", "66", "2016-03-21"),  # C  2
-        ("67", "67", "2015-03-21"),  # D  3
-        ("69", "67", "2018-04-20"),  # E  4
-        ("70", "69", "2015-04-20"),  # F  5
-        ("167", "166", "2015-02-21"),  # G  6
-    )
-
-    fake_cinplan = pd.DataFrame(
-        {
-            "LAchildID": [x[0] for x in plan_is],
-            "CINdetailsID": [x[1] for x in plan_is],
-            "CINPlanStartDate": [x[2] for x in plan_is],
-        }
-    )
-    fake_cindetail = pd.DataFrame(
-        {
-            "LAchildID": [x[0] for x in cin_is],
-            "CINdetailsID": [x[1] for x in cin_is],
-            "CINreferralDate": [x[2] for x in cin_is],
-        }
-    )
-    fake_cinplan[CINPlanStartDate] = pd.to_datetime(
-        fake_cinplan[CINPlanStartDate], format=r"%Y-%m-%d", errors="coerce"
-    )
-    fake_cindetail["CINreferralDate"] = pd.to_datetime(
-        fake_cindetail["CINreferralDate"], format=r"%Y-%m-%d", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINplanDates: fake_cinplan,
-            CINdetails: fake_cindetail,
-        },
-    )
-
-    issues_list = result.type2_issues
-
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINreferralDate]
-
-    issue_rows = issues.row_df
-
-    assert len(issue_rows) == 2
-
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "67",  # ChildID
-                    # Start Date
-                    pd.to_datetime("21/03/2014", format=r"%d/%m/%Y", errors="coerce"),
-                    # Ref date
-                    pd.to_datetime("21/03/2016", format=r"%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "167",  # ChildID
-                    # Start date
-                    pd.to_datetime("21/03/2014", format=r"%d/%m/%Y", errors="coerce"),
-                    # Ref date
-                    pd.to_datetime("21/02/2015", format=r"%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [6],
-            },
-        ]
-    )
-    issue_rows.sort_values(["ROW_ID"], ignore_index=True, inplace=True)
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "4015"
-    assert (
-        result.definition.message
-        == "The CIN Plan start date cannot be before the referral date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+CINplanDates = CINTable.CINplanDates
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+LAchildID = CINplanDates.LAchildID
+
+CINdetails = CINTable.CINdetails
+CINreferralDate = CINdetails.CINreferralDate
+
+
+@rule_definition(
+    code="4015",
+    module=CINTable.CINplanDates,
+    message="The CIN Plan start date cannot be before the referral date",
+    affected_fields=[
+        CINPlanStartDate,
+        CINreferralDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    """
+    Where present, the <CINPlanStartDate> (N00689) must be on or after the <CINReferralDate> (N00100)
+    """
+    df_cindetail = data_container[CINdetails].copy()
+    df_cinplan = data_container[CINplanDates].copy()
+
+    df_cindetail.index.name = "ROW_ID"
+    df_cinplan.index.name = "ROW_ID"
+
+    df_cindetail.reset_index(inplace=True)
+    df_cinplan.reset_index(inplace=True)
+
+    # Where present, the <CINPlanStartDate> (N00689) must be on or after the <CINReferralDate> (N00100)
+    df_cinplan = df_cinplan[df_cinplan[CINPlanStartDate].notna()]
+
+    df_merged = df_cindetail.merge(
+        df_cinplan,
+        how="inner",
+        on=["LAchildID", "CINdetailsID"],
+        suffixes=["_det", "_plan"],
+    )
+
+    df_merged.query(r"CINPlanStartDate < CINreferralDate", inplace=True)
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[CINPlanStartDate],
+            df_merged[CINreferralDate],
+        )
+    )
+
+    df_cindet_issues = (
+        df_cinplan.merge(
+            df_merged, how="inner", left_on="ROW_ID", right_on="ROW_ID_plan"
+        )
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_cinplan_issues = (
+        df_cindetail.merge(
+            df_merged, how="inner", left_on="ROW_ID", right_on="ROW_ID_det"
+        )
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=CINplanDates, columns=[CINPlanStartDate], row_df=df_cindet_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_cinplan_issues
+    )
+
+
+def test_validate():
+    plan_is = (
+        # ID     #CINID   #PlanStartDate
+        ("1", "45", "2020-05-05"),  # 0
+        ("4", "55", "2019-04-20"),  # 1
+        ("67", "66", "2014-03-21"),  # 2
+        ("69", "67", "2018-04-20"),  # 3
+        ("69", "67", pd.NA),  # 4
+        ("167", "166", "2014-03-21"),  # 5
+    )
+
+    cin_is = (
+        # ID     #CINID   #CIN Ref Date
+        ("1", "44", "2017-05-05"),  # A  0
+        ("4", "55", "2019-04-20"),  # B  1
+        ("67", "66", "2016-03-21"),  # C  2
+        ("67", "67", "2015-03-21"),  # D  3
+        ("69", "67", "2018-04-20"),  # E  4
+        ("70", "69", "2015-04-20"),  # F  5
+        ("167", "166", "2015-02-21"),  # G  6
+    )
+
+    fake_cinplan = pd.DataFrame(
+        {
+            "LAchildID": [x[0] for x in plan_is],
+            "CINdetailsID": [x[1] for x in plan_is],
+            "CINPlanStartDate": [x[2] for x in plan_is],
+        }
+    )
+    fake_cindetail = pd.DataFrame(
+        {
+            "LAchildID": [x[0] for x in cin_is],
+            "CINdetailsID": [x[1] for x in cin_is],
+            "CINreferralDate": [x[2] for x in cin_is],
+        }
+    )
+    fake_cinplan[CINPlanStartDate] = pd.to_datetime(
+        fake_cinplan[CINPlanStartDate], format=r"%Y-%m-%d", errors="coerce"
+    )
+    fake_cindetail["CINreferralDate"] = pd.to_datetime(
+        fake_cindetail["CINreferralDate"], format=r"%Y-%m-%d", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINplanDates: fake_cinplan,
+            CINdetails: fake_cindetail,
+        },
+    )
+
+    issues_list = result.type2_issues
+
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINreferralDate]
+
+    issue_rows = issues.row_df
+
+    assert len(issue_rows) == 2
+
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "67",  # ChildID
+                    # Start Date
+                    pd.to_datetime("21/03/2014", format=r"%d/%m/%Y", errors="coerce"),
+                    # Ref date
+                    pd.to_datetime("21/03/2016", format=r"%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "167",  # ChildID
+                    # Start date
+                    pd.to_datetime("21/03/2014", format=r"%d/%m/%Y", errors="coerce"),
+                    # Ref date
+                    pd.to_datetime("21/02/2015", format=r"%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [6],
+            },
+        ]
+    )
+    issue_rows.sort_values(["ROW_ID"], ignore_index=True, inplace=True)
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "4015"
+    assert (
+        result.definition.message
+        == "The CIN Plan start date cannot be before the referral date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4180.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4180.py`

 * *Ordering differences only*

 * *Files 8% similar despite different names*

```diff
@@ -1,80 +1,80 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-# Replace ChildIdentifiers with the table name, and GenderCurrent with the column name you want.
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-GenderCurrent = ChildIdentifiers.GenderCurrent
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of 8500
-    code="4180",
-    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildIdentifiers,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Gender is missing",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[GenderCurrent],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace ChildIdentifiers with the name of the table you need.
-    df = data_container[ChildIdentifiers]
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    valid_gender_codes = ["1", "2", "0", "9"]
-
-    # <GenderCurrent> (N00097) must be present and valid
-
-    failing_indices = df[
-        df[GenderCurrent].isna()
-        | (~df[GenderCurrent].astype("str").isin(valid_gender_codes))
-    ].index
-
-    # Replace ChildIdentifiers and GenderCurrent with the table and column name concerned in your rule, respectively.
-    # If there are multiple columns or table, make this sentence multiple times.
-    rule_context.push_issue(
-        table=ChildIdentifiers, field=GenderCurrent, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    child_identifiers = pd.DataFrame(
-        [1, pd.NA, 7, "Male", 2, 0, 9, "9"], columns=[GenderCurrent]
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issues) == 3
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, GenderCurrent, 1),
-        IssueLocator(CINTable.ChildIdentifiers, GenderCurrent, 2),
-        IssueLocator(CINTable.ChildIdentifiers, GenderCurrent, 3),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '4180' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "4180"
-    assert result.definition.message == "Gender is missing"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+# Replace ChildIdentifiers with the table name, and GenderCurrent with the column name you want.
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+GenderCurrent = ChildIdentifiers.GenderCurrent
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of 8500
+    code="4180",
+    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildIdentifiers,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Gender is missing",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[GenderCurrent],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace ChildIdentifiers with the name of the table you need.
+    df = data_container[ChildIdentifiers]
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    valid_gender_codes = ["1", "2", "0", "9"]
+
+    # <GenderCurrent> (N00097) must be present and valid
+
+    failing_indices = df[
+        df[GenderCurrent].isna()
+        | (~df[GenderCurrent].astype("str").isin(valid_gender_codes))
+    ].index
+
+    # Replace ChildIdentifiers and GenderCurrent with the table and column name concerned in your rule, respectively.
+    # If there are multiple columns or table, make this sentence multiple times.
+    rule_context.push_issue(
+        table=ChildIdentifiers, field=GenderCurrent, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_identifiers = pd.DataFrame(
+        [1, pd.NA, 7, "Male", 2, 0, 9, "9"], columns=[GenderCurrent]
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issues) == 3
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, GenderCurrent, 1),
+        IssueLocator(CINTable.ChildIdentifiers, GenderCurrent, 2),
+        IssueLocator(CINTable.ChildIdentifiers, GenderCurrent, 3),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '4180' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "4180"
+    assert result.definition.message == "Gender is missing"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_4220.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_4220.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,88 +1,88 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildCharacteristics = CINTable.ChildCharacteristics
-Ethnicity = ChildCharacteristics.Ethnicity
-
-
-@rule_definition(
-    code="4220",
-    module=CINTable.ChildCharacteristics,
-    message="Ethnicity is missing or invalid (see Ethnicity table)",
-    affected_fields=[Ethnicity],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildCharacteristics]
-    """
-    <Ethnicity> (N00177) must be present and a valid code
-    """
-
-    eth_list = [
-        "ABAN",
-        "AIND",
-        "AOTH",
-        "APKN",
-        "BAFR",
-        "BCRB",
-        "BOTH",
-        "CHNE",
-        "MOTH",
-        "MWAS",
-        "MWBA",
-        "MWBC",
-        "NOBT",
-        "OOTH",
-        "REFU",
-        "WBRI",
-        "WIRI",
-        "WIRT",
-        "WOTH",
-        "WROM",
-    ]
-
-    df.reset_index(inplace=True)
-
-    # Ethnicity is not in list or is null.
-    df2 = df[(~df["Ethnicity"].isin(eth_list)) | df["Ethnicity"].isna()]
-
-    failing_indices = df2.set_index("index").index
-
-    rule_context.push_issue(
-        table=ChildCharacteristics, field=Ethnicity, row=failing_indices
-    )
-
-
-def test_validate():
-    # 0      #1      #2      #3     #4      #5      #6
-    eths = ["ABAB", "AIND", "AOTH", pd.NA, "MOTH", "WOTH", "AAAA"]
-
-    fake_dataframe = pd.DataFrame({"Ethnicity": eths})
-
-    result = run_rule(validate, {ChildCharacteristics: fake_dataframe})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-
-    assert issues == [
-        IssueLocator(CINTable.ChildCharacteristics, Ethnicity, 0),
-        IssueLocator(CINTable.ChildCharacteristics, Ethnicity, 3),
-        IssueLocator(CINTable.ChildCharacteristics, Ethnicity, 6),
-    ]
-
-    assert result.definition.code == "4220"
-    assert (
-        result.definition.message
-        == "Ethnicity is missing or invalid (see Ethnicity table)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildCharacteristics = CINTable.ChildCharacteristics
+Ethnicity = ChildCharacteristics.Ethnicity
+
+
+@rule_definition(
+    code="4220",
+    module=CINTable.ChildCharacteristics,
+    message="Ethnicity is missing or invalid (see Ethnicity table)",
+    affected_fields=[Ethnicity],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildCharacteristics]
+    """
+    <Ethnicity> (N00177) must be present and a valid code
+    """
+
+    eth_list = [
+        "ABAN",
+        "AIND",
+        "AOTH",
+        "APKN",
+        "BAFR",
+        "BCRB",
+        "BOTH",
+        "CHNE",
+        "MOTH",
+        "MWAS",
+        "MWBA",
+        "MWBC",
+        "NOBT",
+        "OOTH",
+        "REFU",
+        "WBRI",
+        "WIRI",
+        "WIRT",
+        "WOTH",
+        "WROM",
+    ]
+
+    df.reset_index(inplace=True)
+
+    # Ethnicity is not in list or is null.
+    df2 = df[(~df["Ethnicity"].isin(eth_list)) | df["Ethnicity"].isna()]
+
+    failing_indices = df2.set_index("index").index
+
+    rule_context.push_issue(
+        table=ChildCharacteristics, field=Ethnicity, row=failing_indices
+    )
+
+
+def test_validate():
+    # 0      #1      #2      #3     #4      #5      #6
+    eths = ["ABAB", "AIND", "AOTH", pd.NA, "MOTH", "WOTH", "AAAA"]
+
+    fake_dataframe = pd.DataFrame({"Ethnicity": eths})
+
+    result = run_rule(validate, {ChildCharacteristics: fake_dataframe})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+
+    assert issues == [
+        IssueLocator(CINTable.ChildCharacteristics, Ethnicity, 0),
+        IssueLocator(CINTable.ChildCharacteristics, Ethnicity, 3),
+        IssueLocator(CINTable.ChildCharacteristics, Ethnicity, 6),
+    ]
+
+    assert result.definition.code == "4220"
+    assert (
+        result.definition.message
+        == "Ethnicity is missing or invalid (see Ethnicity table)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8500.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8500.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,71 +1,71 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-# Replace ChildIdentifiers with the table name, and LAChildID with the column name you want.
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-LAchildID = ChildIdentifiers.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8500'
-    code="8500",
-    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildIdentifiers,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="LA Child ID missing",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[LAchildID],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace ChildIdentifiers with the name of the table you need.
-    df = data_container[ChildIdentifiers]
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # <LAchildID> (N00097) must be present
-    failing_indices = df[df[LAchildID].isna()].index
-
-    # Replace ChildIdentifiers and LAchildID with the table and column name concerned in your rule, respectively.
-    # If there are multiple columns or table, make this sentence multiple times.
-    rule_context.push_issue(
-        table=ChildIdentifiers, field=LAchildID, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    child_identifiers = pd.DataFrame([[1234], [pd.NA], [pd.NA]], columns=[LAchildID])
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 1),
-        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8500' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8500"
-    assert result.definition.message == "LA Child ID missing"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+# Replace ChildIdentifiers with the table name, and LAChildID with the column name you want.
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+LAchildID = ChildIdentifiers.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8500'
+    code="8500",
+    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildIdentifiers,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="LA Child ID missing",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[LAchildID],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace ChildIdentifiers with the name of the table you need.
+    df = data_container[ChildIdentifiers]
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # <LAchildID> (N00097) must be present
+    failing_indices = df[df[LAchildID].isna()].index
+
+    # Replace ChildIdentifiers and LAchildID with the table and column name concerned in your rule, respectively.
+    # If there are multiple columns or table, make this sentence multiple times.
+    rule_context.push_issue(
+        table=ChildIdentifiers, field=LAchildID, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_identifiers = pd.DataFrame([[1234], [pd.NA], [pd.NA]], columns=[LAchildID])
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 1),
+        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8500' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8500"
+    assert result.definition.message == "LA Child ID missing"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8510.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8510.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,62 +1,62 @@
-"""
-Rule number: '8510'
-Module: Child idenitifiers
-Rule details: Each <LAchildID> (N00097) must be unique across all children within the same LA return. 
-
-Note: This rule should be evaluated at LA-level for imported data
-
-Rule message: More than one child record with the same LA Child ID
-
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-LAchildID = ChildIdentifiers.LAchildID
-
-
-@rule_definition(
-    code="8510",
-    module=CINTable.ChildIdentifiers,
-    message="More than one child record with the same LA Child ID",
-    affected_fields=[LAchildID],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-
-    # Each <LAchildID> (N00097) must be unique across all children within the same LA return
-    failing_indices = df[df.duplicated(subset=[LAchildID], keep=False)].index
-
-    rule_context.push_issue(
-        table=ChildIdentifiers, field=LAchildID, row=failing_indices
-    )
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame([[1234], [1234], [346546]], columns=[LAchildID])
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-    assert len(issues) == 2
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 0),
-        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 1),
-    ]
-
-    assert result.definition.code == "8510"
-    assert (
-        result.definition.message
-        == "More than one child record with the same LA Child ID"
-    )
+"""
+Rule number: '8510'
+Module: Child idenitifiers
+Rule details: Each <LAchildID> (N00097) must be unique across all children within the same LA return. 
+
+Note: This rule should be evaluated at LA-level for imported data
+
+Rule message: More than one child record with the same LA Child ID
+
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+LAchildID = ChildIdentifiers.LAchildID
+
+
+@rule_definition(
+    code="8510",
+    module=CINTable.ChildIdentifiers,
+    message="More than one child record with the same LA Child ID",
+    affected_fields=[LAchildID],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+
+    # Each <LAchildID> (N00097) must be unique across all children within the same LA return
+    failing_indices = df[df.duplicated(subset=[LAchildID], keep=False)].index
+
+    rule_context.push_issue(
+        table=ChildIdentifiers, field=LAchildID, row=failing_indices
+    )
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame([[1234], [1234], [346546]], columns=[LAchildID])
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+    assert len(issues) == 2
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 0),
+        IssueLocator(CINTable.ChildIdentifiers, LAchildID, 1),
+    ]
+
+    assert result.definition.code == "8510"
+    assert (
+        result.definition.message
+        == "More than one child record with the same LA Child ID"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8525Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8535Q.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,140 +1,150 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.rules.cin2022_23.rule_8535Q import PersonDeathDate
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-PersonBirthDate = ChildIdentifiers.PersonBirthDate
-ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
-LAchildID = ChildIdentifiers.LAchildID
-
-
-@rule_definition(
-    code="8525Q",
-    module=CINTable.ChildIdentifiers,
-    rule_type=RuleType.QUERY,
-    message="Either Date of Birth or Expected Date of Birth must be provided (but not both)",
-    affected_fields=[PersonBirthDate, ExpectedPersonBirthDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-    df = df.drop(columns=["ROW_ID"], errors="ignore")
-    df.index.name = "ROW_ID"
-
-    # Either Date of Birth or Expected Date of Birth must be provided (but not both)
-    # condition_1 = (df[PersonBirthDate].isna() & df[ExpectedPersonBirthDate].isna())
-
-    # condition_1 = (df[PersonBirthDate].isna()) & (df[ExpectedPersonBirthDate].isna())
-    # condition_2 = df[PersonBirthDate].notna() & df[ExpectedPersonBirthDate].notna()
-    mega_condition = (
-        df[PersonBirthDate].isna() & df[ExpectedPersonBirthDate].notna()
-    ) | (df[PersonBirthDate].notna() & df[ExpectedPersonBirthDate].isna())
-
-    df_issues = df[~mega_condition].reset_index()
-
-    # (LAchildID,PersonBirthDate,ExpectedPersonBirthDate) could have been used. However, in some failing conditions,
-    # both (PersonBirthDate,ExpectedPersonBirthDate) can be null so their combination does not serve as a unique ID.
-    # Since this is the ChildIdentifiers table and LAchildID is typically unique in it. We use that to serve as a last resort ID.
-
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_1(
-        table=ChildIdentifiers,
-        columns=[PersonBirthDate, ExpectedPersonBirthDate],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    fake_data_frame = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": "26/05/2000",
-            },  # Fails because both DOB and expected DOB are present
-            {
-                "LAchildID": "child2",
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": "26/05/2001",
-            },  # Fails because both DOB and expected DOB are present
-            {
-                "LAchildID": "child4",
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": "26/05/1999",
-            },
-            {
-                "LAchildID": "child4",
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": pd.NA,
-            },
-            {
-                "LAchildID": "child5",
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": "25/05/2000",
-            },  # Fails because both DOB and expected DOB are present
-            {
-                "LAchildID": "child6",
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": pd.NA,
-            },  # Fails because there is no DOB or expected DOB
-        ]
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: fake_data_frame})
-
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    issue_columns = issues.columns
-    assert issue_columns == [PersonBirthDate, ExpectedPersonBirthDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 4
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": ("child1",),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": ("child2",),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": ("child5",),
-                "ROW_ID": [4],
-            },
-            {
-                "ERROR_ID": ("child6",),
-                "ROW_ID": [5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8525Q"
-    assert (
-        result.definition.message
-        == "Either Date of Birth or Expected Date of Birth must be provided (but not both)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+PersonBirthDate = ChildIdentifiers.PersonBirthDate
+ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+LAchildID = ChildIdentifiers.LAchildID
+
+
+@rule_definition(
+    code="8535Q",
+    module=CINTable.ChildIdentifiers,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend data or provide a reason: Child’s date of death should not be prior to the date of birth",
+    affected_fields=[PersonDeathDate, PersonBirthDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+    df.index.name = "ROW_ID"
+
+    # <PersonDeathDate> (N00108) must be on or after <PersonBirthDate> (N00066)
+
+    # Remove all rows with no deathdate
+    df = df[~df[PersonDeathDate].isna()]
+    # Remove children who died unborn. They shouldn't flag this rule [DfE tool doesn't].
+    df = df[~(df[ExpectedPersonBirthDate] > df[PersonDeathDate])]
+
+    # Return rows where DOB is prior to DOD
+    condition1 = df[PersonBirthDate] > df[PersonDeathDate]
+    condition2 = df[PersonBirthDate].isna()
+
+    # df with all rows meeting the conditions
+    df_issues = df[condition1 | condition2].reset_index()
+
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID], df_issues[PersonDeathDate], df_issues[PersonBirthDate]
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_1(
+        table=ChildIdentifiers,
+        columns=[PersonDeathDate, PersonBirthDate],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "PersonDeathDate": "26/05/2000",
+                "PersonBirthDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "PersonDeathDate": "26/05/2001",
+                "PersonBirthDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",
+                "PersonDeathDate": "26/05/1999",
+                "PersonBirthDate": "26/05/2000",
+            },  # 2 error: end is before start
+            {
+                "LAchildID": "child4",
+                "PersonDeathDate": "26/05/2000",
+                "ExpectedPersonBirthDate": "27/05/2000",
+                "PersonBirthDate": pd.NA,
+                # 3 pass: no birth date
+            },
+            {
+                "LAchildID": "child5",
+                "PersonDeathDate": "25/05/2000",
+                "PersonBirthDate": "26/05/2000",
+            },  # 4 error: end is before start
+            {
+                "LAchildID": "child6",
+                "PersonDeathDate": pd.NA,
+                "PersonBirthDate": pd.NA,
+            },
+        ]
+    )
+
+    child_identifiers[PersonDeathDate] = pd.to_datetime(
+        child_identifiers[PersonDeathDate], format="%d/%m/%Y", errors="coerce"
+    )
+    child_identifiers[PersonBirthDate] = pd.to_datetime(
+        child_identifiers[PersonBirthDate], format="%d/%m/%Y", errors="coerce"
+    )
+    child_identifiers[ExpectedPersonBirthDate] = pd.to_datetime(
+        child_identifiers[ExpectedPersonBirthDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    issue_columns = issues.columns
+    assert issue_columns == [PersonDeathDate, PersonBirthDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",
+                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child5",
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8535Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: Child’s date of death should not be prior to the date of birth"
+    )
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8530Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8530Q.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,160 +1,160 @@
-"""
-Rule number: 8530Q
-Module: Child Identifiers
-Rule details: If present <ExpectedPersonBirthDate> (N00098) should be between [<ReferenceDate> (N00603) minus 30 days] and [<ReferenceDate> (N00603) plus 9 months]
-Rule message: Please check: Expected Date of Birth is outside the expected range for this census (March to December of the Census Year end)
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    RuleType,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
-LAchildID = ChildIdentifiers.LAchildID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="8530Q",
-    module=CINTable.ChildIdentifiers,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend data or provide a reason: Expected Date of Birth is outside the expected range for this census (March to December of the Census Year end)",
-    affected_fields=[ExpectedPersonBirthDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-    df.index.name = "ROW_ID"
-
-    df_ref = data_container[Header]
-    ref_date = df_ref[ReferenceDate].iloc[0]
-
-    #  <ExpectedPersonBirthDate> (N00098) should be between [<ReferenceDate> (N00603) minus 30 days] and [<ReferenceDate> (N00603) plus 9 months]
-
-    # Filter to only those with expected birthdate
-    df = df[~df[ExpectedPersonBirthDate].isna()]
-
-    # Find the reference date - 30
-    earliest_date = ref_date - pd.DateOffset(days=30)
-    # Find reference date + 9 months
-    latest_date = ref_date + pd.DateOffset(months=9)
-
-    condition1 = df[ExpectedPersonBirthDate] >= latest_date
-    condition2 = df[ExpectedPersonBirthDate] <= earliest_date
-
-    df_issues = df[condition1 | condition2].reset_index()
-
-    link_id = tuple(zip(df_issues[LAchildID], df_issues[ExpectedPersonBirthDate]))
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildIdentifiers,
-        columns=[ExpectedPersonBirthDate],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    sample_ChildIdentifiers = pd.DataFrame(
-        [
-            {
-                "LAchildID": "ID1",
-                "ExpectedPersonBirthDate": pd.NA,
-                # Pass, no birth date
-            },
-            {
-                "LAchildID": "ID2",
-                "ExpectedPersonBirthDate": "30/03/2023",
-                # Pass, birth date within range
-            },
-            {
-                "LAchildID": "ID3",
-                "ExpectedPersonBirthDate": "15/10/2021",
-                # Fail, start date is before ref date - 45wd
-            },
-            {
-                "LAchildID": "ID4",
-                "ExpectedPersonBirthDate": "15/03/2024",
-                # Fail, later than 9 months after ref date
-            },
-        ]
-    )
-
-    sample_ChildIdentifiers[ExpectedPersonBirthDate] = pd.to_datetime(
-        sample_ChildIdentifiers[ExpectedPersonBirthDate],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-
-    sample_header = pd.DataFrame([{"ReferenceDate": "31/03/2023"}])
-
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_ChildIdentifiers,
-            Header: sample_header,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 1
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    issue_columns = issues.columns
-    assert issue_columns == [ExpectedPersonBirthDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "ID3",
-                    pd.to_datetime("15/10/2021", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "ID4",
-                    pd.to_datetime("15/03/2024", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8530Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: Expected Date of Birth is outside the expected range for this census (March to December of the Census Year end)"
-    )
+"""
+Rule number: 8530Q
+Module: Child Identifiers
+Rule details: If present <ExpectedPersonBirthDate> (N00098) should be between [<ReferenceDate> (N00603) minus 30 days] and [<ReferenceDate> (N00603) plus 9 months]
+Rule message: Please check: Expected Date of Birth is outside the expected range for this census (March to December of the Census Year end)
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    RuleType,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
+LAchildID = ChildIdentifiers.LAchildID
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="8530Q",
+    module=CINTable.ChildIdentifiers,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend data or provide a reason: Expected Date of Birth is outside the expected range for this census (March to December of the Census Year end)",
+    affected_fields=[ExpectedPersonBirthDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+    df.index.name = "ROW_ID"
+
+    df_ref = data_container[Header]
+    ref_date = df_ref[ReferenceDate].iloc[0]
+
+    #  <ExpectedPersonBirthDate> (N00098) should be between [<ReferenceDate> (N00603) minus 30 days] and [<ReferenceDate> (N00603) plus 9 months]
+
+    # Filter to only those with expected birthdate
+    df = df[~df[ExpectedPersonBirthDate].isna()]
+
+    # Find the reference date - 30
+    earliest_date = ref_date - pd.DateOffset(days=30)
+    # Find reference date + 9 months
+    latest_date = ref_date + pd.DateOffset(months=9)
+
+    condition1 = df[ExpectedPersonBirthDate] >= latest_date
+    condition2 = df[ExpectedPersonBirthDate] <= earliest_date
+
+    df_issues = df[condition1 | condition2].reset_index()
+
+    link_id = tuple(zip(df_issues[LAchildID], df_issues[ExpectedPersonBirthDate]))
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildIdentifiers,
+        columns=[ExpectedPersonBirthDate],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    sample_ChildIdentifiers = pd.DataFrame(
+        [
+            {
+                "LAchildID": "ID1",
+                "ExpectedPersonBirthDate": pd.NA,
+                # Pass, no birth date
+            },
+            {
+                "LAchildID": "ID2",
+                "ExpectedPersonBirthDate": "30/03/2023",
+                # Pass, birth date within range
+            },
+            {
+                "LAchildID": "ID3",
+                "ExpectedPersonBirthDate": "15/10/2021",
+                # Fail, start date is before ref date - 45wd
+            },
+            {
+                "LAchildID": "ID4",
+                "ExpectedPersonBirthDate": "15/03/2024",
+                # Fail, later than 9 months after ref date
+            },
+        ]
+    )
+
+    sample_ChildIdentifiers[ExpectedPersonBirthDate] = pd.to_datetime(
+        sample_ChildIdentifiers[ExpectedPersonBirthDate],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    sample_header = pd.DataFrame([{"ReferenceDate": "31/03/2023"}])
+
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildIdentifiers: sample_ChildIdentifiers,
+            Header: sample_header,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 1
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    issue_columns = issues.columns
+    assert issue_columns == [ExpectedPersonBirthDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "ID3",
+                    pd.to_datetime("15/10/2021", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "ID4",
+                    pd.to_datetime("15/03/2024", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8530Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: Expected Date of Birth is outside the expected range for this census (March to December of the Census Year end)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8540.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8540.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,227 +1,227 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-CINdetails = CINTable.CINdetails
-Disabilities = CINTable.Disabilities
-
-LAchildID = ChildIdentifiers.LAchildID
-PersonBirthDate = ChildIdentifiers.PersonBirthDate
-ReferralNFA = CINdetails.ReferralNFA
-Disability = Disabilities.Disability
-
-
-@rule_definition(
-    code="8540",
-    module=CINTable.ChildCharacteristics,
-    message="Child’s disability is missing or invalid (see Disability table)",
-    affected_fields=[Disability, PersonBirthDate, ReferralNFA],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_dis = data_container[Disabilities].copy()
-    df_ci = data_container[ChildIdentifiers].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    df_ci.index.name = "ROW_ID"
-    df_dis.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_ci.reset_index(inplace=True)
-    df_dis.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # If <PersonBirthDate> (N00066) is present and at least one <ReferralNFA> (N00112) is false or 0,
-    # then one or more instances of <Disability> (N00099) must be present,
-    # and all instances must be valid code values
-    valid_dis = [
-        "NONE",
-        "MOB",
-        "HAND",
-        "PC",
-        "INC",
-        "COMM",
-        "LD",
-        "HEAR",
-        "VIS",
-        "BEH",
-        "CON",
-        "AUT",
-        "DDA",
-    ]
-
-    df_ci_cin = df_ci.merge(
-        df_cin, on="LAchildID", how="left", suffixes=("_ci", "_cin")
-    )
-    merged_df = df_ci_cin.merge(
-        df_dis, on="LAchildID", how="left", suffixes=("", "_dis")
-    )
-
-    merged_df = merged_df[~merged_df[Disability].isin(valid_dis)]
-    merged_df = merged_df[merged_df[PersonBirthDate].notna()]
-    merged_df = merged_df[merged_df[ReferralNFA].isin(["false", "0"])]
-
-    merged_df["ERROR_ID"] = tuple(
-        zip(
-            merged_df[LAchildID],
-            merged_df[PersonBirthDate],
-        )
-    )
-
-    df_dis_issues = (
-        df_dis.merge(merged_df, on="ROW_ID")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_ci_issues = (
-        df_ci.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ci")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID_x"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID_x"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonBirthDate], row_df=df_ci_issues
-    )
-    rule_context.push_type_2(
-        table=Disabilities, columns=[Disability], row_df=df_dis_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[ReferralNFA], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    sample_ci = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "PersonBirthDate": "01/01/1880",
-            },
-            {
-                "LAchildID": "child2",
-                "PersonBirthDate": "01/01/1880",
-            },
-            {
-                "LAchildID": "child3",
-                "PersonBirthDate": "01/01/1880",
-            },
-            {
-                "LAchildID": "child4",
-                "PersonBirthDate": "01/01/1880",
-            },
-            {
-                "LAchildID": "child5",  # 4 ignore: has no ReferralNFA
-                "PersonBirthDate": "01/01/1880",
-            },
-        ]
-    )
-
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # considered
-                "CINdetailsID": "CINID1",
-                "ReferralNFA": "false",
-            },
-            {
-                "LAchildID": "child2",  # considered
-                "CINdetailsID": "CINID1",
-                "ReferralNFA": "0",
-            },
-            {
-                "LAchildID": "child3",  # considered since one of its ReferralNFA values is false/0
-                "CINdetailsID": "CINID1",
-                "ReferralNFA": "0",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CINID2",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child4",  # 3 ignore ReferralNFA is not false/0
-                "CINdetailsID": "CINID1",
-                "ReferralNFA": "1",
-            },
-        ]
-    )
-
-    sample_dis = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 fail: Disability should be present
-                "Disability": pd.NA,
-            },
-            {
-                "LAchildID": "child2",  # 1 pass
-                "Disability": "MOB",
-            },
-            {
-                "LAchildID": "child3",  # 2 fail: Disability should be valid
-                "Disability": "notreal",
-            },
-        ]
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_ci,
-            Disabilities: sample_dis,
-            CINdetails: sample_cin,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 3
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == Disabilities
-
-    issue_columns = issues.columns
-    assert issue_columns == [Disability]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "01/01/1880",
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "01/01/1880",
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8540"
-    assert (
-        result.definition.message
-        == "Child’s disability is missing or invalid (see Disability table)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+CINdetails = CINTable.CINdetails
+Disabilities = CINTable.Disabilities
+
+LAchildID = ChildIdentifiers.LAchildID
+PersonBirthDate = ChildIdentifiers.PersonBirthDate
+ReferralNFA = CINdetails.ReferralNFA
+Disability = Disabilities.Disability
+
+
+@rule_definition(
+    code="8540",
+    module=CINTable.ChildCharacteristics,
+    message="Child’s disability is missing or invalid (see Disability table)",
+    affected_fields=[Disability, PersonBirthDate, ReferralNFA],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_dis = data_container[Disabilities].copy()
+    df_ci = data_container[ChildIdentifiers].copy()
+    df_cin = data_container[CINdetails].copy()
+
+    df_ci.index.name = "ROW_ID"
+    df_dis.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    df_ci.reset_index(inplace=True)
+    df_dis.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # If <PersonBirthDate> (N00066) is present and at least one <ReferralNFA> (N00112) is false or 0,
+    # then one or more instances of <Disability> (N00099) must be present,
+    # and all instances must be valid code values
+    valid_dis = [
+        "NONE",
+        "MOB",
+        "HAND",
+        "PC",
+        "INC",
+        "COMM",
+        "LD",
+        "HEAR",
+        "VIS",
+        "BEH",
+        "CON",
+        "AUT",
+        "DDA",
+    ]
+
+    df_ci_cin = df_ci.merge(
+        df_cin, on="LAchildID", how="left", suffixes=("_ci", "_cin")
+    )
+    merged_df = df_ci_cin.merge(
+        df_dis, on="LAchildID", how="left", suffixes=("", "_dis")
+    )
+
+    merged_df = merged_df[~merged_df[Disability].isin(valid_dis)]
+    merged_df = merged_df[merged_df[PersonBirthDate].notna()]
+    merged_df = merged_df[merged_df[ReferralNFA].isin(["false", "0"])]
+
+    merged_df["ERROR_ID"] = tuple(
+        zip(
+            merged_df[LAchildID],
+            merged_df[PersonBirthDate],
+        )
+    )
+
+    df_dis_issues = (
+        df_dis.merge(merged_df, on="ROW_ID")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_ci_issues = (
+        df_ci.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ci")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID_x"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID_x"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildIdentifiers, columns=[PersonBirthDate], row_df=df_ci_issues
+    )
+    rule_context.push_type_2(
+        table=Disabilities, columns=[Disability], row_df=df_dis_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReferralNFA], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    sample_ci = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "PersonBirthDate": "01/01/1880",
+            },
+            {
+                "LAchildID": "child2",
+                "PersonBirthDate": "01/01/1880",
+            },
+            {
+                "LAchildID": "child3",
+                "PersonBirthDate": "01/01/1880",
+            },
+            {
+                "LAchildID": "child4",
+                "PersonBirthDate": "01/01/1880",
+            },
+            {
+                "LAchildID": "child5",  # 4 ignore: has no ReferralNFA
+                "PersonBirthDate": "01/01/1880",
+            },
+        ]
+    )
+
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # considered
+                "CINdetailsID": "CINID1",
+                "ReferralNFA": "false",
+            },
+            {
+                "LAchildID": "child2",  # considered
+                "CINdetailsID": "CINID1",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child3",  # considered since one of its ReferralNFA values is false/0
+                "CINdetailsID": "CINID1",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CINID2",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child4",  # 3 ignore ReferralNFA is not false/0
+                "CINdetailsID": "CINID1",
+                "ReferralNFA": "1",
+            },
+        ]
+    )
+
+    sample_dis = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # 0 fail: Disability should be present
+                "Disability": pd.NA,
+            },
+            {
+                "LAchildID": "child2",  # 1 pass
+                "Disability": "MOB",
+            },
+            {
+                "LAchildID": "child3",  # 2 fail: Disability should be valid
+                "Disability": "notreal",
+            },
+        ]
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildIdentifiers: sample_ci,
+            Disabilities: sample_dis,
+            CINdetails: sample_cin,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 3
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == Disabilities
+
+    issue_columns = issues.columns
+    assert issue_columns == [Disability]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "01/01/1880",
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "01/01/1880",
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8540"
+    assert (
+        result.definition.message
+        == "Child’s disability is missing or invalid (see Disability table)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8545Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8545Q.py`

 * *Ordering differences only*

 * *Files 17% similar despite different names*

```diff
@@ -1,95 +1,95 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    RuleType,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-Header = CINTable.Header
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="8545Q",
-    module=CINTable.ChildIdentifiers,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend data or provide a reason: Child's date of death should be within the census year",
-    affected_fields=[PersonDeathDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-    df_ref = data_container[Header]
-
-    # If present, <PersonDeathDate> (N00108) must be within [Period_of_Census]
-    df = df[[PersonDeathDate]]
-
-    # Death date must not be null, invalid text dates are made null in the line above
-    df = df[df[PersonDeathDate].notna()]
-
-    # Select out only the ReferenceDate column from the DataFrame
-    ref_date_series = df_ref[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # DeathDate isn't in the financial year
-    df = df[
-        ~(
-            (df[PersonDeathDate] >= collection_start)
-            & (df[PersonDeathDate] <= collection_end)
-        )
-    ]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=ChildIdentifiers, field=PersonDeathDate, row=failing_indices
-    )
-
-
-def test_validate():
-    p_death = pd.to_datetime(
-        [
-            "2022-04-25",
-            "2022-03-01",
-            "2022-12-25",
-            "2021-04-27",
-            "2021-11-21",
-            "2021-08-20",
-            "2020-04-17",
-            "1666-55-55",
-            pd.NA,
-        ],
-        format="%Y/%m/%d",
-        errors="coerce",
-    )
-
-    fake_ident = pd.DataFrame({PersonDeathDate: p_death})
-    fake_head = pd.DataFrame({ReferenceDate: ["31/03/2022"]})
-
-    result = run_rule(validate, {ChildIdentifiers: fake_ident, Header: fake_head})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, PersonDeathDate, 0),
-        IssueLocator(CINTable.ChildIdentifiers, PersonDeathDate, 2),
-        IssueLocator(CINTable.ChildIdentifiers, PersonDeathDate, 6),
-    ]
-
-    assert result.definition.code == "8545Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: Child's date of death should be within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    RuleType,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+Header = CINTable.Header
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="8545Q",
+    module=CINTable.ChildIdentifiers,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend data or provide a reason: Child's date of death should be within the census year",
+    affected_fields=[PersonDeathDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+    df_ref = data_container[Header]
+
+    # If present, <PersonDeathDate> (N00108) must be within [Period_of_Census]
+    df = df[[PersonDeathDate]]
+
+    # Death date must not be null, invalid text dates are made null in the line above
+    df = df[df[PersonDeathDate].notna()]
+
+    # Select out only the ReferenceDate column from the DataFrame
+    ref_date_series = df_ref[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # DeathDate isn't in the financial year
+    df = df[
+        ~(
+            (df[PersonDeathDate] >= collection_start)
+            & (df[PersonDeathDate] <= collection_end)
+        )
+    ]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=ChildIdentifiers, field=PersonDeathDate, row=failing_indices
+    )
+
+
+def test_validate():
+    p_death = pd.to_datetime(
+        [
+            "2022-04-25",
+            "2022-03-01",
+            "2022-12-25",
+            "2021-04-27",
+            "2021-11-21",
+            "2021-08-20",
+            "2020-04-17",
+            "1666-55-55",
+            pd.NA,
+        ],
+        format="%Y/%m/%d",
+        errors="coerce",
+    )
+
+    fake_ident = pd.DataFrame({PersonDeathDate: p_death})
+    fake_head = pd.DataFrame({ReferenceDate: ["31/03/2022"]})
+
+    result = run_rule(validate, {ChildIdentifiers: fake_ident, Header: fake_head})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, PersonDeathDate, 0),
+        IssueLocator(CINTable.ChildIdentifiers, PersonDeathDate, 2),
+        IssueLocator(CINTable.ChildIdentifiers, PersonDeathDate, 6),
+    ]
+
+    assert result.definition.code == "8545Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: Child's date of death should be within the census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8555Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8606.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,199 +1,210 @@
-"""
-Rule number: 8555Q
-Module: CIN details
-Rule details: If <PersonDeathDate> (N00108) is present, then the <CINreferralDate> (N00100) must be on or before the <PersonDeathDate> (N00108)
-Rule message: Child cannot be referred after its recorded date of death
-
-"""
-
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-LAchildID = ChildIdentifiers.LAchildID
-
-CINdetails = CINTable.CINdetails
-CINreferralDate = CINdetails.CINreferralDate
-LAchildID = CINdetails.LAchildID
-
-
-@rule_definition(
-    code="8555Q",
-    module=CINTable.CINdetails,
-    rule_type=RuleType.QUERY,
-    message="Child cannot be referred after its recorded date of death",
-    affected_fields=[
-        PersonDeathDate,
-        CINreferralDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_CINDetails = data_container[CINdetails].copy()
-    df_ChildIdentifiers = data_container[ChildIdentifiers].copy()
-
-    df_CINDetails.index.name = "ROW_ID"
-    df_ChildIdentifiers.index.name = "ROW_ID"
-
-    df_CINDetails.reset_index(inplace=True)
-    df_ChildIdentifiers.reset_index(inplace=True)
-
-    # <CINreferralDate> (N00100) must be on or before the <PersonDeathDate> (N00108)
-
-    # Remove rows with no death date
-    df_ChildIdentifiers = df_ChildIdentifiers[
-        df_ChildIdentifiers[PersonDeathDate].notna()
-    ]
-
-    #  Join tables
-    df_merged = df_CINDetails.merge(
-        df_ChildIdentifiers,
-        left_on=["LAchildID"],
-        right_on=["LAchildID"],
-        how="left",
-        suffixes=("_CINDetails", "_ChildIdentifiers"),
-    )
-
-    #  Get rows where PersonDeathDate is less than  CINreferralDate
-    condition = df_merged[PersonDeathDate] < df_merged[CINreferralDate]
-    df_merged = df_merged[condition].reset_index()
-
-    # Error identifier
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID], df_merged[CINreferralDate], df_merged[PersonDeathDate]
-        )
-    )
-    df_CINDetails_issues = (
-        df_CINDetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_CINDetails")
-        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_ChildIdentifiers_issues = (
-        df_ChildIdentifiers.merge(
-            df_merged, left_on="ROW_ID", right_on="ROW_ID_ChildIdentifiers"
-        )
-        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_CINDetails_issues
-    )
-    rule_context.push_type_2(
-        table=ChildIdentifiers,
-        columns=[PersonDeathDate],
-        row_df=df_ChildIdentifiers_issues,
-    )
-
-
-def test_validate():
-    sample_CINDetails = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINreferralDate": "26/05/2000",  # Pass as dates are the same
-            },
-            {
-                "LAchildID": "child2",
-                "CINreferralDate": "27/06/2002",  # Fails, referral after death
-            },
-            {
-                "LAchildID": "child3",
-                "CINreferralDate": "07/02/1999",  # Pass, pre death
-            },
-            {
-                "LAchildID": "child4",
-                "CINreferralDate": pd.NA,  # Ignored, no referral date
-            },
-            {
-                "LAchildID": "child5",
-                "CINreferralDate": "14/03/2001",  # Pass, dropped due to no death date
-            },
-        ]
-    )
-    sample_ChildIdentifiers = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",  # Fails
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child3",  # Pass
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child4",  # Pass
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child5",  # Pass
-                "PersonDeathDate": pd.NA,
-            },
-        ]
-    )
-
-    sample_CINDetails[CINreferralDate] = pd.to_datetime(
-        sample_CINDetails[CINreferralDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_ChildIdentifiers["PersonDeathDate"] = pd.to_datetime(
-        sample_ChildIdentifiers["PersonDeathDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINdetails: sample_CINDetails,
-            ChildIdentifiers: sample_ChildIdentifiers,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    issue_columns = issues.columns
-    assert issue_columns == [PersonDeathDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    # Start Date
-                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
-                    # Review date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8555Q"
-    assert (
-        result.definition.message
-        == "Child cannot be referred after its recorded date of death"
-    )
+"""
+Rule number: '8606'
+Module: CIN details
+Rule details: <CINreferralDate> (N00100) cannot be more than 280 days before <PersonBirthDate> (N00066) or <ExpectedPersonBirthDate> (N00098)
+Rule message: Child referral date is more than 40 weeks before DOB or expected DOB
+
+"""
+
+import datetime as dt
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+PersonBirthDate = ChildIdentifiers.PersonBirthDate
+ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
+LAchildID = ChildIdentifiers.LAchildID
+
+CINdetails = CINTable.CINdetails
+CINreferralDate = CINdetails.CINreferralDate
+LAchildID = CINdetails.LAchildID
+
+
+@rule_definition(
+    code="8606",
+    module=CINTable.CINdetails,
+    message="Child referral date is more than 40 weeks before DOB or expected DOB",
+    affected_fields=[
+        CINreferralDate,
+        PersonBirthDate,
+        ExpectedPersonBirthDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_CINDetails = data_container[CINdetails].copy()
+    df_ChildIdentifiers = data_container[ChildIdentifiers].copy()
+
+    df_CINDetails.index.name = "ROW_ID"
+    df_ChildIdentifiers.index.name = "ROW_ID"
+
+    df_CINDetails.reset_index(inplace=True)
+    df_ChildIdentifiers.reset_index(inplace=True)
+
+    # <CINreferralDate> (N00100) cannot be more than 280 days before <PersonBirthDate> (N00066) or <ExpectedPersonBirthDate>
+    df_merged = df_CINDetails.merge(
+        df_ChildIdentifiers,
+        left_on=["LAchildID"],
+        right_on=["LAchildID"],
+        how="left",
+        suffixes=("_CINDetails", "_ChildIdentifiers"),
+    )
+
+    # Get rows where CINreferralDate is earlier than birth/expected birth -280
+    condition1 = df_merged[CINreferralDate] < (
+        df_merged[PersonBirthDate] - dt.timedelta(days=280)
+    )
+    condition2 = df_merged[CINreferralDate] < (
+        df_merged[ExpectedPersonBirthDate] - dt.timedelta(days=280)
+    )
+    df_merged = df_merged[condition1 | condition2].reset_index()
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[CINreferralDate],
+        )
+    )
+    df_CINDetails_issues = (
+        df_CINDetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_CINDetails")
+        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_ChildIdentifiers_issues = (
+        df_ChildIdentifiers.merge(
+            df_merged, left_on="ROW_ID", right_on="ROW_ID_ChildIdentifiers"
+        )
+        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_CINDetails_issues
+    )
+    rule_context.push_type_2(
+        table=ChildIdentifiers,
+        columns=[PersonBirthDate, ExpectedPersonBirthDate],
+        row_df=df_ChildIdentifiers_issues,
+    )
+
+
+def test_validate():
+    sample_CINDetails = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINreferralDate": "26/04/2000",  # Pass birth less than 280 days before referral
+            },
+            {
+                "LAchildID": "child2",
+                "CINreferralDate": "27/06/1998",  # Fail, referral more than 280 days before birth
+            },
+            {
+                "LAchildID": "child3",
+                "CINreferralDate": "07/04/2000",  # Pass, expected birth less than 280 days before referral
+            },
+            {
+                "LAchildID": "child4",
+                "CINreferralDate": "07/02/1998",  # Fail, referral date more than 280 days before expected birth
+            },
+        ]
+    )
+    sample_ChildIdentifiers = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Pass
+                "PersonBirthDate": "26/05/2000",
+                "ExpectedPersonBirthDate": pd.NA,
+            },
+            {
+                "LAchildID": "child2",  # Fails
+                "PersonBirthDate": "26/05/2000",
+                "ExpectedPersonBirthDate": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # Pass
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child4",  # Fail
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "26/05/2000",
+            },
+        ]
+    )
+
+    sample_CINDetails[CINreferralDate] = pd.to_datetime(
+        sample_CINDetails[CINreferralDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_ChildIdentifiers["PersonBirthDate"] = pd.to_datetime(
+        sample_ChildIdentifiers["PersonBirthDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    sample_ChildIdentifiers["ExpectedPersonBirthDate"] = pd.to_datetime(
+        sample_ChildIdentifiers["ExpectedPersonBirthDate"],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINdetails: sample_CINDetails,
+            ChildIdentifiers: sample_ChildIdentifiers,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    issues = issues_list[1]
+
+    issue_table = issues.table
+
+    assert issue_table == ChildIdentifiers
+
+    issue_columns = issues.columns
+
+    assert issue_columns == [PersonBirthDate, ExpectedPersonBirthDate]
+
+    issue_rows = issues.row_df
+
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    # Referral date
+                    pd.to_datetime("27/06/1998", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",  # ChildID
+                    # Referral date
+                    pd.to_datetime("07/02/1998", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8606"
+    assert (
+        result.definition.message
+        == "Child referral date is more than 40 weeks before DOB or expected DOB"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8565.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8565.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,506 +1,506 @@
-"""
-Rule number: '8565'
-Module: CIN Details
-Rule details: If <CINclosureDate> (N00102) is present then it must be on or after all of the following dates that are present:
-    <AssessmentActualStartDate> (N00159)
-    <AssessmentAuthorisationDate>(N00160)
-    <S47ActualStartDate> (N00148)
-    <DateOfInitialCPC> (N00110)
-    <CPPendDate> (N00115)
-    <CINPlanStartDate> (N00689)
-    <CINPlanEndDate> (N00690)
-Rule message: Activity shown after a case has been closed
-
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINdetails = CINTable.CINdetails
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-CINclosureDate = CINdetails.CINclosureDate
-DateOfInitialCPC = CINdetails.DateOfInitialCPC
-
-Assessments = CINTable.Assessments
-LAchildID = Assessments.LAchildID
-CINdetailsID = Assessments.CINdetailsID
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-
-Section47 = CINTable.Section47
-LAchildID = Section47.LAchildID
-CINdetailsID = Section47.CINdetailsID
-S47ActualStartDate = Section47.S47ActualStartDate
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LAchildID = ChildProtectionPlans.LAchildID
-CINdetailsID = ChildProtectionPlans.CINdetailsID
-CPPendDate = ChildProtectionPlans.CPPendDate
-
-CINplanDates = CINTable.CINplanDates
-LAchildID = CINplanDates.LAchildID
-CINdetailsID = CINplanDates.CINdetailsID
-CINPlanStartDate = CINplanDates.CINPlanStartDate
-CINPlanEndDate = CINplanDates.CINPlanEndDate
-
-
-@rule_definition(
-    code="8565",
-    module=CINTable.ChildProtectionPlans,
-    message="Activity shown after a case has been closed",
-    affected_fields=[
-        CINclosureDate,
-        DateOfInitialCPC,
-        AssessmentActualStartDate,
-        AssessmentAuthorisationDate,
-        S47ActualStartDate,
-        CPPendDate,
-        CINPlanStartDate,
-        CINPlanEndDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cin = data_container[CINdetails]
-    df_ass = data_container[Assessments]
-    df_47 = data_container[Section47]
-    df_cpp = data_container[ChildProtectionPlans]
-    df_plan = data_container[CINplanDates]
-
-    df_cin.index.name = "ROW_ID"
-    df_ass.index.name = "ROW_ID"
-    df_47.index.name = "ROW_ID"
-    df_cpp.index.name = "ROW_ID"
-    df_plan.index.name = "ROW_ID"
-
-    df_cin.reset_index(inplace=True)
-    df_ass.reset_index(inplace=True)
-    df_47.reset_index(inplace=True)
-    df_cpp.reset_index(inplace=True)
-    df_plan.reset_index(inplace=True)
-
-    # Rule details: If <CINclosureDate> (N00102) is present then it must be on or after all of the following dates that are present:
-    #     <AssessmentActualStartDate> (N00159)
-    #     <AssessmentAuthorisationDate>(N00160)
-    #     <S47ActualStartDate> (N00148)
-    #     <DateOfInitialCPC> (N00110)
-    #     <CPPendDate> (N00115)
-    #     <CINPlanStartDate> (N00689)
-    #     <CINPlanEndDate> (N00690)
-
-    # Remove rows without a CIN closure date
-    df_cin = df_cin[df_cin[CINclosureDate].notna()]
-
-    # CIN TABLE
-    df_cin["CINclosureDate"] = pd.to_datetime(
-        df_cin["CINclosureDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    df_cin["DateOfInitialCPC"] = pd.to_datetime(
-        df_cin["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    df_cin_fail = df_cin[df_cin["CINclosureDate"] < df_cin["DateOfInitialCPC"]]
-    df_cin_fail["ERROR_ID"] = tuple(
-        zip(
-            df_cin_fail["LAchildID"],
-            df_cin_fail["CINdetailsID"],
-            df_cin_fail["CINclosureDate"],
-        )
-    )
-
-    df_cin_issues_cin = (
-        df_cin_fail.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # ASSESSMENTS TABLE
-    df_cin_ass = df_cin.merge(
-        df_ass,
-        on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=["_cin", "_ass"],
-    )
-
-    df_cin_ass_fail = df_cin_ass[
-        (df_cin_ass["CINclosureDate"] < df_cin_ass["AssessmentActualStartDate"])
-        | (df_cin_ass["CINclosureDate"] < df_cin_ass["AssessmentAuthorisationDate"])
-    ]
-    df_cin_ass_fail["ERROR_ID"] = tuple(
-        zip(
-            df_cin_ass_fail["LAchildID"],
-            df_cin_ass_fail["CINdetailsID"],
-            df_cin_ass_fail["CINclosureDate"],
-        )
-    )
-
-    df_cin_issues_ass = (
-        df_cin.merge(df_cin_ass_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_ass_issues = (
-        df_ass.merge(df_cin_ass_fail, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # SECTION47 TABLE
-    df_cin_47 = df_cin.merge(
-        df_47,
-        on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=["_cin", "_47"],
-    )  # both have the DateOfInitialCPC column so suffixes are applied.
-
-    df_cin_47_fail = df_cin_47[
-        (df_cin_47["CINclosureDate"] < df_cin_47["S47ActualStartDate"])
-        | (df_cin_47["CINclosureDate"] < df_cin_47["DateOfInitialCPC_47"])
-    ]
-    df_cin_47_fail["ERROR_ID"] = tuple(
-        zip(
-            df_cin_47_fail["LAchildID"],
-            df_cin_47_fail["CINdetailsID"],
-            df_cin_47_fail["CINclosureDate"],
-        )
-    )
-
-    df_cin_issues_47 = (
-        df_cin.merge(df_cin_47_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_47_issues = (
-        df_47.merge(df_cin_47_fail, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # CHILDPROTECTIONPLANS TABLE
-
-    df_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "CPPendDate": "27/05/2022",  # fail
-            }
-        ]
-    )
-
-    df_cpp.index.name = "ROW_ID"
-    df_cpp.reset_index(inplace=True)
-
-    df_cpp["CPPendDate"] = pd.to_datetime(
-        df_cpp["CPPendDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    df_cin_cpp = df_cin.merge(
-        df_cpp,
-        on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=["_cin", "_cpp"],
-    )
-
-    df_cin_cpp_fail = df_cin_cpp[
-        df_cin_cpp["CINclosureDate"] < df_cin_cpp["CPPendDate"]
-    ]
-    df_cin_cpp_fail["ERROR_ID"] = tuple(
-        zip(
-            df_cin_cpp_fail["LAchildID"],
-            df_cin_cpp_fail["CINdetailsID"],
-            df_cin_cpp_fail["CINclosureDate"],
-        )
-    )
-
-    df_cin_issues_cpp = (
-        df_cin.merge(df_cin_cpp_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cpp_issues = (
-        df_cpp.merge(df_cin_cpp_fail, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cpp_issues
-
-    # CINPLANDATES TABLE
-    df_cin_plan = df_cin.merge(
-        df_plan,
-        on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=["_cin", "_plan"],
-    )
-
-    df_cin_plan_fail = df_cin_plan[
-        (df_cin_plan["CINclosureDate"] < df_cin_plan["CINPlanStartDate"])
-        | (df_cin_plan["CINclosureDate"] < df_cin_plan["CINPlanEndDate"])
-    ]
-    df_cin_plan_fail["ERROR_ID"] = tuple(
-        zip(
-            df_cin_47_fail["LAchildID"],
-            df_cin_47_fail["CINdetailsID"],
-            df_cin_47_fail["CINclosureDate"],
-        )
-    )
-
-    df_cin_issues_plan = (
-        df_cin.merge(df_cin_plan_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_plan_issues = (
-        df_plan.merge(df_cin_plan_fail, left_on="ROW_ID", right_on="ROW_ID_plan")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # combine failing cin locations from all tables
-    cin_issues_all = pd.concat(
-        [
-            df_cin_issues_plan,
-            df_cin_issues_cpp,
-            df_cin_issues_47,
-            df_cin_issues_ass,
-            df_cin_issues_cin,
-        ],
-        ignore_index=True,
-    )
-    unique_cin_issues = cin_issues_all.astype(str).drop_duplicates().index
-    df_cin_issues = cin_issues_all.loc[unique_cin_issues].reset_index(drop=True)
-
-    rule_context.push_type_2(
-        table=CINdetails,
-        columns=[CINclosureDate, DateOfInitialCPC],
-        row_df=df_cin_issues,
-    )
-    rule_context.push_type_2(
-        table=Assessments,
-        columns=[AssessmentActualStartDate, AssessmentAuthorisationDate],
-        row_df=df_ass_issues,
-    )
-    rule_context.push_type_2(
-        table=Section47,
-        columns=[S47ActualStartDate, DateOfInitialCPC],
-        row_df=df_47_issues,
-    )
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[CPPendDate], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=CINplanDates,
-        columns=[CINPlanStartDate, CINPlanEndDate],
-        row_df=df_plan_issues,
-    )
-
-
-def test_validate():
-    df_cin = pd.DataFrame(
-        [
-            # Same CINclosureDate value is maintained throughout table for simplicity when cross-checking with other tables.
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "CINclosureDate": "26/05/2022",
-                "DateOfInitialCPC": "26/05/2022",  # pass
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID2",
-                "CINclosureDate": "26/05/2022",
-                "DateOfInitialCPC": pd.NA,  # ignore. date is absent
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID3",
-                "CINclosureDate": "26/05/2022",
-                "DateOfInitialCPC": "27/05/2022",  # fail 27/05/2022 is after CINclosureDate
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID4",
-                "CINclosureDate": "26/05/2022",
-                "DateOfInitialCPC": "26/05/2022",  # pass
-            },
-        ]
-    )
-
-    df_ass = pd.DataFrame(
-        [
-            # multiple assessments in the same CIN. some pass, some fail.
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "AssessmentActualStartDate": "27/05/2022",  # fail
-                "AssessmentAuthorisationDate": "26/05/2022",  # pass
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "AssessmentActualStartDate": "26/05/2022",  # pass
-                "AssessmentAuthorisationDate": "26/05/2022",  # pass
-            },
-            # assessments across multiple CIN modules. some pass, some fail.
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID2",
-                "AssessmentActualStartDate": "27/05/2022",  # fail
-                "AssessmentAuthorisationDate": "26/05/2022",  # pass
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID3",
-                "AssessmentActualStartDate": "26/05/2022",  # pass
-                "AssessmentAuthorisationDate": "26/05/2022",  # pass
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID4",
-                "AssessmentActualStartDate": pd.NA,  # ignore. date is absent
-                "AssessmentAuthorisationDate": pd.NA,  # ignore. date is absent
-            },
-        ]
-    )
-
-    df_47 = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "S47ActualStartDate": "27/05/2022",  # fail. after CINclosureDate.
-                "DateOfInitialCPC": "26/05/2022",
-            }
-        ]
-    )
-
-    df_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "CPPendDate": "27/05/2022",  # fail
-            }
-        ]
-    )
-
-    df_plan = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CINID1",
-                "CINPlanStartDate": "27/05/2022",  # fail
-                "CINPlanEndDate": "26/05/2022",  # pass
-            }
-        ]
-    )
-
-    df_plan["CINPlanStartDate"] = pd.to_datetime(
-        df_plan["CINPlanStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    df_plan["CINPlanEndDate"] = pd.to_datetime(
-        df_plan["CINPlanEndDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    df_cpp["CPPendDate"] = pd.to_datetime(
-        df_cpp["CPPendDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    df_47["S47ActualStartDate"] = pd.to_datetime(
-        df_47["S47ActualStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    df_47["DateOfInitialCPC"] = pd.to_datetime(
-        df_47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    df_ass["AssessmentActualStartDate"] = pd.to_datetime(
-        df_ass["AssessmentActualStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    df_ass["AssessmentAuthorisationDate"] = pd.to_datetime(
-        df_ass["AssessmentAuthorisationDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    df_cin["CINclosureDate"] = pd.to_datetime(
-        df_cin["CINclosureDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    df_cin["DateOfInitialCPC"] = pd.to_datetime(
-        df_cin["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINdetails: df_cin,
-            Assessments: df_ass,
-            Section47: df_47,
-            ChildProtectionPlans: df_cpp,
-            CINplanDates: df_plan,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 5
-
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [
-        CINclosureDate,
-        DateOfInitialCPC,
-    ]
-
-    issue_rows = issues.row_df
-
-    assert len(issue_rows) == 3
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "CINID1",
-                    pd.to_datetime("26/05/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "CINID2",
-                    pd.to_datetime("26/05/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "CINID3",
-                    pd.to_datetime("26/05/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-
-    assert result.definition.code == "8565"
-    assert result.definition.message == "Activity shown after a case has been closed"
+"""
+Rule number: '8565'
+Module: CIN Details
+Rule details: If <CINclosureDate> (N00102) is present then it must be on or after all of the following dates that are present:
+    <AssessmentActualStartDate> (N00159)
+    <AssessmentAuthorisationDate>(N00160)
+    <S47ActualStartDate> (N00148)
+    <DateOfInitialCPC> (N00110)
+    <CPPendDate> (N00115)
+    <CINPlanStartDate> (N00689)
+    <CINPlanEndDate> (N00690)
+Rule message: Activity shown after a case has been closed
+
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+CINclosureDate = CINdetails.CINclosureDate
+DateOfInitialCPC = CINdetails.DateOfInitialCPC
+
+Assessments = CINTable.Assessments
+LAchildID = Assessments.LAchildID
+CINdetailsID = Assessments.CINdetailsID
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+
+Section47 = CINTable.Section47
+LAchildID = Section47.LAchildID
+CINdetailsID = Section47.CINdetailsID
+S47ActualStartDate = Section47.S47ActualStartDate
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+LAchildID = ChildProtectionPlans.LAchildID
+CINdetailsID = ChildProtectionPlans.CINdetailsID
+CPPendDate = ChildProtectionPlans.CPPendDate
+
+CINplanDates = CINTable.CINplanDates
+LAchildID = CINplanDates.LAchildID
+CINdetailsID = CINplanDates.CINdetailsID
+CINPlanStartDate = CINplanDates.CINPlanStartDate
+CINPlanEndDate = CINplanDates.CINPlanEndDate
+
+
+@rule_definition(
+    code="8565",
+    module=CINTable.ChildProtectionPlans,
+    message="Activity shown after a case has been closed",
+    affected_fields=[
+        CINclosureDate,
+        DateOfInitialCPC,
+        AssessmentActualStartDate,
+        AssessmentAuthorisationDate,
+        S47ActualStartDate,
+        CPPendDate,
+        CINPlanStartDate,
+        CINPlanEndDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cin = data_container[CINdetails]
+    df_ass = data_container[Assessments]
+    df_47 = data_container[Section47]
+    df_cpp = data_container[ChildProtectionPlans]
+    df_plan = data_container[CINplanDates]
+
+    df_cin.index.name = "ROW_ID"
+    df_ass.index.name = "ROW_ID"
+    df_47.index.name = "ROW_ID"
+    df_cpp.index.name = "ROW_ID"
+    df_plan.index.name = "ROW_ID"
+
+    df_cin.reset_index(inplace=True)
+    df_ass.reset_index(inplace=True)
+    df_47.reset_index(inplace=True)
+    df_cpp.reset_index(inplace=True)
+    df_plan.reset_index(inplace=True)
+
+    # Rule details: If <CINclosureDate> (N00102) is present then it must be on or after all of the following dates that are present:
+    #     <AssessmentActualStartDate> (N00159)
+    #     <AssessmentAuthorisationDate>(N00160)
+    #     <S47ActualStartDate> (N00148)
+    #     <DateOfInitialCPC> (N00110)
+    #     <CPPendDate> (N00115)
+    #     <CINPlanStartDate> (N00689)
+    #     <CINPlanEndDate> (N00690)
+
+    # Remove rows without a CIN closure date
+    df_cin = df_cin[df_cin[CINclosureDate].notna()]
+
+    # CIN TABLE
+    df_cin["CINclosureDate"] = pd.to_datetime(
+        df_cin["CINclosureDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    df_cin["DateOfInitialCPC"] = pd.to_datetime(
+        df_cin["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    df_cin_fail = df_cin[df_cin["CINclosureDate"] < df_cin["DateOfInitialCPC"]]
+    df_cin_fail["ERROR_ID"] = tuple(
+        zip(
+            df_cin_fail["LAchildID"],
+            df_cin_fail["CINdetailsID"],
+            df_cin_fail["CINclosureDate"],
+        )
+    )
+
+    df_cin_issues_cin = (
+        df_cin_fail.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # ASSESSMENTS TABLE
+    df_cin_ass = df_cin.merge(
+        df_ass,
+        on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=["_cin", "_ass"],
+    )
+
+    df_cin_ass_fail = df_cin_ass[
+        (df_cin_ass["CINclosureDate"] < df_cin_ass["AssessmentActualStartDate"])
+        | (df_cin_ass["CINclosureDate"] < df_cin_ass["AssessmentAuthorisationDate"])
+    ]
+    df_cin_ass_fail["ERROR_ID"] = tuple(
+        zip(
+            df_cin_ass_fail["LAchildID"],
+            df_cin_ass_fail["CINdetailsID"],
+            df_cin_ass_fail["CINclosureDate"],
+        )
+    )
+
+    df_cin_issues_ass = (
+        df_cin.merge(df_cin_ass_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_ass_issues = (
+        df_ass.merge(df_cin_ass_fail, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # SECTION47 TABLE
+    df_cin_47 = df_cin.merge(
+        df_47,
+        on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=["_cin", "_47"],
+    )  # both have the DateOfInitialCPC column so suffixes are applied.
+
+    df_cin_47_fail = df_cin_47[
+        (df_cin_47["CINclosureDate"] < df_cin_47["S47ActualStartDate"])
+        | (df_cin_47["CINclosureDate"] < df_cin_47["DateOfInitialCPC_47"])
+    ]
+    df_cin_47_fail["ERROR_ID"] = tuple(
+        zip(
+            df_cin_47_fail["LAchildID"],
+            df_cin_47_fail["CINdetailsID"],
+            df_cin_47_fail["CINclosureDate"],
+        )
+    )
+
+    df_cin_issues_47 = (
+        df_cin.merge(df_cin_47_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_47_issues = (
+        df_47.merge(df_cin_47_fail, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # CHILDPROTECTIONPLANS TABLE
+
+    df_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "CPPendDate": "27/05/2022",  # fail
+            }
+        ]
+    )
+
+    df_cpp.index.name = "ROW_ID"
+    df_cpp.reset_index(inplace=True)
+
+    df_cpp["CPPendDate"] = pd.to_datetime(
+        df_cpp["CPPendDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    df_cin_cpp = df_cin.merge(
+        df_cpp,
+        on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=["_cin", "_cpp"],
+    )
+
+    df_cin_cpp_fail = df_cin_cpp[
+        df_cin_cpp["CINclosureDate"] < df_cin_cpp["CPPendDate"]
+    ]
+    df_cin_cpp_fail["ERROR_ID"] = tuple(
+        zip(
+            df_cin_cpp_fail["LAchildID"],
+            df_cin_cpp_fail["CINdetailsID"],
+            df_cin_cpp_fail["CINclosureDate"],
+        )
+    )
+
+    df_cin_issues_cpp = (
+        df_cin.merge(df_cin_cpp_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cpp_issues = (
+        df_cpp.merge(df_cin_cpp_fail, left_on="ROW_ID", right_on="ROW_ID_cpp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cpp_issues
+
+    # CINPLANDATES TABLE
+    df_cin_plan = df_cin.merge(
+        df_plan,
+        on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=["_cin", "_plan"],
+    )
+
+    df_cin_plan_fail = df_cin_plan[
+        (df_cin_plan["CINclosureDate"] < df_cin_plan["CINPlanStartDate"])
+        | (df_cin_plan["CINclosureDate"] < df_cin_plan["CINPlanEndDate"])
+    ]
+    df_cin_plan_fail["ERROR_ID"] = tuple(
+        zip(
+            df_cin_47_fail["LAchildID"],
+            df_cin_47_fail["CINdetailsID"],
+            df_cin_47_fail["CINclosureDate"],
+        )
+    )
+
+    df_cin_issues_plan = (
+        df_cin.merge(df_cin_plan_fail, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_plan_issues = (
+        df_plan.merge(df_cin_plan_fail, left_on="ROW_ID", right_on="ROW_ID_plan")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # combine failing cin locations from all tables
+    cin_issues_all = pd.concat(
+        [
+            df_cin_issues_plan,
+            df_cin_issues_cpp,
+            df_cin_issues_47,
+            df_cin_issues_ass,
+            df_cin_issues_cin,
+        ],
+        ignore_index=True,
+    )
+    unique_cin_issues = cin_issues_all.astype(str).drop_duplicates().index
+    df_cin_issues = cin_issues_all.loc[unique_cin_issues].reset_index(drop=True)
+
+    rule_context.push_type_2(
+        table=CINdetails,
+        columns=[CINclosureDate, DateOfInitialCPC],
+        row_df=df_cin_issues,
+    )
+    rule_context.push_type_2(
+        table=Assessments,
+        columns=[AssessmentActualStartDate, AssessmentAuthorisationDate],
+        row_df=df_ass_issues,
+    )
+    rule_context.push_type_2(
+        table=Section47,
+        columns=[S47ActualStartDate, DateOfInitialCPC],
+        row_df=df_47_issues,
+    )
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[CPPendDate], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=CINplanDates,
+        columns=[CINPlanStartDate, CINPlanEndDate],
+        row_df=df_plan_issues,
+    )
+
+
+def test_validate():
+    df_cin = pd.DataFrame(
+        [
+            # Same CINclosureDate value is maintained throughout table for simplicity when cross-checking with other tables.
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "CINclosureDate": "26/05/2022",
+                "DateOfInitialCPC": "26/05/2022",  # pass
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID2",
+                "CINclosureDate": "26/05/2022",
+                "DateOfInitialCPC": pd.NA,  # ignore. date is absent
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID3",
+                "CINclosureDate": "26/05/2022",
+                "DateOfInitialCPC": "27/05/2022",  # fail 27/05/2022 is after CINclosureDate
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID4",
+                "CINclosureDate": "26/05/2022",
+                "DateOfInitialCPC": "26/05/2022",  # pass
+            },
+        ]
+    )
+
+    df_ass = pd.DataFrame(
+        [
+            # multiple assessments in the same CIN. some pass, some fail.
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "AssessmentActualStartDate": "27/05/2022",  # fail
+                "AssessmentAuthorisationDate": "26/05/2022",  # pass
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "AssessmentActualStartDate": "26/05/2022",  # pass
+                "AssessmentAuthorisationDate": "26/05/2022",  # pass
+            },
+            # assessments across multiple CIN modules. some pass, some fail.
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID2",
+                "AssessmentActualStartDate": "27/05/2022",  # fail
+                "AssessmentAuthorisationDate": "26/05/2022",  # pass
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID3",
+                "AssessmentActualStartDate": "26/05/2022",  # pass
+                "AssessmentAuthorisationDate": "26/05/2022",  # pass
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID4",
+                "AssessmentActualStartDate": pd.NA,  # ignore. date is absent
+                "AssessmentAuthorisationDate": pd.NA,  # ignore. date is absent
+            },
+        ]
+    )
+
+    df_47 = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "S47ActualStartDate": "27/05/2022",  # fail. after CINclosureDate.
+                "DateOfInitialCPC": "26/05/2022",
+            }
+        ]
+    )
+
+    df_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "CPPendDate": "27/05/2022",  # fail
+            }
+        ]
+    )
+
+    df_plan = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CINID1",
+                "CINPlanStartDate": "27/05/2022",  # fail
+                "CINPlanEndDate": "26/05/2022",  # pass
+            }
+        ]
+    )
+
+    df_plan["CINPlanStartDate"] = pd.to_datetime(
+        df_plan["CINPlanStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    df_plan["CINPlanEndDate"] = pd.to_datetime(
+        df_plan["CINPlanEndDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    df_cpp["CPPendDate"] = pd.to_datetime(
+        df_cpp["CPPendDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    df_47["S47ActualStartDate"] = pd.to_datetime(
+        df_47["S47ActualStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    df_47["DateOfInitialCPC"] = pd.to_datetime(
+        df_47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    df_ass["AssessmentActualStartDate"] = pd.to_datetime(
+        df_ass["AssessmentActualStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    df_ass["AssessmentAuthorisationDate"] = pd.to_datetime(
+        df_ass["AssessmentAuthorisationDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    df_cin["CINclosureDate"] = pd.to_datetime(
+        df_cin["CINclosureDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    df_cin["DateOfInitialCPC"] = pd.to_datetime(
+        df_cin["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINdetails: df_cin,
+            Assessments: df_ass,
+            Section47: df_47,
+            ChildProtectionPlans: df_cpp,
+            CINplanDates: df_plan,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 5
+
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [
+        CINclosureDate,
+        DateOfInitialCPC,
+    ]
+
+    issue_rows = issues.row_df
+
+    assert len(issue_rows) == 3
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "CINID1",
+                    pd.to_datetime("26/05/2022", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "CINID2",
+                    pd.to_datetime("26/05/2022", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "CINID3",
+                    pd.to_datetime("26/05/2022", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+
+    assert result.definition.code == "8565"
+    assert result.definition.message == "Activity shown after a case has been closed"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8568.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8568.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,56 +1,56 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-CINdetails = CINTable.CINdetails
-ReferralNFA = CINdetails.ReferralNFA
-
-
-@rule_definition(
-    code="8568",
-    module=CINTable.CINdetails,
-    message="RNFA flag is missing or invalid",
-    affected_fields=[ReferralNFA],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINdetails]
-
-    # <ReferralNFA> (N00112) must be present and must be 1 or 0, true or false
-    df["ReferralNFA"] = df["ReferralNFA"].astype(str).str.lower()
-    df = df[~df["ReferralNFA"].isin(["1", "0", "false", "true"])]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(table=CINdetails, field=ReferralNFA, row=failing_indices)
-
-
-def test_validate():
-    RNFA = [1, 0, 2, pd.NA, "true", "Woof", "Meow"]
-
-    fake_dataframe = pd.DataFrame({"ReferralNFA": RNFA})
-
-    result = run_rule(validate, {CINdetails: fake_dataframe})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 4
-
-    assert issues == [
-        IssueLocator(CINTable.CINdetails, ReferralNFA, 2),
-        IssueLocator(CINTable.CINdetails, ReferralNFA, 3),
-        IssueLocator(CINTable.CINdetails, ReferralNFA, 5),
-        IssueLocator(CINTable.CINdetails, ReferralNFA, 6),
-    ]
-
-    assert result.definition.code == "8568"
-    assert result.definition.message == "RNFA flag is missing or invalid"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+CINdetails = CINTable.CINdetails
+ReferralNFA = CINdetails.ReferralNFA
+
+
+@rule_definition(
+    code="8568",
+    module=CINTable.CINdetails,
+    message="RNFA flag is missing or invalid",
+    affected_fields=[ReferralNFA],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINdetails]
+
+    # <ReferralNFA> (N00112) must be present and must be 1 or 0, true or false
+    df["ReferralNFA"] = df["ReferralNFA"].astype(str).str.lower()
+    df = df[~df["ReferralNFA"].isin(["1", "0", "false", "true"])]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(table=CINdetails, field=ReferralNFA, row=failing_indices)
+
+
+def test_validate():
+    RNFA = [1, 0, 2, pd.NA, "true", "Woof", "Meow"]
+
+    fake_dataframe = pd.DataFrame({"ReferralNFA": RNFA})
+
+    result = run_rule(validate, {CINdetails: fake_dataframe})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 4
+
+    assert issues == [
+        IssueLocator(CINTable.CINdetails, ReferralNFA, 2),
+        IssueLocator(CINTable.CINdetails, ReferralNFA, 3),
+        IssueLocator(CINTable.CINdetails, ReferralNFA, 5),
+        IssueLocator(CINTable.CINdetails, ReferralNFA, 6),
+    ]
+
+    assert result.definition.code == "8568"
+    assert result.definition.message == "RNFA flag is missing or invalid"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8569Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8569Q.py`

 * *Ordering differences only*

 * *Files 25% similar despite different names*

```diff
@@ -1,153 +1,153 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import england_working_days, make_census_period
-
-CINdetails = CINTable.CINdetails
-
-ReferralNFA = CINdetails.ReferralNFA
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-CINreferralDate = CINdetails.CINreferralDate
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="8569Q",
-    module=CINTable.CINdetails,
-    rule_type=RuleType.QUERY,
-    message="A case with referral date before one working day prior to the collection start date must not be flagged as a no further action case",
-    affected_fields=[
-        ReferralNFA,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cin = data_container[CINdetails].copy()
-    df_cin.index.name = "ROW_ID"
-
-    df_cin.reset_index(inplace=True)
-
-    header = data_container[Header]
-    ref_date_series = header[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # If <CINreferralDate> (N00100) is before [Start_of_Census_Year] minus 1 working day, <ReferralNFA> (N00112) must be false
-    df_cin_issues = df_cin[
-        df_cin[CINreferralDate] < (collection_start - england_working_days(1))
-    ]
-
-    df_cin_issues = df_cin_issues[
-        ~df_cin_issues[ReferralNFA].isin(["false", "0"])
-    ].reset_index()
-
-    df_cin_issues["ERROR_ID"] = tuple(
-        zip(
-            df_cin_issues[LAchildID],
-            df_cin_issues[CINdetailsID],
-            df_cin_issues[CINreferralDate],
-        )
-    )
-
-    df_issues = (
-        df_cin_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_issues
-    )
-
-
-def test_validate():
-    sample_cin_details = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINreferralDate": "26/10/1880",
-                "ReferralNFA": "true",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child2",
-                "CINreferralDate": "26/10/2001",
-                "ReferralNFA": "true",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "CINreferralDate": "26/10/1880",
-                "ReferralNFA": "false",
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child4",
-                "CINreferralDate": "26/10/1999",
-                "ReferralNFA": "false",
-                "CINdetailsID": "cinID4",
-            },
-            {
-                "LAchildID": "child5",
-                "CINreferralDate": pd.NA,
-                "ReferralNFA": "false",
-                "CINdetailsID": "cinID5",
-            },
-        ]
-    )
-    sample_cin_details["CINreferralDate"] = pd.to_datetime(
-        sample_cin_details["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2000"}]  # the census start date here will be 01/04/2000
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINdetails: sample_cin_details,
-            Header: sample_header,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 1
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINreferralDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "cinID1",  # CINdetailsID
-                    # corresponding CPPstartDate
-                    pd.to_datetime("26/10/1880", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8569Q"
-    assert (
-        result.definition.message
-        == "A case with referral date before one working day prior to the collection start date must not be flagged as a no further action case"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import england_working_days, make_census_period
+
+CINdetails = CINTable.CINdetails
+
+ReferralNFA = CINdetails.ReferralNFA
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+CINreferralDate = CINdetails.CINreferralDate
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="8569Q",
+    module=CINTable.CINdetails,
+    rule_type=RuleType.QUERY,
+    message="A case with referral date before one working day prior to the collection start date must not be flagged as a no further action case",
+    affected_fields=[
+        ReferralNFA,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_cin = data_container[CINdetails].copy()
+    df_cin.index.name = "ROW_ID"
+
+    df_cin.reset_index(inplace=True)
+
+    header = data_container[Header]
+    ref_date_series = header[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # If <CINreferralDate> (N00100) is before [Start_of_Census_Year] minus 1 working day, <ReferralNFA> (N00112) must be false
+    df_cin_issues = df_cin[
+        df_cin[CINreferralDate] < (collection_start - england_working_days(1))
+    ]
+
+    df_cin_issues = df_cin_issues[
+        ~df_cin_issues[ReferralNFA].isin(["false", "0"])
+    ].reset_index()
+
+    df_cin_issues["ERROR_ID"] = tuple(
+        zip(
+            df_cin_issues[LAchildID],
+            df_cin_issues[CINdetailsID],
+            df_cin_issues[CINreferralDate],
+        )
+    )
+
+    df_issues = (
+        df_cin_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINreferralDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    sample_cin_details = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINreferralDate": "26/10/1880",
+                "ReferralNFA": "true",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child2",
+                "CINreferralDate": "26/10/2001",
+                "ReferralNFA": "true",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "CINreferralDate": "26/10/1880",
+                "ReferralNFA": "false",
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child4",
+                "CINreferralDate": "26/10/1999",
+                "ReferralNFA": "false",
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child5",
+                "CINreferralDate": pd.NA,
+                "ReferralNFA": "false",
+                "CINdetailsID": "cinID5",
+            },
+        ]
+    )
+    sample_cin_details["CINreferralDate"] = pd.to_datetime(
+        sample_cin_details["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2000"}]  # the census start date here will be 01/04/2000
+    )
+
+    result = run_rule(
+        validate,
+        {
+            CINdetails: sample_cin_details,
+            Header: sample_header,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 1
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINreferralDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "cinID1",  # CINdetailsID
+                    # corresponding CPPstartDate
+                    pd.to_datetime("26/10/1880", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8569Q"
+    assert (
+        result.definition.message
+        == "A case with referral date before one working day prior to the collection start date must not be flagged as a no further action case"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8585Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8585Q.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,170 +1,170 @@
-"""
-Rule number: '8585Q'
-Module: CIN plan dates
-Rule details: If <ReasonForClosure> (N00103) = RC2 (Died) then a valid <PersonDeathDate> (N00108) must be present.
-Rule message: Please check: CIN episode shows Died as the Closure Reason, however child has no recorded Date of Death
-
-"""
-
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.rules.cin2022_23.rule_8925 import LAchildID
-from cin_validator.test_engine import run_rule
-
-CINdetails = CINTable.CINdetails
-LAchildID = CINdetails.LAchildID
-ReasonForClosure = CINdetails.ReasonForClosure
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-LAchildID = ChildIdentifiers.LAchildID
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-
-
-@rule_definition(
-    code="8585Q",
-    module=CINTable.CINdetails,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend or provide a reason: CIN episode shows Died as the Closure Reason, however child has no recorded Date of Death",
-    affected_fields=[
-        ReasonForClosure,
-        PersonDeathDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_CI = data_container[ChildIdentifiers].copy()
-    df_CIN = data_container[CINdetails].copy()
-
-    df_CI.index.name = "ROW_ID"
-    df_CIN.index.name = "ROW_ID"
-
-    df_CI.reset_index(inplace=True)
-    df_CIN.reset_index(inplace=True)
-
-    # <ReasonForClosure> (N00103) = RC2 (Died) then a valid <PersonDeathDate> (N00108) must be present.
-    df = df_CI.merge(
-        df_CIN,
-        left_on=["LAchildID"],
-        right_on=["LAchildID"],
-        how="left",
-        suffixes=("_CPP", "_CIN"),
-    )
-
-    df = df[df[ReasonForClosure] == "RC2"]
-    df = df[df[PersonDeathDate].isna()].reset_index()
-
-    df["ERROR_ID"] = tuple(
-        zip(df[LAchildID], df[ReasonForClosure], df[PersonDeathDate])
-    )
-
-    df_CI_issues = (
-        df_CI.merge(df, left_on="ROW_ID", right_on="ROW_ID_CPP")
-        .groupby("ERROR_ID")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_CIN_issues = (
-        df_CIN.merge(df, left_on="ROW_ID", right_on="ROW_ID_CIN")
-        .groupby("ERROR_ID")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_CI_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[ReasonForClosure], row_df=df_CIN_issues
-    )
-
-
-def test_validate():
-    sample_CIN = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass, closed due to death and death date
-                "ReasonForClosure": "RC2",
-            },
-            {
-                "LAchildID": "child2",  # Pass, ReasonForClosure not death
-                "ReasonForClosure": "abc",
-            },
-            {
-                "LAchildID": "child3",  # Fail, no death date
-                "ReasonForClosure": "RC2",
-            },
-        ]
-    )
-
-    sample_CI = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "PersonDeathDate": "26/05/2000",  # Pass
-            },
-            {
-                "LAchildID": "child2",
-                "PersonDeathDate": "27/06/2002",  # Pass
-            },
-            {
-                "LAchildID": "child3",
-                "PersonDeathDate": pd.NA,  # Fail
-            },
-        ]
-    )
-
-    sample_CI[PersonDeathDate] = pd.to_datetime(
-        sample_CI[PersonDeathDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_CI,
-            CINdetails: sample_CIN,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [ReasonForClosure]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    # ChildID
-                    "child3",
-                    # Reason for closure
-                    "RC2",
-                    # Death date
-                    pd.to_datetime(pd.NA, format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8585Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend or provide a reason: CIN episode shows Died as the Closure Reason, however child has no recorded Date of Death"
-    )
+"""
+Rule number: '8585Q'
+Module: CIN plan dates
+Rule details: If <ReasonForClosure> (N00103) = RC2 (Died) then a valid <PersonDeathDate> (N00108) must be present.
+Rule message: Please check: CIN episode shows Died as the Closure Reason, however child has no recorded Date of Death
+
+"""
+
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.rules.cin2022_23.rule_8925 import LAchildID
+from cin_validator.test_engine import run_rule
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+ReasonForClosure = CINdetails.ReasonForClosure
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+LAchildID = ChildIdentifiers.LAchildID
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+
+
+@rule_definition(
+    code="8585Q",
+    module=CINTable.CINdetails,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend or provide a reason: CIN episode shows Died as the Closure Reason, however child has no recorded Date of Death",
+    affected_fields=[
+        ReasonForClosure,
+        PersonDeathDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_CI = data_container[ChildIdentifiers].copy()
+    df_CIN = data_container[CINdetails].copy()
+
+    df_CI.index.name = "ROW_ID"
+    df_CIN.index.name = "ROW_ID"
+
+    df_CI.reset_index(inplace=True)
+    df_CIN.reset_index(inplace=True)
+
+    # <ReasonForClosure> (N00103) = RC2 (Died) then a valid <PersonDeathDate> (N00108) must be present.
+    df = df_CI.merge(
+        df_CIN,
+        left_on=["LAchildID"],
+        right_on=["LAchildID"],
+        how="left",
+        suffixes=("_CPP", "_CIN"),
+    )
+
+    df = df[df[ReasonForClosure] == "RC2"]
+    df = df[df[PersonDeathDate].isna()].reset_index()
+
+    df["ERROR_ID"] = tuple(
+        zip(df[LAchildID], df[ReasonForClosure], df[PersonDeathDate])
+    )
+
+    df_CI_issues = (
+        df_CI.merge(df, left_on="ROW_ID", right_on="ROW_ID_CPP")
+        .groupby("ERROR_ID")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_CIN_issues = (
+        df_CIN.merge(df, left_on="ROW_ID", right_on="ROW_ID_CIN")
+        .groupby("ERROR_ID")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_CI_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReasonForClosure], row_df=df_CIN_issues
+    )
+
+
+def test_validate():
+    sample_CIN = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Pass, closed due to death and death date
+                "ReasonForClosure": "RC2",
+            },
+            {
+                "LAchildID": "child2",  # Pass, ReasonForClosure not death
+                "ReasonForClosure": "abc",
+            },
+            {
+                "LAchildID": "child3",  # Fail, no death date
+                "ReasonForClosure": "RC2",
+            },
+        ]
+    )
+
+    sample_CI = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "PersonDeathDate": "26/05/2000",  # Pass
+            },
+            {
+                "LAchildID": "child2",
+                "PersonDeathDate": "27/06/2002",  # Pass
+            },
+            {
+                "LAchildID": "child3",
+                "PersonDeathDate": pd.NA,  # Fail
+            },
+        ]
+    )
+
+    sample_CI[PersonDeathDate] = pd.to_datetime(
+        sample_CI[PersonDeathDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(
+        validate,
+        {
+            ChildIdentifiers: sample_CI,
+            CINdetails: sample_CIN,
+        },
+    )
+
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [ReasonForClosure]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 1
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    # ChildID
+                    "child3",
+                    # Reason for closure
+                    "RC2",
+                    # Death date
+                    pd.to_datetime(pd.NA, format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8585Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend or provide a reason: CIN episode shows Died as the Closure Reason, however child has no recorded Date of Death"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8590.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8610.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,124 +1,112 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-CINdetails = CINTable.CINdetails
-
-LAchildID = ChildIdentifiers.LAchildID
-
-
-@rule_definition(
-    code="8590",
-    module=CINTable.ChildIdentifiers,
-    message="Child does not have a recorded CIN episode.",
-    affected_fields=[LAchildID],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_cid = data_container[ChildIdentifiers].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    df_cid.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_cid.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # Each child must have at least one <CINdetails> group
-    df_merge = df_cid.merge(
-        df_cin[LAchildID], on=[LAchildID], how="left", indicator=True
-    )
-
-    condition = df_merge["_merge"] == "left_only"
-
-    df_merge = df_merge[condition].reset_index()
-
-    df_merge["ERROR_ID"] = tuple(zip(df_merge[LAchildID]))
-
-    df_cid_issues = (
-        df_cid.merge(df_merge, left_on="ROW_ID", right_on="ROW_ID")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[LAchildID], row_df=df_cid_issues
-    )
-
-
-def test_validate():
-    sample_child_identifiers = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass
-            },
-            {
-                "LAchildID": "child2",  # Pass
-            },
-            {
-                "LAchildID": "child3",  # Fail
-            },
-            {
-                "LAchildID": "child4",  # Pass
-            },
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass
-            },
-            {
-                "LAchildID": "child2",  # Pass
-            },
-            {
-                "LAchildID": "child4",  # Pass
-            },
-            {
-                "LAchildID": "child5",  # Ignore
-            },
-        ]
-    )
-
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_child_identifiers,
-            CINdetails: sample_cin_details,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 1
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    issue_columns = issues.columns
-    assert issue_columns == [LAchildID]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 1
-
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": ("child3",),  # ChildID
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8590"
-    assert result.definition.message == "Child does not have a recorded CIN episode."
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+ReferralNFA = CINdetails.ReferralNFA
+PrimaryNeedCode = CINdetails.PrimaryNeedCode
+CINdetailsID = CINdetails.CINdetailsID
+
+
+@rule_definition(
+    code="8610",
+    module=CINTable.CINdetails,
+    message="Primary Need code is missing for a referral which led to further action.",
+    affected_fields=[ReferralNFA, PrimaryNeedCode],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINdetails]
+    df.index.name = "ROW_ID"
+    df.reset_index(inplace=True)
+
+    # If <ReferralNFA> (N00112) = false or 0
+    # then
+    # <PrimaryNeedCode> (N00101) must be present
+
+    condition = (df[ReferralNFA].isin(["false", "0"])) & (df[PrimaryNeedCode].isna())
+    df_issues = df[condition].reset_index()
+
+    link_id = tuple(zip(df_issues[LAchildID], df_issues[CINdetailsID]))
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    rule_context.push_type_1(
+        table=CINdetails, columns=[ReferralNFA, PrimaryNeedCode], row_df=df_issues
+    )
+
+
+def test_validate():
+    #  Fails rows 0, 1, and 3
+    sample_cin = pd.DataFrame(
+        {
+            "LAchildID": ["child1", "child2", "child3", "child4", "child5"],
+            "ReferralNFA": [
+                "false",
+                "0",
+                "1",
+                pd.NA,
+                "true",
+            ],
+            "PrimaryNeedCode": [
+                pd.NA,  # fail
+                pd.NA,  # fail
+                "12/09/2022",
+                "05/12/1997",
+                pd.NA,  # ignore: ReferralNFA is true
+            ],
+            "CINdetailsID": [
+                "ID1",
+                "ID2",
+                "ID3",
+                "ID4",
+                "ID5",
+            ],
+        }
+    )
+
+    result = run_rule(validate, {CINdetails: sample_cin})
+
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+    issue_columns = issues.columns
+    assert issue_columns == [ReferralNFA, PrimaryNeedCode]
+
+    issue_rows = issues.row_df
+
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "ID1",
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": ("child2", "ID2"),
+                "ROW_ID": [1],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8610"
+    assert (
+        result.definition.message
+        == "Primary Need code is missing for a referral which led to further action."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8600.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8600.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,87 +1,87 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-Cindetails = CINTable.CINdetails
-CINreferralDate = Cindetails.CINreferralDate
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-@rule_definition(
-    code="8600",
-    module=CINTable.CINdetails,
-    message="Child referral date missing or after data collection period",
-    affected_fields=[CINreferralDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Cindetails]
-    df_ref = data_container[Header]
-
-    ref_data_series = df_ref[ReferenceDate]
-
-    collection_start, collection_end = make_census_period(ref_data_series)
-
-    # <CINreferralDate> (N00100) must be present and must be on or before <ReferenceDate> (N00603)
-    condition = (df[CINreferralDate] > collection_end) | (df[CINreferralDate].isna())
-    # Where a CINreferralDate exists check to see if it is after the end of the Census Period (collection_end)
-    df = df[condition]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=Cindetails, field=CINreferralDate, row=failing_indices
-    )
-
-
-def test_validate():
-    sample_refdates = pd.to_datetime(
-        [
-            "2021-06-30",  # Pass - the date is before the collection_end of 31st March 2022
-            "2022-01-25",  # Pass - the date is before the collection_end of 31st March 2022
-            "2022-12-25",  # Fail - the date is after the collection_end of 31st March 2022
-            pd.NA,  # Fail - the date field is blank and is therefore missing
-            "2022-12-03",  # Fail - the date is after the collection_end of 31st March 2022
-            "2021-08-20",  # Pass - the date is before the collection_end of 31st March 2022
-            "2021-04-17",  # Pass - the date is before the collection_end of 31st March 2022
-            "2001-01-25",  # Pass - the date is before the collection_end of 31st March 2022
-            pd.NA,  # Fail - the date field is blank and is therefore missing
-        ],
-        format="%Y/%m/%d",
-        errors="coerce",
-    )
-
-    fake_refdates = pd.DataFrame({CINreferralDate: sample_refdates})
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]
-    )  # the census start date here will be 01/04/2021
-
-    result = run_rule(validate, {Cindetails: fake_refdates, Header: fake_header})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 4
-
-    assert issues == [
-        IssueLocator(CINTable.CINdetails, CINreferralDate, 2),
-        IssueLocator(CINTable.CINdetails, CINreferralDate, 3),
-        IssueLocator(CINTable.CINdetails, CINreferralDate, 4),
-        IssueLocator(CINTable.CINdetails, CINreferralDate, 8),
-    ]
-
-    assert result.definition.code == "8600"
-    assert (
-        result.definition.message
-        == "Child referral date missing or after data collection period"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+Cindetails = CINTable.CINdetails
+CINreferralDate = Cindetails.CINreferralDate
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+@rule_definition(
+    code="8600",
+    module=CINTable.CINdetails,
+    message="Child referral date missing or after data collection period",
+    affected_fields=[CINreferralDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Cindetails]
+    df_ref = data_container[Header]
+
+    ref_data_series = df_ref[ReferenceDate]
+
+    collection_start, collection_end = make_census_period(ref_data_series)
+
+    # <CINreferralDate> (N00100) must be present and must be on or before <ReferenceDate> (N00603)
+    condition = (df[CINreferralDate] > collection_end) | (df[CINreferralDate].isna())
+    # Where a CINreferralDate exists check to see if it is after the end of the Census Period (collection_end)
+    df = df[condition]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=Cindetails, field=CINreferralDate, row=failing_indices
+    )
+
+
+def test_validate():
+    sample_refdates = pd.to_datetime(
+        [
+            "2021-06-30",  # Pass - the date is before the collection_end of 31st March 2022
+            "2022-01-25",  # Pass - the date is before the collection_end of 31st March 2022
+            "2022-12-25",  # Fail - the date is after the collection_end of 31st March 2022
+            pd.NA,  # Fail - the date field is blank and is therefore missing
+            "2022-12-03",  # Fail - the date is after the collection_end of 31st March 2022
+            "2021-08-20",  # Pass - the date is before the collection_end of 31st March 2022
+            "2021-04-17",  # Pass - the date is before the collection_end of 31st March 2022
+            "2001-01-25",  # Pass - the date is before the collection_end of 31st March 2022
+            pd.NA,  # Fail - the date field is blank and is therefore missing
+        ],
+        format="%Y/%m/%d",
+        errors="coerce",
+    )
+
+    fake_refdates = pd.DataFrame({CINreferralDate: sample_refdates})
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]
+    )  # the census start date here will be 01/04/2021
+
+    result = run_rule(validate, {Cindetails: fake_refdates, Header: fake_header})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 4
+
+    assert issues == [
+        IssueLocator(CINTable.CINdetails, CINreferralDate, 2),
+        IssueLocator(CINTable.CINdetails, CINreferralDate, 3),
+        IssueLocator(CINTable.CINdetails, CINreferralDate, 4),
+        IssueLocator(CINTable.CINdetails, CINreferralDate, 8),
+    ]
+
+    assert result.definition.code == "8600"
+    assert (
+        result.definition.message
+        == "Child referral date missing or after data collection period"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8606.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2024_25/rule_8750.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,210 +1,178 @@
-"""
-Rule number: '8606'
-Module: CIN details
-Rule details: <CINreferralDate> (N00100) cannot be more than 280 days before <PersonBirthDate> (N00066) or <ExpectedPersonBirthDate> (N00098)
-Rule message: Child referral date is more than 40 weeks before DOB or expected DOB
-
-"""
-
-import datetime as dt
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-PersonBirthDate = ChildIdentifiers.PersonBirthDate
-ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
-LAchildID = ChildIdentifiers.LAchildID
-
-CINdetails = CINTable.CINdetails
-CINreferralDate = CINdetails.CINreferralDate
-LAchildID = CINdetails.LAchildID
-
-
-@rule_definition(
-    code="8606",
-    module=CINTable.CINdetails,
-    message="Child referral date is more than 40 weeks before DOB or expected DOB",
-    affected_fields=[
-        CINreferralDate,
-        PersonBirthDate,
-        ExpectedPersonBirthDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_CINDetails = data_container[CINdetails].copy()
-    df_ChildIdentifiers = data_container[ChildIdentifiers].copy()
-
-    df_CINDetails.index.name = "ROW_ID"
-    df_ChildIdentifiers.index.name = "ROW_ID"
-
-    df_CINDetails.reset_index(inplace=True)
-    df_ChildIdentifiers.reset_index(inplace=True)
-
-    # <CINreferralDate> (N00100) cannot be more than 280 days before <PersonBirthDate> (N00066) or <ExpectedPersonBirthDate>
-    df_merged = df_CINDetails.merge(
-        df_ChildIdentifiers,
-        left_on=["LAchildID"],
-        right_on=["LAchildID"],
-        how="left",
-        suffixes=("_CINDetails", "_ChildIdentifiers"),
-    )
-
-    # Get rows where CINreferralDate is earlier than birth/expected birth -280
-    condition1 = df_merged[CINreferralDate] < (
-        df_merged[PersonBirthDate] - dt.timedelta(days=280)
-    )
-    condition2 = df_merged[CINreferralDate] < (
-        df_merged[ExpectedPersonBirthDate] - dt.timedelta(days=280)
-    )
-    df_merged = df_merged[condition1 | condition2].reset_index()
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[CINreferralDate],
-        )
-    )
-    df_CINDetails_issues = (
-        df_CINDetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_CINDetails")
-        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_ChildIdentifiers_issues = (
-        df_ChildIdentifiers.merge(
-            df_merged, left_on="ROW_ID", right_on="ROW_ID_ChildIdentifiers"
-        )
-        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINreferralDate], row_df=df_CINDetails_issues
-    )
-    rule_context.push_type_2(
-        table=ChildIdentifiers,
-        columns=[PersonBirthDate, ExpectedPersonBirthDate],
-        row_df=df_ChildIdentifiers_issues,
-    )
-
-
-def test_validate():
-    sample_CINDetails = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINreferralDate": "26/04/2000",  # Pass birth less than 280 days before referral
-            },
-            {
-                "LAchildID": "child2",
-                "CINreferralDate": "27/06/1998",  # Fail, referral more than 280 days before birth
-            },
-            {
-                "LAchildID": "child3",
-                "CINreferralDate": "07/04/2000",  # Pass, expected birth less than 280 days before referral
-            },
-            {
-                "LAchildID": "child4",
-                "CINreferralDate": "07/02/1998",  # Fail, referral date more than 280 days before expected birth
-            },
-        ]
-    )
-    sample_ChildIdentifiers = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": pd.NA,
-            },
-            {
-                "LAchildID": "child2",  # Fails
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # Pass
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child4",  # Fail
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": "26/05/2000",
-            },
-        ]
-    )
-
-    sample_CINDetails[CINreferralDate] = pd.to_datetime(
-        sample_CINDetails[CINreferralDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_ChildIdentifiers["PersonBirthDate"] = pd.to_datetime(
-        sample_ChildIdentifiers["PersonBirthDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    sample_ChildIdentifiers["ExpectedPersonBirthDate"] = pd.to_datetime(
-        sample_ChildIdentifiers["ExpectedPersonBirthDate"],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-
-    result = run_rule(
-        validate,
-        {
-            CINdetails: sample_CINDetails,
-            ChildIdentifiers: sample_ChildIdentifiers,
-        },
-    )
-
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    issues = issues_list[1]
-
-    issue_table = issues.table
-
-    assert issue_table == ChildIdentifiers
-
-    issue_columns = issues.columns
-
-    assert issue_columns == [PersonBirthDate, ExpectedPersonBirthDate]
-
-    issue_rows = issues.row_df
-
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    # Referral date
-                    pd.to_datetime("27/06/1998", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",  # ChildID
-                    # Referral date
-                    pd.to_datetime("07/02/1998", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8606"
-    assert (
-        result.definition.message
-        == "Child referral date is more than 40 weeks before DOB or expected DOB"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+LAchildID = ChildIdentifiers.LAchildID
+PersonBirthDate = ChildIdentifiers.PersonBirthDate
+ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
+Sex = ChildIdentifiers.Sex
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of 8750
+    code="8750",
+    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildIdentifiers,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Sex must equal U for an unborn child",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[Sex, PersonBirthDate, ExpectedPersonBirthDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace ChildIdentifiers with the name of the table you need.
+    df = data_container[ChildIdentifiers]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <ExpectedPersonBirthDate> (N00098) is present and <PersonBirthDate> (N00066) is blank then <Sex> (N00783) must equal “0”
+    condition = (
+        df[PersonBirthDate].isna()
+        & df[ExpectedPersonBirthDate].notna()
+        & (df[Sex].astype(str) != "U")
+    )
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error.
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID],
+            df_issues[Sex],
+            df_issues[ExpectedPersonBirthDate],
+        )
+    )
+
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=ChildIdentifiers,
+        columns=[Sex, PersonBirthDate, ExpectedPersonBirthDate],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_identifiers = pd.DataFrame(
+        [
+            {  # 0 - Pass - Not unborn
+                "LAchildID": "child1",
+                "PersonBirthDate": "26/05/2000",
+                "ExpectedPersonBirthDate": "26/05/2000",
+                "Sex": "M",
+            },
+            {  # 1 - Pass - Not unborn
+                "LAchildID": "child2",
+                "PersonBirthDate": "26/05/2000",
+                "ExpectedPersonBirthDate": pd.NA,
+                "Sex": "F",
+            },
+            {  # 2 - Pass - Unborn with Sex = U
+                "LAchildID": "child3",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "26/05/1999",
+                "Sex": "U",
+            },
+            {  # 3 - Pass - Not unborn or born! (Not relevant to this rule)
+                "LAchildID": "child3",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": pd.NA,
+                "Sex": "F",
+            },
+            {  # 4 - Fail - Unborn with Sex = F
+                "LAchildID": "child4",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "25/05/2000",
+                "Sex": "F",
+            },
+            {  # 5 - Fail - Unborn with Sex = F
+                "LAchildID": "child4",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "25/05/2000",
+                "Sex": "M",
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    child_identifiers[PersonBirthDate] = pd.to_datetime(
+        child_identifiers[PersonBirthDate], format="%d/%m/%Y", errors="coerce"
+    )
+    child_identifiers[ExpectedPersonBirthDate] = pd.to_datetime(
+        child_identifiers[ExpectedPersonBirthDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    # get table name and check it. Replace ChildIdentifiers with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    # check that the right columns were returned.
+    issue_columns = issues.columns
+    assert issue_columns == [Sex, PersonBirthDate, ExpectedPersonBirthDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "F",
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "M",
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8750 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8750"
+    assert result.definition.message == "Sex must equal U for an unborn child"
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8608.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8608.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,136 +1,136 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-Assessments = CINTable.Assessments
-LAchildID = Assessments.LAchildID
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-
-
-@rule_definition(
-    code="8608",
-    module=CINTable.Assessments,
-    message="Assessment Start Date cannot be later than its End Date",
-    affected_fields=[AssessmentActualStartDate, AssessmentAuthorisationDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Assessments]
-    df.index.name = "ROW_ID"
-
-    # If present <AssessmentAuthorisationDate> (N00160) must be on or after the <AssessmentActualStartDate> (N00159)
-    condition = df[AssessmentActualStartDate] > df[AssessmentAuthorisationDate]
-
-    df_issues = df[condition].reset_index()
-
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-            df_issues[AssessmentActualStartDate],
-            df_issues[AssessmentAuthorisationDate],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_1(
-        table=Assessments,
-        columns=[AssessmentActualStartDate, AssessmentAuthorisationDate],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    assessments = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "AssessmentActualStartDate": "26/05/2000",
-                "AssessmentAuthorisationDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",
-                "AssessmentActualStartDate": "26/05/2000",
-                "AssessmentAuthorisationDate": "26/05/2001",
-            },
-            {
-                "LAchildID": "child3",
-                "AssessmentActualStartDate": "26/05/2000",
-                "AssessmentAuthorisationDate": "26/05/1999",
-            },  # 2 error: end is before start
-            {
-                "LAchildID": "child3",
-                "AssessmentActualStartDate": "26/05/2000",
-                "AssessmentAuthorisationDate": pd.NA,
-            },
-            {
-                "LAchildID": "child4",
-                "AssessmentActualStartDate": "26/05/2000",
-                "AssessmentAuthorisationDate": "25/05/2000",
-            },  # 4 error: end is before start
-            {
-                "LAchildID": "child5",
-                "AssessmentActualStartDate": pd.NA,
-                "AssessmentAuthorisationDate": pd.NA,
-            },
-        ]
-    )
-
-    assessments[AssessmentActualStartDate] = pd.to_datetime(
-        assessments[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    assessments[AssessmentAuthorisationDate] = pd.to_datetime(
-        assessments[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    result = run_rule(validate, {Assessments: assessments})
-
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == Assessments
-
-    issue_columns = issues.columns
-    assert issue_columns == [AssessmentActualStartDate, AssessmentAuthorisationDate]
-
-    issue_rows = issues.row_df
-    assert len(issue_rows) == 2
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child3",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8608"
-    assert (
-        result.definition.message
-        == "Assessment Start Date cannot be later than its End Date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+Assessments = CINTable.Assessments
+LAchildID = Assessments.LAchildID
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+
+
+@rule_definition(
+    code="8608",
+    module=CINTable.Assessments,
+    message="Assessment Start Date cannot be later than its End Date",
+    affected_fields=[AssessmentActualStartDate, AssessmentAuthorisationDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Assessments]
+    df.index.name = "ROW_ID"
+
+    # If present <AssessmentAuthorisationDate> (N00160) must be on or after the <AssessmentActualStartDate> (N00159)
+    condition = df[AssessmentActualStartDate] > df[AssessmentAuthorisationDate]
+
+    df_issues = df[condition].reset_index()
+
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID],
+            df_issues[AssessmentActualStartDate],
+            df_issues[AssessmentAuthorisationDate],
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_1(
+        table=Assessments,
+        columns=[AssessmentActualStartDate, AssessmentAuthorisationDate],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    assessments = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "AssessmentActualStartDate": "26/05/2000",
+                "AssessmentAuthorisationDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "AssessmentActualStartDate": "26/05/2000",
+                "AssessmentAuthorisationDate": "26/05/2001",
+            },
+            {
+                "LAchildID": "child3",
+                "AssessmentActualStartDate": "26/05/2000",
+                "AssessmentAuthorisationDate": "26/05/1999",
+            },  # 2 error: end is before start
+            {
+                "LAchildID": "child3",
+                "AssessmentActualStartDate": "26/05/2000",
+                "AssessmentAuthorisationDate": pd.NA,
+            },
+            {
+                "LAchildID": "child4",
+                "AssessmentActualStartDate": "26/05/2000",
+                "AssessmentAuthorisationDate": "25/05/2000",
+            },  # 4 error: end is before start
+            {
+                "LAchildID": "child5",
+                "AssessmentActualStartDate": pd.NA,
+                "AssessmentAuthorisationDate": pd.NA,
+            },
+        ]
+    )
+
+    assessments[AssessmentActualStartDate] = pd.to_datetime(
+        assessments[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    assessments[AssessmentAuthorisationDate] = pd.to_datetime(
+        assessments[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {Assessments: assessments})
+
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == Assessments
+
+    issue_columns = issues.columns
+    assert issue_columns == [AssessmentActualStartDate, AssessmentAuthorisationDate]
+
+    issue_rows = issues.row_df
+    assert len(issue_rows) == 2
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8608"
+    assert (
+        result.definition.message
+        == "Assessment Start Date cannot be later than its End Date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8615.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8615.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,153 +1,154 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-Section47 = CINTable.Section47
-S47ActualStartDate = Section47.S47ActualStartDate
-DateOfInitialCPC = Section47.DateOfInitialCPC
-LAchildID = Section47.LAchildID
-
-# define characteristics of rule
-@rule_definition(
-    code="8615",
-    module=CINTable.Section47,
-    message="Section 47 Enquiry Start Date must be present and cannot be later than the date of the initial Child Protection Conference",
-    affected_fields=[S47ActualStartDate, DateOfInitialCPC],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Section47]
-
-    # Within a <Section47> group, if <DateOfInitialCPC> (N00110) is present then <S47ActualStartDate> (N00148) must be present and on or before the <DateOfInitialCPC> (N00110)
-    df.index.name = "ROW_ID"
-
-    df.query(
-        "(S47ActualStartDate > DateOfInitialCPC) or (DateOfInitialCPC.notna() and S47ActualStartDate.isna())",
-        inplace=True,
-    )
-
-    df_issues = df.reset_index()
-
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-            df_issues[S47ActualStartDate],
-            df_issues[DateOfInitialCPC],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_1(
-        table=Section47,
-        columns=[S47ActualStartDate, DateOfInitialCPC],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    IDS_are = [
-        "AAAAAAAA",
-        "BBBBBBBBB",
-        "CCCCCCCCCCC",
-        "DDDDDDDDD",
-        "EEEE",
-        "FFFFFFFFF",
-        "GGGGGGGGGG",
-        "HHHH",
-    ]
-    S47start = [
-        "01-01-2020",
-        "01-02-2020",
-        "01-03-2020",
-        "15-01-2020",
-        pd.NA,
-        "01-07-2020",
-        "15-01-2020",
-        pd.NA,
-    ]
-    ICPCstart = [
-        "01-01-2020",
-        "01-01-2020",  #  Fails as ICPC before S47.
-        "01-03-2020",
-        "17-01-2020",
-        pd.NA,
-        "01-01-2020",  #  Fails as ICPC before S47.
-        "15-01-2020",
-        "01-01-2020",  #  Fails as ICPC with no S47.
-    ]
-    fake_dataframe = pd.DataFrame(
-        {
-            "LAchildID": IDS_are,
-            "S47ActualStartDate": S47start,
-            "DateOfInitialCPC": ICPCstart,
-        }
-    )
-
-    fake_dataframe["S47ActualStartDate"] = pd.to_datetime(
-        fake_dataframe["S47ActualStartDate"], format=r"%d-%m-%Y", errors="coerce"
-    )
-    fake_dataframe["DateOfInitialCPC"] = pd.to_datetime(
-        fake_dataframe["DateOfInitialCPC"], format=r"%d-%m-%Y", errors="coerce"
-    )
-
-    result = run_rule(validate, {Section47: fake_dataframe})
-
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    issue_columns = issues.columns
-    assert issue_columns == [S47ActualStartDate, DateOfInitialCPC]
-
-    issue_rows = issues.row_df
-
-    assert len(issue_rows) == 3
-
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "BBBBBBBBB",
-                    pd.to_datetime("01-02-2020", format=r"%d-%m-%Y", errors="coerce"),
-                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "FFFFFFFFF",
-                    pd.to_datetime("01-07-2020", format=r"%d-%m-%Y", errors="coerce"),
-                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "HHHH",
-                    pd.NaT,
-                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
-                ),
-                "ROW_ID": [7],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8615"
-    assert (
-        result.definition.message
-        == "Section 47 Enquiry Start Date must be present and cannot be later than the date of the initial Child Protection Conference"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+Section47 = CINTable.Section47
+S47ActualStartDate = Section47.S47ActualStartDate
+DateOfInitialCPC = Section47.DateOfInitialCPC
+LAchildID = Section47.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8615",
+    module=CINTable.Section47,
+    message="Section 47 Enquiry Start Date must be present and cannot be later than the date of the initial Child Protection Conference",
+    affected_fields=[S47ActualStartDate, DateOfInitialCPC],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Section47]
+
+    # Within a <Section47> group, if <DateOfInitialCPC> (N00110) is present then <S47ActualStartDate> (N00148) must be present and on or before the <DateOfInitialCPC> (N00110)
+    df.index.name = "ROW_ID"
+
+    df.query(
+        "(S47ActualStartDate > DateOfInitialCPC) or (DateOfInitialCPC.notna() and S47ActualStartDate.isna())",
+        inplace=True,
+    )
+
+    df_issues = df.reset_index()
+
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID],
+            df_issues[S47ActualStartDate],
+            df_issues[DateOfInitialCPC],
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_1(
+        table=Section47,
+        columns=[S47ActualStartDate, DateOfInitialCPC],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    IDS_are = [
+        "AAAAAAAA",
+        "BBBBBBBBB",
+        "CCCCCCCCCCC",
+        "DDDDDDDDD",
+        "EEEE",
+        "FFFFFFFFF",
+        "GGGGGGGGGG",
+        "HHHH",
+    ]
+    S47start = [
+        "01-01-2020",
+        "01-02-2020",
+        "01-03-2020",
+        "15-01-2020",
+        pd.NA,
+        "01-07-2020",
+        "15-01-2020",
+        pd.NA,
+    ]
+    ICPCstart = [
+        "01-01-2020",
+        "01-01-2020",  #  Fails as ICPC before S47.
+        "01-03-2020",
+        "17-01-2020",
+        pd.NA,
+        "01-01-2020",  #  Fails as ICPC before S47.
+        "15-01-2020",
+        "01-01-2020",  #  Fails as ICPC with no S47.
+    ]
+    fake_dataframe = pd.DataFrame(
+        {
+            "LAchildID": IDS_are,
+            "S47ActualStartDate": S47start,
+            "DateOfInitialCPC": ICPCstart,
+        }
+    )
+
+    fake_dataframe["S47ActualStartDate"] = pd.to_datetime(
+        fake_dataframe["S47ActualStartDate"], format=r"%d-%m-%Y", errors="coerce"
+    )
+    fake_dataframe["DateOfInitialCPC"] = pd.to_datetime(
+        fake_dataframe["DateOfInitialCPC"], format=r"%d-%m-%Y", errors="coerce"
+    )
+
+    result = run_rule(validate, {Section47: fake_dataframe})
+
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    issue_columns = issues.columns
+    assert issue_columns == [S47ActualStartDate, DateOfInitialCPC]
+
+    issue_rows = issues.row_df
+
+    assert len(issue_rows) == 3
+
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "BBBBBBBBB",
+                    pd.to_datetime("01-02-2020", format=r"%d-%m-%Y", errors="coerce"),
+                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "FFFFFFFFF",
+                    pd.to_datetime("01-07-2020", format=r"%d-%m-%Y", errors="coerce"),
+                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "HHHH",
+                    pd.NaT,
+                    pd.to_datetime("01-01-2020", format=r"%d-%m-%Y", errors="coerce"),
+                ),
+                "ROW_ID": [7],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8615"
+    assert (
+        result.definition.message
+        == "Section 47 Enquiry Start Date must be present and cannot be later than the date of the initial Child Protection Conference"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8620.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8620.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,103 +1,103 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINdetails = CINTable.CINdetails
-CINclosureDate = CINdetails.CINclosureDate
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8620",
-    module=CINTable.CINdetails,
-    message="CIN Closure Date present and does not fall within the Census year",
-    affected_fields=[CINclosureDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINdetails]
-    df_ref = data_container[Header]
-
-    # ReferenceDate exists in the header table so we get header table too.
-    ref_date_series = df_ref[ReferenceDate]
-
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # If <CINclosureDate> (N00102) is present, it must be within [Period_of_Census]
-    df = df[df[CINclosureDate].notna()]
-    df = df[
-        ~(
-            (df[CINclosureDate] >= collection_start)
-            & (df[CINclosureDate] <= collection_end)
-        )
-    ]
-    failing_indices = df.index
-
-    rule_context.push_issue(table=CINdetails, field=CINclosureDate, row=failing_indices)
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_header = pd.DataFrame(
-        {ReferenceDate: ["31/03/2022"]}  # the census start date here will be 01/04/2021
-    )
-    fake_cinclosure = pd.DataFrame(
-        [
-            {
-                CINclosureDate: "01/03/2019"
-            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
-            {
-                CINclosureDate: "10/04/2021"
-            },  # 1 pass: April 10th is within April 1st, 2021 to March 31st, 2022.
-            {
-                CINclosureDate: "01/10/2022"
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-            {CINclosureDate: "01/04/2021"},  # Pass, first day of census period
-            {CINclosureDate: "31/03/2021"},  # Pass, last day of census period
-        ]
-    )
-
-    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
-    fake_cinclosure[CINclosureDate] = pd.to_datetime(
-        fake_cinclosure[CINclosureDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {CINdetails: fake_cinclosure, Header: fake_header})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.CINdetails, CINclosureDate, 0),
-        IssueLocator(CINTable.CINdetails, CINclosureDate, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8620' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8620"
-    assert (
-        result.definition.message
-        == "CIN Closure Date present and does not fall within the Census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+CINclosureDate = CINdetails.CINclosureDate
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8620",
+    module=CINTable.CINdetails,
+    message="CIN Closure Date present and does not fall within the Census year",
+    affected_fields=[CINclosureDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINdetails]
+    df_ref = data_container[Header]
+
+    # ReferenceDate exists in the header table so we get header table too.
+    ref_date_series = df_ref[ReferenceDate]
+
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # If <CINclosureDate> (N00102) is present, it must be within [Period_of_Census]
+    df = df[df[CINclosureDate].notna()]
+    df = df[
+        ~(
+            (df[CINclosureDate] >= collection_start)
+            & (df[CINclosureDate] <= collection_end)
+        )
+    ]
+    failing_indices = df.index
+
+    rule_context.push_issue(table=CINdetails, field=CINclosureDate, row=failing_indices)
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_header = pd.DataFrame(
+        {ReferenceDate: ["31/03/2022"]}  # the census start date here will be 01/04/2021
+    )
+    fake_cinclosure = pd.DataFrame(
+        [
+            {
+                CINclosureDate: "01/03/2019"
+            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
+            {
+                CINclosureDate: "10/04/2021"
+            },  # 1 pass: April 10th is within April 1st, 2021 to March 31st, 2022.
+            {
+                CINclosureDate: "01/10/2022"
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+            {CINclosureDate: "01/04/2021"},  # Pass, first day of census period
+            {CINclosureDate: "31/03/2021"},  # Pass, last day of census period
+        ]
+    )
+
+    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
+    fake_cinclosure[CINclosureDate] = pd.to_datetime(
+        fake_cinclosure[CINclosureDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {CINdetails: fake_cinclosure, Header: fake_header})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.CINdetails, CINclosureDate, 0),
+        IssueLocator(CINTable.CINdetails, CINclosureDate, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8620' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8620"
+    assert (
+        result.definition.message
+        == "CIN Closure Date present and does not fall within the Census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8640.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8640.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,76 +1,76 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-CINdetails = CINTable.CINdetails
-ReasonForClosure = CINdetails.ReasonForClosure
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8640",
-    module=CINTable.CINdetails,
-    message="CIN Reason for closure code invalid (see Reason for Closure table in CIN Census code set)",
-    affected_fields=[ReasonForClosure],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINdetails]
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # Reason for Closure must be a valid reason for closure code value as shown in the list below
-
-    valid_reason = ["RC1", "RC2", "RC3", "RC4", "RC5", "RC6", "RC7", "RC8", "RC9"]
-
-    # Check if the Reason For Closure is not in the list of valid reasons and a value has been entered.
-
-    df = df[
-        ~(df["ReasonForClosure"].isin(valid_reason)) & df["ReasonForClosure"].notna()
-    ]
-
-    failing_indices = df.index
-
-    # Replace CINdetails and ReasonForClosure with the table and column name concerned in your rule, respectively.
-    # If there are multiple columns or table, make this sentence multiple times.
-    rule_context.push_issue(
-        table=CINdetails, field=ReasonForClosure, row=failing_indices
-    )
-
-
-def test_validate():
-    # Sample test all will pass the validation with the exception RC13 and RC0 which are not valid Closure codes.
-    fake_data = ["RC1", "RC13", pd.NA, "RC0"]
-
-    fake_dataframe = pd.DataFrame({"ReasonForClosure": fake_data})
-
-    # Run rule function passing in our sample test data
-    result = run_rule(validate, {CINdetails: fake_dataframe})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.CINdetails, ReasonForClosure, 1),
-        IssueLocator(CINTable.CINdetails, ReasonForClosure, 3),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    assert result.definition.code == "8640"
-    assert (
-        result.definition.message
-        == "CIN Reason for closure code invalid (see Reason for Closure table in CIN Census code set)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+CINdetails = CINTable.CINdetails
+ReasonForClosure = CINdetails.ReasonForClosure
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8640",
+    module=CINTable.CINdetails,
+    message="CIN Reason for closure code invalid (see Reason for Closure table in CIN Census code set)",
+    affected_fields=[ReasonForClosure],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINdetails]
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # Reason for Closure must be a valid reason for closure code value as shown in the list below
+
+    valid_reason = ["RC1", "RC2", "RC3", "RC4", "RC5", "RC6", "RC7", "RC8", "RC9"]
+
+    # Check if the Reason For Closure is not in the list of valid reasons and a value has been entered.
+
+    df = df[
+        ~(df["ReasonForClosure"].isin(valid_reason)) & df["ReasonForClosure"].notna()
+    ]
+
+    failing_indices = df.index
+
+    # Replace CINdetails and ReasonForClosure with the table and column name concerned in your rule, respectively.
+    # If there are multiple columns or table, make this sentence multiple times.
+    rule_context.push_issue(
+        table=CINdetails, field=ReasonForClosure, row=failing_indices
+    )
+
+
+def test_validate():
+    # Sample test all will pass the validation with the exception RC13 and RC0 which are not valid Closure codes.
+    fake_data = ["RC1", "RC13", pd.NA, "RC0"]
+
+    fake_dataframe = pd.DataFrame({"ReasonForClosure": fake_data})
+
+    # Run rule function passing in our sample test data
+    result = run_rule(validate, {CINdetails: fake_dataframe})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.CINdetails, ReasonForClosure, 1),
+        IssueLocator(CINTable.CINdetails, ReasonForClosure, 3),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    assert result.definition.code == "8640"
+    assert (
+        result.definition.message
+        == "CIN Reason for closure code invalid (see Reason for Closure table in CIN Census code set)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8650.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8650.py`

 * *Ordering differences only*

 * *Files 24% similar despite different names*

```diff
@@ -1,62 +1,62 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-CINdetails = CINTable.CINdetails
-PrimaryNeedCode = CINdetails.PrimaryNeedCode
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8650",
-    module=CINTable.CINdetails,
-    message="Primary Need Code invalid (see Primary Need table in CIN census code set)",
-    affected_fields=[PrimaryNeedCode],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[CINdetails]
-
-    # If present <PrimaryNeedCode> (N00101) must be a valid primary need code value
-    PriNeed_list = ["N0", "N1", "N2", "N3", "N4", "N5", "N6", "N7", "N8", "N9"]
-
-    # Primary Need Code is not in list.
-    df = df[(~df["PrimaryNeedCode"].isin(PriNeed_list)) & df["PrimaryNeedCode"].notna()]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=CINdetails, field=PrimaryNeedCode, row=failing_indices
-    )
-
-
-def test_validate():
-    pri_need = ["N1", "N8", "AA", pd.NA, "N6", "BB", "N9"]
-
-    fake_dataframe = pd.DataFrame({"PrimaryNeedCode": pri_need})
-
-    result = run_rule(validate, {CINdetails: fake_dataframe})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 2
-
-    assert issues == [
-        IssueLocator(CINTable.CINdetails, PrimaryNeedCode, 2),
-        IssueLocator(CINTable.CINdetails, PrimaryNeedCode, 5),
-    ]
-
-    assert result.definition.code == "8650"
-    assert (
-        result.definition.message
-        == "Primary Need Code invalid (see Primary Need table in CIN census code set)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+CINdetails = CINTable.CINdetails
+PrimaryNeedCode = CINdetails.PrimaryNeedCode
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8650",
+    module=CINTable.CINdetails,
+    message="Primary Need Code invalid (see Primary Need table in CIN census code set)",
+    affected_fields=[PrimaryNeedCode],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[CINdetails]
+
+    # If present <PrimaryNeedCode> (N00101) must be a valid primary need code value
+    PriNeed_list = ["N0", "N1", "N2", "N3", "N4", "N5", "N6", "N7", "N8", "N9"]
+
+    # Primary Need Code is not in list.
+    df = df[(~df["PrimaryNeedCode"].isin(PriNeed_list)) & df["PrimaryNeedCode"].notna()]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=CINdetails, field=PrimaryNeedCode, row=failing_indices
+    )
+
+
+def test_validate():
+    pri_need = ["N1", "N8", "AA", pd.NA, "N6", "BB", "N9"]
+
+    fake_dataframe = pd.DataFrame({"PrimaryNeedCode": pri_need})
+
+    result = run_rule(validate, {CINdetails: fake_dataframe})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 2
+
+    assert issues == [
+        IssueLocator(CINTable.CINdetails, PrimaryNeedCode, 2),
+        IssueLocator(CINTable.CINdetails, PrimaryNeedCode, 5),
+    ]
+
+    assert result.definition.code == "8650"
+    assert (
+        result.definition.message
+        == "Primary Need Code invalid (see Primary Need table in CIN census code set)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8670Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8670Q.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,170 +1,170 @@
-"""
-Rule number: 8670Q
-Module: Assessments
-Rule details: Where present, within an <Assessments> group, if <AssessmentAuthorisationDate> (N00160) is not present then <AssessmentActualStartDate>
-(N00159) should not be before the <ReferenceDate> (N00603) minus 45 working days.
-
-Rule message: Please check: Assessment started more than 45 working days before the end of the census year. However, there is no Assessment end date. 
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import england_working_days, make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-LAchildID = Assessments.LAchildID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8670Q",
-    module=CINTable.Assessments,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend data or provide a reason: Assessment started more than 45 working days before the end of the census year. However, there is no Assessment end date.",
-    affected_fields=[AssessmentActualStartDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_assessments = data_container[Assessments]
-    df_assessments.index.name = "ROW_ID"
-
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    #  If <AssessmentAuthorisationDate> (N00160) is not present then <AssessmentActualStartDate> (N00159) should not be before the <ReferenceDate> (N00603) minus 45 working days
-
-    # Filter to only those with no authorisation date
-    df_assessments = df_assessments[df_assessments[AssessmentAuthorisationDate].isna()]
-
-    latest_date = collection_end - england_working_days(45)
-    df_issues = df_assessments[
-        df_assessments[AssessmentActualStartDate] < latest_date
-    ].reset_index()
-
-    link_id = tuple(zip(df_issues[LAchildID], df_issues[AssessmentActualStartDate]))
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_1(
-        table=Assessments,
-        columns=[AssessmentAuthorisationDate, AssessmentActualStartDate],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_assessments = pd.DataFrame(
-        [
-            {
-                "LAchildID": "ID1",
-                "AssessmentAuthorisationDate": "26/05/2022",
-                "AssessmentActualStartDate": "15/10/2022",
-                # Pass, authorisation date present
-            },
-            {
-                "LAchildID": "ID2",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "15/10/2022",
-                # Fail, start date is before ref date - 45wd
-            },
-            {
-                "LAchildID": "ID3",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "15/03/2023",
-                # Pass, start date is withing 45wd of reference date
-            },
-            {
-                "LAchildID": "ID4",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "29/01/2023",
-                # Fail, start date is outside of 45wd of reference date
-            },
-        ]
-    )
-
-    sample_assessments[AssessmentAuthorisationDate] = pd.to_datetime(
-        sample_assessments[AssessmentAuthorisationDate],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-    sample_assessments[AssessmentActualStartDate] = pd.to_datetime(
-        sample_assessments[AssessmentActualStartDate],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-
-    sample_header = pd.DataFrame([{"ReferenceDate": "31/03/2023"}])
-
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(
-        validate, {Assessments: sample_assessments, Header: sample_header}
-    )
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    # get table name and check it. Replace Assessments with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Assessments
-
-    # check that the right columns were returned. Replace AssessmentAuthorisationDate and AssessmentActualStartDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [AssessmentAuthorisationDate, AssessmentActualStartDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 1 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "ID2",
-                    pd.to_datetime("15/10/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "ID4",
-                    pd.to_datetime("29/01/2023", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-
-    assert issue_rows.equals(expected_df)
-
-    # replace 8670Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8670Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: Assessment started more than 45 working days before the end of the census year. However, there is no Assessment end date."
-    )
+"""
+Rule number: 8670Q
+Module: Assessments
+Rule details: Where present, within an <Assessments> group, if <AssessmentAuthorisationDate> (N00160) is not present then <AssessmentActualStartDate>
+(N00159) should not be before the <ReferenceDate> (N00603) minus 45 working days.
+
+Rule message: Please check: Assessment started more than 45 working days before the end of the census year. However, there is no Assessment end date. 
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import england_working_days, make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+LAchildID = Assessments.LAchildID
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8670Q",
+    module=CINTable.Assessments,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend data or provide a reason: Assessment started more than 45 working days before the end of the census year. However, there is no Assessment end date.",
+    affected_fields=[AssessmentActualStartDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_assessments = data_container[Assessments]
+    df_assessments.index.name = "ROW_ID"
+
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    #  If <AssessmentAuthorisationDate> (N00160) is not present then <AssessmentActualStartDate> (N00159) should not be before the <ReferenceDate> (N00603) minus 45 working days
+
+    # Filter to only those with no authorisation date
+    df_assessments = df_assessments[df_assessments[AssessmentAuthorisationDate].isna()]
+
+    latest_date = collection_end - england_working_days(45)
+    df_issues = df_assessments[
+        df_assessments[AssessmentActualStartDate] < latest_date
+    ].reset_index()
+
+    link_id = tuple(zip(df_issues[LAchildID], df_issues[AssessmentActualStartDate]))
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_1(
+        table=Assessments,
+        columns=[AssessmentAuthorisationDate, AssessmentActualStartDate],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_assessments = pd.DataFrame(
+        [
+            {
+                "LAchildID": "ID1",
+                "AssessmentAuthorisationDate": "26/05/2022",
+                "AssessmentActualStartDate": "15/10/2022",
+                # Pass, authorisation date present
+            },
+            {
+                "LAchildID": "ID2",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentActualStartDate": "15/10/2022",
+                # Fail, start date is before ref date - 45wd
+            },
+            {
+                "LAchildID": "ID3",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentActualStartDate": "15/03/2023",
+                # Pass, start date is withing 45wd of reference date
+            },
+            {
+                "LAchildID": "ID4",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentActualStartDate": "29/01/2023",
+                # Fail, start date is outside of 45wd of reference date
+            },
+        ]
+    )
+
+    sample_assessments[AssessmentAuthorisationDate] = pd.to_datetime(
+        sample_assessments[AssessmentAuthorisationDate],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+    sample_assessments[AssessmentActualStartDate] = pd.to_datetime(
+        sample_assessments[AssessmentActualStartDate],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    sample_header = pd.DataFrame([{"ReferenceDate": "31/03/2023"}])
+
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(
+        validate, {Assessments: sample_assessments, Header: sample_header}
+    )
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    # get table name and check it. Replace Assessments with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Assessments
+
+    # check that the right columns were returned. Replace AssessmentAuthorisationDate and AssessmentActualStartDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [AssessmentAuthorisationDate, AssessmentActualStartDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 1 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "ID2",
+                    pd.to_datetime("15/10/2022", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "ID4",
+                    pd.to_datetime("29/01/2023", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+
+    assert issue_rows.equals(expected_df)
+
+    # replace 8670Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8670Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: Assessment started more than 45 working days before the end of the census year. However, there is no Assessment end date."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8675Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8675Q.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,190 +1,190 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import england_working_days, make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-DateOfInitialCPC = Section47.DateOfInitialCPC
-ICPCnotReqiured = Section47.ICPCnotRequired
-S47ActualStartDate = Section47.S47ActualStartDate
-LAchildID = Section47.LAchildID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of 8675Q
-    code="8675Q",
-    rule_type=RuleType.QUERY,
-    module=CINTable.Section47,
-    message="Please check and either amend data or provide a reason: S47 Enquiry started more than 15 working days before the end of the census year. However, there is no date of Initial Child Protection Conference.",
-    affected_fields=[DateOfInitialCPC, S47ActualStartDate, ICPCnotReqiured],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-    df = data_container[Section47]
-    header = data_container[Header]
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    ref_date_series = header[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <DateOfInitialCPC> (N00110) not present and <ICPCnotReqiured> (N00111) equals false
-    # then <S47ActualStartDate> (N00148) should not be before the <ReferenceDate> (N00603) minus 15 working days
-    no_cpc = df[DateOfInitialCPC].isna()
-    icpc_false = df[ICPCnotReqiured].astype(str).isin(["false", "0"])
-    before_15b = df[S47ActualStartDate] < (collection_end - england_working_days(15))
-    condition = (no_cpc & icpc_false) & (before_15b)
-
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error.
-    # Replace S47ActualStartDate and ICPCnotReqiured below with the columns concerned in your rule.
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-            df_issues[S47ActualStartDate],
-            df_issues[ICPCnotReqiured],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=Section47,
-        columns=[DateOfInitialCPC, S47ActualStartDate, ICPCnotReqiured],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-
-    section47 = pd.DataFrame(
-        [
-            {  # 0 fail, no ICPCnotrequied as true or InitialCPC, and date is more than 15 days before end of census year
-                "LAchildID": "child1",
-                "DateOfInitialCPC": pd.NA,
-                "S47ActualStartDate": "29/01/2022",
-                "ICPCnotRequired": "false",
-            },
-            {  # 1 ignore DateOfInitialCPC notna
-                "LAchildID": "child2",
-                "DateOfInitialCPC": "26/05/2000",
-                "S47ActualStartDate": "26/05/2001",
-                "ICPCnotRequired": "false",
-            },
-            {  # 2 pass. more than 15 working days before ref date
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,
-                "S47ActualStartDate": "25/03/2022",
-                "ICPCnotRequired": "false",
-            },
-            {  # ignore S47ActualStartDate isna
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "S47ActualStartDate": pd.NA,
-                "ICPCnotRequired": "false",
-            },
-            {  # ignore
-                "LAchildID": "child5",
-                "DateOfInitialCPC": pd.NA,
-                "S47ActualStartDate": pd.NA,
-                "ICPCnotRequired": "true",
-            },
-            {  # 5 fail, no ICPCnotrequied as true or InitialCPC, and date is more than 15 days before end of census year
-                "LAchildID": "child6",
-                "DateOfInitialCPC": pd.NA,
-                "S47ActualStartDate": "29/01/2022",
-                "ICPCnotRequired": "0",
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    section47["DateOfInitialCPC"] = pd.to_datetime(
-        section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-    section47["S47ActualStartDate"] = pd.to_datetime(
-        section47["S47ActualStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Section47: section47, Header: fake_header})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [DateOfInitialCPC, S47ActualStartDate, ICPCnotReqiured]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 1 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("29/01/2022", format="%d/%m/%Y", errors="coerce"),
-                    "false",
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child6",
-                    pd.to_datetime("29/01/2022", format="%d/%m/%Y", errors="coerce"),
-                    "0",
-                ),
-                "ROW_ID": [5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8675Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8675Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: S47 Enquiry started more than 15 working days before the end of the census year. However, there is no date of Initial Child Protection Conference."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import england_working_days, make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+DateOfInitialCPC = Section47.DateOfInitialCPC
+ICPCnotReqiured = Section47.ICPCnotRequired
+S47ActualStartDate = Section47.S47ActualStartDate
+LAchildID = Section47.LAchildID
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of 8675Q
+    code="8675Q",
+    rule_type=RuleType.QUERY,
+    module=CINTable.Section47,
+    message="Please check and either amend data or provide a reason: S47 Enquiry started more than 15 working days before the end of the census year. However, there is no date of Initial Child Protection Conference.",
+    affected_fields=[DateOfInitialCPC, S47ActualStartDate, ICPCnotReqiured],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+    df = data_container[Section47]
+    header = data_container[Header]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    ref_date_series = header[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <DateOfInitialCPC> (N00110) not present and <ICPCnotReqiured> (N00111) equals false
+    # then <S47ActualStartDate> (N00148) should not be before the <ReferenceDate> (N00603) minus 15 working days
+    no_cpc = df[DateOfInitialCPC].isna()
+    icpc_false = df[ICPCnotReqiured].astype(str).isin(["false", "0"])
+    before_15b = df[S47ActualStartDate] < (collection_end - england_working_days(15))
+    condition = (no_cpc & icpc_false) & (before_15b)
+
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error.
+    # Replace S47ActualStartDate and ICPCnotReqiured below with the columns concerned in your rule.
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID],
+            df_issues[S47ActualStartDate],
+            df_issues[ICPCnotReqiured],
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=Section47,
+        columns=[DateOfInitialCPC, S47ActualStartDate, ICPCnotReqiured],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
+    )
+
+    section47 = pd.DataFrame(
+        [
+            {  # 0 fail, no ICPCnotrequied as true or InitialCPC, and date is more than 15 days before end of census year
+                "LAchildID": "child1",
+                "DateOfInitialCPC": pd.NA,
+                "S47ActualStartDate": "29/01/2022",
+                "ICPCnotRequired": "false",
+            },
+            {  # 1 ignore DateOfInitialCPC notna
+                "LAchildID": "child2",
+                "DateOfInitialCPC": "26/05/2000",
+                "S47ActualStartDate": "26/05/2001",
+                "ICPCnotRequired": "false",
+            },
+            {  # 2 pass. more than 15 working days before ref date
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,
+                "S47ActualStartDate": "25/03/2022",
+                "ICPCnotRequired": "false",
+            },
+            {  # ignore S47ActualStartDate isna
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "S47ActualStartDate": pd.NA,
+                "ICPCnotRequired": "false",
+            },
+            {  # ignore
+                "LAchildID": "child5",
+                "DateOfInitialCPC": pd.NA,
+                "S47ActualStartDate": pd.NA,
+                "ICPCnotRequired": "true",
+            },
+            {  # 5 fail, no ICPCnotrequied as true or InitialCPC, and date is more than 15 days before end of census year
+                "LAchildID": "child6",
+                "DateOfInitialCPC": pd.NA,
+                "S47ActualStartDate": "29/01/2022",
+                "ICPCnotRequired": "0",
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    section47["DateOfInitialCPC"] = pd.to_datetime(
+        section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+    section47["S47ActualStartDate"] = pd.to_datetime(
+        section47["S47ActualStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Section47: section47, Header: fake_header})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [DateOfInitialCPC, S47ActualStartDate, ICPCnotReqiured]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 1 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    pd.to_datetime("29/01/2022", format="%d/%m/%Y", errors="coerce"),
+                    "false",
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child6",
+                    pd.to_datetime("29/01/2022", format="%d/%m/%Y", errors="coerce"),
+                    "0",
+                ),
+                "ROW_ID": [5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8675Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8675Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: S47 Enquiry started more than 15 working days before the end of the census year. However, there is no date of Initial Child Protection Conference."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8696.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8696.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,91 +1,91 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-Header = CINTable.Header
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8696",
-    module=CINTable.Assessments,
-    message="Assessment end date must fall within the census year",
-    affected_fields=[AssessmentAuthorisationDate, ReferenceDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Assessments]
-    df_ref = data_container[Header]
-
-    ref_data_series = df_ref[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_data_series)
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # <If present <AssessmentAuthorisationDate> (N00160) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
-
-    df = df[
-        (df[AssessmentAuthorisationDate] < collection_start)
-        | (df[AssessmentAuthorisationDate] > collection_end)
-    ]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=Assessments, field=AssessmentAuthorisationDate, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-
-    miss_auth = pd.to_datetime(
-        [
-            "01/03/2019",  # 0 fail
-            "01/04/2021",  # 1 pass
-            "01/10/2022",  # 2 fail
-            pd.NA,  # 3 ignored
-        ],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-
-    fake_auth = pd.DataFrame({AssessmentAuthorisationDate: miss_auth})
-    fake_header = pd.DataFrame({ReferenceDate: ["31/03/2022"]})
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Assessments: fake_auth, Header: fake_header})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.Assessments, AssessmentAuthorisationDate, 0),
-        IssueLocator(CINTable.Assessments, AssessmentAuthorisationDate, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    assert result.definition.code == "8696"
-    assert (
-        result.definition.message
-        == "Assessment end date must fall within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+Header = CINTable.Header
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8696",
+    module=CINTable.Assessments,
+    message="Assessment end date must fall within the census year",
+    affected_fields=[AssessmentAuthorisationDate, ReferenceDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Assessments]
+    df_ref = data_container[Header]
+
+    ref_data_series = df_ref[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_data_series)
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # <If present <AssessmentAuthorisationDate> (N00160) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
+
+    df = df[
+        (df[AssessmentAuthorisationDate] < collection_start)
+        | (df[AssessmentAuthorisationDate] > collection_end)
+    ]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=Assessments, field=AssessmentAuthorisationDate, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+
+    miss_auth = pd.to_datetime(
+        [
+            "01/03/2019",  # 0 fail
+            "01/04/2021",  # 1 pass
+            "01/10/2022",  # 2 fail
+            pd.NA,  # 3 ignored
+        ],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    fake_auth = pd.DataFrame({AssessmentAuthorisationDate: miss_auth})
+    fake_header = pd.DataFrame({ReferenceDate: ["31/03/2022"]})
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Assessments: fake_auth, Header: fake_header})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.Assessments, AssessmentAuthorisationDate, 0),
+        IssueLocator(CINTable.Assessments, AssessmentAuthorisationDate, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    assert result.definition.code == "8696"
+    assert (
+        result.definition.message
+        == "Assessment end date must fall within the census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8715.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8715.py`

 * *Ordering differences only*

 * *Files 15% similar despite different names*

```diff
@@ -1,102 +1,102 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-DateOfInitialCPC = Section47.DateOfInitialCPC
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8715",
-    module=CINTable.Section47,
-    message="Date of Initial Child Protection Conference must fall within the census year",
-    affected_fields=[DateOfInitialCPC, ReferenceDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Section47]
-
-    # ReferenceDate exists in the header table so we get header table too.
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # If present <DateOfInitialCPC> (N00110) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
-    # A value is out of range if it is before the start or after the end.
-    failing_indices = df[
-        (df[DateOfInitialCPC] < collection_start)
-        | (df[DateOfInitialCPC] > reference_date)
-    ].index
-
-    # Replace Section47 and DateOfInitialCPC with the table and column name concerned in your rule, respectively.
-    rule_context.push_issue(
-        table=Section47, field=DateOfInitialCPC, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-    fake_section47 = pd.DataFrame(
-        [
-            {
-                DateOfInitialCPC: "01/03/2019"
-            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
-            {
-                DateOfInitialCPC: "01/04/2021"
-            },  # 1 pass: April 1st is within April 1st, 2021 to March 31st, 2022.
-            {
-                DateOfInitialCPC: "01/10/2022"
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-        ]
-    )
-
-    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
-    fake_section47[DateOfInitialCPC] = pd.to_datetime(
-        fake_section47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    # Since the ReferenceDate comes from the Header column, we provide that also.
-    result = run_rule(validate, {Section47: fake_section47, Header: fake_header})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        # from above, index positions 0 and 2 fail.
-        IssueLocator(CINTable.Section47, DateOfInitialCPC, 0),
-        IssueLocator(CINTable.Section47, DateOfInitialCPC, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8715' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8715"
-    assert (
-        result.definition.message
-        == "Date of Initial Child Protection Conference must fall within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+DateOfInitialCPC = Section47.DateOfInitialCPC
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8715",
+    module=CINTable.Section47,
+    message="Date of Initial Child Protection Conference must fall within the census year",
+    affected_fields=[DateOfInitialCPC, ReferenceDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Section47]
+
+    # ReferenceDate exists in the header table so we get header table too.
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # If present <DateOfInitialCPC> (N00110) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
+    # A value is out of range if it is before the start or after the end.
+    failing_indices = df[
+        (df[DateOfInitialCPC] < collection_start)
+        | (df[DateOfInitialCPC] > reference_date)
+    ].index
+
+    # Replace Section47 and DateOfInitialCPC with the table and column name concerned in your rule, respectively.
+    rule_context.push_issue(
+        table=Section47, field=DateOfInitialCPC, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
+    )
+    fake_section47 = pd.DataFrame(
+        [
+            {
+                DateOfInitialCPC: "01/03/2019"
+            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
+            {
+                DateOfInitialCPC: "01/04/2021"
+            },  # 1 pass: April 1st is within April 1st, 2021 to March 31st, 2022.
+            {
+                DateOfInitialCPC: "01/10/2022"
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+        ]
+    )
+
+    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
+    fake_section47[DateOfInitialCPC] = pd.to_datetime(
+        fake_section47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    # Since the ReferenceDate comes from the Header column, we provide that also.
+    result = run_rule(validate, {Section47: fake_section47, Header: fake_header})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        # from above, index positions 0 and 2 fail.
+        IssueLocator(CINTable.Section47, DateOfInitialCPC, 0),
+        IssueLocator(CINTable.Section47, DateOfInitialCPC, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8715' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8715"
+    assert (
+        result.definition.message
+        == "Date of Initial Child Protection Conference must fall within the census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8720.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8720.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,110 +1,110 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-CPPID = ChildProtectionPlans.CPPID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8720'
-    code="8720",
-    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child Protection Plan Start Date missing or out of data collection period",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[CPPstartDate, ReferenceDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace ChildIdentifiers with the name of the table you need.
-    df = data_container[ChildProtectionPlans]
-
-    # ReferenceDate exists in the heder table so we get header table too.
-    df_ref = data_container[Header]
-
-    # Where a CPP module is present, <CPPstartDate> (N00105) must be present and on or before the <ReferenceDate> (N00603)
-    condition = (df[CPPID].notna()) & (
-        (df[CPPstartDate].isna()) | (df[CPPstartDate] > df_ref[ReferenceDate].iloc[0])
-    )
-
-    failing_indices = df[condition].index
-
-    # Replace ChildProtectionPlans and CPPstartDate with the table and column name concerned in your rule, respectively.
-    # If there are multiple columns or table, make this sentence multiple times.
-    rule_context.push_issue(
-        table=ChildProtectionPlans, field=CPPstartDate, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-
-    fake_cpp = pd.DataFrame(
-        [
-            {
-                CPPID: "ID1",
-                CPPstartDate: "01/03/2019",
-            },  # Pass: March 1st is before April 1st, 2021. It is out of range
-            {CPPID: pd.NA, CPPstartDate: pd.NA},  # 1 pass: No CPPID
-            {
-                CPPID: "ID1",
-                CPPstartDate: "01/10/2022",
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-            {
-                CPPID: "ID1",
-                CPPstartDate: pd.NA,
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-        ]
-    )
-
-    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
-    fake_cpp[CPPstartDate] = pd.to_datetime(
-        fake_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    fake_header[ReferenceDate] = pd.to_datetime(
-        fake_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    # Since the ReferenceDate comes from the Header column, we provide that also.
-    result = run_rule(validate, {ChildProtectionPlans: fake_cpp, Header: fake_header})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.ChildProtectionPlans, CPPstartDate, 2),
-        IssueLocator(CINTable.ChildProtectionPlans, CPPstartDate, 3),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8720' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8720"
-    assert (
-        result.definition.message
-        == "Child Protection Plan Start Date missing or out of data collection period"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+CPPID = ChildProtectionPlans.CPPID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8720'
+    code="8720",
+    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child Protection Plan Start Date missing or out of data collection period",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[CPPstartDate, ReferenceDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace ChildIdentifiers with the name of the table you need.
+    df = data_container[ChildProtectionPlans]
+
+    # ReferenceDate exists in the heder table so we get header table too.
+    df_ref = data_container[Header]
+
+    # Where a CPP module is present, <CPPstartDate> (N00105) must be present and on or before the <ReferenceDate> (N00603)
+    condition = (df[CPPID].notna()) & (
+        (df[CPPstartDate].isna()) | (df[CPPstartDate] > df_ref[ReferenceDate].iloc[0])
+    )
+
+    failing_indices = df[condition].index
+
+    # Replace ChildProtectionPlans and CPPstartDate with the table and column name concerned in your rule, respectively.
+    # If there are multiple columns or table, make this sentence multiple times.
+    rule_context.push_issue(
+        table=ChildProtectionPlans, field=CPPstartDate, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
+    )
+
+    fake_cpp = pd.DataFrame(
+        [
+            {
+                CPPID: "ID1",
+                CPPstartDate: "01/03/2019",
+            },  # Pass: March 1st is before April 1st, 2021. It is out of range
+            {CPPID: pd.NA, CPPstartDate: pd.NA},  # 1 pass: No CPPID
+            {
+                CPPID: "ID1",
+                CPPstartDate: "01/10/2022",
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+            {
+                CPPID: "ID1",
+                CPPstartDate: pd.NA,
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+        ]
+    )
+
+    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
+    fake_cpp[CPPstartDate] = pd.to_datetime(
+        fake_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    fake_header[ReferenceDate] = pd.to_datetime(
+        fake_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    # Since the ReferenceDate comes from the Header column, we provide that also.
+    result = run_rule(validate, {ChildProtectionPlans: fake_cpp, Header: fake_header})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.ChildProtectionPlans, CPPstartDate, 2),
+        IssueLocator(CINTable.ChildProtectionPlans, CPPstartDate, 3),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8720' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8720"
+    assert (
+        result.definition.message
+        == "Child Protection Plan Start Date missing or out of data collection period"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8730.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8730.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,75 +1,75 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-NumberOfPreviousCPP = ChildProtectionPlans.NumberOfPreviousCPP
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8730",
-    module=CINTable.ChildProtectionPlans,
-    message="Total Number of previous Child Protection Plans missing",
-    affected_fields=[NumberOfPreviousCPP],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace ChildProtectionPlans with the name of the table you need.
-    df = data_container[ChildProtectionPlans]
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # Where a CPP module is present, <NumberOfPreviousCPP> (N00106) must be greater than or equal to zero
-    # Change the line below to ensure values are >=0 ie not null
-
-    failing_indices = df[
-        (df[NumberOfPreviousCPP].isna()) | (df[NumberOfPreviousCPP].astype("Int64") < 0)
-    ].index
-    # Int64 dtype is used instead of int because it tolerates the possibility of NaN values in the column
-    # nullable integers ==  Int64 dtype
-
-    rule_context.push_issue(
-        table=ChildProtectionPlans, field=NumberOfPreviousCPP, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_data = pd.DataFrame(
-        [[1234], [pd.NA], [pd.NA], [-1]], columns=[NumberOfPreviousCPP]
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildProtectionPlans: fake_data})
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issues) == 3
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.ChildProtectionPlans, NumberOfPreviousCPP, 1),
-        IssueLocator(CINTable.ChildProtectionPlans, NumberOfPreviousCPP, 2),
-        IssueLocator(CINTable.ChildProtectionPlans, NumberOfPreviousCPP, 3),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8730' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8730"
-    assert (
-        result.definition.message
-        == "Total Number of previous Child Protection Plans missing"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+NumberOfPreviousCPP = ChildProtectionPlans.NumberOfPreviousCPP
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8730",
+    module=CINTable.ChildProtectionPlans,
+    message="Total Number of previous Child Protection Plans missing",
+    affected_fields=[NumberOfPreviousCPP],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace ChildProtectionPlans with the name of the table you need.
+    df = data_container[ChildProtectionPlans]
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # Where a CPP module is present, <NumberOfPreviousCPP> (N00106) must be greater than or equal to zero
+    # Change the line below to ensure values are >=0 ie not null
+
+    failing_indices = df[
+        (df[NumberOfPreviousCPP].isna()) | (df[NumberOfPreviousCPP].astype("Int64") < 0)
+    ].index
+    # Int64 dtype is used instead of int because it tolerates the possibility of NaN values in the column
+    # nullable integers ==  Int64 dtype
+
+    rule_context.push_issue(
+        table=ChildProtectionPlans, field=NumberOfPreviousCPP, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_data = pd.DataFrame(
+        [[1234], [pd.NA], [pd.NA], [-1]], columns=[NumberOfPreviousCPP]
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildProtectionPlans: fake_data})
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issues) == 3
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.ChildProtectionPlans, NumberOfPreviousCPP, 1),
+        IssueLocator(CINTable.ChildProtectionPlans, NumberOfPreviousCPP, 2),
+        IssueLocator(CINTable.ChildProtectionPlans, NumberOfPreviousCPP, 3),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8730' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8730"
+    assert (
+        result.definition.message
+        == "Total Number of previous Child Protection Plans missing"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8736.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8896.py`

 * *Files 19% similar despite different names*

```diff
@@ -1,199 +1,182 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-CINdetailsID = Assessments.CINdetailsID
-LAchildID = Assessments.LAchildID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8736",
-    module=CINTable.Assessments,
-    message="For an Assessment that has not been completed, the start date must fall within the census year",
-    affected_fields=[AssessmentAuthorisationDate, AssessmentActualStartDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df = data_container[Assessments]
-    header = data_container[Header]
-    ref_date_series = header[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Where present, if an <Assessments> group does not contain the <AssessmentAuthorisationDate> (N00160) then the <AssessmentActualStartDate> (N00159) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
-    condition_1 = (df[CINdetailsID].notna()) & (df[AssessmentAuthorisationDate].isna())
-    condition_2 = (collection_start <= df[AssessmentActualStartDate]) & (
-        df[AssessmentActualStartDate] <= collection_end
-    )
-
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition_1 & ~condition_2].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error.
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-            df_issues[CINdetailsID],
-            df_issues[AssessmentActualStartDate],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    rule_context.push_type_1(
-        table=Assessments,
-        columns=[AssessmentAuthorisationDate, AssessmentActualStartDate],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-
-    child_assessments = pd.DataFrame(
-        [
-            {
-                "CINdetailsID": pd.NA,
-                "LAchildID": "child1",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "27/05/2021",
-            },
-            {
-                "CINdetailsID": "1",
-                "LAchildID": "child2",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "26/03/2020",
-                # 1 error: start date is outside the reporting period
-            },
-            {
-                "CINdetailsID": "1",
-                "LAchildID": "child3",
-                "AssessmentAuthorisationDate": "27/06/2021",
-                "AssessmentActualStartDate": "27/05/2021",
-            },
-            {
-                "CINdetailsID": "1",
-                "LAchildID": "child4",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "10/04/2024",
-                # 3 error: start date is outside the reporting period
-            },
-            {
-                "CINdetailsID": "1",
-                "LAchildID": "child5",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": "27/05/2022",
-                # 4 error: start date is outside the reporting period
-            },
-            {
-                "CINdetailsID": pd.NA,
-                "LAchildID": "child6",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": pd.NA,
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    child_assessments[AssessmentAuthorisationDate] = pd.to_datetime(
-        child_assessments[AssessmentAuthorisationDate],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-    child_assessments[AssessmentActualStartDate] = pd.to_datetime(
-        child_assessments[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Assessments: child_assessments, Header: fake_header})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == Assessments
-
-    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [AssessmentAuthorisationDate, AssessmentActualStartDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",
-                    "1",
-                    pd.to_datetime("26/03/2020", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    "1",
-                    pd.to_datetime("10/04/2024", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-            {
-                "ERROR_ID": (
-                    "child5",
-                    "1",
-                    pd.to_datetime("27/05/2022", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8736' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8736"
-    assert (
-        result.definition.message
-        == "For an Assessment that has not been completed, the start date must fall within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+LAchildID = Assessments.LAchildID
+CINdetailsID = Assessments.CINdetailsID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8896'
+    code="8896",
+    # replace Assessments with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.Assessments,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Within one CINDetails group there are 2 or more open Assessments groups",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[AssessmentAuthorisationDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace Assessments with the name of the table you need.
+    df = data_container[Assessments]
+    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+    df.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Within one <CINdetails> group, there must not be more than one <Assessments> group that has no <AssessmentAuthorisationDate> (N00160) recorded
+
+    # DF_CHECK: APPLY GROUPBYs IN A SEPARATE DATAFRAME SO THAT OTHER COLUMNS ARE NOT LOST OR CORRUPTED. THEN, MAP THE RESULTS TO THE INITIAL DATAFRAME.
+    df_check = df.copy()
+    # get all the locations where AssessmentAuthorisationDate is null
+    df_check = df_check[df_check[AssessmentAuthorisationDate].isna()]
+    # We'll have to count the number of nan values per group. NaNs cannot be counted so replace them with something that can.
+    # Do this only if your rule requires that you interact with a column made up of all NaNs.
+    df_check[AssessmentAuthorisationDate].fillna(1, inplace=True)
+    # count how many occurences of missing AssessmentAuthorisationDate per CINdetails group in each child.
+    df_check = (
+        df_check.groupby([LAchildID, CINdetailsID])[AssessmentAuthorisationDate]
+        .count()
+        .reset_index()
+    )
+
+    # when you groupby as shown above a series is returned where the columns in the round brackets become the index and the groupby result are the values.
+    # resetting the index pushes the columns in the () back as columns of the dataframe and assigns the groupby result to the column in the square bracket.
+
+    # filter out the instances where AssessmentAuthorisationDate is missing more than once in a CINdetails group.
+    df_check = df_check[df_check[AssessmentAuthorisationDate] > 1]
+    issue_ids = tuple(zip(df_check[LAchildID], df_check[CINdetailsID]))
+
+    # DF_ISSUES: GET ALL THE DATA ABOUT THE LOCATIONS THAT WERE IDENTIFIED IN DF_CHECK
+    df["ERROR_ID"] = tuple(zip(df[LAchildID], df[CINdetailsID]))
+    df_issues = df[df["ERROR_ID"].isin(issue_ids)]
+
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=Assessments, columns=[AssessmentAuthorisationDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_assessments = pd.DataFrame(
+        [  # child1
+            {  # fail
+                LAchildID: "child1",
+                CINdetailsID: "cinID1",
+                AssessmentAuthorisationDate: pd.NA,  # 0 first nan date in group
+            },
+            {  # fail
+                LAchildID: "child1",
+                CINdetailsID: "cinID1",
+                AssessmentAuthorisationDate: pd.NA,  # 1 second nan date in group
+            },
+            {  # won't be flagged because there is not more than one nan authorisation date in this group.
+                LAchildID: "child1",
+                CINdetailsID: "cinID2",
+                AssessmentAuthorisationDate: pd.NA,  # 2
+            },
+            # child2
+            {
+                LAchildID: "child2",
+                CINdetailsID: "cinID1",
+                AssessmentAuthorisationDate: "26/05/2021",  # 3 ignored. not nan
+            },
+            {  # fail
+                LAchildID: "child2",
+                CINdetailsID: "cinID2",
+                AssessmentAuthorisationDate: pd.NA,  # 4 first nan date in group
+            },
+            {  # fail
+                LAchildID: "child2",
+                CINdetailsID: "cinID2",
+                AssessmentAuthorisationDate: pd.NA,  # 5 second nan date in group
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_assessments[AssessmentAuthorisationDate] = pd.to_datetime(
+        sample_assessments[AssessmentAuthorisationDate],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Assessments: sample_assessments})
+
+    # Use .type3_issues to check for the result of .push_type3_issues() which you used above.
+    issues_list = result.type3_issues
+    # Issues list contains the objects pushed in their respective order. Since push_type3 was only used once, there will be one object in issues_list.
+    assert len(issues_list) == 1
+
+    issues = issues_list[0]
+
+    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Assessments
+
+    # check that the right columns were pushed.
+    issue_columns = issues.columns
+    assert issue_columns == [AssessmentAuthorisationDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                ),
+                "ROW_ID": [0, 1],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "cinID2",
+                ),
+                "ROW_ID": [4, 5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8925 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8896"
+    assert (
+        result.definition.message
+        == "Within one CINDetails group there are 2 or more open Assessments groups"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8740.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8740.py`

 * *Ordering differences only*

 * *Files 16% similar despite different names*

```diff
@@ -1,184 +1,184 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-LAchildID = Section47.LAchildID
-S47ActualStartDate = Section47.S47ActualStartDate
-DateOfInitialCPC = Section47.DateOfInitialCPC
-ICPCnotRequired = Section47.ICPCnotRequired
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8740",
-    module=CINTable.Section47,
-    message="For a Section 47 Enquiry that has not held the Initial Child Protection Conference by the end of the census year, the start date must fall within the census year",
-    affected_fields=[S47ActualStartDate, DateOfInitialCPC, ICPCnotRequired],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df = data_container[Section47]
-    # Rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # ReferenceDate exists in the heder table so we get header table too.
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If a <Section47> group does not contain the <DateOfInitialCPC> (N00110) and <ICPCnotRequired> (N00111) is false
-    # then the <S47ActualStartDate> (N00148) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
-    condition = (
-        df[DateOfInitialCPC].isna()
-        & (df[ICPCnotRequired].astype(str) == "0")
-        & (
-            (df[S47ActualStartDate] < collection_start)
-            | (df[S47ActualStartDate] > reference_date)
-        )
-    )
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error.
-    link_id = tuple(zip(df_issues[LAchildID], df_issues[S47ActualStartDate]))
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=Section47,
-        columns=[S47ActualStartDate, DateOfInitialCPC, ICPCnotRequired],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
-    )
-
-    section_47s = pd.DataFrame(
-        [
-            {  # 0 - Ignore
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/2000",
-                "DateOfInitialCPC": "26/05/2000",
-                "ICPCnotRequired": "0",
-            },
-            {  # 1 - Ignore
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/2000",
-                "DateOfInitialCPC": "26/05/2000",
-                "ICPCnotRequired": "1",
-            },
-            {  # 2 - Ignore
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/2000",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "1",
-            },
-            {  # 3 - Pass
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/2000",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "0",
-            },
-            {  # 4 - Fail
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/1999",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "0",
-            },
-            {  # 5 - Fail
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/1999",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "0",
-            },
-            {  # 6 - Ignore
-                "LAchildID": "child1",
-                "S47ActualStartDate": "26/05/1999",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "1",
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    section_47s[S47ActualStartDate] = pd.to_datetime(
-        section_47s[S47ActualStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    section_47s[DateOfInitialCPC] = pd.to_datetime(
-        section_47s[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Section47: section_47s, Header: fake_header})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    issue_columns = issues.columns
-    assert issue_columns == [S47ActualStartDate, DateOfInitialCPC, ICPCnotRequired]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 1 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 1
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4, 5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8740' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8740"
-    assert (
-        result.definition.message
-        == "For a Section 47 Enquiry that has not held the Initial Child Protection Conference by the end of the census year, the start date must fall within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+LAchildID = Section47.LAchildID
+S47ActualStartDate = Section47.S47ActualStartDate
+DateOfInitialCPC = Section47.DateOfInitialCPC
+ICPCnotRequired = Section47.ICPCnotRequired
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8740",
+    module=CINTable.Section47,
+    message="For a Section 47 Enquiry that has not held the Initial Child Protection Conference by the end of the census year, the start date must fall within the census year",
+    affected_fields=[S47ActualStartDate, DateOfInitialCPC, ICPCnotRequired],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df = data_container[Section47]
+    # Rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # ReferenceDate exists in the heder table so we get header table too.
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If a <Section47> group does not contain the <DateOfInitialCPC> (N00110) and <ICPCnotRequired> (N00111) is false
+    # then the <S47ActualStartDate> (N00148) must be on or between [Start_Of_Census_Year] and <ReferenceDate> (N00603)
+    condition = (
+        df[DateOfInitialCPC].isna()
+        & (df[ICPCnotRequired].astype(str) == "0")
+        & (
+            (df[S47ActualStartDate] < collection_start)
+            | (df[S47ActualStartDate] > reference_date)
+        )
+    )
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error.
+    link_id = tuple(zip(df_issues[LAchildID], df_issues[S47ActualStartDate]))
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=Section47,
+        columns=[S47ActualStartDate, DateOfInitialCPC, ICPCnotRequired],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
+    )
+
+    section_47s = pd.DataFrame(
+        [
+            {  # 0 - Ignore
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/2000",
+                "DateOfInitialCPC": "26/05/2000",
+                "ICPCnotRequired": "0",
+            },
+            {  # 1 - Ignore
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/2000",
+                "DateOfInitialCPC": "26/05/2000",
+                "ICPCnotRequired": "1",
+            },
+            {  # 2 - Ignore
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/2000",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "1",
+            },
+            {  # 3 - Pass
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/2000",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "0",
+            },
+            {  # 4 - Fail
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/1999",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "0",
+            },
+            {  # 5 - Fail
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/1999",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "0",
+            },
+            {  # 6 - Ignore
+                "LAchildID": "child1",
+                "S47ActualStartDate": "26/05/1999",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "1",
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    section_47s[S47ActualStartDate] = pd.to_datetime(
+        section_47s[S47ActualStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    section_47s[DateOfInitialCPC] = pd.to_datetime(
+        section_47s[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Section47: section_47s, Header: fake_header})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    issue_columns = issues.columns
+    assert issue_columns == [S47ActualStartDate, DateOfInitialCPC, ICPCnotRequired]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 1 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 1
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4, 5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8740' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8740"
+    assert (
+        result.definition.message
+        == "For a Section 47 Enquiry that has not held the Initial Child Protection Conference by the end of the census year, the start date must fall within the census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8750.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8750.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,177 +1,177 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-LAchildID = ChildIdentifiers.LAchildID
-PersonBirthDate = ChildIdentifiers.PersonBirthDate
-ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
-GenderCurrent = ChildIdentifiers.GenderCurrent
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of 8750
-    code="8750",
-    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildIdentifiers,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Gender must equal 0 for an unborn child",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[GenderCurrent, PersonBirthDate, ExpectedPersonBirthDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Replace ChildIdentifiers with the name of the table you need.
-    df = data_container[ChildIdentifiers]
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <ExpectedPersonBirthDate> (N00098) is present and <PersonBirthDate> (N00066) is blank then <GenderCurrent> (N00065) must equal “0”
-    condition = (
-        df[PersonBirthDate].isna()
-        & df[ExpectedPersonBirthDate].notna()
-        & (df[GenderCurrent].astype(str) != "0")
-    )
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error.
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-            df_issues[GenderCurrent],
-            df_issues[ExpectedPersonBirthDate],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=ChildIdentifiers,
-        columns=[GenderCurrent, PersonBirthDate, ExpectedPersonBirthDate],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    child_identifiers = pd.DataFrame(
-        [
-            {  # 0 - Pass - Not unborn
-                "LAchildID": "child1",
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": "26/05/2000",
-                "GenderCurrent": "1",
-            },
-            {  # 1 - Pass - Not unborn
-                "LAchildID": "child2",
-                "PersonBirthDate": "26/05/2000",
-                "ExpectedPersonBirthDate": pd.NA,
-                "GenderCurrent": "2",
-            },
-            {  # 2 - Pass - Unborn with Gender = 0
-                "LAchildID": "child3",
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": "26/05/1999",
-                "GenderCurrent": "0",
-            },
-            {  # 3 - Pass - Not unborn or born! (Not relevant to this rule)
-                "LAchildID": "child3",
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": pd.NA,
-                "GenderCurrent": "2",
-            },
-            {  # 4 - Fail - Unborn with Gender = 2
-                "LAchildID": "child4",
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": "25/05/2000",
-                "GenderCurrent": "2",
-            },
-            {  # 5 - Fail - Unborn with Gender = 1
-                "LAchildID": "child4",
-                "PersonBirthDate": pd.NA,
-                "ExpectedPersonBirthDate": "25/05/2000",
-                "GenderCurrent": "1",
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    child_identifiers[PersonBirthDate] = pd.to_datetime(
-        child_identifiers[PersonBirthDate], format="%d/%m/%Y", errors="coerce"
-    )
-    child_identifiers[ExpectedPersonBirthDate] = pd.to_datetime(
-        child_identifiers[ExpectedPersonBirthDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    # get table name and check it. Replace ChildIdentifiers with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    # check that the right columns were returned.
-    issue_columns = issues.columns
-    assert issue_columns == [GenderCurrent, PersonBirthDate, ExpectedPersonBirthDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child4",
-                    "1",
-                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    "2",
-                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8750 with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8750"
-    assert result.definition.message == "Gender must equal 0 for an unborn child"
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+LAchildID = ChildIdentifiers.LAchildID
+PersonBirthDate = ChildIdentifiers.PersonBirthDate
+ExpectedPersonBirthDate = ChildIdentifiers.ExpectedPersonBirthDate
+GenderCurrent = ChildIdentifiers.GenderCurrent
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of 8750
+    code="8750",
+    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildIdentifiers,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Gender must equal 0 for an unborn child",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[GenderCurrent, PersonBirthDate, ExpectedPersonBirthDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace ChildIdentifiers with the name of the table you need.
+    df = data_container[ChildIdentifiers]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <ExpectedPersonBirthDate> (N00098) is present and <PersonBirthDate> (N00066) is blank then <GenderCurrent> (N00065) must equal “0”
+    condition = (
+        df[PersonBirthDate].isna()
+        & df[ExpectedPersonBirthDate].notna()
+        & (df[GenderCurrent].astype(str) != "0")
+    )
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error.
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID],
+            df_issues[GenderCurrent],
+            df_issues[ExpectedPersonBirthDate],
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=ChildIdentifiers,
+        columns=[GenderCurrent, PersonBirthDate, ExpectedPersonBirthDate],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_identifiers = pd.DataFrame(
+        [
+            {  # 0 - Pass - Not unborn
+                "LAchildID": "child1",
+                "PersonBirthDate": "26/05/2000",
+                "ExpectedPersonBirthDate": "26/05/2000",
+                "GenderCurrent": "1",
+            },
+            {  # 1 - Pass - Not unborn
+                "LAchildID": "child2",
+                "PersonBirthDate": "26/05/2000",
+                "ExpectedPersonBirthDate": pd.NA,
+                "GenderCurrent": "2",
+            },
+            {  # 2 - Pass - Unborn with Gender = 0
+                "LAchildID": "child3",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "26/05/1999",
+                "GenderCurrent": "0",
+            },
+            {  # 3 - Pass - Not unborn or born! (Not relevant to this rule)
+                "LAchildID": "child3",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": pd.NA,
+                "GenderCurrent": "2",
+            },
+            {  # 4 - Fail - Unborn with Gender = 2
+                "LAchildID": "child4",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "25/05/2000",
+                "GenderCurrent": "2",
+            },
+            {  # 5 - Fail - Unborn with Gender = 1
+                "LAchildID": "child4",
+                "PersonBirthDate": pd.NA,
+                "ExpectedPersonBirthDate": "25/05/2000",
+                "GenderCurrent": "1",
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    child_identifiers[PersonBirthDate] = pd.to_datetime(
+        child_identifiers[PersonBirthDate], format="%d/%m/%Y", errors="coerce"
+    )
+    child_identifiers[ExpectedPersonBirthDate] = pd.to_datetime(
+        child_identifiers[ExpectedPersonBirthDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    # get table name and check it. Replace ChildIdentifiers with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    # check that the right columns were returned.
+    issue_columns = issues.columns
+    assert issue_columns == [GenderCurrent, PersonBirthDate, ExpectedPersonBirthDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "1",
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "2",
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8750 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8750"
+    assert result.definition.message == "Gender must equal 0 for an unborn child"
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8770Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8816.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,252 +1,265 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-CINdetails = CINTable.CINdetails
-
-LAchildID = ChildIdentifiers.LAchildID
-PersonBirthDate = ChildIdentifiers.PersonBirthDate
-UPN = ChildIdentifiers.UPN
-UPNunknown = ChildIdentifiers.UPNunknown
-ReferralNFA = CINdetails.ReferralNFA
-
-# Reference date in header is needed to define the period of census.
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of 8770Q
-    code="8770Q",
-    rule_type=RuleType.QUERY,
-    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.ChildIdentifiers,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Please check and either amend data or provide a reason: UPN or reason UPN missing expected for a child who is more than 5 years old",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        UPNunknown,
-        UPNunknown,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_cid = data_container[ChildIdentifiers].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cid.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_cid.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # get collection period
-    header = data_container[Header]
-    ref_date = header[ReferenceDate].iloc[0]
-    ref_date_minus6 = ref_date - pd.DateOffset(years=6)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <ReferralNFA> (N00112) = 0 or false
-    # and <PersonBirthDate> (N00066) is earlier than [<ReferenceDate> (N00603) minus 6 years]
-    # then either <UPN> (N00001) or a valid <UPNunknown> (N00135) should be present
-
-    # get only CINdetails where ReferralNFA is 0 or false
-    df_cin = df_cin[
-        (df_cin[ReferralNFA] == "0") | (df_cin[ReferralNFA].str.lower() == "false")
-    ]
-
-    # get only ChildIdentifiers where child is old enough to need a UPN
-    df_cid = df_cid[(df_cid[PersonBirthDate] <= ref_date_minus6)]
-
-    # merge ChildIdentifiers with filtered CINdetails and take only those that match
-    df_merged = df_cid.merge(
-        df_cin[[LAchildID, ReferralNFA]],
-        on=[LAchildID],
-        how="left",
-        suffixes=["", "_cin"],
-        indicator=True,
-    )
-
-    df_merged = df_merged[df_merged["_merge"] == "both"]
-
-    # get only rows where UPN is not provided and UPNunknown is not a valid code
-    no_upn = df_merged[UPN].isna()
-
-    upnunknown_reasons = [
-        # "UN1", - excluding UN1 as "Child is not of school age" is not applicable here
-        "UN2",
-        "UN3",
-        "UN4",
-        "UN5",
-        "UN6",
-        "UN7",
-    ]
-
-    valid_upnunknown = df_merged[UPNunknown].str.upper().isin(upnunknown_reasons)
-
-    # get all the data that fits the failing condition.
-    df_merged = df_merged[no_upn & ~valid_upnunknown].reset_index()
-
-    # create an identifier for each error instance.
-    df_merged["ERROR_ID"] = tuple(zip(df_merged[LAchildID]))
-
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cid_issues = (
-        df_cid.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[UPN, UPNunknown], row_df=df_cid_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_cid = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 Ignore - under 5 years old
-                "PersonBirthDate": "26/05/2000",
-                "UPN": pd.NA,
-                "UPNunknown": pd.NA,
-            },
-            {
-                "LAchildID": "child2",  # 1 Pass - over 5 with UPN
-                "PersonBirthDate": "26/05/1990",
-                "UPN": "AAA",
-                "UPNunknown": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # 2 Pass - over 5 with valid UPNunknown
-                "PersonBirthDate": "26/05/1990",
-                "UPN": pd.NA,
-                "UPNunknown": "UN2",
-            },
-            {
-                "LAchildID": "child4",  # 3 Pass - over 5 with valid UPNunknown (lower case)
-                "PersonBirthDate": "26/05/1990",
-                "UPN": pd.NA,
-                "UPNunknown": "un5",
-            },
-            {
-                "LAchildID": "child5",  # 4 Fail - over 5 and no UPN or valid UPNunknown
-                "PersonBirthDate": "26/05/1990",
-                "UPN": pd.NA,
-                "UPNunknown": pd.NA,
-            },
-            {
-                "LAchildID": "child6",  # 5 Fail - over 5 and no UPN or valid UPNunknown (UN1 is not valid for >5yrs)
-                "PersonBirthDate": "26/05/1990",
-                "UPN": pd.NA,
-                "UPNunknown": "UN1",
-            },
-            {
-                "LAchildID": "child7",  # 6 Ignore - over 5 and no UPN or valid UPNunknown (UN8 is not valid) so should fail, BUT ReferralNFA doesn't meet requirement
-                "PersonBirthDate": "26/05/1990",
-                "UPN": pd.NA,
-                "UPNunknown": "UN8",
-            },
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {"LAchildID": "child1", "ReferralNFA": "0"},
-            {"LAchildID": "child2", "ReferralNFA": "false"},
-            {"LAchildID": "child3", "ReferralNFA": "FALSE"},
-            {"LAchildID": "child4", "ReferralNFA": "0"},
-            {"LAchildID": "child5", "ReferralNFA": "0"},
-            {"LAchildID": "child6", "ReferralNFA": "0"},
-            {"LAchildID": "child6", "ReferralNFA": "1"},
-            {"LAchildID": "child7", "ReferralNFA": "1"},
-        ]
-    )
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
-    )
-
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cid[PersonBirthDate] = pd.to_datetime(
-        sample_cid[PersonBirthDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_cid,
-            CINdetails: sample_cin_details,
-            Header: sample_header,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 1
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values.
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    issue_columns = issues.columns
-    assert issue_columns == [UPN, UPNunknown]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": ("child5",),  # ChildID
-                "ROW_ID": [4],
-            },
-            {
-                "ERROR_ID": ("child6",),  # ChildID
-                "ROW_ID": [5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8770Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8770Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: UPN or reason UPN missing expected for a child who is more than 5 years old"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+ReferralNFA = CINdetails.ReferralNFA
+CINreferralDate = CINdetails.CINreferralDate
+CINclosureDate = CINdetails.CINclosureDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here
+    code="8816",
+    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="An open CIN episode is shown and case is not a referral with no further action, but it is not the latest episode.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        CINreferralDate,
+        ReferralNFA,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_cin = data_container[CINdetails].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cin.index.name = "ROW_ID"
+
+    # If there is a <CINdetails> module present for the child where:
+    # <CINclosureDate> (N00102) is missing; and
+    # <ReferralNFA> (N00112) = false or 0
+    # then the <CINreferralDate> (N00100) for this module must be the latest of all Referral Dates for that child.
+
+    # removing nans prevents ValueError: attempt to get argmax of an empty sequence, when no CINreferralDate is present
+    df_cin = df_cin[df_cin[CINreferralDate].notna()]
+
+    # find out the latest referral date (and its index position) for each child and attach it to all the rows for that child.
+    df_cin["latest_referral"] = df_cin.groupby(LAchildID)[CINreferralDate].transform(
+        "max"
+    )
+    df_cin["latest_referral_ind"] = df_cin.groupby(LAchildID)[
+        CINreferralDate
+    ].transform("idxmax")
+
+    # resetting the index makes ROW_ID into a column to keep it intact. The logic can now begin.
+    df_cin.reset_index(inplace=True)
+
+    # filter the rows of interest
+
+    df_cin = df_cin[
+        (df_cin[CINclosureDate].isna()) & (df_cin[ReferralNFA].isin(["false", "0"]))
+    ]
+    # check those that do not meet the requirements
+    condition = df_cin["ROW_ID"] != df_cin["latest_referral_ind"]
+    df_cin = df_cin[condition]
+
+    df_cin["ERROR_ID"] = tuple(
+        zip(df_cin[LAchildID], df_cin[CINdetailsID], df_cin[CINreferralDate])
+    )
+
+    df_cin_issues = (
+        df_cin.groupby("ERROR_ID", group_keys=False)["ROW_ID"].apply(list).reset_index()
+    )
+    # the locations of the latest_referral date should also be flagged
+    df_cin_issues_cause = (
+        df_cin.groupby("ERROR_ID", group_keys=False)["latest_referral_ind"]
+        .apply(list)
+        .reset_index()
+    )
+    # rename column to fit expected structure of a df_issues dataframe
+    df_cin_issues_cause.rename(columns={"latest_referral_ind": "ROW_ID"}, inplace=True)
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=CINdetails,
+        columns=[CINreferralDate],
+        row_df=df_cin_issues,
+    )
+    rule_context.push_type_3(
+        table=CINdetails,
+        columns=[CINreferralDate],
+        row_df=df_cin_issues_cause,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": "26/10/2000",  # 0 fail: not latest referral in child1
+                "CINdetailsID": "cinID1",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child1",
+                "CINclosureDate": "26/05/2001",
+                "CINreferralDate": "26/10/2001",  # 1 ignore: CINclosureDate notna
+                "CINdetailsID": "cinID2",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child1",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": "26/10/1999",  # 2 fail: not latest referral in child1
+                "CINdetailsID": "cinID3",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child1",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": "26/10/2002",  # 3 pass: latest referral in child1
+                "CINdetailsID": "cinID4",
+                "ReferralNFA": "0",
+            },
+            # child2
+            {
+                "LAchildID": "child2",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": "26/10/1999",  # 4 pass: latest referral in child2
+                "CINdetailsID": "cinID3",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child2",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": "26/10/1990",  # 5 fail: not latest referral in child2
+                "CINdetailsID": "cinID3",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child4",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": pd.NA,
+                "CINdetailsID": "cinID3",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child4",
+                "CINclosureDate": pd.NA,
+                "CINreferralDate": pd.NA,
+                "CINdetailsID": "cinID4",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child5",
+                "CINreferralDate": "26/10/1999",
+                "CINdetailsID": "cinID4",
+                "ReferralNFA": "0",
+            },
+            {
+                "LAchildID": "child5",  # 9, Fail, shared CINreferralDate
+                "CINdetailsID": "cinID5",
+                "CINreferralDate": "26/10/1999",
+                "ReferralNFA": "0",
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cin[CINclosureDate] = pd.to_datetime(
+        sample_cin[CINclosureDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin[CINreferralDate] = pd.to_datetime(
+        sample_cin[CINreferralDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            CINdetails: sample_cin,
+        },
+    )
+
+    # Use .type3_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type3_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values.
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINreferralDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 4
+
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                    pd.to_datetime("26/10/2000", format="%d/%m/%Y"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID3",
+                    pd.to_datetime("26/10/1999", format="%d/%m/%Y"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "cinID3",
+                    pd.to_datetime("26/10/1990", format="%d/%m/%Y"),
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child5",
+                    "cinID5",
+                    pd.to_datetime("26/10/1999", format="%d/%m/%Y"),
+                ),
+                "ROW_ID": [9],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8816' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8816"
+    assert (
+        result.definition.message
+        == "An open CIN episode is shown and case is not a referral with no further action, but it is not the latest episode."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8772.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8772.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,211 +1,211 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-LAchildID = ChildIdentifiers.LAchildID
-UPNunknown = ChildIdentifiers.UPNunknown
-
-CINdetails = CINTable.CINdetails
-LAchildID = CINdetails.LAchildID
-ReferralNFA = CINdetails.ReferralNFA
-
-
-@rule_definition(
-    code="8772",
-    module=CINTable.ChildIdentifiers,
-    message="UPN unknown reason is UN7 (Referral with no further action) but at least one CIN details is a referral going on to further action",
-    affected_fields=[
-        UPNunknown,
-        ReferralNFA,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_upn = data_container[ChildIdentifiers].copy()
-    df_refs = data_container[CINdetails].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_upn.index.name = "ROW_ID"
-    df_refs.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_upn.reset_index(inplace=True)
-    df_refs.reset_index(inplace=True)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <UPNunknown> (N00135) is UN7 then all of the CIN details must have <ReferralNFA> (N00112) = 1 or true
-
-    df_merged = df_upn.merge(
-        df_refs,
-        on=["LAchildID"],
-        how="left",
-        suffixes=("_upn", "_refs"),
-    )
-
-    #  Get rows where UPNunknown is equal to 'UN7'
-    condition_1 = df_merged[UPNunknown] == "UN7"
-
-    #  Get rows where ReferralNFA is equal to either 'True' or '1'
-    trueor1 = ["true", "1"]
-    condition_2 = df_merged[ReferralNFA].str.lower().isin(trueor1)
-
-    # Combine the results of the two rows
-    df_merged = df_merged[condition_1 & ~condition_2].reset_index()
-
-    # create an identifier for each error instance.
-    df_merged["ERROR_ID"] = tuple(zip(df_merged[LAchildID], df_merged[ReferralNFA]))
-
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_upn_issues = (
-        df_upn.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_upn")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_refs_issues = (
-        df_refs.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_refs")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[UPNunknown], row_df=df_upn_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[ReferralNFA], row_df=df_refs_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_upn = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "UPNunknown": "UN6",  # Ignore: code is not UN7
-            },
-            {
-                "LAchildID": "child2",
-                "UPNunknown": "UN7",
-            },
-            {
-                "LAchildID": "child3",
-                "UPNunknown": "UN7",
-            },
-            {
-                "LAchildID": "child4",
-                "UPNunknown": "UN7",
-            },
-            {
-                "LAchildID": "child5",
-                "UPNunknown": "UN4",  # Ignore: code is not UN7
-            },
-        ]
-    )
-
-    sample_refs = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "ReferralNFA": "True",  # 0 Ignore: upn is not UN7
-            },
-            {
-                "LAchildID": "child2",
-                "ReferralNFA": "1",  # 1 Pass as Referral Code is True
-            },
-            {
-                "LAchildID": "child3",
-                "ReferralNFA": pd.NA,  # 2 Fail as Referral Code is NULL
-            },
-            {
-                "LAchildID": "child4",
-                "ReferralNFA": "nottrue",  # 3 Fail: Referral Code is neither "1" not "true"
-            },
-            {
-                "LAchildID": "child5",
-                "ReferralNFA": "True",  # 4 Ignore: upn is not UN7
-            },
-        ]
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_upn,
-            CINdetails: sample_refs,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace CINdetails with the name of your table.
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    # check that the right columns were returned. Replace ReferralNFA with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [ReferralNFA]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    pd.NA,  # ReferralNFA
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",  # ChildID
-                    "nottrue",  # ReferralNFA
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8772' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8772"
-    assert (
-        result.definition.message
-        == "UPN unknown reason is UN7 (Referral with no further action) but at least one CIN details is a referral going on to further action"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+LAchildID = ChildIdentifiers.LAchildID
+UPNunknown = ChildIdentifiers.UPNunknown
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+ReferralNFA = CINdetails.ReferralNFA
+
+
+@rule_definition(
+    code="8772",
+    module=CINTable.ChildIdentifiers,
+    message="UPN unknown reason is UN7 (Referral with no further action) but at least one CIN details is a referral going on to further action",
+    affected_fields=[
+        UPNunknown,
+        ReferralNFA,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_upn = data_container[ChildIdentifiers].copy()
+    df_refs = data_container[CINdetails].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_upn.index.name = "ROW_ID"
+    df_refs.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_upn.reset_index(inplace=True)
+    df_refs.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <UPNunknown> (N00135) is UN7 then all of the CIN details must have <ReferralNFA> (N00112) = 1 or true
+
+    df_merged = df_upn.merge(
+        df_refs,
+        on=["LAchildID"],
+        how="left",
+        suffixes=("_upn", "_refs"),
+    )
+
+    #  Get rows where UPNunknown is equal to 'UN7'
+    condition_1 = df_merged[UPNunknown] == "UN7"
+
+    #  Get rows where ReferralNFA is equal to either 'True' or '1'
+    trueor1 = ["true", "1"]
+    condition_2 = df_merged[ReferralNFA].str.lower().isin(trueor1)
+
+    # Combine the results of the two rows
+    df_merged = df_merged[condition_1 & ~condition_2].reset_index()
+
+    # create an identifier for each error instance.
+    df_merged["ERROR_ID"] = tuple(zip(df_merged[LAchildID], df_merged[ReferralNFA]))
+
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_upn_issues = (
+        df_upn.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_upn")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_refs_issues = (
+        df_refs.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_refs")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=ChildIdentifiers, columns=[UPNunknown], row_df=df_upn_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReferralNFA], row_df=df_refs_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_upn = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "UPNunknown": "UN6",  # Ignore: code is not UN7
+            },
+            {
+                "LAchildID": "child2",
+                "UPNunknown": "UN7",
+            },
+            {
+                "LAchildID": "child3",
+                "UPNunknown": "UN7",
+            },
+            {
+                "LAchildID": "child4",
+                "UPNunknown": "UN7",
+            },
+            {
+                "LAchildID": "child5",
+                "UPNunknown": "UN4",  # Ignore: code is not UN7
+            },
+        ]
+    )
+
+    sample_refs = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "ReferralNFA": "True",  # 0 Ignore: upn is not UN7
+            },
+            {
+                "LAchildID": "child2",
+                "ReferralNFA": "1",  # 1 Pass as Referral Code is True
+            },
+            {
+                "LAchildID": "child3",
+                "ReferralNFA": pd.NA,  # 2 Fail as Referral Code is NULL
+            },
+            {
+                "LAchildID": "child4",
+                "ReferralNFA": "nottrue",  # 3 Fail: Referral Code is neither "1" not "true"
+            },
+            {
+                "LAchildID": "child5",
+                "ReferralNFA": "True",  # 4 Ignore: upn is not UN7
+            },
+        ]
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            ChildIdentifiers: sample_upn,
+            CINdetails: sample_refs,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace CINdetails with the name of your table.
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    # check that the right columns were returned. Replace ReferralNFA with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [ReferralNFA]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    pd.NA,  # ReferralNFA
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",  # ChildID
+                    "nottrue",  # ReferralNFA
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8772' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8772"
+    assert (
+        result.definition.message
+        == "UPN unknown reason is UN7 (Referral with no further action) but at least one CIN details is a referral going on to further action"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8775Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8825Q.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,231 +1,222 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-CINdetails = CINTable.CINdetails
-LAchildID = ChildIdentifiers.LAchildID
-
-
-PersonBirthDate = ChildIdentifiers.PersonBirthDate
-CINclosureDate = CINdetails.CINclosureDate
-
-# Reference date in header is needed to define the period of census.
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of 8775Q
-    code="8775Q",
-    rule_type=RuleType.QUERY,
-    # replace ChildIdentifiers with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.ChildIdentifiers,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Please check and either amend data or provide a reason: Child is over 25 years old",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        PersonBirthDate,
-        CINclosureDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_ci = data_container[ChildIdentifiers].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_ci.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_ci.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # get collection period
-    df_ref = data_container[Header]
-    ref_date = df_ref[ReferenceDate].iloc[0]
-
-    # lOGIC
-    # <PersonBirthDate> (N00066) is before (<ReferenceDate> (N00603) minus 25 years) AND
-    # {<CINClosureDate> (N00102) is after (<PersonBirthDate> plus 25 years) OR <CINClosureDate> is NULL}
-    over_25 = df_ci[PersonBirthDate] < (ref_date - pd.DateOffset(years=25))
-    df_ci = df_ci[over_25]
-
-    merged_df = df_ci.merge(
-        df_cin,
-        on=[
-            LAchildID,
-        ],
-        suffixes=["_ci", "_cin"],
-    )
-
-    condition = (
-        (
-            merged_df["CINclosureDate"]
-            > (merged_df[PersonBirthDate] + pd.DateOffset(years=25))
-        )
-        | (merged_df["CINclosureDate"].isna())
-        | (merged_df["CINclosureDate"] == "NULL")
-    )
-
-    merged_df = merged_df[condition].reset_index()
-
-    # create an identifier for each error instance.
-    merged_df["ERROR_ID"] = tuple(zip(merged_df[LAchildID], merged_df[PersonBirthDate]))
-
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_ci_issues = (
-        df_ci.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ci")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonBirthDate], row_df=df_ci_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINclosureDate], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_ci = pd.DataFrame(
-        [
-            {"LAchildID": "child1", "PersonBirthDate": "01/01/1880"},
-            {"LAchildID": "child2", "PersonBirthDate": "01/01/1880"},
-            {
-                "LAchildID": "child3",
-                "PersonBirthDate": "01/01/2000",
-            },  # ignore: not 25 years before refdate
-            {
-                "LAchildID": "child4",
-                "PersonBirthDate": "01/01/1800",
-            },  # ignore: CINclosureDate not up to 25years after birthdate
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {  # 0 fail
-                "LAchildID": "child1",
-                "CINclosureDate": "01/01/2000",
-            },
-            {  # 1 fail
-                "LAchildID": "child2",
-                "CINclosureDate": "NULL",
-            },
-            {  # 2 pass
-                "LAchildID": "child2",
-                "CINclosureDate": "26/10/1890",
-            },
-            {  # 3 pass
-                "LAchildID": "child3",
-                "CINclosureDate": "26/10/1999",
-            },
-            {  # 4 pass
-                "LAchildID": "child4",
-                "CINclosureDate": "26/10/1804",
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_ci["PersonBirthDate"] = pd.to_datetime(
-        sample_ci["PersonBirthDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin_details["CINclosureDate"] = pd.to_datetime(
-        sample_cin_details["CINclosureDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header = pd.DataFrame(
-        [
-            {
-                ReferenceDate: pd.to_datetime(
-                    "31/03/2001", format="%d/%m/%Y", errors="coerce"
-                )
-            }
-        ]  # the census start date here will be 01/04/2000
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildIdentifiers: sample_ci,
-            CINdetails: sample_cin_details,
-            Header: sample_header,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Section47 with the name of your table.
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINclosureDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    pd.to_datetime("01/01/1880", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    pd.to_datetime("01/01/1880", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8775Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8775Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: Child is over 25 years old"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+Assessments = CINTable.Assessments
+
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+ReasonForClosure = CINdetails.ReasonForClosure
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of 2885
+    code="8825Q",
+    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.CINdetails,
+    rule_type=RuleType.QUERY,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Please check and either amend data or provide a reason: Reason for Closure code RC8 (case closed after assessment) or RC9 (case closed after assessment, referred to early help) has been returned but there is no assessment present for the episode.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        ReasonForClosure,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_ass = data_container[Assessments]
+    df_cin = data_container[CINdetails]
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_ass.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_ass.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # lOGIC
+    # If <ReasonforClosure> (N00103) = RC8 or RC9 then at least one <Assessments> module must be present
+
+    df_cin_check = df_cin.copy()
+
+    df_cin_check = df_cin_check[df_cin_check[ReasonForClosure].isin(["RC8", "RC9"])]
+
+    merged_df = df_cin_check.merge(
+        df_ass,
+        on=[LAchildID, CINdetailsID],
+        suffixes=["_cin", "_ass"],
+        how="left",
+        indicator=True,
+    )
+    # get modules whose ReasonForClosure is RC8/RC9 but are not found in the assessment table.
+    condition = merged_df["_merge"] == "left_only"
+    merged_df = merged_df[condition].reset_index()
+
+    # create an identifier for each error instance.
+    merged_df["ERROR_ID"] = tuple(zip(merged_df[LAchildID], merged_df[CINdetailsID]))
+
+    # The merges were done on copies of df_ass and df_cin so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_ass_issues = (
+        df_ass.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=Assessments, columns=[CINdetailsID], row_df=df_ass_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReasonForClosure], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_ass = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child7",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID4",
+            },
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "cinID1",
+            },
+        ]
+    )
+    sample_cin_details = pd.DataFrame(
+        [
+            {  # 0 pass
+                "LAchildID": "child1",
+                "ReasonForClosure": pd.NA,  # 0 ignore
+                "CINdetailsID": "cinID1",
+            },
+            {  # 1 ignore
+                "LAchildID": "child1",
+                "ReasonForClosure": "EX7",  # 1 ignore
+                "CINdetailsID": "cinID2",
+            },
+            {  # 2
+                "LAchildID": "child2",
+                "ReasonForClosure": "EX7",  # 2 ignore
+                "CINdetailsID": "cinID1",
+            },
+            {  # 3
+                "LAchildID": "child3",
+                "ReasonForClosure": "RC8",  # 3 pass. present in assessment table
+                "CINdetailsID": "cinID1",
+            },
+            {  # 4 ignore
+                "LAchildID": "child3",
+                "ReasonForClosure": "EX7",  # 4 ignore
+                "CINdetailsID": "cinID2",
+            },
+            {  # 5 pass
+                "LAchildID": "child3",
+                "ReasonForClosure": "RC9",  # 5 pass. present in assessment table
+                "CINdetailsID": "cinID3",
+            },
+            {  # 6 fail
+                "LAchildID": "child4",
+                "ReasonForClosure": "RC8",  # 6 fail: no assessment recorded.
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            Assessments: sample_ass,
+            CINdetails: sample_cin_details,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the CINdetails columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace CINdetails with the name of your table.
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    # check that the right columns were returned. Replace ReasonForClosure with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [ReasonForClosure]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 1 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 1
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "cinID4",
+                ),
+                "ROW_ID": [6],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8825Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8825Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: Reason for Closure code RC8 (case closed after assessment) or RC9 (case closed after assessment, referred to early help) has been returned but there is no assessment present for the episode."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8790.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8790.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,72 +1,72 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-Disabilities = CINTable.Disabilities
-Disability = Disabilities.Disability
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8790",
-    module=CINTable.Disabilities,
-    message="Disability information includes both None and other values",
-    affected_fields=[Disability],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Disabilities]
-    """
-    If a <Disability> (N00099) value of NONE is present, then there should be 
-    no other <Disability> (N00099) values present for the same child
-    """
-
-    df.reset_index(inplace=True)
-    df_orig = df.copy()
-    # Form df containing only the NONE disability values
-    df = df[df["Disability"].str.upper() == "NONE"]
-
-    # Join back to the original dataframe via LAchildID
-    df = df.merge(df_orig, how="left", on="LAchildID", suffixes=["", "_orig"])
-
-    # Any disability values that aren't NONE in the merged table are now an error.
-    df = df[df["Disability_orig"].str.upper() != "NONE"]
-
-    # Return original index for the error rows
-    failing_indices = df.set_index("index_orig").index
-
-    rule_context.push_issue(table=Disabilities, field=Disability, row=failing_indices)
-
-
-def test_validate():
-    # 0      #1      #2      #3     #4      #5      #6      #7
-    ids = ["1", "1", "2", "3", "3", "4", "4", "5"]
-    dis_is = ["NONE", "AIND", "NONE", pd.NA, "MOTH", "NONE", "AAAA", "AA"]
-
-    fake_dataframe = pd.DataFrame({"LAchildID": ids, "Disability": dis_is})
-
-    result = run_rule(validate, {Disabilities: fake_dataframe})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 2
-
-    assert issues == [
-        IssueLocator(CINTable.Disabilities, Disability, 1),
-        IssueLocator(CINTable.Disabilities, Disability, 6),
-    ]
-
-    assert result.definition.code == "8790"
-    assert (
-        result.definition.message
-        == "Disability information includes both None and other values"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+Disabilities = CINTable.Disabilities
+Disability = Disabilities.Disability
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8790",
+    module=CINTable.Disabilities,
+    message="Disability information includes both None and other values",
+    affected_fields=[Disability],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Disabilities]
+    """
+    If a <Disability> (N00099) value of NONE is present, then there should be 
+    no other <Disability> (N00099) values present for the same child
+    """
+
+    df.reset_index(inplace=True)
+    df_orig = df.copy()
+    # Form df containing only the NONE disability values
+    df = df[df["Disability"].str.upper() == "NONE"]
+
+    # Join back to the original dataframe via LAchildID
+    df = df.merge(df_orig, how="left", on="LAchildID", suffixes=["", "_orig"])
+
+    # Any disability values that aren't NONE in the merged table are now an error.
+    df = df[df["Disability_orig"].str.upper() != "NONE"]
+
+    # Return original index for the error rows
+    failing_indices = df.set_index("index_orig").index
+
+    rule_context.push_issue(table=Disabilities, field=Disability, row=failing_indices)
+
+
+def test_validate():
+    # 0      #1      #2      #3     #4      #5      #6      #7
+    ids = ["1", "1", "2", "3", "3", "4", "4", "5"]
+    dis_is = ["NONE", "AIND", "NONE", pd.NA, "MOTH", "NONE", "AAAA", "AA"]
+
+    fake_dataframe = pd.DataFrame({"LAchildID": ids, "Disability": dis_is})
+
+    result = run_rule(validate, {Disabilities: fake_dataframe})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 2
+
+    assert issues == [
+        IssueLocator(CINTable.Disabilities, Disability, 1),
+        IssueLocator(CINTable.Disabilities, Disability, 6),
+    ]
+
+    assert result.definition.code == "8790"
+    assert (
+        result.definition.message
+        == "Disability information includes both None and other values"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8805.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8805.py`

 * *Ordering differences only*

 * *Files 20% similar despite different names*

```diff
@@ -1,161 +1,161 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINDetails = CINTable.CINdetails
-CINclosureDate = CINDetails.CINclosureDate
-ReasonForClosure = CINDetails.ReasonForClosure
-LAchildID = CINDetails.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8805'
-    code="8805",
-    module=CINTable.CINdetails,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="A CIN case cannot have a CIN closure date without a Reason for Closure",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[CINclosureDate, ReasonForClosure],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df = data_container[CINDetails]
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <CINclosureDate> (N00102) is present then <ReasonForClosure> (N00103) must also be present
-    # return rows where CINClosureDate is present but ReasonForClosure is not.
-    # If CINclosureDate is not null and ReasonForClosure is null
-    condition = df[CINclosureDate].notna() & df[ReasonForClosure].isna()
-
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID], df_issues[CINclosureDate], df_issues[ReasonForClosure]
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=CINDetails, columns=[CINclosureDate, ReasonForClosure], row_df=df_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_date_frame = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINclosureDate": "26/05/2000",
-                "ReasonForClosure": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",
-                "CINclosureDate": pd.NA,
-                "ReasonForClosure": "26/05/2000",
-            },
-            {
-                "LAchildID": "child3",
-                "CINclosureDate": "26/05/1999",
-                "ReasonForClosure": "26/05/2000",
-            },
-            {
-                "LAchildID": "child3",
-                "CINclosureDate": "26/05/2000",
-                "ReasonForClosure": pd.NA,
-            },  # fail because CINClosureDate is populated and ReasonForClosure isn't
-            {
-                "LAchildID": "child4",
-                "CINclosureDate": "25/05/2000",
-                "ReasonForClosure": pd.NA,
-            },  # fail because CINClosureDate is populated and ReasonForClosure isn't
-            {
-                "LAchildID": "child5",
-                "CINclosureDate": pd.NA,
-                "ReasonForClosure": pd.NA,
-            },
-        ]
-    )
-
-    # Date values not checked so no datetime conversion required
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {CINDetails: fake_date_frame})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    # get table name and check it.
-    issue_table = issues.table
-    assert issue_table == CINDetails
-
-    # check that the right columns were returned.
-    issue_columns = issues.columns
-    assert issue_columns == [CINclosureDate, ReasonForClosure]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "26/05/2000",
-                    pd.NA,
-                ),
-                "ROW_ID": [3],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    "25/05/2000",
-                    pd.NA,
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8805' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8805"
-    assert (
-        result.definition.message
-        == "A CIN case cannot have a CIN closure date without a Reason for Closure"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINDetails = CINTable.CINdetails
+CINclosureDate = CINDetails.CINclosureDate
+ReasonForClosure = CINDetails.ReasonForClosure
+LAchildID = CINDetails.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8805'
+    code="8805",
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="A CIN case cannot have a CIN closure date without a Reason for Closure",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[CINclosureDate, ReasonForClosure],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df = data_container[CINDetails]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <CINclosureDate> (N00102) is present then <ReasonForClosure> (N00103) must also be present
+    # return rows where CINClosureDate is present but ReasonForClosure is not.
+    # If CINclosureDate is not null and ReasonForClosure is null
+    condition = df[CINclosureDate].notna() & df[ReasonForClosure].isna()
+
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID], df_issues[CINclosureDate], df_issues[ReasonForClosure]
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=CINDetails, columns=[CINclosureDate, ReasonForClosure], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_date_frame = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINclosureDate": "26/05/2000",
+                "ReasonForClosure": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "CINclosureDate": pd.NA,
+                "ReasonForClosure": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",
+                "CINclosureDate": "26/05/1999",
+                "ReasonForClosure": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",
+                "CINclosureDate": "26/05/2000",
+                "ReasonForClosure": pd.NA,
+            },  # fail because CINClosureDate is populated and ReasonForClosure isn't
+            {
+                "LAchildID": "child4",
+                "CINclosureDate": "25/05/2000",
+                "ReasonForClosure": pd.NA,
+            },  # fail because CINClosureDate is populated and ReasonForClosure isn't
+            {
+                "LAchildID": "child5",
+                "CINclosureDate": pd.NA,
+                "ReasonForClosure": pd.NA,
+            },
+        ]
+    )
+
+    # Date values not checked so no datetime conversion required
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {CINDetails: fake_date_frame})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    # get table name and check it.
+    issue_table = issues.table
+    assert issue_table == CINDetails
+
+    # check that the right columns were returned.
+    issue_columns = issues.columns
+    assert issue_columns == [CINclosureDate, ReasonForClosure]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "26/05/2000",
+                    pd.NA,
+                ),
+                "ROW_ID": [3],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "25/05/2000",
+                    pd.NA,
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8805' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8805"
+    assert (
+        result.definition.message
+        == "A CIN case cannot have a CIN closure date without a Reason for Closure"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8831.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8831.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,361 +1,361 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINdetails = CINTable.CINdetails
-Section47 = CINTable.Section47
-Assessments = CINTable.Assessments
-
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-S47ActualStartDate = Section47.S47ActualStartDate
-ReferralNFA = CINdetails.ReferralNFA
-DateOfInitialCPC = CINdetails.DateOfInitialCPC
-
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8831'
-    code="8831",
-    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.CINdetails,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Activity is recorded against a case marked as a referral with no further action",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        AssessmentActualStartDate,
-        AssessmentAuthorisationDate,
-        S47ActualStartDate,
-        DateOfInitialCPC,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_ass = data_container[Assessments].copy()
-    df_47 = data_container[Section47].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_47.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-    df_ass.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_47.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-    df_ass.reset_index(inplace=True)
-
-    # If a <CINdetails> module has <ReferralNFA> (N00112) = true or 1, then it cannot have any of the following:
-    # <AssessmentActualStartDate> (N00159)
-    # <AssessmentAuthorisationDate> (N00160)
-    # <S47ActualStartDate> (N00148)
-    # <DateOfInitialCPC> (N00110)
-
-    df_cin = df_cin[df_cin[ReferralNFA].isin(["true", "1"])]
-
-    # Check columns in Section47 table
-    df_cin_47 = df_cin.merge(
-        df_47,
-        on=[
-            "LAchildID",
-            "CINdetailsID",
-        ],
-        how="left",
-        suffixes=["_cin", "_47"],
-    )
-
-    # filter out rows that have an S47ActualStartDate or DateOfInitialCPC from the CINdetails module
-    condition_1 = (
-        df_cin_47["DateOfInitialCPC_cin"].notna()
-        | df_cin_47[S47ActualStartDate].notna()
-    )
-    df_cin_47 = df_cin_47[condition_1]
-
-    df_cin_47["ERROR_ID"] = tuple(zip(df_cin_47[LAchildID], df_cin_47[CINdetailsID]))
-
-    df_47_issues = (
-        df_47.merge(df_cin_47, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    cin_issues_47 = (
-        df_cin.merge(df_cin_47, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Check columns in Assessments table
-    df_cin_ass = df_cin.merge(
-        df_ass,
-        on=["LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=["_cin", "_ass"],
-    )
-    # filter out rows that have an AssessmentActualStartDate or AssessmentAuthorisationDate
-    condition_2 = df_cin_ass[AssessmentActualStartDate].notna()
-    condition_3 = df_cin_ass[AssessmentAuthorisationDate].notna()
-    df_cin_ass = df_cin_ass[condition_2 | condition_3]
-    df_cin_ass["ERROR_ID"] = tuple(zip(df_cin_ass[LAchildID], df_cin_ass[CINdetailsID]))
-    df_ass_issues = (
-        df_ass.merge(df_cin_ass, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    cin_issues_ass = (
-        df_cin.merge(df_cin_ass, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_cin_issues = pd.concat([cin_issues_47, cin_issues_ass])
-    # in case a value was flagged in both table combinations, it'll exist twice so deduplicate df_cin_issues
-    df_cin_issues.drop_duplicates("ERROR_ID")
-    df_cin_issues.reset_index(inplace=True, drop=True)
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=CINdetails, columns=[DateOfInitialCPC], row_df=df_cin_issues
-    )
-    rule_context.push_type_2(
-        table=Assessments, columns=[LAchildID], row_df=df_ass_issues
-    )
-    rule_context.push_type_2(table=Section47, columns=[LAchildID], row_df=df_47_issues)
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_section47 = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child2",  # fails for having a module
-                "CINdetailsID": "cinID2",
-                "DateOfInitialCPC": pd.NA,
-                "S47ActualStartDate": "01/01/2000",
-            },
-            {
-                "LAchildID": "child2",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-    sample_cin_details = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 fail: has AssessmentAuthorisationDate
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID1",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child2",  # 1 fail: has S47ActualStartDate
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID2",
-                "ReferralNFA": "true",
-            },
-            {
-                "LAchildID": "child3",  # 2 fail: has AssessmentActualStartDate
-                "DateOfInitialCPC": pd.NA,
-                "CINdetailsID": "cinID3",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child4",
-                "DateOfInitialCPC": "28/05/2000",  # 3 fails for having initial cpc
-                "CINdetailsID": "cinID4",
-                "ReferralNFA": "true",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",
-                "CINdetailsID": "cinID2",
-                "ReferralNFA": "false",  # 4 ignore
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2003",
-                "CINdetailsID": "cinID8",
-                "ReferralNFA": "false",  # 5 ignore
-            },
-            {  # 6 pass
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "14/03/2001",
-                "CINdetailsID": "cinID4",
-                "ReferralNFA": "false",  # 6 ignore
-            },
-        ]
-    )
-    sample_ass = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # fails for having a module
-                "CINdetailsID": "cinID1",
-                "AssessmentAuthorisationDate": "01/01/2000",
-                "AssessmentActualStartDate": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # fails for having a module
-                "CINdetailsID": "cinID3",
-                "AssessmentAuthorisationDate": "01/01/2000",
-                "AssessmentActualStartDate": "01/01/2000",
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID2",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": pd.NA,
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID3",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": pd.NA,
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID4",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentActualStartDate": pd.NA,
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-
-    sample_cin_details["DateOfInitialCPC"] = pd.to_datetime(
-        sample_cin_details["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
-        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_section47["S47ActualStartDate"] = pd.to_datetime(
-        sample_section47["S47ActualStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_ass["AssessmentAuthorisationDate"] = pd.to_datetime(
-        sample_ass["AssessmentAuthorisationDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_ass["AssessmentActualStartDate"] = pd.to_datetime(
-        sample_ass["AssessmentActualStartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            Section47: sample_section47,
-            CINdetails: sample_cin_details,
-            Assessments: sample_ass,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 3
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 0 will contain the CINdetails columns because that's the first thing pushed above.
-    issues = issues_list[0]
-
-    # get table name and check it. Replace Section47 with the name of your table.
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [DateOfInitialCPC]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 4 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 4
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    "cinID2",  # CINdetailsID
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",  # ChildID
-                    "cinID4",  # CINdetailsID
-                ),
-                "ROW_ID": [3],
-            },
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "cinID1",  # CINdetailsID
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID3",  # CINdetailsID
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8831' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8831"
-    assert (
-        result.definition.message
-        == "Activity is recorded against a case marked as a referral with no further action"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+Section47 = CINTable.Section47
+Assessments = CINTable.Assessments
+
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+S47ActualStartDate = Section47.S47ActualStartDate
+ReferralNFA = CINdetails.ReferralNFA
+DateOfInitialCPC = CINdetails.DateOfInitialCPC
+
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8831'
+    code="8831",
+    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Activity is recorded against a case marked as a referral with no further action",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        AssessmentActualStartDate,
+        AssessmentAuthorisationDate,
+        S47ActualStartDate,
+        DateOfInitialCPC,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_ass = data_container[Assessments].copy()
+    df_47 = data_container[Section47].copy()
+    df_cin = data_container[CINdetails].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_47.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+    df_ass.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_47.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+    df_ass.reset_index(inplace=True)
+
+    # If a <CINdetails> module has <ReferralNFA> (N00112) = true or 1, then it cannot have any of the following:
+    # <AssessmentActualStartDate> (N00159)
+    # <AssessmentAuthorisationDate> (N00160)
+    # <S47ActualStartDate> (N00148)
+    # <DateOfInitialCPC> (N00110)
+
+    df_cin = df_cin[df_cin[ReferralNFA].isin(["true", "1"])]
+
+    # Check columns in Section47 table
+    df_cin_47 = df_cin.merge(
+        df_47,
+        on=[
+            "LAchildID",
+            "CINdetailsID",
+        ],
+        how="left",
+        suffixes=["_cin", "_47"],
+    )
+
+    # filter out rows that have an S47ActualStartDate or DateOfInitialCPC from the CINdetails module
+    condition_1 = (
+        df_cin_47["DateOfInitialCPC_cin"].notna()
+        | df_cin_47[S47ActualStartDate].notna()
+    )
+    df_cin_47 = df_cin_47[condition_1]
+
+    df_cin_47["ERROR_ID"] = tuple(zip(df_cin_47[LAchildID], df_cin_47[CINdetailsID]))
+
+    df_47_issues = (
+        df_47.merge(df_cin_47, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    cin_issues_47 = (
+        df_cin.merge(df_cin_47, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Check columns in Assessments table
+    df_cin_ass = df_cin.merge(
+        df_ass,
+        on=["LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=["_cin", "_ass"],
+    )
+    # filter out rows that have an AssessmentActualStartDate or AssessmentAuthorisationDate
+    condition_2 = df_cin_ass[AssessmentActualStartDate].notna()
+    condition_3 = df_cin_ass[AssessmentAuthorisationDate].notna()
+    df_cin_ass = df_cin_ass[condition_2 | condition_3]
+    df_cin_ass["ERROR_ID"] = tuple(zip(df_cin_ass[LAchildID], df_cin_ass[CINdetailsID]))
+    df_ass_issues = (
+        df_ass.merge(df_cin_ass, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    cin_issues_ass = (
+        df_cin.merge(df_cin_ass, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_cin_issues = pd.concat([cin_issues_47, cin_issues_ass])
+    # in case a value was flagged in both table combinations, it'll exist twice so deduplicate df_cin_issues
+    df_cin_issues.drop_duplicates("ERROR_ID")
+    df_cin_issues.reset_index(inplace=True, drop=True)
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=CINdetails, columns=[DateOfInitialCPC], row_df=df_cin_issues
+    )
+    rule_context.push_type_2(
+        table=Assessments, columns=[LAchildID], row_df=df_ass_issues
+    )
+    rule_context.push_type_2(table=Section47, columns=[LAchildID], row_df=df_47_issues)
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_section47 = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child2",  # fails for having a module
+                "CINdetailsID": "cinID2",
+                "DateOfInitialCPC": pd.NA,
+                "S47ActualStartDate": "01/01/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+    sample_cin_details = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # 0 fail: has AssessmentAuthorisationDate
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID1",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child2",  # 1 fail: has S47ActualStartDate
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID2",
+                "ReferralNFA": "true",
+            },
+            {
+                "LAchildID": "child3",  # 2 fail: has AssessmentActualStartDate
+                "DateOfInitialCPC": pd.NA,
+                "CINdetailsID": "cinID3",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child4",
+                "DateOfInitialCPC": "28/05/2000",  # 3 fails for having initial cpc
+                "CINdetailsID": "cinID4",
+                "ReferralNFA": "true",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",
+                "CINdetailsID": "cinID2",
+                "ReferralNFA": "false",  # 4 ignore
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2003",
+                "CINdetailsID": "cinID8",
+                "ReferralNFA": "false",  # 5 ignore
+            },
+            {  # 6 pass
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "14/03/2001",
+                "CINdetailsID": "cinID4",
+                "ReferralNFA": "false",  # 6 ignore
+            },
+        ]
+    )
+    sample_ass = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # fails for having a module
+                "CINdetailsID": "cinID1",
+                "AssessmentAuthorisationDate": "01/01/2000",
+                "AssessmentActualStartDate": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # fails for having a module
+                "CINdetailsID": "cinID3",
+                "AssessmentAuthorisationDate": "01/01/2000",
+                "AssessmentActualStartDate": "01/01/2000",
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID2",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentActualStartDate": pd.NA,
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID3",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentActualStartDate": pd.NA,
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID4",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentActualStartDate": pd.NA,
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+
+    sample_cin_details["DateOfInitialCPC"] = pd.to_datetime(
+        sample_cin_details["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
+        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_section47["S47ActualStartDate"] = pd.to_datetime(
+        sample_section47["S47ActualStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_ass["AssessmentAuthorisationDate"] = pd.to_datetime(
+        sample_ass["AssessmentAuthorisationDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_ass["AssessmentActualStartDate"] = pd.to_datetime(
+        sample_ass["AssessmentActualStartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            Section47: sample_section47,
+            CINdetails: sample_cin_details,
+            Assessments: sample_ass,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 3
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 0 will contain the CINdetails columns because that's the first thing pushed above.
+    issues = issues_list[0]
+
+    # get table name and check it. Replace Section47 with the name of your table.
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [DateOfInitialCPC]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 4 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 4
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    "cinID2",  # CINdetailsID
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",  # ChildID
+                    "cinID4",  # CINdetailsID
+                ),
+                "ROW_ID": [3],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "cinID1",  # CINdetailsID
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID3",  # CINdetailsID
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8831' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8831"
+    assert (
+        result.definition.message
+        == "Activity is recorded against a case marked as a referral with no further action"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8832.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8832.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,223 +1,223 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LAchildID_cpp = ChildProtectionPlans.LAchildID
-CINdetailsID_cpp = ChildProtectionPlans.CINdetailsID
-
-CINdetails = CINTable.CINdetails
-ReferralNFA = CINdetails.ReferralNFA
-LAchildID_details = CINdetails.LAchildID
-CINdetailsID_details = CINdetails.CINdetailsID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here
-    code="8832",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child Protection details provided for a referral with no further action.",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        CINdetailsID_cpp,
-        ReferralNFA,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Replace ChildProtectionPlans with the name of the table you need.
-    df_cpp = data_container[ChildProtectionPlans]
-    df_CINdetails = data_container[CINdetails]
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cpp.index.name = "ROW_ID"
-    df_CINdetails.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_cpp.reset_index(inplace=True)
-    df_CINdetails.reset_index(inplace=True)
-
-    # If a <CINdetails> module has <ReferralNFA> (N00112) = true or 1, then there should be no Child Protection module present
-
-    # Excluding rows with false or 0 <ReferralNFA> to fix bug where they were flagged as failing
-    # TODO remove this step when proven to be redundant.
-    df_CINdetails = df_CINdetails[
-        ~(df_CINdetails[ReferralNFA].str.lower() == "false")
-        | ~(df_CINdetails[ReferralNFA].astype(str) == "0")
-    ]
-
-    df_CINdetails = df_CINdetails[
-        (df_CINdetails[ReferralNFA].str.lower() == "true")
-        | (df_CINdetails[ReferralNFA].astype(str) == "1")
-    ]
-
-    #  Merge tables to get corresponding CP plan group and reviews
-    df_merged = df_CINdetails.merge(
-        df_cpp,
-        on=["LAchildID", "CINdetailsID"],
-        how="inner",
-        suffixes=("_cpp", "_cin"),
-    )
-    # any rows found in df_merged are ones where <ReferralNFA> (N00112) = true or 1 and yet the child existed in the CINdetails table.
-    df_merged = df_merged.reset_index()
-
-    # create an identifier for each error instance.
-    # In this case, the rule is checked for each CPPstartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
-    # So, a combination of LAchildID, CPPstartDate and CPPreviewDate identifies and error instance.
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged["LAchildID"],
-            df_merged["CINdetailsID"],
-        )
-    )
-
-    # The merges were done on copies of cpp_df and reviews_df so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cpp_issues = (
-        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_CINdetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[LAchildID_cpp], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[ReferralNFA], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID1",
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID2",
-            },
-            # {
-            #     "LAchildID": "child3",
-            #     "CINdetailsID": "CDID6",
-            # },
-            {
-                "LAchildID": "child4",  # ignored
-                "CINdetailsID": "CDID0",
-            },
-            {
-                "LAchildID": "child5",  # ignored, ReferralNFA is neither "1" nor "true"
-                "CINdetailsID": "CDID0",
-            },
-        ]
-    )
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Fail, module present
-                "CINdetailsID": "CDID1",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child1",  # Pass, no referralNFA
-                "CINdetailsID": "CDID2",
-                "ReferralNFA": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # Pass, no module
-                "CINdetailsID": "CDID6",
-                "ReferralNFA": "1",
-            },
-            {
-                "LAchildID": "child4",  # ignored, ReferralNFA is neither "1" nor "true"
-                "CINdetailsID": "CDID0",
-                "ReferralNFA": "false",
-            },
-            {
-                "LAchildID": "child5",  # ignored, ReferralNFA is neither "1" nor "true"
-                "CINdetailsID": "CDID0",
-                "ReferralNFA": 0,
-            },
-        ]
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            CINdetails: sample_cin,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the CINdetails columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [ReferralNFA]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 1 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 1
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "CDID1",
-                ),
-                "ROW_ID": [0],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8832' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8832"
-    assert (
-        result.definition.message
-        == "Child Protection details provided for a referral with no further action."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+LAchildID_cpp = ChildProtectionPlans.LAchildID
+CINdetailsID_cpp = ChildProtectionPlans.CINdetailsID
+
+CINdetails = CINTable.CINdetails
+ReferralNFA = CINdetails.ReferralNFA
+LAchildID_details = CINdetails.LAchildID
+CINdetailsID_details = CINdetails.CINdetailsID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here
+    code="8832",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child Protection details provided for a referral with no further action.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        CINdetailsID_cpp,
+        ReferralNFA,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace ChildProtectionPlans with the name of the table you need.
+    df_cpp = data_container[ChildProtectionPlans]
+    df_CINdetails = data_container[CINdetails]
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cpp.index.name = "ROW_ID"
+    df_CINdetails.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_cpp.reset_index(inplace=True)
+    df_CINdetails.reset_index(inplace=True)
+
+    # If a <CINdetails> module has <ReferralNFA> (N00112) = true or 1, then there should be no Child Protection module present
+
+    # Excluding rows with false or 0 <ReferralNFA> to fix bug where they were flagged as failing
+    # TODO remove this step when proven to be redundant.
+    df_CINdetails = df_CINdetails[
+        ~(df_CINdetails[ReferralNFA].str.lower() == "false")
+        | ~(df_CINdetails[ReferralNFA].astype(str) == "0")
+    ]
+
+    df_CINdetails = df_CINdetails[
+        (df_CINdetails[ReferralNFA].str.lower() == "true")
+        | (df_CINdetails[ReferralNFA].astype(str) == "1")
+    ]
+
+    #  Merge tables to get corresponding CP plan group and reviews
+    df_merged = df_CINdetails.merge(
+        df_cpp,
+        on=["LAchildID", "CINdetailsID"],
+        how="inner",
+        suffixes=("_cpp", "_cin"),
+    )
+    # any rows found in df_merged are ones where <ReferralNFA> (N00112) = true or 1 and yet the child existed in the CINdetails table.
+    df_merged = df_merged.reset_index()
+
+    # create an identifier for each error instance.
+    # In this case, the rule is checked for each CPPstartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
+    # So, a combination of LAchildID, CPPstartDate and CPPreviewDate identifies and error instance.
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged["LAchildID"],
+            df_merged["CINdetailsID"],
+        )
+    )
+
+    # The merges were done on copies of cpp_df and reviews_df so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_cpp_issues = (
+        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_CINdetails.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[LAchildID_cpp], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReferralNFA], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID1",
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID2",
+            },
+            # {
+            #     "LAchildID": "child3",
+            #     "CINdetailsID": "CDID6",
+            # },
+            {
+                "LAchildID": "child4",  # ignored
+                "CINdetailsID": "CDID0",
+            },
+            {
+                "LAchildID": "child5",  # ignored, ReferralNFA is neither "1" nor "true"
+                "CINdetailsID": "CDID0",
+            },
+        ]
+    )
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Fail, module present
+                "CINdetailsID": "CDID1",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child1",  # Pass, no referralNFA
+                "CINdetailsID": "CDID2",
+                "ReferralNFA": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # Pass, no module
+                "CINdetailsID": "CDID6",
+                "ReferralNFA": "1",
+            },
+            {
+                "LAchildID": "child4",  # ignored, ReferralNFA is neither "1" nor "true"
+                "CINdetailsID": "CDID0",
+                "ReferralNFA": "false",
+            },
+            {
+                "LAchildID": "child5",  # ignored, ReferralNFA is neither "1" nor "true"
+                "CINdetailsID": "CDID0",
+                "ReferralNFA": 0,
+            },
+        ]
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            CINdetails: sample_cin,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the CINdetails columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [ReferralNFA]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 1 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 1
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "CDID1",
+                ),
+                "ROW_ID": [0],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8832' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8832"
+    assert (
+        result.definition.message
+        == "Child Protection details provided for a referral with no further action."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8839.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8839.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,224 +1,224 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-LAchildID = Section47.LAchildID
-CINdetailsID = Section47.CINdetailsID
-DateOfInitialCPC = Section47.DateOfInitialCPC
-ICPCnotRequired = Section47.ICPCnotRequired
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8839",
-    module=CINTable.Section47,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Within one CINDetails group there are 2 or more open S47 Assessments",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[DateOfInitialCPC],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Replace Section47 with the name of the table you need.
-    df = data_container[Section47]
-    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-    df.reset_index(inplace=True)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Within one <CINdetails> group, there must be only one <Section47> group that has no <DateOfInitialCPC> (N00110) recorded
-    # OR <Section47> group that has a missing <DateOfInitialCPC> (N00110) and the <ICPCnotRequired> (N00111) flag is not true
-
-    # DF_CHECK: APPLY GROUPBYs IN A SEPARATE DATAFRAME SO THAT OTHER COLUMNS ARE NOT LOST OR CORRUPTED. THEN, MAP THE RESULTS TO THE INITIAL DATAFRAME.
-    df_check = df.copy()
-    # get all the locations where ICPCnotRequired is null or not true (1)
-    # The rule originally asks for true, not 1, but an analyst coded it for 1, so their LA may use 1 and 0 instead, as such, it now checks for either.
-    df_check = df_check[
-        df_check[ICPCnotRequired].isna()
-        | (~df_check[ICPCnotRequired].astype(str).isin(["true", "1"]))
-    ]
-    # get all the locations where DateOfInitialCPC is null
-    df_check = df_check[df_check[DateOfInitialCPC].isna()]
-    # We'll have to count the number of nan values per group. NaNs cannot be counted so replace them with something that can.
-    # Do this only if your rule requires that you interact with a column made up of all NaNs.
-    # Adding as a separate column because I need the original column in the groupby for df_issues later on.
-    df_check["CountICPC"] = df_check[DateOfInitialCPC]
-    df_check["CountICPC"].fillna(1, inplace=True)
-    # count how many occurences of missing DateOfInitialCPC per CINdetails group in each child.
-    df_check = (
-        df_check.groupby([LAchildID, CINdetailsID, DateOfInitialCPC], dropna=False)[
-            "CountICPC"
-        ]
-        .count()
-        .reset_index()
-    )
-
-    # when you groupby as shown above a series is returned where the columns in the round brackets become the index and the groupby result are the values.
-    # resetting the index pushes the columns in the () back as columns of the dataframe and assigns the groupby result to the column in the square bracket.
-
-    # filter out the instances where DateOfInitialCPC is missing more than once in a CINdetails group.
-    df_check = df_check[df_check["CountICPC"] > 1]
-    issue_ids = tuple(
-        zip(df_check[LAchildID], df_check[CINdetailsID], df_check[DateOfInitialCPC])
-    )
-    # DF_ISSUES: GET ALL THE DATA ABOUT THE LOCATIONS THAT WERE IDENTIFIED IN DF_CHECK
-    df["ERROR_ID"] = tuple(zip(df[LAchildID], df[CINdetailsID], df[DateOfInitialCPC]))
-    df_issues = df[df.ERROR_ID.isin(issue_ids)]
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_3(
-        table=Section47, columns=[DateOfInitialCPC], row_df=df_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_s47 = pd.DataFrame(
-        [  # child1
-            {  # fail
-                LAchildID: "child1",
-                CINdetailsID: "cinID1",
-                DateOfInitialCPC: pd.NA,  # 0 first nan date in group
-                ICPCnotRequired: 0,
-            },
-            {  # fail
-                LAchildID: "child1",
-                CINdetailsID: "cinID1",
-                DateOfInitialCPC: pd.NA,  # 1 second nan date in group
-                ICPCnotRequired: 0,
-            },
-            {  # pass
-                LAchildID: "child1",
-                CINdetailsID: "cinID2",
-                DateOfInitialCPC: pd.NA,  # 2 not more than one nan authorisation date in group
-                ICPCnotRequired: 0,
-            },
-            # child2
-            {  # pass
-                LAchildID: "child2",
-                CINdetailsID: "cinID2",
-                DateOfInitialCPC: "26/05/2021",  # 3 not nan
-                ICPCnotRequired: 0,
-            },
-            {  # fail
-                LAchildID: "child2",
-                CINdetailsID: "cinID2",
-                DateOfInitialCPC: pd.NA,  # 4 first nan date in group
-                ICPCnotRequired: pd.NA,
-            },
-            {  # fail
-                LAchildID: "child2",
-                CINdetailsID: "cinID2",
-                DateOfInitialCPC: pd.NA,  # 5 second nan date in group
-                ICPCnotRequired: pd.NA,
-            },
-            # child 3
-            {  # pass
-                LAchildID: "child3",
-                CINdetailsID: "cinID3",
-                DateOfInitialCPC: pd.NA,  # 6 nan but also ICPC not required
-                ICPCnotRequired: "true",
-            },
-            {  # pass
-                LAchildID: "child3",
-                CINdetailsID: "cinID3",
-                DateOfInitialCPC: pd.NA,  # 7 not more than one nan authorisation date in group
-                ICPCnotRequired: pd.NA,
-            },
-            {  # pass
-                LAchildID: "child3",
-                CINdetailsID: "cinID3",
-                DateOfInitialCPC: pd.NA,  # 6 nan but also ICPC not required
-                ICPCnotRequired: 1,
-            },
-            {  # pass, 1 as string for issue 373
-                LAchildID: "child3",
-                CINdetailsID: "cinID3",
-                DateOfInitialCPC: pd.NA,
-                ICPCnotRequired: "1",
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_s47[DateOfInitialCPC] = pd.to_datetime(
-        sample_s47[DateOfInitialCPC],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Section47: sample_s47})
-
-    # Use .type3_issues to check for the result of .push_type3_issues() which you used above.
-    issues_list = result.type3_issues
-    # Issues list contains the objects pushed in their respective order. Since push_type3 was only used once, there will be one object in issues_list.
-    assert len(issues_list) == 1
-
-    issues = issues_list[0]
-
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    issue_columns = issues.columns
-    assert issue_columns == [DateOfInitialCPC]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID1",
-                    pd.NaT,
-                ),
-                "ROW_ID": [0, 1],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    "cinID2",
-                    pd.NaT,
-                ),
-                "ROW_ID": [4, 5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8839' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8839"
-    assert (
-        result.definition.message
-        == "Within one CINDetails group there are 2 or more open S47 Assessments"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+LAchildID = Section47.LAchildID
+CINdetailsID = Section47.CINdetailsID
+DateOfInitialCPC = Section47.DateOfInitialCPC
+ICPCnotRequired = Section47.ICPCnotRequired
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8839",
+    module=CINTable.Section47,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Within one CINDetails group there are 2 or more open S47 Assessments",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[DateOfInitialCPC],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace Section47 with the name of the table you need.
+    df = data_container[Section47]
+    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+    df.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Within one <CINdetails> group, there must be only one <Section47> group that has no <DateOfInitialCPC> (N00110) recorded
+    # OR <Section47> group that has a missing <DateOfInitialCPC> (N00110) and the <ICPCnotRequired> (N00111) flag is not true
+
+    # DF_CHECK: APPLY GROUPBYs IN A SEPARATE DATAFRAME SO THAT OTHER COLUMNS ARE NOT LOST OR CORRUPTED. THEN, MAP THE RESULTS TO THE INITIAL DATAFRAME.
+    df_check = df.copy()
+    # get all the locations where ICPCnotRequired is null or not true (1)
+    # The rule originally asks for true, not 1, but an analyst coded it for 1, so their LA may use 1 and 0 instead, as such, it now checks for either.
+    df_check = df_check[
+        df_check[ICPCnotRequired].isna()
+        | (~df_check[ICPCnotRequired].astype(str).isin(["true", "1"]))
+    ]
+    # get all the locations where DateOfInitialCPC is null
+    df_check = df_check[df_check[DateOfInitialCPC].isna()]
+    # We'll have to count the number of nan values per group. NaNs cannot be counted so replace them with something that can.
+    # Do this only if your rule requires that you interact with a column made up of all NaNs.
+    # Adding as a separate column because I need the original column in the groupby for df_issues later on.
+    df_check["CountICPC"] = df_check[DateOfInitialCPC]
+    df_check["CountICPC"].fillna(1, inplace=True)
+    # count how many occurences of missing DateOfInitialCPC per CINdetails group in each child.
+    df_check = (
+        df_check.groupby([LAchildID, CINdetailsID, DateOfInitialCPC], dropna=False)[
+            "CountICPC"
+        ]
+        .count()
+        .reset_index()
+    )
+
+    # when you groupby as shown above a series is returned where the columns in the round brackets become the index and the groupby result are the values.
+    # resetting the index pushes the columns in the () back as columns of the dataframe and assigns the groupby result to the column in the square bracket.
+
+    # filter out the instances where DateOfInitialCPC is missing more than once in a CINdetails group.
+    df_check = df_check[df_check["CountICPC"] > 1]
+    issue_ids = tuple(
+        zip(df_check[LAchildID], df_check[CINdetailsID], df_check[DateOfInitialCPC])
+    )
+    # DF_ISSUES: GET ALL THE DATA ABOUT THE LOCATIONS THAT WERE IDENTIFIED IN DF_CHECK
+    df["ERROR_ID"] = tuple(zip(df[LAchildID], df[CINdetailsID], df[DateOfInitialCPC]))
+    df_issues = df[df.ERROR_ID.isin(issue_ids)]
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=Section47, columns=[DateOfInitialCPC], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_s47 = pd.DataFrame(
+        [  # child1
+            {  # fail
+                LAchildID: "child1",
+                CINdetailsID: "cinID1",
+                DateOfInitialCPC: pd.NA,  # 0 first nan date in group
+                ICPCnotRequired: 0,
+            },
+            {  # fail
+                LAchildID: "child1",
+                CINdetailsID: "cinID1",
+                DateOfInitialCPC: pd.NA,  # 1 second nan date in group
+                ICPCnotRequired: 0,
+            },
+            {  # pass
+                LAchildID: "child1",
+                CINdetailsID: "cinID2",
+                DateOfInitialCPC: pd.NA,  # 2 not more than one nan authorisation date in group
+                ICPCnotRequired: 0,
+            },
+            # child2
+            {  # pass
+                LAchildID: "child2",
+                CINdetailsID: "cinID2",
+                DateOfInitialCPC: "26/05/2021",  # 3 not nan
+                ICPCnotRequired: 0,
+            },
+            {  # fail
+                LAchildID: "child2",
+                CINdetailsID: "cinID2",
+                DateOfInitialCPC: pd.NA,  # 4 first nan date in group
+                ICPCnotRequired: pd.NA,
+            },
+            {  # fail
+                LAchildID: "child2",
+                CINdetailsID: "cinID2",
+                DateOfInitialCPC: pd.NA,  # 5 second nan date in group
+                ICPCnotRequired: pd.NA,
+            },
+            # child 3
+            {  # pass
+                LAchildID: "child3",
+                CINdetailsID: "cinID3",
+                DateOfInitialCPC: pd.NA,  # 6 nan but also ICPC not required
+                ICPCnotRequired: "true",
+            },
+            {  # pass
+                LAchildID: "child3",
+                CINdetailsID: "cinID3",
+                DateOfInitialCPC: pd.NA,  # 7 not more than one nan authorisation date in group
+                ICPCnotRequired: pd.NA,
+            },
+            {  # pass
+                LAchildID: "child3",
+                CINdetailsID: "cinID3",
+                DateOfInitialCPC: pd.NA,  # 6 nan but also ICPC not required
+                ICPCnotRequired: 1,
+            },
+            {  # pass, 1 as string for issue 373
+                LAchildID: "child3",
+                CINdetailsID: "cinID3",
+                DateOfInitialCPC: pd.NA,
+                ICPCnotRequired: "1",
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_s47[DateOfInitialCPC] = pd.to_datetime(
+        sample_s47[DateOfInitialCPC],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Section47: sample_s47})
+
+    # Use .type3_issues to check for the result of .push_type3_issues() which you used above.
+    issues_list = result.type3_issues
+    # Issues list contains the objects pushed in their respective order. Since push_type3 was only used once, there will be one object in issues_list.
+    assert len(issues_list) == 1
+
+    issues = issues_list[0]
+
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    issue_columns = issues.columns
+    assert issue_columns == [DateOfInitialCPC]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                    pd.NaT,
+                ),
+                "ROW_ID": [0, 1],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "cinID2",
+                    pd.NaT,
+                ),
+                "ROW_ID": [4, 5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8839' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8839"
+    assert (
+        result.definition.message
+        == "Within one CINDetails group there are 2 or more open S47 Assessments"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8840.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8840.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,162 +1,162 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-# Replace ChildProtectionPlans with the table name, and LAChildID with the column name you want.
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LAchildID = ChildProtectionPlans.LAchildID
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-CPPendDate = ChildProtectionPlans.CPPendDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8840'
-    code="8840",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child Protection Plan cannot start and end on the same day",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[ChildProtectionPlans, CPPstartDate, CPPendDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace ChildProtectionPlans with the name of the table you need.
-    df = data_container[ChildProtectionPlans]
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # LOGIC
-    # Within a <ChildProtectionPlans> group, <CPPstartDate> (N00105) must not be the same as the <CPPendDate> (N00115)
-
-    #  Determine if the dates are the same by finding if the difference between dates is 0
-    condition = df["CPPstartDate"] == df["CPPendDate"]
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error. In this case,
-    # - If only LAchildID is used as an identifier, multiple instances of the error on a child will be understood as 1 instance.
-    # We don't want that because in reality, a child can have multiple instances of an error.
-    # - If we use the LAchildID-CPPstartDate combination, that artificially cancels out the instances where a start date repeats for the same child.
-    # Another rule checks for that condition. Not this one.
-    # - It is very unlikely that a combination of LAchildID-CPPstartDate-CPPendDate will repeat in the DataFrame.
-    # Hence, it can be used as a unique identifier of the row.
-
-    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
-    link_id = tuple(
-        zip(df_issues[LAchildID], df_issues[CPPstartDate], df_issues[CPPendDate])
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=ChildProtectionPlans, columns=[CPPstartDate, CPPendDate], row_df=df_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-
-    #  Fails rows 0, 1, and 3
-    child_protection_plans = pd.DataFrame(
-        {
-            "LAchildID": ["child1", "child2", "child3", "child4", "child5"],
-            "CPPstartDate": [
-                "08/10/1989",
-                "05/12/1993",
-                "05/12/1993",
-                "05/12/1997",
-                pd.NA,
-            ],
-            "CPPendDate": [
-                "08/10/1989",
-                "05/12/1993",
-                "12/09/2022",
-                "05/12/1997",
-                pd.NA,
-            ],
-        }
-    )
-    child_protection_plans["CPPstartDate"] = pd.to_datetime(
-        child_protection_plans["CPPstartDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    child_protection_plans["CPPendDate"] = pd.to_datetime(
-        child_protection_plans["CPPendDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildProtectionPlans: child_protection_plans})
-
-    # The result contains a NamedTuple of issues encountered
-    issues = result.type1_issues
-
-    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildProtectionPlans
-
-    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [CPPstartDate, CPPendDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("08/10/1989", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("08/10/1989", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    pd.to_datetime("05/12/1993", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("05/12/1993", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    pd.to_datetime("05/12/1997", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("05/12/1997", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8840' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8840"
-    assert (
-        result.definition.message
-        == "Child Protection Plan cannot start and end on the same day"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+# Replace ChildProtectionPlans with the table name, and LAChildID with the column name you want.
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+LAchildID = ChildProtectionPlans.LAchildID
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+CPPendDate = ChildProtectionPlans.CPPendDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8840'
+    code="8840",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child Protection Plan cannot start and end on the same day",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[ChildProtectionPlans, CPPstartDate, CPPendDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace ChildProtectionPlans with the name of the table you need.
+    df = data_container[ChildProtectionPlans]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # LOGIC
+    # Within a <ChildProtectionPlans> group, <CPPstartDate> (N00105) must not be the same as the <CPPendDate> (N00115)
+
+    #  Determine if the dates are the same by finding if the difference between dates is 0
+    condition = df["CPPstartDate"] == df["CPPendDate"]
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error. In this case,
+    # - If only LAchildID is used as an identifier, multiple instances of the error on a child will be understood as 1 instance.
+    # We don't want that because in reality, a child can have multiple instances of an error.
+    # - If we use the LAchildID-CPPstartDate combination, that artificially cancels out the instances where a start date repeats for the same child.
+    # Another rule checks for that condition. Not this one.
+    # - It is very unlikely that a combination of LAchildID-CPPstartDate-CPPendDate will repeat in the DataFrame.
+    # Hence, it can be used as a unique identifier of the row.
+
+    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
+    link_id = tuple(
+        zip(df_issues[LAchildID], df_issues[CPPstartDate], df_issues[CPPendDate])
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=ChildProtectionPlans, columns=[CPPstartDate, CPPendDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+
+    #  Fails rows 0, 1, and 3
+    child_protection_plans = pd.DataFrame(
+        {
+            "LAchildID": ["child1", "child2", "child3", "child4", "child5"],
+            "CPPstartDate": [
+                "08/10/1989",
+                "05/12/1993",
+                "05/12/1993",
+                "05/12/1997",
+                pd.NA,
+            ],
+            "CPPendDate": [
+                "08/10/1989",
+                "05/12/1993",
+                "12/09/2022",
+                "05/12/1997",
+                pd.NA,
+            ],
+        }
+    )
+    child_protection_plans["CPPstartDate"] = pd.to_datetime(
+        child_protection_plans["CPPstartDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    child_protection_plans["CPPendDate"] = pd.to_datetime(
+        child_protection_plans["CPPendDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildProtectionPlans: child_protection_plans})
+
+    # The result contains a NamedTuple of issues encountered
+    issues = result.type1_issues
+
+    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildProtectionPlans
+
+    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [CPPstartDate, CPPendDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    pd.to_datetime("08/10/1989", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("08/10/1989", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    pd.to_datetime("05/12/1993", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("05/12/1993", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    pd.to_datetime("05/12/1997", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("05/12/1997", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8840' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8840"
+    assert (
+        result.definition.message
+        == "Child Protection Plan cannot start and end on the same day"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8841.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8841.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,292 +1,292 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-LAchildID = ChildProtectionPlans.LAchildID
-CPPID_CPP = ChildProtectionPlans.CPPID
-CINdetailsCPP = ChildProtectionPlans.CINdetailsID
-
-Reviews = CINTable.Reviews
-CPPreviewDate = Reviews.CPPreviewDate
-CPPID_reviews = Reviews.CPPID
-CINdetailsReviews = Reviews.CINdetailsID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here
-    code="8841",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="The review date cannot be on the same day or before the Child protection Plan start date.",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        CPPstartDate,
-        CPPreviewDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_cpp = data_container[ChildProtectionPlans].copy()
-    df_reviews = data_container[Reviews].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cpp.index.name = "ROW_ID"
-    df_reviews.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_cpp.reset_index(inplace=True)
-    df_reviews.reset_index(inplace=True)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Within a <ChildProtectionPlans> group, there should be no <CPPreviewDate> (N00116) that is the same as or before the <CPPstartDate> (N00105)
-    # Issues dfs should return rows where CPPreviewDate is less than or equal to the CPPstartDate
-
-    #  Create dataframes which only have rows with CP plans, and which should have one plan per row.
-    df_cpp = df_cpp[df_cpp[CPPstartDate].notna()]
-    df_reviews = df_reviews[df_reviews[CPPreviewDate].notna()]
-
-    #  Merge tables to get corresponding CP plan group and reviews
-    df_merged = df_cpp.merge(
-        df_reviews,
-        left_on=["CPPID", "LAchildID", "CINdetailsID"],
-        right_on=["CPPID", "LAchildID", "CINdetailsID"],
-        how="left",
-        suffixes=("_cpp", "_reviews"),
-    )
-
-    #  Get rows where CPPreviewDate is less than or equal to CPPstartDate
-    condition = df_merged[CPPreviewDate] <= df_merged[CPPstartDate]
-    df_merged = df_merged[condition].reset_index()
-
-    # create an identifier for each error instance.
-    # In this case, the rule is checked for each CPPstartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
-    # So, a combination of LAchildID, CPPstartDate and CPPreviewDate identifies and error instance.
-    df_merged["ERROR_ID"] = tuple(
-        zip(df_merged[LAchildID], df_merged[CPPstartDate], df_merged[CPPreviewDate])
-    )
-
-    # The merges were done on copies of cpp_df and reviews_df so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cpp_issues = (
-        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_reviews_issues = (
-        df_reviews.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_reviews")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=Reviews, columns=[CPPreviewDate], row_df=df_reviews_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID1",
-                "CPPstartDate": "26/05/2000",  # Fails as dates are the same
-                "CPPID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID2",
-                "CPPstartDate": "27/06/2002",  #  Fails, review (26/5/2000) before start
-                "CPPID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID6",
-                "CPPstartDate": "07/02/2001",  # Fails as review is before start (26/5/2000)
-                "CPPID": "cinID6",
-            },
-            {
-                "LAchildID": "child2",
-                "CINdetailsID": "CDID3",
-                "CPPstartDate": "26/05/2000",  # Passes as Start is before Review (30/05/2000)
-                "CPPID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID4",
-                "CPPstartDate": "26/05/2000",  # Passes
-                "CPPID": "cinID4",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID5",
-                "CPPstartDate": pd.NA,  # Ignored as rows with no start and end are dropped (this is picked up by other rules)
-                "CPPID": "cinID5",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID7",
-                "CPPstartDate": "14/03/2001",  # Ignored as there is no review date
-                "CPPID": "cinID7",
-            },
-        ]
-    )
-    sample_reviews = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Fails
-                "CINdetailsID": "CDID1",
-                "CPPreviewDate": "26/05/2000",
-                "CPPID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",  # Fails
-                "CINdetailsID": "CDID2",
-                "CPPreviewDate": "26/05/2000",
-                "CPPID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",  # Fails
-                "CINdetailsID": "CDID6",
-                "CPPreviewDate": "26/05/2000",
-                "CPPID": "cinID6",
-            },
-            {
-                "LAchildID": "child2",
-                "CINdetailsID": "CDID3",
-                "CPPreviewDate": "30/05/2000",
-                "CPPID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID4",
-                "CPPreviewDate": "27/05/2000",
-                "CPPID": "cinID4",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID5",
-                "CPPreviewDate": "26/05/2000",
-                "CPPID": "cinID5",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID7",
-                "CPPreviewDate": pd.NA,
-                "CPPID": "cinID7",
-            },
-        ]
-    )
-
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cpp[CPPstartDate] = pd.to_datetime(
-        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_reviews["CPPreviewDate"] = pd.to_datetime(
-        sample_reviews["CPPreviewDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            Reviews: sample_reviews,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Reviews
-
-    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [CPPreviewDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    # Start Date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    # Review date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    # Start date
-                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
-                    # Review date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    # Start date
-                    pd.to_datetime("07/02/2001", format="%d/%m/%Y", errors="coerce"),
-                    # Review date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8841' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8841"
-    assert (
-        result.definition.message
-        == "The review date cannot be on the same day or before the Child protection Plan start date."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+LAchildID = ChildProtectionPlans.LAchildID
+CPPID_CPP = ChildProtectionPlans.CPPID
+CINdetailsCPP = ChildProtectionPlans.CINdetailsID
+
+Reviews = CINTable.Reviews
+CPPreviewDate = Reviews.CPPreviewDate
+CPPID_reviews = Reviews.CPPID
+CINdetailsReviews = Reviews.CINdetailsID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here
+    code="8841",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="The review date cannot be on the same day or before the Child protection Plan start date.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        CPPstartDate,
+        CPPreviewDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_cpp = data_container[ChildProtectionPlans].copy()
+    df_reviews = data_container[Reviews].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cpp.index.name = "ROW_ID"
+    df_reviews.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_cpp.reset_index(inplace=True)
+    df_reviews.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Within a <ChildProtectionPlans> group, there should be no <CPPreviewDate> (N00116) that is the same as or before the <CPPstartDate> (N00105)
+    # Issues dfs should return rows where CPPreviewDate is less than or equal to the CPPstartDate
+
+    #  Create dataframes which only have rows with CP plans, and which should have one plan per row.
+    df_cpp = df_cpp[df_cpp[CPPstartDate].notna()]
+    df_reviews = df_reviews[df_reviews[CPPreviewDate].notna()]
+
+    #  Merge tables to get corresponding CP plan group and reviews
+    df_merged = df_cpp.merge(
+        df_reviews,
+        left_on=["CPPID", "LAchildID", "CINdetailsID"],
+        right_on=["CPPID", "LAchildID", "CINdetailsID"],
+        how="left",
+        suffixes=("_cpp", "_reviews"),
+    )
+
+    #  Get rows where CPPreviewDate is less than or equal to CPPstartDate
+    condition = df_merged[CPPreviewDate] <= df_merged[CPPstartDate]
+    df_merged = df_merged[condition].reset_index()
+
+    # create an identifier for each error instance.
+    # In this case, the rule is checked for each CPPstartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
+    # So, a combination of LAchildID, CPPstartDate and CPPreviewDate identifies and error instance.
+    df_merged["ERROR_ID"] = tuple(
+        zip(df_merged[LAchildID], df_merged[CPPstartDate], df_merged[CPPreviewDate])
+    )
+
+    # The merges were done on copies of cpp_df and reviews_df so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_cpp_issues = (
+        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_reviews_issues = (
+        df_reviews.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_reviews")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=Reviews, columns=[CPPreviewDate], row_df=df_reviews_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID1",
+                "CPPstartDate": "26/05/2000",  # Fails as dates are the same
+                "CPPID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID2",
+                "CPPstartDate": "27/06/2002",  #  Fails, review (26/5/2000) before start
+                "CPPID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID6",
+                "CPPstartDate": "07/02/2001",  # Fails as review is before start (26/5/2000)
+                "CPPID": "cinID6",
+            },
+            {
+                "LAchildID": "child2",
+                "CINdetailsID": "CDID3",
+                "CPPstartDate": "26/05/2000",  # Passes as Start is before Review (30/05/2000)
+                "CPPID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID4",
+                "CPPstartDate": "26/05/2000",  # Passes
+                "CPPID": "cinID4",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID5",
+                "CPPstartDate": pd.NA,  # Ignored as rows with no start and end are dropped (this is picked up by other rules)
+                "CPPID": "cinID5",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID7",
+                "CPPstartDate": "14/03/2001",  # Ignored as there is no review date
+                "CPPID": "cinID7",
+            },
+        ]
+    )
+    sample_reviews = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Fails
+                "CINdetailsID": "CDID1",
+                "CPPreviewDate": "26/05/2000",
+                "CPPID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",  # Fails
+                "CINdetailsID": "CDID2",
+                "CPPreviewDate": "26/05/2000",
+                "CPPID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",  # Fails
+                "CINdetailsID": "CDID6",
+                "CPPreviewDate": "26/05/2000",
+                "CPPID": "cinID6",
+            },
+            {
+                "LAchildID": "child2",
+                "CINdetailsID": "CDID3",
+                "CPPreviewDate": "30/05/2000",
+                "CPPID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID4",
+                "CPPreviewDate": "27/05/2000",
+                "CPPID": "cinID4",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID5",
+                "CPPreviewDate": "26/05/2000",
+                "CPPID": "cinID5",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID7",
+                "CPPreviewDate": pd.NA,
+                "CPPID": "cinID7",
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cpp[CPPstartDate] = pd.to_datetime(
+        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_reviews["CPPreviewDate"] = pd.to_datetime(
+        sample_reviews["CPPreviewDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            Reviews: sample_reviews,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Reviews
+
+    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [CPPreviewDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    # Start Date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    # Review date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    # Start date
+                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
+                    # Review date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    # Start date
+                    pd.to_datetime("07/02/2001", format="%d/%m/%Y", errors="coerce"),
+                    # Review date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8841' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8841"
+    assert (
+        result.definition.message
+        == "The review date cannot be on the same day or before the Child protection Plan start date."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8842Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8842Q.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,79 +1,79 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    RuleType,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Reviews = CINTable.Reviews
-CPPreviewDate = Reviews.CPPreviewDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8842Q",
-    module=CINTable.Reviews,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend or provide a reason: Review Record has a missing date",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[CPPreviewDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace Reviews with the name of the table you need.
-    df = data_container[Reviews]
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # Where a <Reviews> group is present, a valid <CPPreviewdate> (N00116) should be present within the group
-    # Valid values for columns can be found in this document:
-    # https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1025195/Children_in_need_census_2022_to_2023_guide.pdf
-    condition = df[CPPreviewDate].isna()
-
-    # This is a straightforward check because it is not possible to have multiple <CPPreviewdate> that belong to the same review group.
-    failing_indices = df[condition].index
-
-    rule_context.push_issue(table=Reviews, field=CPPreviewDate, row=failing_indices)
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    reviews = pd.DataFrame(
-        [["26/05/2000"], [pd.NA], ["not a date"]], columns=[CPPreviewDate]
-    )
-
-    reviews[CPPreviewDate] = pd.to_datetime(
-        reviews[CPPreviewDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Reviews: reviews})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.Reviews, CPPreviewDate, 1),
-        IssueLocator(CINTable.Reviews, CPPreviewDate, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8842Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8842Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend or provide a reason: Review Record has a missing date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    RuleType,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Reviews = CINTable.Reviews
+CPPreviewDate = Reviews.CPPreviewDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8842Q",
+    module=CINTable.Reviews,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend or provide a reason: Review Record has a missing date",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[CPPreviewDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace Reviews with the name of the table you need.
+    df = data_container[Reviews]
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # Where a <Reviews> group is present, a valid <CPPreviewdate> (N00116) should be present within the group
+    # Valid values for columns can be found in this document:
+    # https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1025195/Children_in_need_census_2022_to_2023_guide.pdf
+    condition = df[CPPreviewDate].isna()
+
+    # This is a straightforward check because it is not possible to have multiple <CPPreviewdate> that belong to the same review group.
+    failing_indices = df[condition].index
+
+    rule_context.push_issue(table=Reviews, field=CPPreviewDate, row=failing_indices)
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    reviews = pd.DataFrame(
+        [["26/05/2000"], [pd.NA], ["not a date"]], columns=[CPPreviewDate]
+    )
+
+    reviews[CPPreviewDate] = pd.to_datetime(
+        reviews[CPPreviewDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Reviews: reviews})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.Reviews, CPPreviewDate, 1),
+        IssueLocator(CINTable.Reviews, CPPreviewDate, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8842Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8842Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend or provide a reason: Review Record has a missing date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8863Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8863Q.py`

 * *Ordering differences only*

 * *Files 10% similar despite different names*

```diff
@@ -1,300 +1,300 @@
-# this is similar to rule 8890
-
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-LAchildID = Assessments.LAchildID
-CINdetailsID = Assessments.CINdetailsID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8863Q",
-    module=CINTable.Assessments,
-    rule_type=RuleType.QUERY,
-    message="An Assessment is shown as starting when there is another Assessment ongoing.",
-    affected_fields=[AssessmentActualStartDate, AssessmentAuthorisationDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Name of the table required.
-    df_ass = data_container[Assessments].copy()
-    df_ass_2 = data_container[Assessments].copy()
-
-    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
-    df_ass.index.name = "ROW_ID"
-    df_ass_2.index.name = "ROW_ID"
-
-    df_ass.reset_index(inplace=True)
-    df_ass_2.reset_index(inplace=True)
-
-    # ReferenceDate exists in the header table so we get header table too.
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Within one <CINdetails> group, where present each <AssessmentActualStartDate> (N00159) must not fall on or between:
-    # a) the <AssessmentActualStartDate> (N00159) and <AssessmentAuthorisation Date (N00160) of any other <Assessments> group that has an <AssessmentAuthorisationDate> (N00160)
-    # OR
-    # b) the <AssessmentActualStartDate> (N00159) and the <ReferenceDate> (N00603) where the <AssessmentAuthorisationDate> (N00160) is missing
-
-    df_ass = df_ass[df_ass[AssessmentActualStartDate].notna()]
-    df_ass_2 = df_ass_2[df_ass_2[AssessmentActualStartDate].notna()]
-
-    #  Merge tables to test for overlaps
-    df_merged = df_ass.merge(
-        df_ass_2,
-        on=[LAchildID, CINdetailsID],
-        how="left",
-        suffixes=("_ass", "_ass2"),
-    )
-
-    # Prevent Assessments from being compared to themselves.
-    same_start = (
-        df_merged["AssessmentActualStartDate_ass"]
-        == df_merged["AssessmentActualStartDate_ass2"]
-    )
-    same_end = (
-        df_merged["AssessmentAuthorisationDate_ass"]
-        == df_merged["AssessmentAuthorisationDate_ass2"]
-    ) | (
-        df_merged[
-            "AssessmentAuthorisationDate_ass"
-        ].isna()  # nans are checked separately because they are not considered equal by ==
-        & df_merged["AssessmentAuthorisationDate_ass2"].isna()
-    )
-    duplicate = same_start & same_end
-    df_merged = df_merged[~duplicate]
-
-    # Determine whether assessment overlaps with another assessment
-    ass_started_after_start = (
-        df_merged["AssessmentActualStartDate_ass"]  # 1 starts later than 2 starts
-        >= df_merged["AssessmentActualStartDate_ass2"]
-    )
-    ass_started_before_end = (
-        df_merged["AssessmentActualStartDate_ass"]  # 1 starts earlier than 2 finishes
-        <= df_merged["AssessmentAuthorisationDate_ass2"]
-    ) & df_merged["AssessmentAuthorisationDate_ass2"].notna()
-    ass_started_before_refdate = (
-        df_merged["AssessmentActualStartDate_ass"] <= reference_date
-    ) & df_merged["AssessmentAuthorisationDate_ass2"].isna()
-
-    df_merged = df_merged[
-        ass_started_after_start & (ass_started_before_end | ass_started_before_refdate)
-    ].reset_index()
-
-    # create an identifier for each error instance.
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[CINdetailsID],
-            df_merged["AssessmentActualStartDate_ass"],
-        )
-    )
-
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_ass_issues = (
-        df_ass.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_ass_2_issues = (
-        df_ass_2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass2")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_3(
-        table=Assessments, columns=[AssessmentActualStartDate], row_df=df_ass_issues
-    )
-    rule_context.push_type_3(
-        table=Assessments,
-        columns=[AssessmentActualStartDate, AssessmentAuthorisationDate],
-        row_df=df_ass_2_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
-    )
-
-    sample_ass = pd.DataFrame(
-        [  # child1
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "26/05/2000",  # 0 Pass: not between "26/08/2000" and "31/03/2001"
-                "AssessmentAuthorisationDate": "26/10/2000",
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "26/08/2000",  # 1 Fail: between "26/05/2000" and "26/10/2000"
-                "AssessmentAuthorisationDate": pd.NA,
-            },
-            {
-                "LAchildID": "child2",  # 2 alone in cin group: not compared
-                "CINdetailsID": "cinID2",
-                "AssessmentActualStartDate": "26/05/2000",
-                "AssessmentAuthorisationDate": "25/10/2000",
-            },
-            {
-                "LAchildID": "child2",  # 3 alone in cin group: not compared
-                "CINdetailsID": "cinID22",
-                "AssessmentActualStartDate": "26/10/2000",
-                "AssessmentAuthorisationDate": "26/12/2000",
-            },
-            # child3
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID3",
-                "AssessmentActualStartDate": "26/05/2000",  # 4 Pass: not between "26/08/2000" and "26/10/2000"
-                "AssessmentAuthorisationDate": "26/10/2001",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID3",
-                "AssessmentActualStartDate": "26/08/2000",  # 5 Fail: between "26/05/2000" and "26/10/2001"
-                "AssessmentAuthorisationDate": "26/10/2000",
-            },
-            # child4
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "26/10/2000",  # 6 Fail: between "26/09/2000" and ReferenceDate
-                "AssessmentAuthorisationDate": "31/03/2001",
-            },
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "26/09/2000",  # 7 Pass: not between "26/10/2000" and "31/03/2001"
-                "AssessmentAuthorisationDate": pd.NA,
-            },
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "01/03/2000",
-                "AssessmentAuthorisationDate": "01/04/2000",
-            },
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "01/09/2000",
-                "AssessmentAuthorisationDate": "01/10/2000",
-            },
-        ]
-    )
-
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_ass[AssessmentActualStartDate] = pd.to_datetime(
-        sample_ass[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_ass[AssessmentAuthorisationDate] = pd.to_datetime(
-        sample_ass[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            Assessments: sample_ass,
-            Header: sample_header,
-        },
-    )
-
-    issues_list = result.type3_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
-    issues = issues_list[0]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Assessments
-
-    issue_columns = issues.columns
-    assert issue_columns == [AssessmentActualStartDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID1",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID3",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    "cinID1",
-                    pd.to_datetime("26/10/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [6],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8863Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8863Q"
-    assert (
-        result.definition.message
-        == "An Assessment is shown as starting when there is another Assessment ongoing."
-    )
+# this is similar to rule 8890
+
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+LAchildID = Assessments.LAchildID
+CINdetailsID = Assessments.CINdetailsID
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8863Q",
+    module=CINTable.Assessments,
+    rule_type=RuleType.QUERY,
+    message="An Assessment is shown as starting when there is another Assessment ongoing.",
+    affected_fields=[AssessmentActualStartDate, AssessmentAuthorisationDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Name of the table required.
+    df_ass = data_container[Assessments].copy()
+    df_ass_2 = data_container[Assessments].copy()
+
+    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
+    df_ass.index.name = "ROW_ID"
+    df_ass_2.index.name = "ROW_ID"
+
+    df_ass.reset_index(inplace=True)
+    df_ass_2.reset_index(inplace=True)
+
+    # ReferenceDate exists in the header table so we get header table too.
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Within one <CINdetails> group, where present each <AssessmentActualStartDate> (N00159) must not fall on or between:
+    # a) the <AssessmentActualStartDate> (N00159) and <AssessmentAuthorisation Date (N00160) of any other <Assessments> group that has an <AssessmentAuthorisationDate> (N00160)
+    # OR
+    # b) the <AssessmentActualStartDate> (N00159) and the <ReferenceDate> (N00603) where the <AssessmentAuthorisationDate> (N00160) is missing
+
+    df_ass = df_ass[df_ass[AssessmentActualStartDate].notna()]
+    df_ass_2 = df_ass_2[df_ass_2[AssessmentActualStartDate].notna()]
+
+    #  Merge tables to test for overlaps
+    df_merged = df_ass.merge(
+        df_ass_2,
+        on=[LAchildID, CINdetailsID],
+        how="left",
+        suffixes=("_ass", "_ass2"),
+    )
+
+    # Prevent Assessments from being compared to themselves.
+    same_start = (
+        df_merged["AssessmentActualStartDate_ass"]
+        == df_merged["AssessmentActualStartDate_ass2"]
+    )
+    same_end = (
+        df_merged["AssessmentAuthorisationDate_ass"]
+        == df_merged["AssessmentAuthorisationDate_ass2"]
+    ) | (
+        df_merged[
+            "AssessmentAuthorisationDate_ass"
+        ].isna()  # nans are checked separately because they are not considered equal by ==
+        & df_merged["AssessmentAuthorisationDate_ass2"].isna()
+    )
+    duplicate = same_start & same_end
+    df_merged = df_merged[~duplicate]
+
+    # Determine whether assessment overlaps with another assessment
+    ass_started_after_start = (
+        df_merged["AssessmentActualStartDate_ass"]  # 1 starts later than 2 starts
+        >= df_merged["AssessmentActualStartDate_ass2"]
+    )
+    ass_started_before_end = (
+        df_merged["AssessmentActualStartDate_ass"]  # 1 starts earlier than 2 finishes
+        <= df_merged["AssessmentAuthorisationDate_ass2"]
+    ) & df_merged["AssessmentAuthorisationDate_ass2"].notna()
+    ass_started_before_refdate = (
+        df_merged["AssessmentActualStartDate_ass"] <= reference_date
+    ) & df_merged["AssessmentAuthorisationDate_ass2"].isna()
+
+    df_merged = df_merged[
+        ass_started_after_start & (ass_started_before_end | ass_started_before_refdate)
+    ].reset_index()
+
+    # create an identifier for each error instance.
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[CINdetailsID],
+            df_merged["AssessmentActualStartDate_ass"],
+        )
+    )
+
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_ass_issues = (
+        df_ass.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_ass_2_issues = (
+        df_ass_2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass2")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=Assessments, columns=[AssessmentActualStartDate], row_df=df_ass_issues
+    )
+    rule_context.push_type_3(
+        table=Assessments,
+        columns=[AssessmentActualStartDate, AssessmentAuthorisationDate],
+        row_df=df_ass_2_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
+    )
+
+    sample_ass = pd.DataFrame(
+        [  # child1
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "AssessmentActualStartDate": "26/05/2000",  # 0 Pass: not between "26/08/2000" and "31/03/2001"
+                "AssessmentAuthorisationDate": "26/10/2000",
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "AssessmentActualStartDate": "26/08/2000",  # 1 Fail: between "26/05/2000" and "26/10/2000"
+                "AssessmentAuthorisationDate": pd.NA,
+            },
+            {
+                "LAchildID": "child2",  # 2 alone in cin group: not compared
+                "CINdetailsID": "cinID2",
+                "AssessmentActualStartDate": "26/05/2000",
+                "AssessmentAuthorisationDate": "25/10/2000",
+            },
+            {
+                "LAchildID": "child2",  # 3 alone in cin group: not compared
+                "CINdetailsID": "cinID22",
+                "AssessmentActualStartDate": "26/10/2000",
+                "AssessmentAuthorisationDate": "26/12/2000",
+            },
+            # child3
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID3",
+                "AssessmentActualStartDate": "26/05/2000",  # 4 Pass: not between "26/08/2000" and "26/10/2000"
+                "AssessmentAuthorisationDate": "26/10/2001",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID3",
+                "AssessmentActualStartDate": "26/08/2000",  # 5 Fail: between "26/05/2000" and "26/10/2001"
+                "AssessmentAuthorisationDate": "26/10/2000",
+            },
+            # child4
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "cinID1",
+                "AssessmentActualStartDate": "26/10/2000",  # 6 Fail: between "26/09/2000" and ReferenceDate
+                "AssessmentAuthorisationDate": "31/03/2001",
+            },
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "cinID1",
+                "AssessmentActualStartDate": "26/09/2000",  # 7 Pass: not between "26/10/2000" and "31/03/2001"
+                "AssessmentAuthorisationDate": pd.NA,
+            },
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "cinID1",
+                "AssessmentActualStartDate": "01/03/2000",
+                "AssessmentAuthorisationDate": "01/04/2000",
+            },
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "cinID1",
+                "AssessmentActualStartDate": "01/09/2000",
+                "AssessmentAuthorisationDate": "01/10/2000",
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_ass[AssessmentActualStartDate] = pd.to_datetime(
+        sample_ass[AssessmentActualStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_ass[AssessmentAuthorisationDate] = pd.to_datetime(
+        sample_ass[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            Assessments: sample_ass,
+            Header: sample_header,
+        },
+    )
+
+    issues_list = result.type3_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
+    issues = issues_list[0]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Assessments
+
+    issue_columns = issues.columns
+    assert issue_columns == [AssessmentActualStartDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID3",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "cinID1",
+                    pd.to_datetime("26/10/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [6],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8863Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8863Q"
+    assert (
+        result.definition.message
+        == "An Assessment is shown as starting when there is another Assessment ongoing."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8866.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8866.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,174 +1,174 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINdetails = CINTable.CINdetails
-LAchildID = CINdetails.LAchildID
-CINreferralDate = CINdetails.CINreferralDate
-ReferralSource = CINdetails.ReferralSource
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8866'
-    code="8866",
-    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.CINdetails,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Source of Referral is missing or an invalid code",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        CINreferralDate,
-        ReferralSource,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # Replace CINdetails with the name of the table you need.
-    df = data_container[CINdetails]
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-    df.reset_index(inplace=True)
-
-    valid_referrals = [
-        "1A",
-        "1B",
-        "1C",
-        "1D",
-        "2A",
-        "2B",
-        "3A",
-        "3B",
-        "3C",
-        "3D",
-        "3E",
-        "3F",
-        "4",
-        "5A",
-        "5B",
-        "5C",
-        "5D",
-        "6",
-        "7",
-        "8",
-        "9",
-        "10",
-    ]
-
-    # If <CinReferralDate> (N00100) is on or after 1 April 2013 then <ReferralSource> (N00152) must be present and must be a valid code
-    condition = (
-        df[CINreferralDate] >= pd.to_datetime("01/04/2013", format="%d/%m/%Y")
-    ) & ((df[ReferralSource].isna()) | (~df[ReferralSource].isin(valid_referrals)))
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error.
-
-    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
-    link_id = tuple(zip(df_issues[LAchildID], df_issues[CINreferralDate]))
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=CINdetails, columns=[CINreferralDate, ReferralSource], row_df=df_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-
-    #  Fails rows 0, 1, and 3
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "ID1",  # Fail
-                "CINreferralDate": "01/01/2020",
-                "ReferralSource": "1Z",
-            },
-            {
-                "LAchildID": "ID2",  # Fail
-                "CINreferralDate": "01/01/2020",
-                "ReferralSource": pd.NA,
-            },
-            {
-                "LAchildID": "ID3",
-                "CINreferralDate": "01/01/2000",
-                "ReferralSource": "1A",
-            },
-            {
-                "LAchildID": "ID4",
-                "CINreferralDate": "01/01/2012",  # ignore
-                "ReferralSource": "pd.NA",
-            },
-            {
-                "LAchildID": "ID4",
-                "CINreferralDate": "01/01/2020",
-                "ReferralSource": "1C",
-            },
-        ]
-    )
-    sample_cin["CINreferralDate"] = pd.to_datetime(
-        sample_cin["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {CINdetails: sample_cin})
-
-    # The result contains a NamedTuple of issues encountered
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    issue_columns = issues.columns
-    assert issue_columns == [CINreferralDate, ReferralSource]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "ID1",
-                    pd.to_datetime("01/01/2020", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "ID2",
-                    pd.to_datetime("01/01/2020", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    assert result.definition.code == "8866"
-    assert (
-        result.definition.message == "Source of Referral is missing or an invalid code"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+CINreferralDate = CINdetails.CINreferralDate
+ReferralSource = CINdetails.ReferralSource
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8866'
+    code="8866",
+    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Source of Referral is missing or an invalid code",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        CINreferralDate,
+        ReferralSource,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # Replace CINdetails with the name of the table you need.
+    df = data_container[CINdetails]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+    df.reset_index(inplace=True)
+
+    valid_referrals = [
+        "1A",
+        "1B",
+        "1C",
+        "1D",
+        "2A",
+        "2B",
+        "3A",
+        "3B",
+        "3C",
+        "3D",
+        "3E",
+        "3F",
+        "4",
+        "5A",
+        "5B",
+        "5C",
+        "5D",
+        "6",
+        "7",
+        "8",
+        "9",
+        "10",
+    ]
+
+    # If <CinReferralDate> (N00100) is on or after 1 April 2013 then <ReferralSource> (N00152) must be present and must be a valid code
+    condition = (
+        df[CINreferralDate] >= pd.to_datetime("01/04/2013", format="%d/%m/%Y")
+    ) & ((df[ReferralSource].isna()) | (~df[ReferralSource].isin(valid_referrals)))
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error.
+
+    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
+    link_id = tuple(zip(df_issues[LAchildID], df_issues[CINreferralDate]))
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=CINdetails, columns=[CINreferralDate, ReferralSource], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+
+    #  Fails rows 0, 1, and 3
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "ID1",  # Fail
+                "CINreferralDate": "01/01/2020",
+                "ReferralSource": "1Z",
+            },
+            {
+                "LAchildID": "ID2",  # Fail
+                "CINreferralDate": "01/01/2020",
+                "ReferralSource": pd.NA,
+            },
+            {
+                "LAchildID": "ID3",
+                "CINreferralDate": "01/01/2000",
+                "ReferralSource": "1A",
+            },
+            {
+                "LAchildID": "ID4",
+                "CINreferralDate": "01/01/2012",  # ignore
+                "ReferralSource": "pd.NA",
+            },
+            {
+                "LAchildID": "ID4",
+                "CINreferralDate": "01/01/2020",
+                "ReferralSource": "1C",
+            },
+        ]
+    )
+    sample_cin["CINreferralDate"] = pd.to_datetime(
+        sample_cin["CINreferralDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {CINdetails: sample_cin})
+
+    # The result contains a NamedTuple of issues encountered
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    issue_columns = issues.columns
+    assert issue_columns == [CINreferralDate, ReferralSource]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "ID1",
+                    pd.to_datetime("01/01/2020", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "ID2",
+                    pd.to_datetime("01/01/2020", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    assert result.definition.code == "8866"
+    assert (
+        result.definition.message == "Source of Referral is missing or an invalid code"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8867.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8867.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,251 +1,251 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINdetails = CINTable.CINdetails
-CINclosureDate = CINdetails.CINclosureDate
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-
-Assessments = CINTable.Assessments
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-LAchildID = Assessments.LAchildID
-CINdetailsAssID = Assessments.CINdetailsID
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8867",
-    module=CINTable.CINdetails,
-    message="CIN episode is shown as closed, however Assessment is not shown as completed",
-    affected_fields=[
-        CINclosureDate,
-        AssessmentAuthorisationDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_cind = data_container[CINdetails].copy()
-    df_ass = data_container[Assessments].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cind.index.name = "ROW_ID"
-    df_ass.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_cind.reset_index(inplace=True)
-    df_ass.reset_index(inplace=True)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <CINclosureDate> (N00102) is present then all instances of the <Assessments> group must include the <AssesssmentAuthorisationDate> (N00160)
-    # Issues dfs should return rows where an AssessmentAuthorisationDate exists if a CINclosureDate has been recorded for that child.
-
-    #  Create dataframes which only have rows with a CINclosureDate and an AssessmentAuthorisation Date and which should have one plan per row.
-    df_cind = df_cind[df_cind[CINclosureDate].notna()]
-
-    #  Merge tables to get corresponding CP plan group and reviews
-    df_merged = df_cind.merge(
-        df_ass,
-        left_on=["LAchildID", "CINdetailsID"],
-        right_on=["LAchildID", "CINdetailsID"],
-        how="inner",
-        suffixes=("_cind", "_ass"),
-    )
-
-    #  Get rows where there is no AssessmentAuthorisationDate when a CINclosureDate is recorded.
-    condition = df_merged[AssessmentAuthorisationDate].isna()
-    df_merged = df_merged[condition].reset_index()
-
-    # create an identifier for each error instance.
-    # In this case, the rule is checked for each CINclosureDate and AssessmentAuthorisationDate in each child (differentiated by LAchildID)
-    # So, a combination of LAchildID, CINclosureDate and AssessmentAuthorisationDate identifies and error instance.
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[CINdetailsID],
-            df_merged[CINclosureDate],
-        )
-    )
-
-    # The merges were done on copies of df_cind and df_ass so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cind_issues = (
-        df_cind.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cind")
-        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_ass_issues = (
-        df_ass.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINclosureDate], row_df=df_cind_issues
-    )
-    rule_context.push_type_2(
-        table=Assessments, columns=[AssessmentAuthorisationDate], row_df=df_ass_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_cind = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID1",
-                "CINclosureDate": "30/06/2000",  # Pass
-            },
-            {
-                "LAchildID": "child2",
-                "CINdetailsID": "CDID2",
-                "CINclosureDate": "29/08/2002",  # Fails (no Assessment Authorisation Date entered)
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID3",
-                "CINclosureDate": "25/10/2002",  # Pass
-            },
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "CDID4",
-                "CINclosureDate": "10/06/2000",  # Pass
-            },
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "CDID5",
-                "CINclosureDate": "15/11/2001",  # Fails (no Assessment Authorisation Date entered)
-            },
-            {
-                "LAchildID": "child6",
-                "CINdetailsID": "CDID5",
-                "CINclosureDate": "15/11/2001",  # Passes, no Assessment module
-            },
-        ]
-    )
-
-    sample_ass = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "CDID1",
-                "AssessmentAuthorisationDate": "26/05/2000",  # Pass
-            },
-            {
-                "LAchildID": "child2",
-                "CINdetailsID": "CDID2",
-                "AssessmentAuthorisationDate": pd.NA,  # Fails (no date entered)
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "CDID3",
-                "AssessmentAuthorisationDate": "26/05/2000",  # Pass
-            },
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "CDID4",
-                "AssessmentAuthorisationDate": "30/05/2000",  # Pass
-            },
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "CDID5",
-                "AssessmentAuthorisationDate": pd.NA,  # Fails (no date entered)
-            },
-        ]
-    )
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cind[CINclosureDate] = pd.to_datetime(
-        sample_cind[CINclosureDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_ass[AssessmentAuthorisationDate] = pd.to_datetime(
-        sample_ass[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            CINdetails: sample_cind,
-            Assessments: sample_ass,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Assessments
-
-    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [AssessmentAuthorisationDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    "CDID2",  # CindetailsID
-                    # CIN Closure Date
-                    pd.to_datetime("29/08/2002", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child5",  # ChildID
-                    "CDID5",  # CindetailsID
-                    # CIN Closure Date
-                    pd.to_datetime("15/11/2001", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-    assert (issue_rows["ROW_ID"] == expected_df["ROW_ID"]).all()
-    assert (issue_rows["ERROR_ID"] == expected_df["ERROR_ID"]).all()
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    assert result.definition.code == "8867"
-    assert (
-        result.definition.message
-        == "CIN episode is shown as closed, however Assessment is not shown as completed"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+CINclosureDate = CINdetails.CINclosureDate
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+
+Assessments = CINTable.Assessments
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+LAchildID = Assessments.LAchildID
+CINdetailsAssID = Assessments.CINdetailsID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8867",
+    module=CINTable.CINdetails,
+    message="CIN episode is shown as closed, however Assessment is not shown as completed",
+    affected_fields=[
+        CINclosureDate,
+        AssessmentAuthorisationDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_cind = data_container[CINdetails].copy()
+    df_ass = data_container[Assessments].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cind.index.name = "ROW_ID"
+    df_ass.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_cind.reset_index(inplace=True)
+    df_ass.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <CINclosureDate> (N00102) is present then all instances of the <Assessments> group must include the <AssesssmentAuthorisationDate> (N00160)
+    # Issues dfs should return rows where an AssessmentAuthorisationDate exists if a CINclosureDate has been recorded for that child.
+
+    #  Create dataframes which only have rows with a CINclosureDate and an AssessmentAuthorisation Date and which should have one plan per row.
+    df_cind = df_cind[df_cind[CINclosureDate].notna()]
+
+    #  Merge tables to get corresponding CP plan group and reviews
+    df_merged = df_cind.merge(
+        df_ass,
+        left_on=["LAchildID", "CINdetailsID"],
+        right_on=["LAchildID", "CINdetailsID"],
+        how="inner",
+        suffixes=("_cind", "_ass"),
+    )
+
+    #  Get rows where there is no AssessmentAuthorisationDate when a CINclosureDate is recorded.
+    condition = df_merged[AssessmentAuthorisationDate].isna()
+    df_merged = df_merged[condition].reset_index()
+
+    # create an identifier for each error instance.
+    # In this case, the rule is checked for each CINclosureDate and AssessmentAuthorisationDate in each child (differentiated by LAchildID)
+    # So, a combination of LAchildID, CINclosureDate and AssessmentAuthorisationDate identifies and error instance.
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[CINdetailsID],
+            df_merged[CINclosureDate],
+        )
+    )
+
+    # The merges were done on copies of df_cind and df_ass so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_cind_issues = (
+        df_cind.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cind")
+        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_ass_issues = (
+        df_ass.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys="False")["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINclosureDate], row_df=df_cind_issues
+    )
+    rule_context.push_type_2(
+        table=Assessments, columns=[AssessmentAuthorisationDate], row_df=df_ass_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_cind = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID1",
+                "CINclosureDate": "30/06/2000",  # Pass
+            },
+            {
+                "LAchildID": "child2",
+                "CINdetailsID": "CDID2",
+                "CINclosureDate": "29/08/2002",  # Fails (no Assessment Authorisation Date entered)
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID3",
+                "CINclosureDate": "25/10/2002",  # Pass
+            },
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "CDID4",
+                "CINclosureDate": "10/06/2000",  # Pass
+            },
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "CDID5",
+                "CINclosureDate": "15/11/2001",  # Fails (no Assessment Authorisation Date entered)
+            },
+            {
+                "LAchildID": "child6",
+                "CINdetailsID": "CDID5",
+                "CINclosureDate": "15/11/2001",  # Passes, no Assessment module
+            },
+        ]
+    )
+
+    sample_ass = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "CDID1",
+                "AssessmentAuthorisationDate": "26/05/2000",  # Pass
+            },
+            {
+                "LAchildID": "child2",
+                "CINdetailsID": "CDID2",
+                "AssessmentAuthorisationDate": pd.NA,  # Fails (no date entered)
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "CDID3",
+                "AssessmentAuthorisationDate": "26/05/2000",  # Pass
+            },
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "CDID4",
+                "AssessmentAuthorisationDate": "30/05/2000",  # Pass
+            },
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "CDID5",
+                "AssessmentAuthorisationDate": pd.NA,  # Fails (no date entered)
+            },
+        ]
+    )
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cind[CINclosureDate] = pd.to_datetime(
+        sample_cind[CINclosureDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_ass[AssessmentAuthorisationDate] = pd.to_datetime(
+        sample_ass[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            CINdetails: sample_cind,
+            Assessments: sample_ass,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Assessments
+
+    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [AssessmentAuthorisationDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    "CDID2",  # CindetailsID
+                    # CIN Closure Date
+                    pd.to_datetime("29/08/2002", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child5",  # ChildID
+                    "CDID5",  # CindetailsID
+                    # CIN Closure Date
+                    pd.to_datetime("15/11/2001", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+    assert (issue_rows["ROW_ID"] == expected_df["ROW_ID"]).all()
+    assert (issue_rows["ERROR_ID"] == expected_df["ERROR_ID"]).all()
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    assert result.definition.code == "8867"
+    assert (
+        result.definition.message
+        == "CIN episode is shown as closed, however Assessment is not shown as completed"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8868.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8868.py`

 * *Ordering differences only*

 * *Files 22% similar despite different names*

```diff
@@ -1,276 +1,276 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-CINdetails = CINTable.CINdetails
-Section47 = CINTable.Section47
-
-CINclosureDate = CINdetails.CINclosureDate
-LAchildID = CINdetails.LAchildID
-CINdetailsID = CINdetails.CINdetailsID
-DateOfInitialCPC = Section47.DateOfInitialCPC
-ICPCnotRequired = Section47.ICPCnotRequired
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8868",
-    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.CINdetails,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="CIN episode is shown as closed, however Section 47 enquiry is not shown as completed by ICPC date or ICPC not required flag",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        ICPCnotRequired,
-        CINclosureDate,
-        DateOfInitialCPC,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_47 = data_container[Section47].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_47.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    df_47.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # If <CINclosureDate> (N00102) is present then all instances of the <Section47> group must either
-    # i) include the <DateOfInitialCPC> (N00110) or
-    # ii) include <ICPCnotRequired> (N00111) with a value of true or 1
-
-    CINclosure_present = df_cin[df_cin[CINclosureDate].notna()]
-
-    # Children with no s47 module must be excluded to prevent falsely flagging them, done usig inner merge.
-    merged_df = CINclosure_present.merge(
-        df_47,
-        on=[
-            LAchildID,
-            "CINdetailsID",
-        ],
-        how="inner",
-        suffixes=["_cin", "_47"],
-    )
-
-    # Checks DateOfInitialCPC from s47 model
-    condition_1 = (merged_df["DateOfInitialCPC_47"].isna()) & (
-        ~merged_df[ICPCnotRequired].isin(["1", "true"])
-    )
-    condition_2 = (merged_df["DateOfInitialCPC_47"].notna()) & (
-        merged_df[ICPCnotRequired].isin(["1", "true"])
-    )
-
-    # get all the data that fits the failing condition.
-    merged_df = merged_df[condition_1 | condition_2].reset_index()
-
-    # create an identifier for each error instance.
-    merged_df["ERROR_ID"] = tuple(zip(merged_df[LAchildID], merged_df[CINdetailsID]))
-
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_47_issues = (
-        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-
-    rule_context.push_type_2(
-        table=Section47,
-        columns=[DateOfInitialCPC, ICPCnotRequired],
-        row_df=df_47_issues,
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[CINclosureDate], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_section47 = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "DateOfInitialCPC": pd.NA,  # 0 fail: DateOfInitialCPC missing and ICPCnotRequired false
-                "ICPCnotRequired": "false",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",
-                "DateOfInitialCPC": pd.NA,  # 1 pass ICPCnotRequired true
-                "ICPCnotRequired": "true",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child2",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "1",  # 2 pass ICPCnotRequired true
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "27/05/2000",  # 3 pass DateOfInitialCPC present
-                "ICPCnotRequired": "false",
-                "CINdetailsID": "cinID1",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/10/1999",  # 4 fail
-                "ICPCnotRequired": "nottrue",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child3",
-                "DateOfInitialCPC": "26/05/2000",  # 5 pass DateOfInitialCPC present
-                "ICPCnotRequired": "1",
-                "CINdetailsID": "cinID2",
-            },
-            {
-                "LAchildID": "child4",
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "false",  # 6 ignore
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-    sample_cin = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 fail: contains a section47 group that fails.
-                "CINclosureDate": "26/10/1999",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": "26/10/2001",
-            },
-            {
-                "LAchildID": "child1",  # 1 pass
-                "CINclosureDate": "26/05/2000",
-                "CINdetailsID": "cinID2",
-                "DateOfInitialCPC": pd.NA,
-            },
-            {
-                "LAchildID": "child2",  # 2
-                "CINclosureDate": "26/05/2000",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # 3 pass
-                "CINclosureDate": "28/05/2000",
-                "CINdetailsID": "cinID1",
-                "DateOfInitialCPC": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # 4 fail: contains a section47 group that fails.
-                "CINclosureDate": "26/05/2000",
-                "CINdetailsID": "cinID2",
-                "DateOfInitialCPC": pd.NA,
-            },
-            {
-                "LAchildID": "child3",  # 5 Pass, not present in section47 table so none of the values meets the requirements
-                "CINclosureDate": "26/05/2003",
-                "CINdetailsID": "cinID3",
-                "DateOfInitialCPC": pd.NA,
-            },
-            {
-                "LAchildID": "child4",
-                "CINclosureDate": pd.NA,  # 6 ignore: date absent
-                "CINdetailsID": "cinID4",
-                "DateOfInitialCPC": pd.NA,
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cin[CINclosureDate] = pd.to_datetime(
-        sample_cin[CINclosureDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
-        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cin["DateOfInitialCPC"] = pd.to_datetime(
-        sample_cin["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            Section47: sample_section47,
-            CINdetails: sample_cin,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the CINdetails columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace CINdetails with the name of your table.
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    # check that the right columns were returned. Replace CINclosureDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [CINclosureDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    "cinID1",  # CINdetailsID
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID2",  # CINdetailsID
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8868' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8868"
-    assert (
-        result.definition.message
-        == "CIN episode is shown as closed, however Section 47 enquiry is not shown as completed by ICPC date or ICPC not required flag"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+CINdetails = CINTable.CINdetails
+Section47 = CINTable.Section47
+
+CINclosureDate = CINdetails.CINclosureDate
+LAchildID = CINdetails.LAchildID
+CINdetailsID = CINdetails.CINdetailsID
+DateOfInitialCPC = Section47.DateOfInitialCPC
+ICPCnotRequired = Section47.ICPCnotRequired
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8868",
+    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="CIN episode is shown as closed, however Section 47 enquiry is not shown as completed by ICPC date or ICPC not required flag",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        ICPCnotRequired,
+        CINclosureDate,
+        DateOfInitialCPC,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_47 = data_container[Section47].copy()
+    df_cin = data_container[CINdetails].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_47.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    df_47.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # If <CINclosureDate> (N00102) is present then all instances of the <Section47> group must either
+    # i) include the <DateOfInitialCPC> (N00110) or
+    # ii) include <ICPCnotRequired> (N00111) with a value of true or 1
+
+    CINclosure_present = df_cin[df_cin[CINclosureDate].notna()]
+
+    # Children with no s47 module must be excluded to prevent falsely flagging them, done usig inner merge.
+    merged_df = CINclosure_present.merge(
+        df_47,
+        on=[
+            LAchildID,
+            "CINdetailsID",
+        ],
+        how="inner",
+        suffixes=["_cin", "_47"],
+    )
+
+    # Checks DateOfInitialCPC from s47 model
+    condition_1 = (merged_df["DateOfInitialCPC_47"].isna()) & (
+        ~merged_df[ICPCnotRequired].isin(["1", "true"])
+    )
+    condition_2 = (merged_df["DateOfInitialCPC_47"].notna()) & (
+        merged_df[ICPCnotRequired].isin(["1", "true"])
+    )
+
+    # get all the data that fits the failing condition.
+    merged_df = merged_df[condition_1 | condition_2].reset_index()
+
+    # create an identifier for each error instance.
+    merged_df["ERROR_ID"] = tuple(zip(merged_df[LAchildID], merged_df[CINdetailsID]))
+
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_47_issues = (
+        df_47.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+
+    rule_context.push_type_2(
+        table=Section47,
+        columns=[DateOfInitialCPC, ICPCnotRequired],
+        row_df=df_47_issues,
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[CINclosureDate], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_section47 = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "DateOfInitialCPC": pd.NA,  # 0 fail: DateOfInitialCPC missing and ICPCnotRequired false
+                "ICPCnotRequired": "false",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",
+                "DateOfInitialCPC": pd.NA,  # 1 pass ICPCnotRequired true
+                "ICPCnotRequired": "true",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child2",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "1",  # 2 pass ICPCnotRequired true
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "27/05/2000",  # 3 pass DateOfInitialCPC present
+                "ICPCnotRequired": "false",
+                "CINdetailsID": "cinID1",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/10/1999",  # 4 fail
+                "ICPCnotRequired": "nottrue",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child3",
+                "DateOfInitialCPC": "26/05/2000",  # 5 pass DateOfInitialCPC present
+                "ICPCnotRequired": "1",
+                "CINdetailsID": "cinID2",
+            },
+            {
+                "LAchildID": "child4",
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "false",  # 6 ignore
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+    sample_cin = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # 0 fail: contains a section47 group that fails.
+                "CINclosureDate": "26/10/1999",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": "26/10/2001",
+            },
+            {
+                "LAchildID": "child1",  # 1 pass
+                "CINclosureDate": "26/05/2000",
+                "CINdetailsID": "cinID2",
+                "DateOfInitialCPC": pd.NA,
+            },
+            {
+                "LAchildID": "child2",  # 2
+                "CINclosureDate": "26/05/2000",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # 3 pass
+                "CINclosureDate": "28/05/2000",
+                "CINdetailsID": "cinID1",
+                "DateOfInitialCPC": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # 4 fail: contains a section47 group that fails.
+                "CINclosureDate": "26/05/2000",
+                "CINdetailsID": "cinID2",
+                "DateOfInitialCPC": pd.NA,
+            },
+            {
+                "LAchildID": "child3",  # 5 Pass, not present in section47 table so none of the values meets the requirements
+                "CINclosureDate": "26/05/2003",
+                "CINdetailsID": "cinID3",
+                "DateOfInitialCPC": pd.NA,
+            },
+            {
+                "LAchildID": "child4",
+                "CINclosureDate": pd.NA,  # 6 ignore: date absent
+                "CINdetailsID": "cinID4",
+                "DateOfInitialCPC": pd.NA,
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cin[CINclosureDate] = pd.to_datetime(
+        sample_cin[CINclosureDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_section47["DateOfInitialCPC"] = pd.to_datetime(
+        sample_section47["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cin["DateOfInitialCPC"] = pd.to_datetime(
+        sample_cin["DateOfInitialCPC"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            Section47: sample_section47,
+            CINdetails: sample_cin,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the CINdetails columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace CINdetails with the name of your table.
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    # check that the right columns were returned. Replace CINclosureDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [CINclosureDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    "cinID1",  # CINdetailsID
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID2",  # CINdetailsID
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8868' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8868"
+    assert (
+        result.definition.message
+        == "CIN episode is shown as closed, however Section 47 enquiry is not shown as completed by ICPC date or ICPC not required flag"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8869.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8869.py`

 * *Ordering differences only*

 * *Files 18% similar despite different names*

```diff
@@ -1,130 +1,130 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-LAchildID = Assessments.LAchildID
-AssessmentFactors = Assessments.AssessmentFactors
-CINdetailsID = Assessments.CINdetailsID
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here
-    code="8869",
-    # replace Assessments with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.Assessments,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="The assessment factors code “21” cannot be used in conjunction with any other assessment factors.",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        AssessmentFactors,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df = data_container[Assessments].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df.reset_index(inplace=True)
-
-    # lOGIC
-    # If <AssessmentFactors> (N00181) = “21”, this must be the only <AssessmentFactors> (N00181) present.
-    df_orig = df.copy()
-
-    df = df[(df[AssessmentFactors].astype(str) == "21")]
-
-    #  Merge tables
-    df = df.merge(
-        df_orig,
-        how="left",
-        on=[LAchildID, CINdetailsID, AssessmentAuthorisationDate],
-        suffixes=["", "_orig"],
-    )
-
-    # Values that aren't 21 are now errors (using guidelines from rule 8790)
-    df = df[df["AssessmentFactors_orig"] != "21"]
-
-    failing_indices = df.set_index("ROW_ID_orig").index
-
-    rule_context.push_issue(
-        table=Assessments, field=AssessmentFactors, row=failing_indices
-    )
-
-
-def test_validate():
-    # 0      #1      #2      #3     #4      #5      #6      #7
-    ids = ["1", "1", "2", "3", "3", "4", "4", "5", "6", "6", "6"]
-    cinid = ["1", "1", "2", "3", "3", "4", "4", "5", "6", "6", "6"]
-    assessmentfactors = [
-        "21",
-        "AIND",  # id1, cinid1 fail. same assessment period has factor 21
-        "NONE",
-        pd.NA,
-        "MOTH",
-        "21",
-        "AAAA",  # id4, cinid4 fail. same assessment period has factor 21
-        "AA",
-        "21",
-        "14",  # ignored. not the same auth date as preceding.
-        "15",
-    ]
-    # non-date placeholders can be used since this rule doesn't require date-object properties.
-    assessmentauthorisationdate = [
-        "1",
-        "1",
-        "2",
-        "3",
-        "3",
-        "4",
-        "4",
-        "5",
-        "2021-02-09",
-        "2020-12-15",
-        "2020-12-15",
-    ]
-
-    fake_df = pd.DataFrame(
-        {
-            "LAchildID": ids,
-            "CINdetailsID": cinid,
-            "AssessmentFactors": assessmentfactors,
-            "AssessmentAuthorisationDate": assessmentauthorisationdate,
-        }
-    )
-
-    result = run_rule(validate, {Assessments: fake_df})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 2
-
-    assert issues == [
-        IssueLocator(CINTable.Assessments, AssessmentFactors, 1),
-        IssueLocator(CINTable.Assessments, AssessmentFactors, 6),
-    ]
-
-    assert result.definition.code == "8869"
-    assert (
-        result.definition.message
-        == "The assessment factors code “21” cannot be used in conjunction with any other assessment factors."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+LAchildID = Assessments.LAchildID
+AssessmentFactors = Assessments.AssessmentFactors
+CINdetailsID = Assessments.CINdetailsID
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here
+    code="8869",
+    # replace Assessments with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.Assessments,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="The assessment factors code “21” cannot be used in conjunction with any other assessment factors.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        AssessmentFactors,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df = data_container[Assessments].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df.reset_index(inplace=True)
+
+    # lOGIC
+    # If <AssessmentFactors> (N00181) = “21”, this must be the only <AssessmentFactors> (N00181) present.
+    df_orig = df.copy()
+
+    df = df[(df[AssessmentFactors].astype(str) == "21")]
+
+    #  Merge tables
+    df = df.merge(
+        df_orig,
+        how="left",
+        on=[LAchildID, CINdetailsID, AssessmentAuthorisationDate],
+        suffixes=["", "_orig"],
+    )
+
+    # Values that aren't 21 are now errors (using guidelines from rule 8790)
+    df = df[df["AssessmentFactors_orig"] != "21"]
+
+    failing_indices = df.set_index("ROW_ID_orig").index
+
+    rule_context.push_issue(
+        table=Assessments, field=AssessmentFactors, row=failing_indices
+    )
+
+
+def test_validate():
+    # 0      #1      #2      #3     #4      #5      #6      #7
+    ids = ["1", "1", "2", "3", "3", "4", "4", "5", "6", "6", "6"]
+    cinid = ["1", "1", "2", "3", "3", "4", "4", "5", "6", "6", "6"]
+    assessmentfactors = [
+        "21",
+        "AIND",  # id1, cinid1 fail. same assessment period has factor 21
+        "NONE",
+        pd.NA,
+        "MOTH",
+        "21",
+        "AAAA",  # id4, cinid4 fail. same assessment period has factor 21
+        "AA",
+        "21",
+        "14",  # ignored. not the same auth date as preceding.
+        "15",
+    ]
+    # non-date placeholders can be used since this rule doesn't require date-object properties.
+    assessmentauthorisationdate = [
+        "1",
+        "1",
+        "2",
+        "3",
+        "3",
+        "4",
+        "4",
+        "5",
+        "2021-02-09",
+        "2020-12-15",
+        "2020-12-15",
+    ]
+
+    fake_df = pd.DataFrame(
+        {
+            "LAchildID": ids,
+            "CINdetailsID": cinid,
+            "AssessmentFactors": assessmentfactors,
+            "AssessmentAuthorisationDate": assessmentauthorisationdate,
+        }
+    )
+
+    result = run_rule(validate, {Assessments: fake_df})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 2
+
+    assert issues == [
+        IssueLocator(CINTable.Assessments, AssessmentFactors, 1),
+        IssueLocator(CINTable.Assessments, AssessmentFactors, 6),
+    ]
+
+    assert result.definition.code == "8869"
+    assert (
+        result.definition.message
+        == "The assessment factors code “21” cannot be used in conjunction with any other assessment factors."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8870Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8870Q.py`

 * *Ordering differences only*

 * *Files 9% similar despite different names*

```diff
@@ -1,81 +1,81 @@
-"""
-Rule number: 8870Q
-Module: Section 47
-Rule details: Where present, the <InitialCPCtarget> (N00109) should not be a Saturday, Sunday
-
-Rule message: Please check: The Target Date for Initial Child Protection Conference should not be a weekend
-
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    RuleType,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-InitialCPCtarget = Section47.InitialCPCtarget
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8870Q",
-    module=CINTable.Section47,
-    rule_type=RuleType.QUERY,
-    message="Please check and either amend or provide a reason: The Target Date for Initial Child Protection Conference should not be a weekend",
-    affected_fields=[InitialCPCtarget],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Section47]
-
-    # <InitialCPCtarget> (N00109) should not be a Saturday, Sunday
-    # Convert column to date format
-    df[InitialCPCtarget] = pd.to_datetime(
-        df[InitialCPCtarget], format="%d-%m-%Y", errors="coerce"
-    )
-
-    # .weekday() returns the integer value for each day (0-6) with weekends being 5 and 6
-    failing_indices = df[df[InitialCPCtarget].dt.weekday >= 5].index
-
-    rule_context.push_issue(
-        table=Section47, field=InitialCPCtarget, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    child_identifiers = pd.DataFrame(
-        [["17-06-2021"], ["09-10-2022"], ["14-03-2020"]], columns=[InitialCPCtarget]
-    )  # 9/10 is a Sunday and 14/3 is a Saturday
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Section47: child_identifiers})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.Section47, InitialCPCtarget, 1),
-        IssueLocator(CINTable.Section47, InitialCPCtarget, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    assert result.definition.code == "8870Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend or provide a reason: The Target Date for Initial Child Protection Conference should not be a weekend"
-    )
+"""
+Rule number: 8870Q
+Module: Section 47
+Rule details: Where present, the <InitialCPCtarget> (N00109) should not be a Saturday, Sunday
+
+Rule message: Please check: The Target Date for Initial Child Protection Conference should not be a weekend
+
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    RuleType,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+InitialCPCtarget = Section47.InitialCPCtarget
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8870Q",
+    module=CINTable.Section47,
+    rule_type=RuleType.QUERY,
+    message="Please check and either amend or provide a reason: The Target Date for Initial Child Protection Conference should not be a weekend",
+    affected_fields=[InitialCPCtarget],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Section47]
+
+    # <InitialCPCtarget> (N00109) should not be a Saturday, Sunday
+    # Convert column to date format
+    df[InitialCPCtarget] = pd.to_datetime(
+        df[InitialCPCtarget], format="%d-%m-%Y", errors="coerce"
+    )
+
+    # .weekday() returns the integer value for each day (0-6) with weekends being 5 and 6
+    failing_indices = df[df[InitialCPCtarget].dt.weekday >= 5].index
+
+    rule_context.push_issue(
+        table=Section47, field=InitialCPCtarget, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_identifiers = pd.DataFrame(
+        [["17-06-2021"], ["09-10-2022"], ["14-03-2020"]], columns=[InitialCPCtarget]
+    )  # 9/10 is a Sunday and 14/3 is a Saturday
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Section47: child_identifiers})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.Section47, InitialCPCtarget, 1),
+        IssueLocator(CINTable.Section47, InitialCPCtarget, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    assert result.definition.code == "8870Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend or provide a reason: The Target Date for Initial Child Protection Conference should not be a weekend"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8873Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8873Q.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,281 +1,307 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-LAchildID = Assessments.LAchildID
-AssessmentFactors = Assessments.AssessmentFactors
-CINdetailsID = Assessments.CINdetailsID
-AssessmentActualStartDate = Assessments.AssessmentActualStartDate
-
-CINdetails = CINTable.CINdetails
-LAchildID = CINdetails.LAchildID
-CINdetailsID_cin = CINdetails.CINdetailsID
-ReasonForClosure = CINdetails.ReasonForClosure
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of 8873Q
-    code="8873Q",
-    # replace Assesments with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.Assessments,
-    rule_type=RuleType.QUERY,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Please check and either amend data or provide a reason: When there is only one assessment on the episode and the factors code “21 No factors identified” has been used for the completed assessment, the reason for closure ‘RC8’ or 'RC9' should be used.",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[ReasonForClosure, AssessmentFactors],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_ass = data_container[Assessments].copy()
-    df_cin = data_container[CINdetails].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_ass.index.name = "ROW_ID"
-    df_cin.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_ass.reset_index(inplace=True)
-    df_cin.reset_index(inplace=True)
-
-    # lOGIC
-    # Within a <CINDetails> group, if there is only one <Assessment> group present and <AssessmentFactors> (N00181) = “21”, <ReasonForClosure> (N00103) must should = RC8 or RC9.
-
-    # Eliminates rows with more than 1 assessment per CINdetails group by determining if there's more than 1 AssessmentActualStartDate per CINdetailsID per child
-    df_ass_merged = df_ass.merge(df_ass, on=["LAchildID", "CINdetailsID"])
-    df_ass_merged = df_ass_merged[
-        (
-            df_ass_merged["AssessmentActualStartDate_x"]
-            != df_ass_merged["AssessmentActualStartDate_y"]
-        )
-    ]
-    more_than_1_ass = df_ass_merged["ROW_ID_x"].tolist()
-
-    df_ass = df_ass[~df_ass["ROW_ID"].isin(more_than_1_ass)]
-
-    df_ass = df_ass[
-        (df_ass[AssessmentFactors] == "21")
-        | (df_ass[AssessmentFactors] == "21 No factors identified")
-        | (df_ass[AssessmentFactors].str.contains("21"))
-    ]
-
-    # left merge means that only the filtered cpp children will be considered and there is no possibility of additonal children coming in from other tables.
-
-    # get only the CINdetails groups with AssessmentFactors including 21.
-    merged_df = df_ass.copy().merge(
-        df_cin.copy(),
-        on=[LAchildID, "CINdetailsID"],
-        how="left",
-        suffixes=["_ass", "_cin"],
-    )
-
-    # Fails rows where reason for closure is not RC8 or RC9.
-    condition = ~merged_df["ReasonForClosure"].isin(["RC8", "RC9"])
-
-    # get all the data that fits the failing condition.
-    merged_df = merged_df[condition].reset_index()
-
-    # create an identifier for each error instance.
-    merged_df["ERROR_ID"] = tuple(
-        zip(merged_df[LAchildID], merged_df[CINdetailsID], merged_df[ReasonForClosure])
-    )
-
-    # The merges were done on copies of df_ass, and df_cin so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_ass_issues = (
-        df_ass.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ass")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cin_issues = (
-        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=Assessments, columns=[AssessmentFactors], row_df=df_ass_issues
-    )
-    rule_context.push_type_2(
-        table=CINdetails, columns=[ReasonForClosure], row_df=df_cin_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_ass = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "AssessmentFactors": "21",  # 0 pass
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {
-                "LAchildID": "child1",
-                "AssessmentFactors": "BOO",  # 1 ignore: factor!=21
-                "CINdetailsID": "cinID2",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {
-                "LAchildID": "child2",
-                "AssessmentFactors": "BOO",  # 2 ignore: factor!=21
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {
-                "LAchildID": "child3",
-                "AssessmentFactors": "21",  # 3 fail. reason!=RC8
-                "CINdetailsID": "cinID1",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {  # absent
-                "LAchildID": "child3",
-                "AssessmentFactors": pd.NA,  # 4 ignore: factor!=21
-                "CINdetailsID": "cinID2",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {  # fail
-                "LAchildID": "child3",
-                "AssessmentFactors": "21",  # 5 fail. reason!=RC8
-                "CINdetailsID": "cinID3",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {
-                "LAchildID": "child3",
-                "AssessmentFactors": "21",  # ignore: more than one assessment in CIN episode
-                "CINdetailsID": "cinID4",
-                "AssessmentActualStartDate": "5/12/1993",
-            },
-            {
-                "LAchildID": "child3",
-                "AssessmentFactors": "20",  # 6 ignore: factor!=21
-                "CINdetailsID": "cinID4",
-                "AssessmentActualStartDate": "5/12/1994",
-            },
-        ]
-    )
-    sample_cin = pd.DataFrame(
-        [
-            {  # 0 pass
-                "LAchildID": "child1",
-                "ReasonForClosure": "RC8",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 1 ignored
-                "LAchildID": "child1",
-                "ReasonForClosure": "RC3",
-                "CINdetailsID": "cinID2",
-            },
-            {  # 2 pass
-                "LAchildID": "child2",
-                "ReasonForClosure": "RC8",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 3 fail
-                "LAchildID": "child3",
-                "ReasonForClosure": "RC10",
-                "CINdetailsID": "cinID1",
-            },
-            {  # 4, ignored
-                "LAchildID": "child3",
-                "ReasonForClosure": "RC9",
-                "CINdetailsID": "cinID2",
-            },
-            {  # 5 fail
-                "LAchildID": "child3",
-                "ReasonForClosure": "RC10",
-                "CINdetailsID": "cinID3",
-            },
-            {  # 6 pass
-                "LAchildID": "child3",
-                "ReasonForClosure": "RC10",
-                "CINdetailsID": "cinID4",
-            },
-        ]
-    )
-
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            Assessments: sample_ass,
-            CINdetails: sample_cin,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Section47 columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Section47 with the name of your table.
-    issue_table = issues.table
-    assert issue_table == CINdetails
-
-    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [ReasonForClosure]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    "cinID1",  # CINdetailsID
-                    # corresponding CPPstartDate
-                    "RC10",
-                ),
-                "ROW_ID": [3],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID3",
-                    "RC10",
-                ),
-                "ROW_ID": [5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8873Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8873Q"
-    assert (
-        result.definition.message
-        == "Please check and either amend data or provide a reason: When there is only one assessment on the episode and the factors code “21 No factors identified” has been used for the completed assessment, the reason for closure ‘RC8’ or 'RC9' should be used."
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+LAchildID = Assessments.LAchildID
+CINdetailsID = Assessments.CINdetailsID
+AssessmentID = Assessments.AssessmentID
+AssessmentActualStartDate = Assessments.AssessmentActualStartDate
+AssessmentFactors = Assessments.AssessmentFactors
+
+AssessmentFactorsList = CINTable.AssessmentFactorsList
+AssessmentFactor = AssessmentFactorsList.AssessmentFactor
+
+CINdetails = CINTable.CINdetails
+LAchildID = CINdetails.LAchildID
+CINdetailsID_cin = CINdetails.CINdetailsID
+ReasonForClosure = CINdetails.ReasonForClosure
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of 8873Q
+    code="8873Q",
+    # replace Assesments with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.Assessments,
+    rule_type=RuleType.QUERY,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Please check and either amend data or provide a reason: When there is only one assessment on the episode and the factors code “21 No factors identified” has been used for the completed assessment, the reason for closure ‘RC8’ or 'RC9' should be used.",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[ReasonForClosure, AssessmentFactors],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_ass = data_container[Assessments].copy()
+    df_asslist = data_container[AssessmentFactorsList].copy()
+    df_cin = data_container[CINdetails].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_ass.index.name = "ROW_ID"
+    df_asslist.index.name = "ROW_ID"
+    df_cin.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_ass.reset_index(inplace=True)
+    df_asslist.reset_index(inplace=True)
+    df_cin.reset_index(inplace=True)
+
+    # lOGIC
+    # Within a <CINDetails> group, if there is only one <Assessment> group present and <AssessmentFactors> (N00181) = “21”, <ReasonForClosure> (N00103) must should = RC8 or RC9.
+
+    # Eliminates rows with more than 1 assessment per CINdetails group by determining if there's more than 1 AssessmentID per CINdetailsID per child
+    df_ass_merged = df_ass.merge(df_ass, on=["LAchildID", "CINdetailsID"])
+    df_ass_merged = df_ass_merged[
+        (df_ass_merged["AssessmentID_x"] != df_ass_merged["AssessmentID_y"])
+    ]
+    more_than_1_ass = df_ass_merged["ROW_ID_x"].tolist()
+
+    df_ass = df_ass[~df_ass["ROW_ID"].isin(more_than_1_ass)]
+
+    df_ass_merged = df_ass.merge(
+        df_asslist[["LAchildID", "CINdetailsID", "AssessmentID", "AssessmentFactor"]],
+        on=["LAchildID", "CINdetailsID", "AssessmentID"],
+    )
+
+    df_ass_merged = df_ass_merged[
+        (df_ass_merged[AssessmentFactor] == "2B")
+        | (df_ass_merged[AssessmentFactor] == "21 No factors identified")
+        | (df_ass_merged[AssessmentFactor].str.contains("21"))
+    ]
+
+    # left merge means that only the filtered cin children will be considered and there is no possibility of additonal children coming in from other tables.
+
+    # get only the CINdetails groups with AssessmentFactors including 21.
+    merged_df = df_ass_merged.merge(
+        df_cin,
+        on=[LAchildID, "CINdetailsID"],
+        how="left",
+        suffixes=["_ass", "_cin"],
+    )
+
+    # Fails rows where reason for closure is not RC8 or RC9.
+    condition = ~merged_df["ReasonForClosure"].isin(["RC8", "RC9"])
+
+    # get all the data that fits the failing condition.
+    merged_df = merged_df[condition].reset_index()
+
+    # create an identifier for each error instance.
+    merged_df["ERROR_ID"] = tuple(
+        zip(
+            merged_df[LAchildID],
+            merged_df[CINdetailsID],
+            merged_df[AssessmentID],
+            merged_df[ReasonForClosure],
+        )
+    )
+
+    # The merges were done on copies of df_ass, and df_cin so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_ass_issues = (
+        df_ass.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_ass")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cin_issues = (
+        df_cin.merge(merged_df, left_on="ROW_ID", right_on="ROW_ID_cin")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=Assessments, columns=[AssessmentFactors], row_df=df_ass_issues
+    )
+    rule_context.push_type_2(
+        table=CINdetails, columns=[ReasonForClosure], row_df=df_cin_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_ass = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "AssessmentFactors": "21",  # 0 pass
+                "CINdetailsID": "cinID1",
+                "AssessmentID": "11",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {
+                "LAchildID": "child1",
+                "AssessmentFactors": "BOO",  # 1 ignore: factor!=21
+                "CINdetailsID": "cinID2",
+                "AssessmentID": "12",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {
+                "LAchildID": "child2",
+                "AssessmentFactors": "BOO",  # 2 ignore: factor!=21
+                "CINdetailsID": "cinID1",
+                "AssessmentID": "21",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {
+                "LAchildID": "child3",
+                "AssessmentFactors": "21",  # 3 fail. reason!=RC8
+                "CINdetailsID": "cinID1",
+                "AssessmentID": "31",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {  # absent
+                "LAchildID": "child3",
+                "AssessmentFactors": pd.NA,  # 4 ignore: factor!=21
+                "CINdetailsID": "cinID2",
+                "AssessmentID": "32",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {  # fail
+                "LAchildID": "child3",
+                "AssessmentFactors": "21",  # 5 fail. reason!=RC8
+                "CINdetailsID": "cinID3",
+                "AssessmentID": "33",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {
+                "LAchildID": "child3",
+                "AssessmentFactors": "21",  # ignore: more than one assessment in CIN episode
+                "CINdetailsID": "cinID4",
+                "AssessmentID": "34",
+                "AssessmentActualStartDate": "5/12/1993",
+            },
+            {
+                "LAchildID": "child3",
+                "AssessmentFactors": "20",  # 6 ignore: factor!=21
+                "CINdetailsID": "cinID4",
+                "AssessmentID": "35",
+                "AssessmentActualStartDate": "5/12/1994",
+            },
+        ]
+    )
+    sample_cin = pd.DataFrame(
+        [
+            {  # 0 pass
+                "LAchildID": "child1",
+                "ReasonForClosure": "RC8",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 1 ignored
+                "LAchildID": "child1",
+                "ReasonForClosure": "RC3",
+                "CINdetailsID": "cinID2",
+            },
+            {  # 2 pass
+                "LAchildID": "child2",
+                "ReasonForClosure": "RC8",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 3 fail
+                "LAchildID": "child3",
+                "ReasonForClosure": "RC10",
+                "CINdetailsID": "cinID1",
+            },
+            {  # 4, ignored
+                "LAchildID": "child3",
+                "ReasonForClosure": "RC9",
+                "CINdetailsID": "cinID2",
+            },
+            {  # 5 fail
+                "LAchildID": "child3",
+                "ReasonForClosure": "RC10",
+                "CINdetailsID": "cinID3",
+            },
+            {  # 6 pass
+                "LAchildID": "child3",
+                "ReasonForClosure": "RC10",
+                "CINdetailsID": "cinID4",
+            },
+        ]
+    )
+
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            Assessments: sample_ass,
+            AssessmentFactorsList: sample_ass.rename(
+                columns={"AssessmentFactors": "AssessmentFactor"}
+            ),
+            CINdetails: sample_cin,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the Section47 columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace Section47 with the name of your table.
+    issue_table = issues.table
+    assert issue_table == CINdetails
+
+    # check that the right columns were returned. Replace DateOfInitialCPC  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [ReasonForClosure]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    "cinID1",  # CINdetailsID
+                    "31",  # AssessmentID
+                    "RC10",
+                ),
+                "ROW_ID": [3],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID3",
+                    "33",
+                    "RC10",
+                ),
+                "ROW_ID": [5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8873Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8873Q"
+    assert (
+        result.definition.message
+        == "Please check and either amend data or provide a reason: When there is only one assessment on the episode and the factors code “21 No factors identified” has been used for the completed assessment, the reason for closure ‘RC8’ or 'RC9' should be used."
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8875.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8875.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,80 +1,80 @@
-"""
-Rule number: '8875'
-Module: Section 47
-Rule details: Where present, the <DateOfInitialCPC> (N00110) must not be a Saturday, Sunday
-Rule message: The Date of Initial Child Protection Conference cannot be a weekend
-
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-DateOfInitialCPC = Section47.DateOfInitialCPC
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8875",
-    module=CINTable.Section47,
-    message="The Date of Initial Child Protection Conference cannot be a weekend",
-    affected_fields=[DateOfInitialCPC],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[Section47]
-    # <DateOfInitialCPC> should not be a Saturday, Sunday
-    # .weekday() returns the integer value for each day (0-6) with weekends being 5 and 6
-    failing_indices = df[df[DateOfInitialCPC].dt.weekday >= 5].index
-
-    rule_context.push_issue(
-        table=Section47, field=DateOfInitialCPC, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    child_identifiers = pd.DataFrame(
-        [
-            {"DateOfInitialCPC": "17/06/2021"},  # Pass
-            {"DateOfInitialCPC": "09/10/2022"},  # Fail, Sunday
-            {"DateOfInitialCPC": "14/03/2020"},  # Fail, Saturday
-        ],
-    )  # 9/10 is a Sunday and 14/3 is a Saturday
-
-    child_identifiers[DateOfInitialCPC] = pd.to_datetime(
-        child_identifiers[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Section47: child_identifiers})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.Section47, DateOfInitialCPC, 1),
-        IssueLocator(CINTable.Section47, DateOfInitialCPC, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    assert result.definition.code == "8875"
-    assert (
-        result.definition.message
-        == "The Date of Initial Child Protection Conference cannot be a weekend"
-    )
+"""
+Rule number: '8875'
+Module: Section 47
+Rule details: Where present, the <DateOfInitialCPC> (N00110) must not be a Saturday, Sunday
+Rule message: The Date of Initial Child Protection Conference cannot be a weekend
+
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+DateOfInitialCPC = Section47.DateOfInitialCPC
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8875",
+    module=CINTable.Section47,
+    message="The Date of Initial Child Protection Conference cannot be a weekend",
+    affected_fields=[DateOfInitialCPC],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[Section47]
+    # <DateOfInitialCPC> should not be a Saturday, Sunday
+    # .weekday() returns the integer value for each day (0-6) with weekends being 5 and 6
+    failing_indices = df[df[DateOfInitialCPC].dt.weekday >= 5].index
+
+    rule_context.push_issue(
+        table=Section47, field=DateOfInitialCPC, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_identifiers = pd.DataFrame(
+        [
+            {"DateOfInitialCPC": "17/06/2021"},  # Pass
+            {"DateOfInitialCPC": "09/10/2022"},  # Fail, Sunday
+            {"DateOfInitialCPC": "14/03/2020"},  # Fail, Saturday
+        ],
+    )  # 9/10 is a Sunday and 14/3 is a Saturday
+
+    child_identifiers[DateOfInitialCPC] = pd.to_datetime(
+        child_identifiers[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {Section47: child_identifiers})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.Section47, DateOfInitialCPC, 1),
+        IssueLocator(CINTable.Section47, DateOfInitialCPC, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    assert result.definition.code == "8875"
+    assert (
+        result.definition.message
+        == "The Date of Initial Child Protection Conference cannot be a weekend"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8890.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8890.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,317 +1,317 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Section47 = CINTable.Section47
-LAchildID = Section47.LAchildID
-CINdetailsID = Section47.CINdetailsID
-DateOfInitialCPC = Section47.DateOfInitialCPC
-S47ActualStartDate = Section47.S47ActualStartDate
-ICPCnotRequired = Section47.ICPCnotRequired
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here
-    code="8890",
-    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.CINdetails,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="A Section 47 enquiry is shown as starting when there is another Section 47 Enquiry ongoing",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        S47ActualStartDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_47 = data_container[Section47].copy()
-    df_47_2 = data_container[Section47].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_47.index.name = "ROW_ID"
-    df_47_2.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_47.reset_index(inplace=True)
-    df_47_2.reset_index(inplace=True)
-
-    # ReferenceDate exists in the header table so we get header table too.
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Within one <CINdetails> group, each <S47ActualStartDate> (N00148) must not fall on or between
-    # a) the <S47ActualStartDate> (N00148) and <DateOfInitialCPC> (N00110) of any other <Section47> group that has a <DateOfInitialCPC> (N00110) or
-    # b) the <S47ActualStartDate> (N00148) and the <ReferenceDate> (N00603) of any other <Section47> group
-    #   that has a missing <DateOfInitialCPC> (N00110) and the <ICPCnotRequired> (N00111) flag is not true
-
-    #  Create dataframes which only have rows with s47 modules, and which don't have ICPCnotrequired as true should have one plan per row.
-    df_47 = df_47[(df_47[S47ActualStartDate].notna())]
-    df_47_2 = df_47_2[(df_47_2[S47ActualStartDate].notna())]
-
-    #  Merge tables to test for overlaps
-    df_merged = df_47.merge(
-        df_47_2,
-        on=[LAchildID, CINdetailsID],
-        how="left",
-        suffixes=("_47", "_472"),
-    )
-
-    # prevent a session from being compared to itself
-    same_start = (
-        df_merged["S47ActualStartDate_47"] == df_merged["S47ActualStartDate_472"]
-    )
-    same_cpc = (
-        df_merged["DateOfInitialCPC_47"] == df_merged["DateOfInitialCPC_472"]
-    ) | (
-        df_merged["DateOfInitialCPC_47"].isna()
-        & df_merged["DateOfInitialCPC_472"].isna()
-    )
-    duplicate = same_start & same_cpc
-    df_merged = df_merged[~duplicate]
-
-    true_or_one = ["1", "true"]
-
-    # Determine whether CPP overlaps another CPP
-    s47_started_after_start = (
-        df_merged["S47ActualStartDate_47"] >= df_merged["S47ActualStartDate_472"]
-    )
-    s47_started_before_end = (
-        df_merged["S47ActualStartDate_47"] <= df_merged["DateOfInitialCPC_472"]
-    ) & df_merged["DateOfInitialCPC_472"].notna()
-    s47_started_before_refdate = (
-        (df_merged["S47ActualStartDate_47"] <= reference_date)
-        & df_merged["DateOfInitialCPC_472"].isna()
-        & (~(df_merged["ICPCnotRequired_472"].str.lower().isin(true_or_one)))
-    )
-
-    df_merged = df_merged[
-        s47_started_after_start & (s47_started_before_end | s47_started_before_refdate)
-    ].reset_index()
-
-    # create an identifier for each error instance.
-    df_merged["ERROR_ID"] = tuple(
-        zip(
-            df_merged[LAchildID],
-            df_merged[CINdetailsID],
-            df_merged["S47ActualStartDate_47"],
-        )
-    )
-
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_47_issues = (
-        df_47.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_47")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_47_2_issues = (
-        df_47_2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_472")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_3(
-        table=Section47, columns=[S47ActualStartDate], row_df=df_47_issues
-    )
-    rule_context.push_type_3(
-        table=Section47,
-        columns=[S47ActualStartDate, DateOfInitialCPC],
-        row_df=df_47_2_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
-    )
-
-    sample_s47 = pd.DataFrame(
-        [  # child1
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "S47ActualStartDate": "26/05/2000",  # 0 Pass: not between "26/08/2000" and "31/03/2001"
-                "DateOfInitialCPC": "26/10/2000",
-                "ICPCnotRequired": "1",
-            },
-            {
-                "LAchildID": "child1",
-                "CINdetailsID": "cinID1",
-                "S47ActualStartDate": "26/08/2000",  # 1 Fail: between "26/05/2000" and "26/10/2000"
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "nottrue",
-            },
-            {
-                "LAchildID": "child2",  # 2 alone in cin group: not compared
-                "CINdetailsID": "cinID2",
-                "S47ActualStartDate": "26/05/2000",
-                "DateOfInitialCPC": "25/10/2000",
-                "ICPCnotRequired": "1",
-            },
-            {
-                "LAchildID": "child2",  # 3 alone in cin group: not compared
-                "CINdetailsID": "cinID22",
-                "S47ActualStartDate": "26/10/2000",
-                "DateOfInitialCPC": "26/12/2000",
-                "ICPCnotRequired": "1",
-            },
-            # child3
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID3",
-                "S47ActualStartDate": "26/05/2000",  # 4 Pass: not between "26/08/2000" and "26/10/2000"
-                "DateOfInitialCPC": "26/10/2001",
-                "ICPCnotRequired": "1",
-            },
-            {
-                "LAchildID": "child3",
-                "CINdetailsID": "cinID3",
-                "S47ActualStartDate": "26/08/2000",  # 5 Fail: between "26/05/2000" and "26/10/2001"
-                "DateOfInitialCPC": "26/10/2000",
-                "ICPCnotRequired": "1",
-            },
-            # child4
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "cinID1",
-                "S47ActualStartDate": "26/10/2000",  # 6 Ignore: between "26/09/2000" and ReferenceDate but ICPCnotRequired is true
-                "DateOfInitialCPC": "31/03/2001",
-                "ICPCnotRequired": "1",
-            },
-            {
-                "LAchildID": "child4",
-                "CINdetailsID": "cinID1",
-                "S47ActualStartDate": "26/09/2000",  # 7 Pass: not between "26/10/2000" and "31/03/2001"
-                "DateOfInitialCPC": pd.NA,
-                "ICPCnotRequired": "1",
-            },
-            # child5
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "cinID0",
-                "S47ActualStartDate": "26/05/2000",  # 8 Pass: not between "26/08/2000" and "26/10/2000"
-                "DateOfInitialCPC": "26/10/2001",
-                "ICPCnotRequired": "true",
-            },
-            {
-                "LAchildID": "child5",
-                "CINdetailsID": "cinID0",
-                "S47ActualStartDate": "26/08/2000",  # 9 Fail: between "26/05/2000" and "26/10/2001"
-                "DateOfInitialCPC": "26/10/2000",
-                "ICPCnotRequired": "1",
-            },
-        ]
-    )
-
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_s47[S47ActualStartDate] = pd.to_datetime(
-        sample_s47[S47ActualStartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_s47[DateOfInitialCPC] = pd.to_datetime(
-        sample_s47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            Section47: sample_s47,
-            Header: sample_header,
-        },
-    )
-
-    issues_list = result.type3_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 0 will contain the Section47 columns because that's the first thing pushed above.
-    issues = issues_list[0]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == Section47
-
-    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [S47ActualStartDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID1",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID3",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "child5",
-                    "cinID0",
-                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [9],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8890' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8890"
-    assert (
-        result.definition.message
-        == "A Section 47 enquiry is shown as starting when there is another Section 47 Enquiry ongoing"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Section47 = CINTable.Section47
+LAchildID = Section47.LAchildID
+CINdetailsID = Section47.CINdetailsID
+DateOfInitialCPC = Section47.DateOfInitialCPC
+S47ActualStartDate = Section47.S47ActualStartDate
+ICPCnotRequired = Section47.ICPCnotRequired
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here
+    code="8890",
+    # replace CINdetails with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.CINdetails,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="A Section 47 enquiry is shown as starting when there is another Section 47 Enquiry ongoing",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        S47ActualStartDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_47 = data_container[Section47].copy()
+    df_47_2 = data_container[Section47].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_47.index.name = "ROW_ID"
+    df_47_2.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_47.reset_index(inplace=True)
+    df_47_2.reset_index(inplace=True)
+
+    # ReferenceDate exists in the header table so we get header table too.
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Within one <CINdetails> group, each <S47ActualStartDate> (N00148) must not fall on or between
+    # a) the <S47ActualStartDate> (N00148) and <DateOfInitialCPC> (N00110) of any other <Section47> group that has a <DateOfInitialCPC> (N00110) or
+    # b) the <S47ActualStartDate> (N00148) and the <ReferenceDate> (N00603) of any other <Section47> group
+    #   that has a missing <DateOfInitialCPC> (N00110) and the <ICPCnotRequired> (N00111) flag is not true
+
+    #  Create dataframes which only have rows with s47 modules, and which don't have ICPCnotrequired as true should have one plan per row.
+    df_47 = df_47[(df_47[S47ActualStartDate].notna())]
+    df_47_2 = df_47_2[(df_47_2[S47ActualStartDate].notna())]
+
+    #  Merge tables to test for overlaps
+    df_merged = df_47.merge(
+        df_47_2,
+        on=[LAchildID, CINdetailsID],
+        how="left",
+        suffixes=("_47", "_472"),
+    )
+
+    # prevent a session from being compared to itself
+    same_start = (
+        df_merged["S47ActualStartDate_47"] == df_merged["S47ActualStartDate_472"]
+    )
+    same_cpc = (
+        df_merged["DateOfInitialCPC_47"] == df_merged["DateOfInitialCPC_472"]
+    ) | (
+        df_merged["DateOfInitialCPC_47"].isna()
+        & df_merged["DateOfInitialCPC_472"].isna()
+    )
+    duplicate = same_start & same_cpc
+    df_merged = df_merged[~duplicate]
+
+    true_or_one = ["1", "true"]
+
+    # Determine whether CPP overlaps another CPP
+    s47_started_after_start = (
+        df_merged["S47ActualStartDate_47"] >= df_merged["S47ActualStartDate_472"]
+    )
+    s47_started_before_end = (
+        df_merged["S47ActualStartDate_47"] <= df_merged["DateOfInitialCPC_472"]
+    ) & df_merged["DateOfInitialCPC_472"].notna()
+    s47_started_before_refdate = (
+        (df_merged["S47ActualStartDate_47"] <= reference_date)
+        & df_merged["DateOfInitialCPC_472"].isna()
+        & (~(df_merged["ICPCnotRequired_472"].str.lower().isin(true_or_one)))
+    )
+
+    df_merged = df_merged[
+        s47_started_after_start & (s47_started_before_end | s47_started_before_refdate)
+    ].reset_index()
+
+    # create an identifier for each error instance.
+    df_merged["ERROR_ID"] = tuple(
+        zip(
+            df_merged[LAchildID],
+            df_merged[CINdetailsID],
+            df_merged["S47ActualStartDate_47"],
+        )
+    )
+
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_47_issues = (
+        df_47.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_47")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_47_2_issues = (
+        df_47_2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_472")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=Section47, columns=[S47ActualStartDate], row_df=df_47_issues
+    )
+    rule_context.push_type_3(
+        table=Section47,
+        columns=[S47ActualStartDate, DateOfInitialCPC],
+        row_df=df_47_2_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
+    )
+
+    sample_s47 = pd.DataFrame(
+        [  # child1
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "S47ActualStartDate": "26/05/2000",  # 0 Pass: not between "26/08/2000" and "31/03/2001"
+                "DateOfInitialCPC": "26/10/2000",
+                "ICPCnotRequired": "1",
+            },
+            {
+                "LAchildID": "child1",
+                "CINdetailsID": "cinID1",
+                "S47ActualStartDate": "26/08/2000",  # 1 Fail: between "26/05/2000" and "26/10/2000"
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "nottrue",
+            },
+            {
+                "LAchildID": "child2",  # 2 alone in cin group: not compared
+                "CINdetailsID": "cinID2",
+                "S47ActualStartDate": "26/05/2000",
+                "DateOfInitialCPC": "25/10/2000",
+                "ICPCnotRequired": "1",
+            },
+            {
+                "LAchildID": "child2",  # 3 alone in cin group: not compared
+                "CINdetailsID": "cinID22",
+                "S47ActualStartDate": "26/10/2000",
+                "DateOfInitialCPC": "26/12/2000",
+                "ICPCnotRequired": "1",
+            },
+            # child3
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID3",
+                "S47ActualStartDate": "26/05/2000",  # 4 Pass: not between "26/08/2000" and "26/10/2000"
+                "DateOfInitialCPC": "26/10/2001",
+                "ICPCnotRequired": "1",
+            },
+            {
+                "LAchildID": "child3",
+                "CINdetailsID": "cinID3",
+                "S47ActualStartDate": "26/08/2000",  # 5 Fail: between "26/05/2000" and "26/10/2001"
+                "DateOfInitialCPC": "26/10/2000",
+                "ICPCnotRequired": "1",
+            },
+            # child4
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "cinID1",
+                "S47ActualStartDate": "26/10/2000",  # 6 Ignore: between "26/09/2000" and ReferenceDate but ICPCnotRequired is true
+                "DateOfInitialCPC": "31/03/2001",
+                "ICPCnotRequired": "1",
+            },
+            {
+                "LAchildID": "child4",
+                "CINdetailsID": "cinID1",
+                "S47ActualStartDate": "26/09/2000",  # 7 Pass: not between "26/10/2000" and "31/03/2001"
+                "DateOfInitialCPC": pd.NA,
+                "ICPCnotRequired": "1",
+            },
+            # child5
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "cinID0",
+                "S47ActualStartDate": "26/05/2000",  # 8 Pass: not between "26/08/2000" and "26/10/2000"
+                "DateOfInitialCPC": "26/10/2001",
+                "ICPCnotRequired": "true",
+            },
+            {
+                "LAchildID": "child5",
+                "CINdetailsID": "cinID0",
+                "S47ActualStartDate": "26/08/2000",  # 9 Fail: between "26/05/2000" and "26/10/2001"
+                "DateOfInitialCPC": "26/10/2000",
+                "ICPCnotRequired": "1",
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_s47[S47ActualStartDate] = pd.to_datetime(
+        sample_s47[S47ActualStartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_s47[DateOfInitialCPC] = pd.to_datetime(
+        sample_s47[DateOfInitialCPC], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            Section47: sample_s47,
+            Header: sample_header,
+        },
+    )
+
+    issues_list = result.type3_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 0 will contain the Section47 columns because that's the first thing pushed above.
+    issues = issues_list[0]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == Section47
+
+    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [S47ActualStartDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID1",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID3",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child5",
+                    "cinID0",
+                    pd.to_datetime("26/08/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [9],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8890' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8890"
+    assert (
+        result.definition.message
+        == "A Section 47 enquiry is shown as starting when there is another Section 47 Enquiry ongoing"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8897Q.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8897Q.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,250 +1,278 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-Assessments = CINTable.Assessments
-AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
-AssessmentFactors = Assessments.AssessmentFactors
-LAchildID = Assessments.LAchildID
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8897Q",
-    module=CINTable.Assessments,
-    rule_type=RuleType.QUERY,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Parental or child factors at assessment information is missing from a completed assessment",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[AssessmentAuthorisationDate, AssessmentFactors],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df = data_container[Assessments]
-
-    header = data_container[Header]
-    ref_date_series = header[ReferenceDate]
-    collection_start, collection_end = make_census_period(ref_date_series)
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Where present, if <AssessmentAuthorisationDate> (N00160) is on or after [Start_Of_Census_Year] then one or more <AssessmentFactors>
-    # (N00181) must be present within the same assessment module and must be a valid code
-    # Get collection period
-    factors_list = [
-        "1A",
-        "1B",
-        "1C",
-        "2A",
-        "2B",
-        "2C",
-        "3A",
-        "3B",
-        "3C",
-        "4A",
-        "4B",
-        "4C",
-        "5A",
-        "5B",
-        "5C",
-        "6A",
-        "6B",
-        "6C",
-        "7A",
-        "8B",
-        "8C",
-        "8D",
-        "8E",
-        "8F",
-        "9A",
-        "10A",
-        "11A",
-        "12A",
-        "13A",
-        "14A",
-        "15A",
-        "16A",
-        "17A",
-        "18A",
-        "18B",
-        "18C",
-        "19A",
-        "19B",
-        "19C",
-        "20",
-        "21",
-        "22A",
-        "23A",
-        "24A",
-    ]
-
-    condition1 = (df[AssessmentAuthorisationDate] >= collection_start) & (
-        df[AssessmentAuthorisationDate].notna()
-    )
-    condition2 = (df[AssessmentFactors].notna()) & (
-        df[AssessmentFactors].isin(factors_list)
-    )
-
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition1 & ~condition2].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error. In this case,
-    # - If only LAchildID is used as an identifier, multiple instances of the error on a child will be understood as 1 instance.
-    # We don't want that because in reality, a child can have multiple instances of an error.
-    # - If we use the LAchildID-CPPstartDate combination, that artificially cancels out the instances where a start date repeats for the same child.
-    # Another rule checks for that condition. Not this one.
-    # - It is very unlikely that a combination of LAchildID-CPPstartDate-CPPendDate will repeat in the DataFrame.
-    # Hence, it can be used as a unique identifier of the row.
-
-    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
-    link_id = tuple(
-        zip(
-            df_issues[LAchildID],
-            df_issues[AssessmentAuthorisationDate],
-            df_issues[AssessmentFactors],
-        )
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=Assessments,
-        columns=[AssessmentAuthorisationDate, AssessmentFactors],
-        row_df=df_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_data = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "AssessmentFactors": pd.NA,
-                "AssessmentAuthorisationDate": "26/05/2000",
-            },  # Fails as no assessment factor code
-            {
-                "LAchildID": "child2",
-                "AssessmentFactors": "99",
-                "AssessmentAuthorisationDate": "26/05/2000",
-            },  # Fails as incorrect assessment factor code
-            {
-                "LAchildID": "child3",
-                "AssessmentFactors": "1A",
-                "AssessmentAuthorisationDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child3",
-                "AssessmentAuthorisationDate": "26/05/2000",
-                "AssessmentFactors": pd.NA,
-            },  # Fails as no factor selected
-            {
-                "LAchildID": "child4",
-                "AssessmentFactors": "1A",
-                "AssessmentAuthorisationDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child5",
-                "AssessmentAuthorisationDate": pd.NA,
-                "AssessmentFactors": pd.NA,
-            },
-            {
-                "LAchildID": "child5",
-                "AssessmentAuthorisationDate": "26/05/1945",
-                "AssessmentFactors": pd.NA,  # Passes as before census year
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-
-    fake_data[AssessmentAuthorisationDate] = pd.to_datetime(
-        fake_data[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    sample_header = pd.DataFrame([{ReferenceDate: "31/03/2001"}])
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {Assessments: fake_data, Header: sample_header})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    issue_table = issues.table
-    assert issue_table == Assessments
-
-    issue_columns = issues.columns
-    assert issue_columns == [AssessmentAuthorisationDate, AssessmentFactors]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.NA,
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    "99",
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.NA,
-                ),
-                "ROW_ID": [3],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8897Q with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8897Q"
-    assert (
-        result.definition.message
-        == "Parental or child factors at assessment information is missing from a completed assessment"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, RuleType, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+Assessments = CINTable.Assessments
+AssessmentAuthorisationDate = Assessments.AssessmentAuthorisationDate
+AssessmentFactors = Assessments.AssessmentFactors
+LAchildID = Assessments.LAchildID
+AssessmentID = Assessments.AssessmentID
+
+AssessmentFactorsList = CINTable.AssessmentFactorsList
+AssessmentFactor = AssessmentFactorsList.AssessmentFactor
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8897Q",
+    module=CINTable.Assessments,
+    rule_type=RuleType.QUERY,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Parental or child factors at assessment information is missing from a completed assessment",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[AssessmentAuthorisationDate, AssessmentFactors],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_ass = data_container[Assessments]
+    df_asslist = data_container[AssessmentFactorsList]
+
+    header = data_container[Header]
+    ref_date_series = header[ReferenceDate]
+    collection_start, collection_end = make_census_period(ref_date_series)
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_ass.index.name = "ROW_ID"
+    df_ass.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Where present, if <AssessmentAuthorisationDate> (N00160) is on or after [Start_Of_Census_Year] then one or more <AssessmentFactors>
+    # (N00181) must be present within the same assessment module and must be a valid code
+    # Get collection period
+    factors_list = [
+        "1A",
+        "1B",
+        "1C",
+        "2A",
+        "2B",
+        "2C",
+        "3A",
+        "3B",
+        "3C",
+        "4A",
+        "4B",
+        "4C",
+        "5A",
+        "5B",
+        "5C",
+        "6A",
+        "6B",
+        "6C",
+        "7A",
+        "8B",
+        "8C",
+        "8D",
+        "8E",
+        "8F",
+        "9A",
+        "10A",
+        "11A",
+        "12A",
+        "13A",
+        "14A",
+        "15A",
+        "16A",
+        "17A",
+        "18A",
+        "18B",
+        "18C",
+        "19A",
+        "19B",
+        "19C",
+        "20",
+        "21",
+        "22A",
+        "23A",
+        "24A",
+    ]
+
+    df_ass_merged = df_ass.merge(
+        df_asslist[["LAchildID", "AssessmentID", "AssessmentFactor"]],
+        on=["LAchildID", "AssessmentID"],
+        how="left",
+    )
+
+    condition1 = (df_ass_merged[AssessmentAuthorisationDate] >= collection_start) & (
+        df_ass_merged[AssessmentAuthorisationDate].notna()
+    )
+    condition2 = (df_ass_merged[AssessmentFactors].notna()) & (
+        df_ass_merged[AssessmentFactor].isin(factors_list)
+    )
+
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df_ass_merged[condition1 & ~condition2].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error. In this case,
+    # - If only LAchildID is used as an identifier, multiple instances of the error on a child will be understood as 1 instance.
+    # We don't want that because in reality, a child can have multiple instances of an error.
+    # - If we use the LAchildID-CPPstartDate combination, that artificially cancels out the instances where a start date repeats for the same child.
+    # Another rule checks for that condition. Not this one.
+    # - It is very unlikely that a combination of LAchildID-CPPstartDate-CPPendDate will repeat in the DataFrame.
+    # Hence, it can be used as a unique identifier of the row.
+
+    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
+    link_id = tuple(
+        zip(
+            df_issues[LAchildID],
+            df_issues[AssessmentID],
+            df_issues[AssessmentFactors],
+        )
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=Assessments,
+        columns=[AssessmentAuthorisationDate, AssessmentFactors],
+        row_df=df_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_data = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "AssessmentID": "11",
+                "AssessmentFactors": pd.NA,
+                "AssessmentAuthorisationDate": "26/05/2000",
+            },  # Fails as no assessment factor code
+            {
+                "LAchildID": "child2",
+                "AssessmentID": "21",
+                "AssessmentFactors": "99",
+                "AssessmentAuthorisationDate": "26/05/2000",
+            },  # Fails as incorrect assessment factor code
+            {
+                "LAchildID": "child3",
+                "AssessmentID": "31",
+                "AssessmentFactors": "1A",
+                "AssessmentAuthorisationDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",
+                "AssessmentID": "32",
+                "AssessmentAuthorisationDate": "26/05/2000",
+                "AssessmentFactors": pd.NA,
+            },  # Fails as no factor selected
+            {
+                "LAchildID": "child4",
+                "AssessmentID": "41",
+                "AssessmentFactors": "1A",
+                "AssessmentAuthorisationDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child5",
+                "AssessmentID": "51",
+                "AssessmentAuthorisationDate": pd.NA,
+                "AssessmentFactors": pd.NA,
+            },
+            {
+                "LAchildID": "child5",
+                "AssessmentID": "52",
+                "AssessmentAuthorisationDate": "26/05/1945",
+                "AssessmentFactors": pd.NA,  # Passes as before census year
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+
+    fake_data[AssessmentAuthorisationDate] = pd.to_datetime(
+        fake_data[AssessmentAuthorisationDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    sample_header = pd.DataFrame([{ReferenceDate: "31/03/2001"}])
+
+    # Run rule function passing in our sample data
+    result = run_rule(
+        validate,
+        {
+            Assessments: fake_data,
+            AssessmentFactorsList: fake_data.rename(
+                columns={"AssessmentFactors": "AssessmentFactor"}
+            ),
+            Header: sample_header,
+        },
+    )
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    issue_table = issues.table
+    assert issue_table == Assessments
+
+    issue_columns = issues.columns
+    assert issue_columns == [AssessmentAuthorisationDate, AssessmentFactors]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "11",
+                    pd.NA,
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "21",
+                    "99",
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "32",
+                    pd.NA,
+                ),
+                "ROW_ID": [3],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8897Q with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8897Q"
+    assert (
+        result.definition.message
+        == "Parental or child factors at assessment information is missing from a completed assessment"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8905.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8905.py`

 * *Ordering differences only*

 * *Files 21% similar despite different names*

```diff
@@ -1,67 +1,67 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-InitialCategoryOfAbuse = ChildProtectionPlans.InitialCategoryOfAbuse
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8905",
-    module=CINTable.ChildProtectionPlans,
-    message="Initial Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)",
-    affected_fields=[InitialCategoryOfAbuse],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildProtectionPlans]
-    """
-    Where a Child Protection Plan module is present, <InitialCategoryOfAbuse> (N00113) must be present and be a valid code
-    """
-    abuse_cats = ["NEG", "PHY", "SAB", "EMO", "MUL"]
-
-    # Initial Category Code is not in list.
-    df = df[
-        (~df[InitialCategoryOfAbuse].isin(abuse_cats))
-        | df[InitialCategoryOfAbuse].isna()
-    ]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=ChildProtectionPlans, field=InitialCategoryOfAbuse, row=failing_indices
-    )
-
-
-def test_validate():
-    fake_cats = ["NEG", "AAA", "PHY", pd.NA, "BBB", "EMO", "MUL"]
-
-    fake_dataframe = pd.DataFrame({InitialCategoryOfAbuse: fake_cats})
-
-    result = run_rule(validate, {ChildProtectionPlans: fake_dataframe})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-
-    assert issues == [
-        IssueLocator(CINTable.ChildProtectionPlans, InitialCategoryOfAbuse, 1),
-        IssueLocator(CINTable.ChildProtectionPlans, InitialCategoryOfAbuse, 3),
-        IssueLocator(CINTable.ChildProtectionPlans, InitialCategoryOfAbuse, 4),
-    ]
-
-    assert result.definition.code == "8905"
-    assert (
-        result.definition.message
-        == "Initial Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+InitialCategoryOfAbuse = ChildProtectionPlans.InitialCategoryOfAbuse
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8905",
+    module=CINTable.ChildProtectionPlans,
+    message="Initial Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)",
+    affected_fields=[InitialCategoryOfAbuse],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildProtectionPlans]
+    """
+    Where a Child Protection Plan module is present, <InitialCategoryOfAbuse> (N00113) must be present and be a valid code
+    """
+    abuse_cats = ["NEG", "PHY", "SAB", "EMO", "MUL"]
+
+    # Initial Category Code is not in list.
+    df = df[
+        (~df[InitialCategoryOfAbuse].isin(abuse_cats))
+        | df[InitialCategoryOfAbuse].isna()
+    ]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=ChildProtectionPlans, field=InitialCategoryOfAbuse, row=failing_indices
+    )
+
+
+def test_validate():
+    fake_cats = ["NEG", "AAA", "PHY", pd.NA, "BBB", "EMO", "MUL"]
+
+    fake_dataframe = pd.DataFrame({InitialCategoryOfAbuse: fake_cats})
+
+    result = run_rule(validate, {ChildProtectionPlans: fake_dataframe})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+
+    assert issues == [
+        IssueLocator(CINTable.ChildProtectionPlans, InitialCategoryOfAbuse, 1),
+        IssueLocator(CINTable.ChildProtectionPlans, InitialCategoryOfAbuse, 3),
+        IssueLocator(CINTable.ChildProtectionPlans, InitialCategoryOfAbuse, 4),
+    ]
+
+    assert result.definition.code == "8905"
+    assert (
+        result.definition.message
+        == "Initial Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8910.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8910.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,66 +1,66 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LatestCategoryOfAbuse = ChildProtectionPlans.LatestCategoryOfAbuse
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8910",
-    module=CINTable.ChildProtectionPlans,
-    message="Latest Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)",
-    affected_fields=[LatestCategoryOfAbuse],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildProtectionPlans]
-
-    # Where a Child Protection Plan module is present, <LatestCategoryOfAbuse> (N00114) must be present and be a valid code
-    abuse_cats = ["NEG", "PHY", "SAB", "EMO", "MUL"]
-
-    # Initial Category Code is not in list.
-    df = df[
-        (~df["LatestCategoryOfAbuse"].isin(abuse_cats))
-        | df["LatestCategoryOfAbuse"].isna()
-    ]
-
-    failing_indices = df.index
-
-    rule_context.push_issue(
-        table=ChildProtectionPlans, field=LatestCategoryOfAbuse, row=failing_indices
-    )
-
-
-def test_validate():
-    fake_cats = ["NEG", "AAA", "BBB", pd.NA, "PHY", "EMO", "MUL"]
-
-    fake_dataframe = pd.DataFrame({"LatestCategoryOfAbuse": fake_cats})
-
-    result = run_rule(validate, {ChildProtectionPlans: fake_dataframe})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-
-    assert issues == [
-        IssueLocator(CINTable.ChildProtectionPlans, LatestCategoryOfAbuse, 1),
-        IssueLocator(CINTable.ChildProtectionPlans, LatestCategoryOfAbuse, 2),
-        IssueLocator(CINTable.ChildProtectionPlans, LatestCategoryOfAbuse, 3),
-    ]
-
-    assert result.definition.code == "8910"
-    assert (
-        result.definition.message
-        == "Latest Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+LatestCategoryOfAbuse = ChildProtectionPlans.LatestCategoryOfAbuse
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8910",
+    module=CINTable.ChildProtectionPlans,
+    message="Latest Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)",
+    affected_fields=[LatestCategoryOfAbuse],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildProtectionPlans]
+
+    # Where a Child Protection Plan module is present, <LatestCategoryOfAbuse> (N00114) must be present and be a valid code
+    abuse_cats = ["NEG", "PHY", "SAB", "EMO", "MUL"]
+
+    # Initial Category Code is not in list.
+    df = df[
+        (~df["LatestCategoryOfAbuse"].isin(abuse_cats))
+        | df["LatestCategoryOfAbuse"].isna()
+    ]
+
+    failing_indices = df.index
+
+    rule_context.push_issue(
+        table=ChildProtectionPlans, field=LatestCategoryOfAbuse, row=failing_indices
+    )
+
+
+def test_validate():
+    fake_cats = ["NEG", "AAA", "BBB", pd.NA, "PHY", "EMO", "MUL"]
+
+    fake_dataframe = pd.DataFrame({"LatestCategoryOfAbuse": fake_cats})
+
+    result = run_rule(validate, {ChildProtectionPlans: fake_dataframe})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+
+    assert issues == [
+        IssueLocator(CINTable.ChildProtectionPlans, LatestCategoryOfAbuse, 1),
+        IssueLocator(CINTable.ChildProtectionPlans, LatestCategoryOfAbuse, 2),
+        IssueLocator(CINTable.ChildProtectionPlans, LatestCategoryOfAbuse, 3),
+    ]
+
+    assert result.definition.code == "8910"
+    assert (
+        result.definition.message
+        == "Latest Category of Abuse code missing or invalid (see Category of Abuse table in CIN Census code set)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8915.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8915.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,211 +1,211 @@
-"""
-Rule number: '8915'
-Module: Child protection plans
-Rule details: If <PersonDeathDate> (N00108) is present, then <CPPstartDate> (N00105) must be on or before <PersonDeathDate> (N00108)
-Rule message: Child Protection Plan shown as starting after the child’s Date of Death
-
-"""
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-CPP_LAID = ChildProtectionPlans.LAchildID
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-CI_LAID = ChildIdentifiers.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8915",
-    module=CINTable.ChildProtectionPlans,
-    message="Child Protection Plan shown as starting after the child’s Date of Death",
-    affected_fields=[
-        CPPstartDate,
-        PersonDeathDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df_CPP = data_container[ChildProtectionPlans].copy()
-    df_CI = data_container[ChildIdentifiers].copy()
-
-    df_CPP.index.name = "ROW_ID"
-    df_CI.index.name = "ROW_ID"
-
-    df_CPP.reset_index(inplace=True)
-    df_CI.reset_index(inplace=True)
-
-    # Remove rows with no death date
-
-    df_CI = df_CI[df_CI[PersonDeathDate].notna()]
-
-    # <CPPstartDate> (N00105) must be on or before <PersonDeathDate>
-
-    # Join 2 tables together
-
-    df = df_CPP.merge(
-        df_CI,
-        left_on=["LAchildID"],
-        right_on=["LAchildID"],
-        how="left",
-        suffixes=("_CPP", "_CI"),
-    )
-
-    # Return those where dates don't align
-    df = df[df[CPPstartDate] > df[PersonDeathDate]].reset_index()
-
-    df["ERROR_ID"] = tuple(zip(df["LAchildID"], df[CPPstartDate], df[PersonDeathDate]))
-
-    df_CPP_issues = (
-        df_CPP.merge(df, left_on="ROW_ID", right_on="ROW_ID_CPP")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    df_CI_issues = (
-        df_CI.merge(df, left_on="ROW_ID", right_on="ROW_ID_CI")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_CPP_issues
-    )
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_CI_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_CPP = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPstartDate": pd.NA,  # Pass, no CP plan
-            },
-            {
-                "LAchildID": "child2",
-                "CPPstartDate": "27/06/2002",  # Fail, after death
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "07/02/1999",  # Pass, prior to death
-            },
-            {
-                "LAchildID": "child4",
-                "CPPstartDate": "26/05/2000",  # Pass, no death
-            },
-            {
-                "LAchildID": "child5",
-                "CPPstartDate": "26/05/2001",  # Fail, after death
-            },
-        ]
-    )
-
-    sample_CI = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # Pass
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",  # Fail
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child3",  # Pass
-                "PersonDeathDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child4",  # Pass
-                "PersonDeathDate": pd.NA,
-            },
-            {
-                "LAchildID": "child5",  # Fail
-                "PersonDeathDate": "27/05/2000",
-            },
-        ]
-    )
-
-    sample_CPP[CPPstartDate] = pd.to_datetime(
-        sample_CPP[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_CI[PersonDeathDate] = pd.to_datetime(
-        sample_CI[PersonDeathDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_CPP,
-            ChildIdentifiers: sample_CI,
-        },
-    )
-
-    # The result contains a list of issues encountered
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-
-    issues = issues_list[1]
-
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    # check that the right columns were returned. Replace PersonDeathDate  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [PersonDeathDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    # Start date
-                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
-                    # Referral date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child5",  # ChildID
-                    # Start Date
-                    pd.to_datetime("26/05/2001", format="%d/%m/%Y", errors="coerce"),
-                    # Referral date
-                    pd.to_datetime("27/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-
-    assert issue_rows.equals(expected_df)
-
-    assert result.definition.code == "8915"
-    assert (
-        result.definition.message
-        == "Child Protection Plan shown as starting after the child’s Date of Death"
-    )
+"""
+Rule number: '8915'
+Module: Child protection plans
+Rule details: If <PersonDeathDate> (N00108) is present, then <CPPstartDate> (N00105) must be on or before <PersonDeathDate> (N00108)
+Rule message: Child Protection Plan shown as starting after the child’s Date of Death
+
+"""
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+CPP_LAID = ChildProtectionPlans.LAchildID
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+CI_LAID = ChildIdentifiers.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8915",
+    module=CINTable.ChildProtectionPlans,
+    message="Child Protection Plan shown as starting after the child’s Date of Death",
+    affected_fields=[
+        CPPstartDate,
+        PersonDeathDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df_CPP = data_container[ChildProtectionPlans].copy()
+    df_CI = data_container[ChildIdentifiers].copy()
+
+    df_CPP.index.name = "ROW_ID"
+    df_CI.index.name = "ROW_ID"
+
+    df_CPP.reset_index(inplace=True)
+    df_CI.reset_index(inplace=True)
+
+    # Remove rows with no death date
+
+    df_CI = df_CI[df_CI[PersonDeathDate].notna()]
+
+    # <CPPstartDate> (N00105) must be on or before <PersonDeathDate>
+
+    # Join 2 tables together
+
+    df = df_CPP.merge(
+        df_CI,
+        left_on=["LAchildID"],
+        right_on=["LAchildID"],
+        how="left",
+        suffixes=("_CPP", "_CI"),
+    )
+
+    # Return those where dates don't align
+    df = df[df[CPPstartDate] > df[PersonDeathDate]].reset_index()
+
+    df["ERROR_ID"] = tuple(zip(df["LAchildID"], df[CPPstartDate], df[PersonDeathDate]))
+
+    df_CPP_issues = (
+        df_CPP.merge(df, left_on="ROW_ID", right_on="ROW_ID_CPP")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    df_CI_issues = (
+        df_CI.merge(df, left_on="ROW_ID", right_on="ROW_ID_CI")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_CPP_issues
+    )
+    rule_context.push_type_2(
+        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_CI_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_CPP = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPstartDate": pd.NA,  # Pass, no CP plan
+            },
+            {
+                "LAchildID": "child2",
+                "CPPstartDate": "27/06/2002",  # Fail, after death
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "07/02/1999",  # Pass, prior to death
+            },
+            {
+                "LAchildID": "child4",
+                "CPPstartDate": "26/05/2000",  # Pass, no death
+            },
+            {
+                "LAchildID": "child5",
+                "CPPstartDate": "26/05/2001",  # Fail, after death
+            },
+        ]
+    )
+
+    sample_CI = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # Pass
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",  # Fail
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child3",  # Pass
+                "PersonDeathDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child4",  # Pass
+                "PersonDeathDate": pd.NA,
+            },
+            {
+                "LAchildID": "child5",  # Fail
+                "PersonDeathDate": "27/05/2000",
+            },
+        ]
+    )
+
+    sample_CPP[CPPstartDate] = pd.to_datetime(
+        sample_CPP[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_CI[PersonDeathDate] = pd.to_datetime(
+        sample_CI[PersonDeathDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_CPP,
+            ChildIdentifiers: sample_CI,
+        },
+    )
+
+    # The result contains a list of issues encountered
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+
+    issues = issues_list[1]
+
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    # check that the right columns were returned. Replace PersonDeathDate  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [PersonDeathDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    # Start date
+                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
+                    # Referral date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child5",  # ChildID
+                    # Start Date
+                    pd.to_datetime("26/05/2001", format="%d/%m/%Y", errors="coerce"),
+                    # Referral date
+                    pd.to_datetime("27/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+
+    assert issue_rows.equals(expected_df)
+
+    assert result.definition.code == "8915"
+    assert (
+        result.definition.message
+        == "Child Protection Plan shown as starting after the child’s Date of Death"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8920.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8940.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,257 +1,280 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPendDate = ChildProtectionPlans.CPPendDate
-LAchildID = ChildProtectionPlans.LAchildID
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-PersonDeathDate = ChildIdentifiers.PersonDeathDate
-LAchildID = ChildIdentifiers.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8920",
-    module=CINTable.ChildProtectionPlans,
-    message="Child Protection Plan cannot end after the child’s Date of Death",
-    affected_fields=[
-        PersonDeathDate,
-        CPPendDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df_cpp = data_container[ChildProtectionPlans].copy()
-    df_child = data_container[ChildIdentifiers].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cpp.index.name = "ROW_ID"
-    df_child.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_cpp.reset_index(inplace=True)
-    df_child.reset_index(inplace=True)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If <PersonDeathDate> (N00108) is present, then <CPPendDate> (N00115) must be on or before <PersonDeathDate> (N00108)
-    # Issues dfs should return rows where PersonDeathDate is less than or equal to the CPPendDate
-
-    #  Create dataframes which only have rows with CP plans, and which should have one plan per row.
-    df_cpp = df_cpp[df_cpp[CPPendDate].notna()]
-    df_child = df_child[df_child[PersonDeathDate].notna()]
-
-    #  Merge tables to get corresponding CP plan group for the child
-    df_merged = df_cpp.merge(
-        df_child,
-        left_on=["LAchildID"],
-        right_on=["LAchildID"],
-        how="left",
-        suffixes=("_cpp", "_child"),
-    )
-
-    #  Get rows where CPPendDate is after PersonDeathDate
-    condition = df_merged[CPPendDate] > df_merged[PersonDeathDate]
-    df_merged = df_merged[condition].reset_index()
-
-    # create an identifier for each error instance.
-    # In this case, the rule is checked for each CPPendDate against the PersonDeathDate for that child.
-    # A child may have multiple CP Plans but only 1 should be current at anytime and requires a CPPendDate
-
-    df_merged["ERROR_ID"] = tuple(
-        zip(df_merged[LAchildID], df_merged[CPPendDate], df_merged[PersonDeathDate])
-    )
-
-    # The merges were done on copies of df_cpp and df_child so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cpp_issues = (
-        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_reviews_issues = (
-        df_child.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_child")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_2(
-        table=ChildProtectionPlans, columns=[CPPendDate], row_df=df_cpp_issues
-    )
-    rule_context.push_type_2(
-        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_reviews_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPendDate": "26/05/2000",  # Fails as PersonDeathDate is before the CPPendDate
-            },
-            {
-                "LAchildID": "child2",
-                "CPPendDate": "27/06/2002",  # Fails as PersonDeathDate is before the CPPendDate
-            },
-            {
-                "LAchildID": "child3",
-                "CPPendDate": "07/02/2001",  # Fails as PersonDeathDate is before the CPPendDate
-            },
-            {
-                "LAchildID": "child4",
-                "CPPendDate": "26/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
-            },
-            {
-                "LAchildID": "child5",
-                "CPPendDate": "26/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
-            },
-            {
-                "LAchildID": "child6",
-                "CPPendDate": pd.NA,  # Ignored as rows with no CPPendDate are dropped (this is picked up by other rules)
-            },
-            {
-                "LAchildID": "child7",
-                "CPPendDate": "14/03/2001",  # Ignored as rows with no PersonDeathDate are dropped (this is picked up by other rules)
-            },
-        ]
-    )
-    sample_children = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "PersonDeathDate": "25/05/2000",  # Fails as PersonDeathDate is before the CPPendDate
-            },
-            {
-                "LAchildID": "child2",
-                "PersonDeathDate": "29/05/2000",  # Fails as PersonDeathDate is before the CPPendDate
-            },
-            {
-                "LAchildID": "child3",
-                "PersonDeathDate": "26/03/2000",  # Fails as PersonDeathDate is before the CPPendDate
-            },
-            {
-                "LAchildID": "child4",
-                "PersonDeathDate": "30/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
-            },
-            {
-                "LAchildID": "child5",
-                "PersonDeathDate": "27/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
-            },
-            {
-                "LAchildID": "child6",
-                "PersonDeathDate": "26/05/2000",  # Ignored as rows with no CPPendDate are dropped (this is picked up by other rules)
-            },
-            {
-                "LAchildID": "child7",
-                "PersonDeathDate": pd.NA,  # Ignored as rows with no PersonDeathDate are dropped (this is picked up by other rules)
-            },
-        ]
-    )
-
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cpp[CPPendDate] = pd.to_datetime(
-        sample_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_children["PersonDeathDate"] = pd.to_datetime(
-        sample_children["PersonDeathDate"], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            ChildIdentifiers: sample_children,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type2_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
-    issues = issues_list[1]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildIdentifiers
-
-    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [PersonDeathDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",  # ChildID
-                    # CPP End Date
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    # Person Death Date
-                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [0],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",  # ChildID
-                    # CPP End Date
-                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
-                    # Person Death Date
-                    pd.to_datetime("29/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",  # ChildID
-                    # CPP End Date
-                    pd.to_datetime("07/02/2001", format="%d/%m/%Y", errors="coerce"),
-                    # Person Death Date
-                    pd.to_datetime("26/03/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 2885 with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8920"
-    assert (
-        result.definition.message
-        == "Child Protection Plan cannot end after the child’s Date of Death"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+LAchildID = ChildProtectionPlans.LAchildID
+CPPID = ChildProtectionPlans.CPPID
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+CPPendDate = ChildProtectionPlans.CPPendDate
+
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here
+    code="8940",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    # Note that even if multiple tables are involved, one table will be named in the module column.
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child Protection Plan data contains overlapping dates",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[
+        CPPstartDate,
+        CPPendDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace ChildProtectionPlans with the name of the table you need.
+    df_cpp = data_container[ChildProtectionPlans].copy()
+    df_cpp2 = data_container[ChildProtectionPlans].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cpp.index.name = "ROW_ID"
+    df_cpp2.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_cpp.reset_index(inplace=True)
+    df_cpp2.reset_index(inplace=True)
+
+    # ReferenceDate exists in the header table so we get header table too.
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # Where more than one <ChildProtectionPlans> group is included,
+    # the <CPPstartDate> (N00105) of each group cannot fall within either:
+    #   a) <CPPstartDate> (N00105) to <CPPendDate> (N00115), or
+    #   b) <CPPstartDate> (N00105) and <ReferenceDate> if <CPPendDate> (N00115) is not present
+    # of any other group
+    #
+    # Issues dfs should return rows where CPPstartDate is between another CPPstartDate and CPPendDate (or ReferenceDate)
+
+    #  Create dataframes which only have rows with CP plans, and which should have one plan per row.
+    df_cpp = df_cpp[df_cpp[CPPstartDate].notna()]
+    df_cpp2 = df_cpp2[df_cpp2[CPPstartDate].notna()]
+
+    #  Merge tables to test for overlaps
+    df_merged = df_cpp.merge(
+        df_cpp2,
+        on=["LAchildID"],
+        how="left",
+        suffixes=("_cpp", "_cpp2"),
+    )
+
+    # Exclude rows where the CPPID is the same on both sides
+    df_merged = df_merged[(df_merged["CPPID_cpp"] != df_merged["CPPID_cpp2"])]
+
+    # Determine whether CPP overlaps another CPP
+    cpp_started_after_start = (
+        df_merged["CPPstartDate_cpp"] >= df_merged["CPPstartDate_cpp2"]
+    )
+    cpp_started_before_end = (
+        df_merged["CPPstartDate_cpp"] <= df_merged["CPPendDate_cpp2"]
+    ) & df_merged["CPPendDate_cpp2"].notna()
+    cpp_started_before_refdate = (
+        df_merged["CPPstartDate_cpp"] <= reference_date
+    ) & df_merged["CPPendDate_cpp2"].isna()
+
+    df_merged = df_merged[
+        cpp_started_after_start & (cpp_started_before_end | cpp_started_before_refdate)
+    ].reset_index()
+
+    # create an identifier for each error instance.
+    # In this case, the rule is checked for each CPPstartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
+    df_merged["ERROR_ID"] = tuple(
+        zip(df_merged[LAchildID], df_merged["CPPID_cpp"], df_merged["CPPID_cpp2"])
+    )
+
+    # The merges were done on copies of cpp_df so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_cpp_issues = (
+        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_cpp2_issues = (
+        df_cpp2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp2")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_cpp_issues
+    )
+    rule_context.push_type_3(
+        table=ChildProtectionPlans,
+        columns=[CPPstartDate, CPPendDate],
+        row_df=df_cpp2_issues,
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
+    )
+
+    sample_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",  # 0 Pass
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": "26/10/2000",
+                "CPPID": "cinID1",
+            },
+            {
+                "LAchildID": "child1",  # 1 Fail
+                "CPPstartDate": "26/08/2000",
+                "CPPendDate": "26/12/2000",
+                "CPPID": "cinID12",
+            },
+            {
+                "LAchildID": "child2",  # 2 Pass
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": "25/10/2000",
+                "CPPID": "cinID2",
+            },
+            {
+                "LAchildID": "child2",  # 3 Pass
+                "CPPstartDate": "26/10/2000",
+                "CPPendDate": "26/12/2000",
+                "CPPID": "cinID22",
+            },
+            {
+                "LAchildID": "child3",  # 4 Pass
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": pd.NA,
+                "CPPID": "cinID3",
+            },
+            {
+                "LAchildID": "child3",  # 5 Fail
+                "CPPstartDate": "26/08/2000",
+                "CPPendDate": "26/10/2000",
+                "CPPID": "cinID32",
+            },
+            {
+                "LAchildID": "child4",  # 6 Pass
+                "CPPstartDate": "26/10/2000",
+                "CPPendDate": "31/03/2001",
+                "CPPID": "cinID4",
+            },
+            {
+                "LAchildID": "child4",  # 7 Fail
+                "CPPstartDate": "31/03/2001",
+                "CPPendDate": pd.NA,
+                "CPPID": "cinID42",
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cpp[CPPstartDate] = pd.to_datetime(
+        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_cpp["CPPendDate"] = pd.to_datetime(
+        sample_cpp["CPPendDate"], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_header[ReferenceDate] = pd.to_datetime(
+        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            Header: sample_header,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type3_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
+    issues = issues_list[0]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildProtectionPlans
+
+    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [CPPstartDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "cinID12",
+                    "cinID1",
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",
+                    "cinID32",
+                    "cinID3",
+                ),
+                "ROW_ID": [5],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    "cinID42",
+                    "cinID4",
+                ),
+                "ROW_ID": [7],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 2885 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8940"
+    assert (
+        result.definition.message
+        == "Child Protection Plan data contains overlapping dates"
+    )
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8925.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8925.py`

 * *Ordering differences only*

 * *Files 13% similar despite different names*

```diff
@@ -1,169 +1,169 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPendDate = ChildProtectionPlans.CPPendDate
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-LAchildID = ChildProtectionPlans.LAchildID
-
-
-# define characteristics of rule
-@rule_definition(
-    code="8925",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child Protection Plan End Date earlier than Start Date",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[CPPstartDate, CPPendDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    df = data_container[ChildProtectionPlans]
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # If present <CPPendDate> (N00115) must be on or after the <CPPstartDate> (N00105)
-    condition = df[CPPendDate] < df[CPPstartDate]
-    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
-    df_issues = df[condition].reset_index()
-
-    # SUBMIT ERRORS
-    # Generate a unique ID for each instance of an error. In this case,
-    # - If only LAchildID is used as an identifier, multiple instances of the error on a child will be understood as 1 instance.
-    # We don't want that because in reality, a child can have multiple instances of an error.
-    # - If we use the LAchildID-CPPstartDate combination, that artificially cancels out the instances where a start date repeats for the same child.
-    # Another rule checks for that condition. Not this one.
-    # - It is very unlikely that a combination of LAchildID-CPPstartDate-CPPendDate will repeat in the DataFrame.
-    # Hence, it can be used as a unique identifier of the row.
-
-    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
-    link_id = tuple(
-        zip(df_issues[LAchildID], df_issues[CPPstartDate], df_issues[CPPendDate])
-    )
-    df_issues["ERROR_ID"] = link_id
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_1(
-        table=ChildProtectionPlans, columns=[CPPstartDate, CPPendDate], row_df=df_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    child_protection_plans = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": "26/05/2000",
-            },
-            {
-                "LAchildID": "child2",
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": "26/05/2001",
-            },
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": "26/05/1999",
-            },  # 2 error: end is before start
-            {
-                "LAchildID": "child3",
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": pd.NA,
-            },
-            {
-                "LAchildID": "child4",
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": "25/05/2000",
-            },  # 4 error: end is before start
-            {
-                "LAchildID": "child5",
-                "CPPstartDate": pd.NA,
-                "CPPendDate": pd.NA,
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    child_protection_plans[CPPstartDate] = pd.to_datetime(
-        child_protection_plans[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    child_protection_plans[CPPendDate] = pd.to_datetime(
-        child_protection_plans[CPPendDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildProtectionPlans: child_protection_plans})
-
-    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
-    issues = result.type1_issues
-
-    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildProtectionPlans
-
-    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [CPPstartDate, CPPendDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child3",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [2],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
-                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
-                ),
-                "ROW_ID": [4],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8925' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8925"
-    assert (
-        result.definition.message
-        == "Child Protection Plan End Date earlier than Start Date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPendDate = ChildProtectionPlans.CPPendDate
+CPPstartDate = ChildProtectionPlans.CPPstartDate
+LAchildID = ChildProtectionPlans.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8925",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child Protection Plan End Date earlier than Start Date",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[CPPstartDate, CPPendDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df = data_container[ChildProtectionPlans]
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If present <CPPendDate> (N00115) must be on or after the <CPPstartDate> (N00105)
+    condition = df[CPPendDate] < df[CPPstartDate]
+    # get all the data that fits the failing condition. Reset the index so that ROW_ID now becomes a column of df
+    df_issues = df[condition].reset_index()
+
+    # SUBMIT ERRORS
+    # Generate a unique ID for each instance of an error. In this case,
+    # - If only LAchildID is used as an identifier, multiple instances of the error on a child will be understood as 1 instance.
+    # We don't want that because in reality, a child can have multiple instances of an error.
+    # - If we use the LAchildID-CPPstartDate combination, that artificially cancels out the instances where a start date repeats for the same child.
+    # Another rule checks for that condition. Not this one.
+    # - It is very unlikely that a combination of LAchildID-CPPstartDate-CPPendDate will repeat in the DataFrame.
+    # Hence, it can be used as a unique identifier of the row.
+
+    # Replace CPPstartDate and CPPendDate below with the columns concerned in your rule.
+    link_id = tuple(
+        zip(df_issues[LAchildID], df_issues[CPPstartDate], df_issues[CPPendDate])
+    )
+    df_issues["ERROR_ID"] = link_id
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_1(
+        table=ChildProtectionPlans, columns=[CPPstartDate, CPPendDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    child_protection_plans = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": "26/05/2000",
+            },
+            {
+                "LAchildID": "child2",
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": "26/05/2001",
+            },
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": "26/05/1999",
+            },  # 2 error: end is before start
+            {
+                "LAchildID": "child3",
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": pd.NA,
+            },
+            {
+                "LAchildID": "child4",
+                "CPPstartDate": "26/05/2000",
+                "CPPendDate": "25/05/2000",
+            },  # 4 error: end is before start
+            {
+                "LAchildID": "child5",
+                "CPPstartDate": pd.NA,
+                "CPPendDate": pd.NA,
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    child_protection_plans[CPPstartDate] = pd.to_datetime(
+        child_protection_plans[CPPstartDate], format="%d/%m/%Y", errors="coerce"
+    )
+    child_protection_plans[CPPendDate] = pd.to_datetime(
+        child_protection_plans[CPPendDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildProtectionPlans: child_protection_plans})
+
+    # Use .type1_issues to check for the result of .push_type1_issues() which you used above.
+    issues = result.type1_issues
+
+    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildProtectionPlans
+
+    # check that the right columns were returned. Replace CPPstartDate and CPPendDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [CPPstartDate, CPPendDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child3",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("26/05/1999", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+            {
+                "ERROR_ID": (
+                    "child4",
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [4],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8925' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8925"
+    assert (
+        result.definition.message
+        == "Child Protection Plan End Date earlier than Start Date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8930.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8930.py`

 * *Ordering differences only*

 * *Files 23% similar despite different names*

```diff
@@ -1,107 +1,107 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-CPPendDate = ChildProtectionPlans.CPPendDate
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8930'
-    code="8930",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child Protection Plan End Date must fall within the census year",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[CPPendDate, ReferenceDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildProtectionPlans]
-
-    # ReferenceDate exists in the heder table so we get header table too.
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
-
-    # If <CPPendDate> (N00115) is present, then<CPPendDate> (N00115) must fall within [Period_of_Census] inclusive
-    failing_indices = df[
-        (df[CPPendDate] < collection_start) | (df[CPPendDate] > reference_date)
-    ].index
-
-    rule_context.push_issue(
-        table=ChildProtectionPlans, field=CPPendDate, row=failing_indices
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    fake_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
-    )
-
-    fake_cpp = pd.DataFrame(
-        [
-            {
-                CPPendDate: "01/03/2019"
-            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
-            {
-                CPPendDate: "01/04/2021"
-            },  # 1 pass: April 1st is within April 1st, 2021 to March 31st, 2022.
-            {
-                CPPendDate: "01/10/2022"
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-            {
-                CPPendDate: pd.NA
-            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
-        ]
-    )
-
-    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
-    fake_cpp[CPPendDate] = pd.to_datetime(
-        fake_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run rule function passing in our sample data
-    # Since the ReferenceDate comes from the Header column, we provide that also.
-    result = run_rule(validate, {ChildProtectionPlans: fake_cpp, Header: fake_header})
-
-    # The result contains a list of issues encountered
-    issues = list(result.issues)
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issues) == 2
-    # replace the table and column name as done earlier.
-    # The last numbers represent the index values where you expect the sample data to fail the validation check.
-    assert issues == [
-        IssueLocator(CINTable.ChildProtectionPlans, CPPendDate, 0),
-        IssueLocator(CINTable.ChildProtectionPlans, CPPendDate, 2),
-    ]
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace '8930' with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8930"
-    assert (
-        result.definition.message
-        == "Child Protection Plan End Date must fall within the census year"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+from cin_validator.utils import make_census_period
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPendDate = ChildProtectionPlans.CPPendDate
+Header = CINTable.Header
+ReferenceDate = Header.ReferenceDate
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8930'
+    code="8930",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="Child Protection Plan End Date must fall within the census year",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[CPPendDate, ReferenceDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildProtectionPlans]
+
+    # ReferenceDate exists in the heder table so we get header table too.
+    df_ref = data_container[Header]
+    ref_date_series = df_ref[ReferenceDate]
+
+    # the make_census_period function generates the start and end date so that you don't have to do it each time.
+    collection_start, reference_date = make_census_period(ref_date_series)
+
+    # implement rule logic as described by the Github issue. Put the description as a comment above the implementation as shown.
+
+    # If <CPPendDate> (N00115) is present, then<CPPendDate> (N00115) must fall within [Period_of_Census] inclusive
+    failing_indices = df[
+        (df[CPPendDate] < collection_start) | (df[CPPendDate] > reference_date)
+    ].index
+
+    rule_context.push_issue(
+        table=ChildProtectionPlans, field=CPPendDate, row=failing_indices
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    fake_header = pd.DataFrame(
+        [{ReferenceDate: "31/03/2022"}]  # the census start date here will be 01/04/2021
+    )
+
+    fake_cpp = pd.DataFrame(
+        [
+            {
+                CPPendDate: "01/03/2019"
+            },  # 0 fail: March 1st is before April 1st, 2021. It is out of range
+            {
+                CPPendDate: "01/04/2021"
+            },  # 1 pass: April 1st is within April 1st, 2021 to March 31st, 2022.
+            {
+                CPPendDate: "01/10/2022"
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+            {
+                CPPendDate: pd.NA
+            },  # 2 fail: October 1st is after March 31st, 2022. It is out of range
+        ]
+    )
+
+    # if date columns are involved, the validate function will be expecting them as dates so convert before passing them in.
+    fake_cpp[CPPendDate] = pd.to_datetime(
+        fake_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run rule function passing in our sample data
+    # Since the ReferenceDate comes from the Header column, we provide that also.
+    result = run_rule(validate, {ChildProtectionPlans: fake_cpp, Header: fake_header})
+
+    # The result contains a list of issues encountered
+    issues = list(result.issues)
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issues) == 2
+    # replace the table and column name as done earlier.
+    # The last numbers represent the index values where you expect the sample data to fail the validation check.
+    assert issues == [
+        IssueLocator(CINTable.ChildProtectionPlans, CPPendDate, 0),
+        IssueLocator(CINTable.ChildProtectionPlans, CPPendDate, 2),
+    ]
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace '8930' with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8930"
+    assert (
+        result.definition.message
+        == "Child Protection Plan End Date must fall within the census year"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8935.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8935.py`

 * *Ordering differences only*

 * *Files 19% similar despite different names*

```diff
@@ -1,177 +1,177 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LAchildID = ChildProtectionPlans.LAchildID
-CPPendDate = ChildProtectionPlans.CPPendDate
-CPPID = ChildProtectionPlans.CPPID
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here, in place of '8935'
-    code="8935",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="This child is showing more than one open Child Protection plan, i.e. with no End Date",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[CPPendDate],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Replace ChildProtectionPlans with the name of the table you need.
-    df = data_container[ChildProtectionPlans]
-    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
-    df.index.name = "ROW_ID"
-    df.reset_index(inplace=True)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # There must be only one <ChildProtectionPlans> group where the <CPPendDate> (N00115) is missing
-
-    # DF_CHECK: APPLY GROUPBYs IN A SEPARATE DATAFRAME SO THAT OTHER COLUMNS ARE NOT LOST OR CORRUPTED. THEN, MAP THE RESULTS TO THE INITIAL DATAFRAME.
-    df_check = df.copy()
-    # get all the locations where CPPendDate is null
-    df_check = df_check[df_check[CPPendDate].isna()]
-    # We'll have to count the number of nan values per group. NaNs cannot be counted so replace them with something that can.
-    # Do this only if your rule requires that you interact with a column made up of all NaNs.
-    df_check[CPPendDate].fillna(1, inplace=True)
-    # count how many occurences of missing CPPendDate per ChildProtectionPlan group in each child.
-    df_check = df_check.groupby([LAchildID, CPPID])[CPPendDate].count().reset_index()
-
-    # when you groupby as shown above a series is returned where the columns in the round brackets become the index and the groupby result are the values.
-    # resetting the index pushes the columns in the () back as columns of the dataframe and assigns the groupby result to the column in the square bracket.
-
-    # filter out the instances where CPPendDate is missing more than once in a CP plan group.
-    df_check = df_check[df_check[CPPendDate] > 1]
-    issue_ids = tuple(zip(df_check[LAchildID], df_check[CPPID]))
-
-    # DF_ISSUES: GET ALL THE DATA ABOUT THE LOCATIONS THAT WERE IDENTIFIED IN DF_CHECK
-    df["ERROR_ID"] = tuple(zip(df[LAchildID], df[CPPID]))
-    df_issues = df[df.ERROR_ID.isin(issue_ids)]
-
-    df_issues = (
-        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_3(
-        table=ChildProtectionPlans, columns=[CPPendDate], row_df=df_issues
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_ChildProtectionPlans = pd.DataFrame(
-        [  # child1
-            {  # fail
-                LAchildID: "child1",
-                CPPID: "CPPID1",
-                CPPendDate: pd.NA,  # 0 first nan date in group
-            },
-            {  # fail
-                LAchildID: "child1",
-                CPPID: "CPPID1",
-                CPPendDate: pd.NA,  # 1 second nan date in group
-            },
-            {  # won't be flagged because there is not more than one nan authorisation date in this group.
-                LAchildID: "child1",
-                CPPID: "CPPID2",
-                CPPendDate: pd.NA,  # 2
-            },
-            # child2
-            {
-                LAchildID: "child2",
-                CPPID: "CPPID1",
-                CPPendDate: "26/05/2021",  # 3 ignored. not nan
-            },
-            {  # fail
-                LAchildID: "child2",
-                CPPID: "CPPID2",
-                CPPendDate: pd.NA,  # 4 first nan date in group
-            },
-            {  # fail
-                LAchildID: "child2",
-                CPPID: "CPPID2",
-                CPPendDate: pd.NA,  # 5 second nan date in group
-            },
-        ]
-    )
-    # if rule requires columns containing date values, convert those columns to
-    # datetime objects first. Do it here in the test_validate function, not above.
-    sample_ChildProtectionPlans[CPPendDate] = pd.to_datetime(
-        sample_ChildProtectionPlans[CPPendDate],
-        format="%d/%m/%Y",
-        errors="coerce",
-    )
-
-    # Run rule function passing in our sample data
-    result = run_rule(validate, {ChildProtectionPlans: sample_ChildProtectionPlans})
-
-    # Use .type3_issues to check for the result of .push_type3_issues() which you used above.
-    issues_list = result.type3_issues
-    # Issues list contains the objects pushed in their respective order. Since push_type3 was only used once, there will be one object in issues_list.
-    assert len(issues_list) == 1
-    issues = issues_list[0]
-
-    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildProtectionPlans
-
-    # check that the right columns were returned. Replace CPPendDate with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [CPPendDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 2 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 2
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "CPPID1",
-                ),
-                "ROW_ID": [0, 1],
-            },
-            {
-                "ERROR_ID": (
-                    "child2",
-                    "CPPID2",
-                ),
-                "ROW_ID": [4, 5],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 8925 with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8935"
-    assert (
-        result.definition.message
-        == "This child is showing more than one open Child Protection plan, i.e. with no End Date"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+LAchildID = ChildProtectionPlans.LAchildID
+CPPendDate = ChildProtectionPlans.CPPendDate
+CPPID = ChildProtectionPlans.CPPID
+
+
+# define characteristics of rule
+@rule_definition(
+    # write the rule code here, in place of '8935'
+    code="8935",
+    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
+    module=CINTable.ChildProtectionPlans,
+    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
+    message="This child is showing more than one open Child Protection plan, i.e. with no End Date",
+    # The column names tend to be the words within the < > signs in the github issue description.
+    affected_fields=[CPPendDate],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    # Replace ChildProtectionPlans with the name of the table you need.
+    df = data_container[ChildProtectionPlans]
+    # Before you begin, rename the index and make it a column, so that the initial row positions can be kept intact.
+    df.index.name = "ROW_ID"
+    df.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # There must be only one <ChildProtectionPlans> group where the <CPPendDate> (N00115) is missing
+
+    # DF_CHECK: APPLY GROUPBYs IN A SEPARATE DATAFRAME SO THAT OTHER COLUMNS ARE NOT LOST OR CORRUPTED. THEN, MAP THE RESULTS TO THE INITIAL DATAFRAME.
+    df_check = df.copy()
+    # get all the locations where CPPendDate is null
+    df_check = df_check[df_check[CPPendDate].isna()]
+    # We'll have to count the number of nan values per group. NaNs cannot be counted so replace them with something that can.
+    # Do this only if your rule requires that you interact with a column made up of all NaNs.
+    df_check[CPPendDate].fillna(1, inplace=True)
+    # count how many occurences of missing CPPendDate per ChildProtectionPlan group in each child.
+    df_check = df_check.groupby([LAchildID, CPPID])[CPPendDate].count().reset_index()
+
+    # when you groupby as shown above a series is returned where the columns in the round brackets become the index and the groupby result are the values.
+    # resetting the index pushes the columns in the () back as columns of the dataframe and assigns the groupby result to the column in the square bracket.
+
+    # filter out the instances where CPPendDate is missing more than once in a CP plan group.
+    df_check = df_check[df_check[CPPendDate] > 1]
+    issue_ids = tuple(zip(df_check[LAchildID], df_check[CPPID]))
+
+    # DF_ISSUES: GET ALL THE DATA ABOUT THE LOCATIONS THAT WERE IDENTIFIED IN DF_CHECK
+    df["ERROR_ID"] = tuple(zip(df[LAchildID], df[CPPID]))
+    df_issues = df[df.ERROR_ID.isin(issue_ids)]
+
+    df_issues = (
+        df_issues.groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    # Ensure that you do not change the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_3(
+        table=ChildProtectionPlans, columns=[CPPendDate], row_df=df_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_ChildProtectionPlans = pd.DataFrame(
+        [  # child1
+            {  # fail
+                LAchildID: "child1",
+                CPPID: "CPPID1",
+                CPPendDate: pd.NA,  # 0 first nan date in group
+            },
+            {  # fail
+                LAchildID: "child1",
+                CPPID: "CPPID1",
+                CPPendDate: pd.NA,  # 1 second nan date in group
+            },
+            {  # won't be flagged because there is not more than one nan authorisation date in this group.
+                LAchildID: "child1",
+                CPPID: "CPPID2",
+                CPPendDate: pd.NA,  # 2
+            },
+            # child2
+            {
+                LAchildID: "child2",
+                CPPID: "CPPID1",
+                CPPendDate: "26/05/2021",  # 3 ignored. not nan
+            },
+            {  # fail
+                LAchildID: "child2",
+                CPPID: "CPPID2",
+                CPPendDate: pd.NA,  # 4 first nan date in group
+            },
+            {  # fail
+                LAchildID: "child2",
+                CPPID: "CPPID2",
+                CPPendDate: pd.NA,  # 5 second nan date in group
+            },
+        ]
+    )
+    # if rule requires columns containing date values, convert those columns to
+    # datetime objects first. Do it here in the test_validate function, not above.
+    sample_ChildProtectionPlans[CPPendDate] = pd.to_datetime(
+        sample_ChildProtectionPlans[CPPendDate],
+        format="%d/%m/%Y",
+        errors="coerce",
+    )
+
+    # Run rule function passing in our sample data
+    result = run_rule(validate, {ChildProtectionPlans: sample_ChildProtectionPlans})
+
+    # Use .type3_issues to check for the result of .push_type3_issues() which you used above.
+    issues_list = result.type3_issues
+    # Issues list contains the objects pushed in their respective order. Since push_type3 was only used once, there will be one object in issues_list.
+    assert len(issues_list) == 1
+    issues = issues_list[0]
+
+    # get table name and check it. Replace ChildProtectionPlans with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildProtectionPlans
+
+    # check that the right columns were returned. Replace CPPendDate with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [CPPendDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 2 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 2
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",
+                    "CPPID1",
+                ),
+                "ROW_ID": [0, 1],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",
+                    "CPPID2",
+                ),
+                "ROW_ID": [4, 5],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 8925 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8935"
+    assert (
+        result.definition.message
+        == "This child is showing more than one open Child Protection plan, i.e. with no End Date"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2022_23/rule_8940.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_8920.py`

 * *Files 24% similar despite different names*

```diff
@@ -1,280 +1,257 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
-from cin_validator.test_engine import run_rule
-from cin_validator.utils import make_census_period
-
-# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
-
-ChildProtectionPlans = CINTable.ChildProtectionPlans
-LAchildID = ChildProtectionPlans.LAchildID
-CPPID = ChildProtectionPlans.CPPID
-CPPstartDate = ChildProtectionPlans.CPPstartDate
-CPPendDate = ChildProtectionPlans.CPPendDate
-
-Header = CINTable.Header
-ReferenceDate = Header.ReferenceDate
-
-
-# define characteristics of rule
-@rule_definition(
-    # write the rule code here
-    code="8940",
-    # replace ChildProtectionPlans with the value in the module column of the excel sheet corresponding to this rule .
-    # Note that even if multiple tables are involved, one table will be named in the module column.
-    module=CINTable.ChildProtectionPlans,
-    # replace the message with the corresponding value for this rule, gotten from the excel sheet.
-    message="Child Protection Plan data contains overlapping dates",
-    # The column names tend to be the words within the < > signs in the github issue description.
-    affected_fields=[
-        CPPstartDate,
-        CPPendDate,
-    ],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    # PREPARING DATA
-
-    # Replace ChildProtectionPlans with the name of the table you need.
-    df_cpp = data_container[ChildProtectionPlans].copy()
-    df_cpp2 = data_container[ChildProtectionPlans].copy()
-
-    # Before you begin, rename the index so that the initial row positions can be kept intact.
-    df_cpp.index.name = "ROW_ID"
-    df_cpp2.index.name = "ROW_ID"
-
-    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
-    # so that they can come along when the merge is done.
-    df_cpp.reset_index(inplace=True)
-    df_cpp2.reset_index(inplace=True)
-
-    # ReferenceDate exists in the header table so we get header table too.
-    df_ref = data_container[Header]
-    ref_date_series = df_ref[ReferenceDate]
-
-    # the make_census_period function generates the start and end date so that you don't have to do it each time.
-    collection_start, reference_date = make_census_period(ref_date_series)
-
-    # lOGIC
-    # Implement rule logic as described by the Github issue.
-    # Put the description as a comment above the implementation as shown.
-
-    # Where more than one <ChildProtectionPlans> group is included,
-    # the <CPPstartDate> (N00105) of each group cannot fall within either:
-    #   a) <CPPstartDate> (N00105) to <CPPendDate> (N00115), or
-    #   b) <CPPstartDate> (N00105) and <ReferenceDate> if <CPPendDate> (N00115) is not present
-    # of any other group
-    #
-    # Issues dfs should return rows where CPPstartDate is between another CPPstartDate and CPPendDate (or ReferenceDate)
-
-    #  Create dataframes which only have rows with CP plans, and which should have one plan per row.
-    df_cpp = df_cpp[df_cpp[CPPstartDate].notna()]
-    df_cpp2 = df_cpp2[df_cpp2[CPPstartDate].notna()]
-
-    #  Merge tables to test for overlaps
-    df_merged = df_cpp.merge(
-        df_cpp2,
-        on=["LAchildID"],
-        how="left",
-        suffixes=("_cpp", "_cpp2"),
-    )
-
-    # Exclude rows where the CPPID is the same on both sides
-    df_merged = df_merged[(df_merged["CPPID_cpp"] != df_merged["CPPID_cpp2"])]
-
-    # Determine whether CPP overlaps another CPP
-    cpp_started_after_start = (
-        df_merged["CPPstartDate_cpp"] >= df_merged["CPPstartDate_cpp2"]
-    )
-    cpp_started_before_end = (
-        df_merged["CPPstartDate_cpp"] <= df_merged["CPPendDate_cpp2"]
-    ) & df_merged["CPPendDate_cpp2"].notna()
-    cpp_started_before_refdate = (
-        df_merged["CPPstartDate_cpp"] <= reference_date
-    ) & df_merged["CPPendDate_cpp2"].isna()
-
-    df_merged = df_merged[
-        cpp_started_after_start & (cpp_started_before_end | cpp_started_before_refdate)
-    ].reset_index()
-
-    # create an identifier for each error instance.
-    # In this case, the rule is checked for each CPPstartDate, in each CPplanDates group (differentiated by CP dates), in each child (differentiated by LAchildID)
-    df_merged["ERROR_ID"] = tuple(
-        zip(df_merged[LAchildID], df_merged["CPPID_cpp"], df_merged["CPPID_cpp2"])
-    )
-
-    # The merges were done on copies of cpp_df so that the column names in dataframes themselves aren't affected by the suffixes.
-    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
-    df_cpp_issues = (
-        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-    df_cpp2_issues = (
-        df_cpp2.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp2")
-        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
-        .apply(list)
-        .reset_index()
-    )
-
-    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
-    rule_context.push_type_3(
-        table=ChildProtectionPlans, columns=[CPPstartDate], row_df=df_cpp_issues
-    )
-    rule_context.push_type_3(
-        table=ChildProtectionPlans,
-        columns=[CPPstartDate, CPPendDate],
-        row_df=df_cpp2_issues,
-    )
-
-
-def test_validate():
-    # Create some sample data such that some values pass the validation and some fail.
-    sample_header = pd.DataFrame(
-        [{ReferenceDate: "31/03/2001"}]  # the census start date here will be 01/04/2000
-    )
-
-    sample_cpp = pd.DataFrame(
-        [
-            {
-                "LAchildID": "child1",  # 0 Pass
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": "26/10/2000",
-                "CPPID": "cinID1",
-            },
-            {
-                "LAchildID": "child1",  # 1 Fail
-                "CPPstartDate": "26/08/2000",
-                "CPPendDate": "26/12/2000",
-                "CPPID": "cinID12",
-            },
-            {
-                "LAchildID": "child2",  # 2 Pass
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": "25/10/2000",
-                "CPPID": "cinID2",
-            },
-            {
-                "LAchildID": "child2",  # 3 Pass
-                "CPPstartDate": "26/10/2000",
-                "CPPendDate": "26/12/2000",
-                "CPPID": "cinID22",
-            },
-            {
-                "LAchildID": "child3",  # 4 Pass
-                "CPPstartDate": "26/05/2000",
-                "CPPendDate": pd.NA,
-                "CPPID": "cinID3",
-            },
-            {
-                "LAchildID": "child3",  # 5 Fail
-                "CPPstartDate": "26/08/2000",
-                "CPPendDate": "26/10/2000",
-                "CPPID": "cinID32",
-            },
-            {
-                "LAchildID": "child4",  # 6 Pass
-                "CPPstartDate": "26/10/2000",
-                "CPPendDate": "31/03/2001",
-                "CPPID": "cinID4",
-            },
-            {
-                "LAchildID": "child4",  # 7 Fail
-                "CPPstartDate": "31/03/2001",
-                "CPPendDate": pd.NA,
-                "CPPID": "cinID42",
-            },
-        ]
-    )
-
-    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
-    sample_cpp[CPPstartDate] = pd.to_datetime(
-        sample_cpp[CPPstartDate], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_cpp["CPPendDate"] = pd.to_datetime(
-        sample_cpp["CPPendDate"], format="%d/%m/%Y", errors="coerce"
-    )
-    sample_header[ReferenceDate] = pd.to_datetime(
-        sample_header[ReferenceDate], format="%d/%m/%Y", errors="coerce"
-    )
-
-    # Run the rule function, passing in our sample data.
-    result = run_rule(
-        validate,
-        {
-            ChildProtectionPlans: sample_cpp,
-            Header: sample_header,
-        },
-    )
-
-    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
-    issues_list = result.type3_issues
-    assert len(issues_list) == 2
-    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
-    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
-    issues = issues_list[0]
-
-    # get table name and check it. Replace Reviews with the name of your table.
-    issue_table = issues.table
-    assert issue_table == ChildProtectionPlans
-
-    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
-    issue_columns = issues.columns
-    assert issue_columns == [CPPstartDate]
-
-    # check that the location linking dataframe was formed properly.
-    issue_rows = issues.row_df
-    # replace 3 with the number of failing points you expect from the sample data.
-    assert len(issue_rows) == 3
-
-    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
-    assert isinstance(issue_rows, pd.DataFrame)
-    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
-
-    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
-    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
-    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
-
-    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
-    expected_df = pd.DataFrame(
-        [
-            {
-                "ERROR_ID": (
-                    "child1",
-                    "cinID12",
-                    "cinID1",
-                ),
-                "ROW_ID": [1],
-            },
-            {
-                "ERROR_ID": (
-                    "child3",
-                    "cinID32",
-                    "cinID3",
-                ),
-                "ROW_ID": [5],
-            },
-            {
-                "ERROR_ID": (
-                    "child4",
-                    "cinID42",
-                    "cinID4",
-                ),
-                "ROW_ID": [7],
-            },
-        ]
-    )
-    assert issue_rows.equals(expected_df)
-
-    # Check that the rule definition is what you wrote in the context above.
-
-    # replace 2885 with the rule code and put the appropriate message in its place too.
-    assert result.definition.code == "8940"
-    assert (
-        result.definition.message
-        == "Child Protection Plan data contains overlapping dates"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import CINTable, RuleContext, rule_definition
+from cin_validator.test_engine import run_rule
+
+# Get tables and columns of interest from the CINTable object defined in rule_engine/__api.py
+
+ChildProtectionPlans = CINTable.ChildProtectionPlans
+CPPendDate = ChildProtectionPlans.CPPendDate
+LAchildID = ChildProtectionPlans.LAchildID
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+PersonDeathDate = ChildIdentifiers.PersonDeathDate
+LAchildID = ChildIdentifiers.LAchildID
+
+
+# define characteristics of rule
+@rule_definition(
+    code="8920",
+    module=CINTable.ChildProtectionPlans,
+    message="Child Protection Plan cannot end after the child’s Date of Death",
+    affected_fields=[
+        PersonDeathDate,
+        CPPendDate,
+    ],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    # PREPARING DATA
+
+    df_cpp = data_container[ChildProtectionPlans].copy()
+    df_child = data_container[ChildIdentifiers].copy()
+
+    # Before you begin, rename the index so that the initial row positions can be kept intact.
+    df_cpp.index.name = "ROW_ID"
+    df_child.index.name = "ROW_ID"
+
+    # Resetting the index causes the ROW_IDs to become columns of their respective DataFrames
+    # so that they can come along when the merge is done.
+    df_cpp.reset_index(inplace=True)
+    df_child.reset_index(inplace=True)
+
+    # lOGIC
+    # Implement rule logic as described by the Github issue.
+    # Put the description as a comment above the implementation as shown.
+
+    # If <PersonDeathDate> (N00108) is present, then <CPPendDate> (N00115) must be on or before <PersonDeathDate> (N00108)
+    # Issues dfs should return rows where PersonDeathDate is less than or equal to the CPPendDate
+
+    #  Create dataframes which only have rows with CP plans, and which should have one plan per row.
+    df_cpp = df_cpp[df_cpp[CPPendDate].notna()]
+    df_child = df_child[df_child[PersonDeathDate].notna()]
+
+    #  Merge tables to get corresponding CP plan group for the child
+    df_merged = df_cpp.merge(
+        df_child,
+        left_on=["LAchildID"],
+        right_on=["LAchildID"],
+        how="left",
+        suffixes=("_cpp", "_child"),
+    )
+
+    #  Get rows where CPPendDate is after PersonDeathDate
+    condition = df_merged[CPPendDate] > df_merged[PersonDeathDate]
+    df_merged = df_merged[condition].reset_index()
+
+    # create an identifier for each error instance.
+    # In this case, the rule is checked for each CPPendDate against the PersonDeathDate for that child.
+    # A child may have multiple CP Plans but only 1 should be current at anytime and requires a CPPendDate
+
+    df_merged["ERROR_ID"] = tuple(
+        zip(df_merged[LAchildID], df_merged[CPPendDate], df_merged[PersonDeathDate])
+    )
+
+    # The merges were done on copies of df_cpp and df_child so that the column names in dataframes themselves aren't affected by the suffixes.
+    # we can now map the suffixes columns to their corresponding source tables such that the failing ROW_IDs and ERROR_IDs exist per table.
+    df_cpp_issues = (
+        df_cpp.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_cpp")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+    df_reviews_issues = (
+        df_child.merge(df_merged, left_on="ROW_ID", right_on="ROW_ID_child")
+        .groupby("ERROR_ID", group_keys=False)["ROW_ID"]
+        .apply(list)
+        .reset_index()
+    )
+
+    # Ensure that you maintain the ROW_ID, and ERROR_ID column names which are shown above. They are keywords in this project.
+    rule_context.push_type_2(
+        table=ChildProtectionPlans, columns=[CPPendDate], row_df=df_cpp_issues
+    )
+    rule_context.push_type_2(
+        table=ChildIdentifiers, columns=[PersonDeathDate], row_df=df_reviews_issues
+    )
+
+
+def test_validate():
+    # Create some sample data such that some values pass the validation and some fail.
+    sample_cpp = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "CPPendDate": "26/05/2000",  # Fails as PersonDeathDate is before the CPPendDate
+            },
+            {
+                "LAchildID": "child2",
+                "CPPendDate": "27/06/2002",  # Fails as PersonDeathDate is before the CPPendDate
+            },
+            {
+                "LAchildID": "child3",
+                "CPPendDate": "07/02/2001",  # Fails as PersonDeathDate is before the CPPendDate
+            },
+            {
+                "LAchildID": "child4",
+                "CPPendDate": "26/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
+            },
+            {
+                "LAchildID": "child5",
+                "CPPendDate": "26/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
+            },
+            {
+                "LAchildID": "child6",
+                "CPPendDate": pd.NA,  # Ignored as rows with no CPPendDate are dropped (this is picked up by other rules)
+            },
+            {
+                "LAchildID": "child7",
+                "CPPendDate": "14/03/2001",  # Ignored as rows with no PersonDeathDate are dropped (this is picked up by other rules)
+            },
+        ]
+    )
+    sample_children = pd.DataFrame(
+        [
+            {
+                "LAchildID": "child1",
+                "PersonDeathDate": "25/05/2000",  # Fails as PersonDeathDate is before the CPPendDate
+            },
+            {
+                "LAchildID": "child2",
+                "PersonDeathDate": "29/05/2000",  # Fails as PersonDeathDate is before the CPPendDate
+            },
+            {
+                "LAchildID": "child3",
+                "PersonDeathDate": "26/03/2000",  # Fails as PersonDeathDate is before the CPPendDate
+            },
+            {
+                "LAchildID": "child4",
+                "PersonDeathDate": "30/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
+            },
+            {
+                "LAchildID": "child5",
+                "PersonDeathDate": "27/05/2000",  # Passes as PersonDeathDate is after the CPPendDate
+            },
+            {
+                "LAchildID": "child6",
+                "PersonDeathDate": "26/05/2000",  # Ignored as rows with no CPPendDate are dropped (this is picked up by other rules)
+            },
+            {
+                "LAchildID": "child7",
+                "PersonDeathDate": pd.NA,  # Ignored as rows with no PersonDeathDate are dropped (this is picked up by other rules)
+            },
+        ]
+    )
+
+    # If rule requires columns containing date values, convert those columns to datetime objects first. Do it here in the test_validate function, not above.
+    sample_cpp[CPPendDate] = pd.to_datetime(
+        sample_cpp[CPPendDate], format="%d/%m/%Y", errors="coerce"
+    )
+    sample_children["PersonDeathDate"] = pd.to_datetime(
+        sample_children["PersonDeathDate"], format="%d/%m/%Y", errors="coerce"
+    )
+
+    # Run the rule function, passing in our sample data.
+    result = run_rule(
+        validate,
+        {
+            ChildProtectionPlans: sample_cpp,
+            ChildIdentifiers: sample_children,
+        },
+    )
+
+    # Use .type2_issues to check for the result of .push_type2_issues() which you used above.
+    issues_list = result.type2_issues
+    assert len(issues_list) == 2
+    # the function returns a list on NamedTuples where each NamedTuple contains (table, column_list, df_issues)
+    # pick any table and check it's values. the tuple in location 1 will contain the Reviews columns because that's the second thing pushed above.
+    issues = issues_list[1]
+
+    # get table name and check it. Replace Reviews with the name of your table.
+    issue_table = issues.table
+    assert issue_table == ChildIdentifiers
+
+    # check that the right columns were returned. Replace CPPreviewDate  with a list of your columns.
+    issue_columns = issues.columns
+    assert issue_columns == [PersonDeathDate]
+
+    # check that the location linking dataframe was formed properly.
+    issue_rows = issues.row_df
+    # replace 3 with the number of failing points you expect from the sample data.
+    assert len(issue_rows) == 3
+    # check that the failing locations are contained in a DataFrame having the appropriate columns. These lines do not change.
+    assert isinstance(issue_rows, pd.DataFrame)
+    assert issue_rows.columns.to_list() == ["ERROR_ID", "ROW_ID"]
+
+    # Create the dataframe which you expect, based on the fake data you created. It should have two columns.
+    # - The first column is ERROR_ID which contains the unique combination that identifies each error instance, which you decided on, in your zip, earlier.
+    # - The second column in ROW_ID which contains a list of index positions that belong to each error instance.
+
+    # The ROW ID values represent the index positions where you expect the sample data to fail the validation check.
+    expected_df = pd.DataFrame(
+        [
+            {
+                "ERROR_ID": (
+                    "child1",  # ChildID
+                    # CPP End Date
+                    pd.to_datetime("26/05/2000", format="%d/%m/%Y", errors="coerce"),
+                    # Person Death Date
+                    pd.to_datetime("25/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [0],
+            },
+            {
+                "ERROR_ID": (
+                    "child2",  # ChildID
+                    # CPP End Date
+                    pd.to_datetime("27/06/2002", format="%d/%m/%Y", errors="coerce"),
+                    # Person Death Date
+                    pd.to_datetime("29/05/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [1],
+            },
+            {
+                "ERROR_ID": (
+                    "child3",  # ChildID
+                    # CPP End Date
+                    pd.to_datetime("07/02/2001", format="%d/%m/%Y", errors="coerce"),
+                    # Person Death Date
+                    pd.to_datetime("26/03/2000", format="%d/%m/%Y", errors="coerce"),
+                ),
+                "ROW_ID": [2],
+            },
+        ]
+    )
+    assert issue_rows.equals(expected_df)
+
+    # Check that the rule definition is what you wrote in the context above.
+
+    # replace 2885 with the rule code and put the appropriate message in its place too.
+    assert result.definition.code == "8920"
+    assert (
+        result.definition.message
+        == "Child Protection Plan cannot end after the child’s Date of Death"
+    )
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2023_24/__init__.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2023_24/__init__.py`

 * *Ordering differences only*

 * *Files 14% similar despite different names*

```diff
@@ -1,21 +1,21 @@
-from pathlib import Path
-
-from cin_validator.rule_engine import RuleDefinition, YearConfig
-from cin_validator.rules.cin2022_23 import registry as prev_registry
-from cin_validator.rules.ruleset_utils import (
-    extract_validator_functions,
-    update_validator_functions,
-)
-
-files = Path(__file__).parent.glob("*.py")
-this_year_validator_funcs: dict[str, RuleDefinition] = extract_validator_functions(
-    files
-)
-# if any rules need to be deleted, add their codes as strings into del_list
-del_list: list[str] = []
-this_year_config = YearConfig(
-    deleted=del_list, added_or_modified=this_year_validator_funcs
-)
-
-registry = update_validator_functions(prev_registry, this_year_config)
-__all__ = ["registry"]
+from pathlib import Path
+
+from cin_validator.rule_engine import RuleDefinition, YearConfig
+from cin_validator.rules.cin2022_23 import registry as prev_registry
+from cin_validator.rules.ruleset_utils import (
+    extract_validator_functions,
+    update_validator_functions,
+)
+
+files = Path(__file__).parent.glob("*.py")
+this_year_validator_funcs: dict[str, RuleDefinition] = extract_validator_functions(
+    files
+)
+# if any rules need to be deleted, add their codes as strings into del_list
+del_list: list[str] = []
+this_year_config = YearConfig(
+    deleted=del_list, added_or_modified=this_year_validator_funcs
+)
+
+registry = update_validator_functions(prev_registry, this_year_config)
+__all__ = ["registry"]
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/cin2023_24/rule_1530.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/cin2022_23/rule_1530.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,136 +1,133 @@
-from typing import Mapping
-
-import pandas as pd
-
-from cin_validator.rule_engine import (
-    CINTable,
-    IssueLocator,
-    RuleContext,
-    rule_definition,
-)
-from cin_validator.test_engine import run_rule
-
-ChildIdentifiers = CINTable.ChildIdentifiers
-UPN = ChildIdentifiers.UPN
-
-
-@rule_definition(
-    code=1530,
-    module=CINTable.ChildIdentifiers,
-    message="UPN invalid (characters 2-4 not a recognised LA code)",
-    affected_fields=[UPN],
-)
-def validate(
-    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
-):
-    df = data_container[ChildIdentifiers]
-    """
-    If <UPN> (N00001) present then characters 2-4 of <UPN> must be a valid post April 1998 LA code 
-    or a recognised ‘pseudo LA’ code 
-
-    001-005, 201-213, 301-320, 330-336, 340-344, 350-359, 370-373, 380-384, 390-394, 420, 660-681, 
-    701-708, 800-803, 805-808, 810-813, 815, 816, 820- 823, 825, 826, 830, 831, 835-837, 838-839, 
-    840, 841, 845, 846, 850-852, 855-857, 860, 861, 865-896, 908, 909, 916, 919, 921, 925, 
-    926, 928, 929, 931, 933, 935-938, 940-941
-    """
-    LA_list = []
-    LA_list.extend("00" + str(x) for x in range(1, 6))
-    LA_list.extend(range(201, 214))
-    LA_list.extend(range(301, 321))
-    LA_list.extend(range(330, 337))
-    LA_list.extend(range(340, 345))
-    LA_list.extend(range(350, 360))
-    LA_list.extend(range(370, 374))
-    LA_list.extend(range(380, 385))
-    LA_list.extend(range(390, 395))
-    LA_list.extend(range(660, 682))
-    LA_list.extend(range(701, 709))
-    LA_list.extend(range(800, 804))
-    LA_list.extend(range(805, 809))
-    LA_list.extend(range(810, 814))
-    LA_list.extend(range(820, 824))
-    LA_list.extend(range(835, 840))
-    LA_list.extend(range(850, 853))
-    LA_list.extend(range(855, 858))
-    LA_list.extend(range(865, 897))
-    LA_list.extend(range(935, 939))
-    LA_list.extend(range(940, 942))
-    LA_list.extend(
-        [
-            420,
-            815,
-            816,
-            825,
-            826,
-            830,
-            831,
-            840,
-            841,
-            845,
-            846,
-            860,
-            861,
-            908,
-            909,
-            916,
-            919,
-            921,
-            925,
-            926,
-            928,
-            929,
-            931,
-            933,
-            942,
-            943,
-        ]
-    )
-
-    LA_list = [str(x) for x in LA_list]
-
-    df.reset_index(inplace=True)
-    df2 = df[["index", "UPN"]]
-    df2 = df2[(df2["UPN"].str.len() == 13) & df2["UPN"].notna()]
-    df2["C2_to_C4"] = df2["UPN"].str[1:4]
-    df2 = df2[~df2["C2_to_C4"].isin(LA_list)]
-
-    failing_indices = df2.set_index("index").index
-
-    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
-
-
-def test_validate():
-    child_identifiers = pd.DataFrame(
-        {
-            "UPN": [
-                # These should pass
-                "A38100178301",  # 0 In LA list
-                pd.NA,  # 1
-                "H003278544154",  # 2 In LA list
-                "R34",  # 3 Nonsense
-                # These should fail
-                "R421962919251",  # 4 Not in LA list
-                "X817558133462",  # 5 Not in LA list
-                "ASFFAGSVSV123",  # 6 Not in LA list, not numeric.
-                "A94300178301",  # 942/3 added in 23/24 ruleset, data added to check correct addition to rule
-            ]
-        }
-    )
-
-    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
-
-    issues = list(result.issues)
-
-    assert len(issues) == 3
-
-    assert issues == [
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 4),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 5),
-        IssueLocator(CINTable.ChildIdentifiers, UPN, 6),
-    ]
-
-    assert result.definition.code == 1530
-    assert (
-        result.definition.message
-        == "UPN invalid (characters 2-4 not a recognised LA code)"
-    )
+from typing import Mapping
+
+import pandas as pd
+
+from cin_validator.rule_engine import (
+    CINTable,
+    IssueLocator,
+    RuleContext,
+    rule_definition,
+)
+from cin_validator.test_engine import run_rule
+
+ChildIdentifiers = CINTable.ChildIdentifiers
+UPN = ChildIdentifiers.UPN
+
+
+@rule_definition(
+    code="1530",
+    module=CINTable.ChildIdentifiers,
+    message="UPN invalid (characters 2-4 not a recognised LA code)",
+    affected_fields=[UPN],
+)
+def validate(
+    data_container: Mapping[CINTable, pd.DataFrame], rule_context: RuleContext
+):
+    df = data_container[ChildIdentifiers]
+    """
+    If <UPN> (N00001) present then characters 2-4 of <UPN> must be a valid post April 1998 LA code 
+    or a recognised ‘pseudo LA’ code 
+
+    001-005, 201-213, 301-320, 330-336, 340-344, 350-359, 370-373, 380-384, 390-394, 420, 660-681, 
+    701-708, 800-803, 805-808, 810-813, 815, 816, 820- 823, 825, 826, 830, 831, 835-837, 838-839, 
+    840, 841, 845, 846, 850-852, 855-857, 860, 861, 865-896, 908, 909, 916, 919, 921, 925, 
+    926, 928, 929, 931, 933, 935-938, 940-941
+    """
+    LA_list = []
+    LA_list.extend("00" + str(x) for x in range(1, 6))
+    LA_list.extend(range(201, 214))
+    LA_list.extend(range(301, 321))
+    LA_list.extend(range(330, 337))
+    LA_list.extend(range(340, 345))
+    LA_list.extend(range(350, 360))
+    LA_list.extend(range(370, 374))
+    LA_list.extend(range(380, 385))
+    LA_list.extend(range(390, 395))
+    LA_list.extend(range(660, 682))
+    LA_list.extend(range(701, 709))
+    LA_list.extend(range(800, 804))
+    LA_list.extend(range(805, 809))
+    LA_list.extend(range(810, 814))
+    LA_list.extend(range(820, 824))
+    LA_list.extend(range(835, 840))
+    LA_list.extend(range(850, 853))
+    LA_list.extend(range(855, 858))
+    LA_list.extend(range(865, 897))
+    LA_list.extend(range(935, 939))
+    LA_list.extend(range(940, 942))
+    LA_list.extend(
+        [
+            420,
+            815,
+            816,
+            825,
+            826,
+            830,
+            831,
+            840,
+            841,
+            845,
+            846,
+            860,
+            861,
+            908,
+            909,
+            916,
+            919,
+            921,
+            925,
+            926,
+            928,
+            929,
+            931,
+            933,
+        ]
+    )
+
+    LA_list = [str(x) for x in LA_list]
+
+    df.reset_index(inplace=True)
+    df2 = df[["index", "UPN"]]
+    df2 = df2[(df2["UPN"].str.len() == 13) & df2["UPN"].notna()]
+    df2["C2_to_C4"] = df2["UPN"].str[1:4]
+    df2 = df2[~df2["C2_to_C4"].isin(LA_list)]
+
+    failing_indices = df2.set_index("index").index
+
+    rule_context.push_issue(table=ChildIdentifiers, field=UPN, row=failing_indices)
+
+
+def test_validate():
+    child_identifiers = pd.DataFrame(
+        {
+            "UPN": [
+                # These should pass
+                "A38100178301",  # 0 In LA list
+                pd.NA,  # 1
+                "H003278544154",  # 2 In LA list
+                "R34",  # 3 Nonsense
+                # These should fail
+                "R421962919251",  # 4 Not in LA list
+                "X817558133462",  # 5 Not in LA list
+                "ASFFAGSVSV123",  # 6 Not in LA list, not numeric.
+            ]
+        }
+    )
+
+    result = run_rule(validate, {ChildIdentifiers: child_identifiers})
+
+    issues = list(result.issues)
+
+    assert len(issues) == 3
+
+    assert issues == [
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 4),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 5),
+        IssueLocator(CINTable.ChildIdentifiers, UPN, 6),
+    ]
+
+    assert result.definition.code == "1530"
+    assert (
+        result.definition.message
+        == "UPN invalid (characters 2-4 not a recognised LA code)"
+    )
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/rules/ruleset_utils.py` & `csc_validator_be_cin-0.1.4/cin_validator/rules/ruleset_utils.py`

 * *Ordering differences only*

 * *Files 12% similar despite different names*

```diff
@@ -1,76 +1,76 @@
-import importlib
-from typing import Iterable
-
-from cin_validator.rule_engine import RuleDefinition, YearConfig
-
-
-def check_duplicate_rules(new_funcs: dict, funcs_so_far: dict) -> None:
-    duplicate_funcs = set(new_funcs.keys()) & set(funcs_so_far.keys())
-    if duplicate_funcs:
-        raise ValueError(f"Rule with code {duplicate_funcs} already exists")
-
-
-def extract_validator_functions(
-    file_paths: Iterable, marker: str = "__rule_def__"
-) -> dict[str, RuleDefinition]:
-    """
-    :param list file_paths: list of file paths to extract functions from.
-    :param str marker: marker to identify functions to extract.
-
-    :return: functions extracted from files.
-    :rtype: dict
-    """
-    validator_funcs: dict[str, RuleDefinition] = {}
-    for path in file_paths:
-        if path.stem == "__init__":
-            continue
-        try:
-            rule_content = importlib.import_module(
-                # for example, path.parent.stem == "cin2022_23" and path.stem == "rule_100.py"
-                f"cin_validator.rules.{path.parent.stem}.{path.stem}"
-            )
-        except ModuleNotFoundError:
-            # in the case where the file itself is passed in, rather than the directory
-            rule_content = importlib.import_module(f"{path.stem}")
-
-        validator_func = {
-            str(element.__rule_def__.code): element.__rule_def__
-            for _, element in vars(rule_content).items()
-            if hasattr(element, "__rule_def__")
-        }
-
-        check_duplicate_rules(validator_func, validator_funcs)
-
-        validator_funcs.update(validator_func)
-    return validator_funcs
-
-
-def update_validator_functions(
-    prev_validator_funcs, this_year_config: YearConfig
-) -> dict:
-    """
-    :param dict prev_registry: previous year's registry.
-    :param dict this_year_config: codes of rules that have been added or deleted.
-
-    :return: valid validator functions according to config.
-    :rtype: dict
-    """
-    # Rules present in both will be updated to this year's version. rules present in only this year will be added.
-    updated_validator_funcs = prev_validator_funcs | this_year_config.added_or_modified
-    # delete rules by their rules codes, if specified.
-    for deleted_rule in this_year_config.deleted:
-        del updated_validator_funcs[deleted_rule]
-    return updated_validator_funcs
-
-
-def get_year_ruleset(collection_year: str) -> dict[str, RuleDefinition]:
-    """
-    Gets the registry of validation rules for the year specified in the metadata.
-    """
-    # for example, convert "2023" to "lac2022_23"
-    ruleset = f"cin{int(collection_year)-1}_{collection_year[2:4]}"
-
-    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
-    registry = getattr(module, "registry")
-
-    return registry
+import importlib
+from typing import Iterable
+
+from cin_validator.rule_engine import RuleDefinition, YearConfig
+
+
+def check_duplicate_rules(new_funcs: dict, funcs_so_far: dict) -> None:
+    duplicate_funcs = set(new_funcs.keys()) & set(funcs_so_far.keys())
+    if duplicate_funcs:
+        raise ValueError(f"Rule with code {duplicate_funcs} already exists")
+
+
+def extract_validator_functions(
+    file_paths: Iterable, marker: str = "__rule_def__"
+) -> dict[str, RuleDefinition]:
+    """
+    :param list file_paths: list of file paths to extract functions from.
+    :param str marker: marker to identify functions to extract.
+
+    :return: functions extracted from files.
+    :rtype: dict
+    """
+    validator_funcs: dict[str, RuleDefinition] = {}
+    for path in file_paths:
+        if path.stem == "__init__":
+            continue
+        try:
+            rule_content = importlib.import_module(
+                # for example, path.parent.stem == "cin2022_23" and path.stem == "rule_100.py"
+                f"cin_validator.rules.{path.parent.stem}.{path.stem}"
+            )
+        except ModuleNotFoundError:
+            # in the case where the file itself is passed in, rather than the directory
+            rule_content = importlib.import_module(f"{path.stem}")
+
+        validator_func = {
+            str(element.__rule_def__.code): element.__rule_def__
+            for _, element in vars(rule_content).items()
+            if hasattr(element, "__rule_def__")
+        }
+
+        check_duplicate_rules(validator_func, validator_funcs)
+
+        validator_funcs.update(validator_func)
+    return validator_funcs
+
+
+def update_validator_functions(
+    prev_validator_funcs, this_year_config: YearConfig
+) -> dict:
+    """
+    :param dict prev_registry: previous year's registry.
+    :param dict this_year_config: codes of rules that have been added or deleted.
+
+    :return: valid validator functions according to config.
+    :rtype: dict
+    """
+    # Rules present in both will be updated to this year's version. rules present in only this year will be added.
+    updated_validator_funcs = prev_validator_funcs | this_year_config.added_or_modified
+    # delete rules by their rules codes, if specified.
+    for deleted_rule in this_year_config.deleted:
+        del updated_validator_funcs[deleted_rule]
+    return updated_validator_funcs
+
+
+def get_year_ruleset(collection_year: str) -> dict[str, RuleDefinition]:
+    """
+    Gets the registry of validation rules for the year specified in the metadata.
+    """
+    # for example, convert "2023" to "lac2022_23"
+    ruleset = f"cin{int(collection_year)-1}_{collection_year[2:4]}"
+
+    module = importlib.import_module(f"cin_validator.rules.{ruleset}")
+    registry = getattr(module, "registry")
+
+    return registry
```

### Comparing `csc_validator_be_cin-0.1.3/cin_validator/utils.py` & `csc_validator_be_cin-0.1.4/cin_validator/utils.py`

 * *Ordering differences only*

 * *Files 27% similar despite different names*

```diff
@@ -1,136 +1,136 @@
-import numpy as np
-import pandas as pd
-
-from cin_validator.england_holidates import england_holidates
-
-
-def get_values(xml_elements, table_dict: dict, xml_block):
-    """
-    Iterates through the input XML to extract values from XML input data for validation.
-    Called in the ingress to create each table.
-
-     :param list xml_elements: Contains elements of the collection to add to dictionary.
-     :param dictionary table_dict: Dictionary containing columns of each table to get values for.
-     :param DataFrame xml_block: Contains the name of the block to search the XML to make each table.
-        (Tambe these are DataFrames in ingress but are they DataFrames here?)
-     :returns: table_dict with XML elements where they exist, and pd.NA where they do not.
-     :rtype: Dictionary
-    """
-
-    for element in xml_elements:
-        try:
-            table_dict[element] = xml_block.find(element).text
-        except:
-            table_dict[element] = pd.NA
-    return table_dict
-
-
-def make_date(date_input: str):
-    """
-    Allows Ymd or dmY date inputs, used for make_census_period.
-    Important for test_validate functions.
-
-    :param str date_input: Contains the data data to be converted to pd.datetime
-        object as a string.
-    :reutrns: Date data input as pd.datetime object.
-    :rtype: pd.datetime object.
-    """
-
-    date = pd.to_datetime(date_input, format="%Y/%m/%d", errors="coerce")
-    if pd.isna(date):
-        date = pd.to_datetime(date_input, format="%d/%m/%Y", errors="coerce")
-    return date
-
-
-def make_census_period(reference_date: pd.Series):
-    """
-    Generates the census period with variables for each of the first and last
-    day of the census period. Thesze are April first of the previous year and the reference date.
-
-    :param DataFrame reference_date: A DataFrame containing data with the reference date of
-        the data being validated, selected from the Header DataFrame ReferenceDate column.
-    :returns: Dates of collection start and colleciton end as pd.datetime variables collection_start and
-        collection_end as a tuple.
-    :rtype: Tuple
-    """
-
-    # reference_date is a pandas series. Get it's value as a string by indexing the series' values array.
-    reference_date = reference_date.values[0]
-
-    # the ReferenceDate value is always the collection_end date
-    collection_end = make_date(reference_date)
-
-    # the collection start is the 1st of April of the previous year but dates from the day of the previous collection move to the next collection.
-    # e.g. in the 22-23 collection, 2022-03-31 is an allowed date according to the test data.
-    collection_start = make_date(reference_date) - pd.DateOffset(years=1)
-
-    return collection_start, collection_end
-
-
-def create_issue_locs(issues):
-    """
-    Reverses grouping of issue rows, creating a DataFrame where each row contains a single issue location.
-
-    :param NamedTuple-like-object issues: An object containing the fields for table, columns, and
-        row_df for issues found when validating data.
-    :returns: DataFrame with fields for ERROR_ID, ROW_ID, columns_affected, and tables_affected for
-        issues found in validation.
-    :rtype: DataFrame
-    """
-
-    # expand the row_id groups such that row_id value exists per row instead of a list
-    df_issue_locs = issues.row_df
-    df_issue_locs = df_issue_locs.explode("ROW_ID")
-
-    # map every row_id to its respective columns_affected list and expand that list
-    df_issue_locs["columns_affected"] = df_issue_locs["ERROR_ID"].apply(
-        lambda x: issues.columns
-    )
-    df_issue_locs = df_issue_locs.explode("columns_affected")
-
-    # all locations from a NamedTuple object will have the same singular value of tables_affected.
-    df_issue_locs["tables_affected"] = str(issues.table)[9:]
-
-    # now a one-to-one relationship exists across table-column-row
-    df_issue_locs.reset_index(inplace=True)
-    df_issue_locs.drop("index", axis=1, inplace=True)
-
-    return df_issue_locs
-
-
-def process_date_columns(df: pd.DataFrame):
-    """
-    Takes a DataFrame in and converts all columns with Date or date in the
-    title to pd.datetime objects. Used before validating rules to allow
-    comparisons between dates and datetime methods.
-
-    :param DataFrame df: DataFrame containing data to be validated.
-    :returns: DataFrame with date columns formatted to pd.datetime objects.
-    :rtype: DataFrame
-    """
-
-    for column in df:
-        if "date" in column.lower():
-            # pd.to_datetime is intelligent. It can deal with unforseen date formats
-            df[column] = pd.to_datetime(df[column], errors="coerce")
-    return df
-
-
-def create_holidays_array():
-    """
-    :return numpy-object _: business day calendar object that considers the bank holiday calendar of England and Wales
-    """
-    return np.busdaycalendar(holidays=england_holidates)
-
-
-def england_working_days(num_days: int):
-    """
-    This function implements a date offset based on a holiday calendar.
-    :param int num_days: number of days to offset by
-    :return pd.DateOffset-obj _: date offset
-    """
-
-    holiday_calendar = create_holidays_array()
-
-    # pd.offsets.CustomBusinessDay doesn't seem to include the end date so offset by 1 so that it does.
-    return pd.offsets.CustomBusinessDay(n=num_days - 1, calendar=holiday_calendar)
+import numpy as np
+import pandas as pd
+
+from cin_validator.england_holidates import england_holidates
+
+
+def get_values(xml_elements, table_dict: dict, xml_block):
+    """
+    Iterates through the input XML to extract values from XML input data for validation.
+    Called in the ingress to create each table.
+
+     :param list xml_elements: Contains elements of the collection to add to dictionary.
+     :param dictionary table_dict: Dictionary containing columns of each table to get values for.
+     :param DataFrame xml_block: Contains the name of the block to search the XML to make each table.
+        (Tambe these are DataFrames in ingress but are they DataFrames here?)
+     :returns: table_dict with XML elements where they exist, and pd.NA where they do not.
+     :rtype: Dictionary
+    """
+
+    for element in xml_elements:
+        try:
+            table_dict[element] = xml_block.find(element).text
+        except:
+            table_dict[element] = pd.NA
+    return table_dict
+
+
+def make_date(date_input: str):
+    """
+    Allows Ymd or dmY date inputs, used for make_census_period.
+    Important for test_validate functions.
+
+    :param str date_input: Contains the data data to be converted to pd.datetime
+        object as a string.
+    :reutrns: Date data input as pd.datetime object.
+    :rtype: pd.datetime object.
+    """
+
+    date = pd.to_datetime(date_input, format="%Y/%m/%d", errors="coerce")
+    if pd.isna(date):
+        date = pd.to_datetime(date_input, format="%d/%m/%Y", errors="coerce")
+    return date
+
+
+def make_census_period(reference_date: pd.Series):
+    """
+    Generates the census period with variables for each of the first and last
+    day of the census period. Thesze are April first of the previous year and the reference date.
+
+    :param DataFrame reference_date: A DataFrame containing data with the reference date of
+        the data being validated, selected from the Header DataFrame ReferenceDate column.
+    :returns: Dates of collection start and colleciton end as pd.datetime variables collection_start and
+        collection_end as a tuple.
+    :rtype: Tuple
+    """
+
+    # reference_date is a pandas series. Get it's value as a string by indexing the series' values array.
+    reference_date = reference_date.values[0]
+
+    # the ReferenceDate value is always the collection_end date
+    collection_end = make_date(reference_date)
+
+    # the collection start is the 1st of April of the previous year but dates from the day of the previous collection move to the next collection.
+    # e.g. in the 22-23 collection, 2022-03-31 is an allowed date according to the test data.
+    collection_start = make_date(reference_date) - pd.DateOffset(years=1)
+
+    return collection_start, collection_end
+
+
+def create_issue_locs(issues):
+    """
+    Reverses grouping of issue rows, creating a DataFrame where each row contains a single issue location.
+
+    :param NamedTuple-like-object issues: An object containing the fields for table, columns, and
+        row_df for issues found when validating data.
+    :returns: DataFrame with fields for ERROR_ID, ROW_ID, columns_affected, and tables_affected for
+        issues found in validation.
+    :rtype: DataFrame
+    """
+
+    # expand the row_id groups such that row_id value exists per row instead of a list
+    df_issue_locs = issues.row_df
+    df_issue_locs = df_issue_locs.explode("ROW_ID")
+
+    # map every row_id to its respective columns_affected list and expand that list
+    df_issue_locs["columns_affected"] = df_issue_locs["ERROR_ID"].apply(
+        lambda x: issues.columns
+    )
+    df_issue_locs = df_issue_locs.explode("columns_affected")
+
+    # all locations from a NamedTuple object will have the same singular value of tables_affected.
+    df_issue_locs["tables_affected"] = str(issues.table)[9:]
+
+    # now a one-to-one relationship exists across table-column-row
+    df_issue_locs.reset_index(inplace=True)
+    df_issue_locs.drop("index", axis=1, inplace=True)
+
+    return df_issue_locs
+
+
+def process_date_columns(df: pd.DataFrame):
+    """
+    Takes a DataFrame in and converts all columns with Date or date in the
+    title to pd.datetime objects. Used before validating rules to allow
+    comparisons between dates and datetime methods.
+
+    :param DataFrame df: DataFrame containing data to be validated.
+    :returns: DataFrame with date columns formatted to pd.datetime objects.
+    :rtype: DataFrame
+    """
+
+    for column in df:
+        if "date" in column.lower():
+            # pd.to_datetime is intelligent. It can deal with unforseen date formats
+            df[column] = pd.to_datetime(df[column], errors="coerce")
+    return df
+
+
+def create_holidays_array():
+    """
+    :return numpy-object _: business day calendar object that considers the bank holiday calendar of England and Wales
+    """
+    return np.busdaycalendar(holidays=england_holidates)
+
+
+def england_working_days(num_days: int):
+    """
+    This function implements a date offset based on a holiday calendar.
+    :param int num_days: number of days to offset by
+    :return pd.DateOffset-obj _: date offset
+    """
+
+    holiday_calendar = create_holidays_array()
+
+    # pd.offsets.CustomBusinessDay doesn't seem to include the end date so offset by 1 so that it does.
+    return pd.offsets.CustomBusinessDay(n=num_days - 1, calendar=holiday_calendar)
```

### Comparing `csc_validator_be_cin-0.1.3/rpc_main.py` & `csc_validator_be_cin-0.1.4/rpc_main.py`

 * *Ordering differences only*

 * *Files 11% similar despite different names*

```diff
@@ -1,118 +1,118 @@
-import datetime
-import json
-import logging
-import xml.etree.ElementTree as ET
-from typing import Optional
-
-from prpc_python import RpcApp
-
-from cin_validator import cin_validator
-from cin_validator.rules.ruleset_utils import get_year_ruleset
-
-logger = logging.getLogger(__name__)
-handler = logging.FileHandler(
-    datetime.datetime.now().strftime("lac validator --%d-%m-%Y %H.%M.%S.log")
-)
-
-f_format = logging.Formatter("%(asctime)s - %(levelname)s - % (message)s")
-handler.setFormatter(f_format)
-logger.addHandler(handler)
-
-app = RpcApp("validate_cin")
-
-
-@app.call
-def get_rules(collection_year: str) -> str:
-    """
-    :param str collection_year: validation year e.g "2023" for 2022/2023 validation rules.
-    :return rules_df: available rule codes and definitions according to chosen ruleset.
-    """
-    ruleset_registry = get_year_ruleset(collection_year)
-
-    rules = []
-    for _, rule in ruleset_registry.items():
-        rules.append(
-            {
-                "code": str(rule.code),
-                "description": str(rule.code) + " - " + str(rule.message),
-            }
-        )
-
-    return json.dumps(rules)
-
-
-@app.call
-def generate_tables(cin_data: dict) -> dict[str, dict]:
-    """
-    :param cin_data: files uploaded by user mapped to the field where files were uploaded.
-    :return cin_data_tables:  a dictionary of dataframes that has been converted to json.
-    """
-    # Only a single XML file representing the current year is accepted as an input by the tool.
-    cin_data_file = cin_data["This year"][0]
-    filetext = cin_data_file.read().decode("utf-8")
-    root = ET.fromstring(filetext)
-
-    data_files = cin_validator.convert_data(root)
-
-    # make data json-serialisable
-    cin_data_tables = {
-        table_name: table_df.to_json(orient="records")
-        for table_name, table_df in data_files.items()
-    }
-
-    return cin_data_tables
-
-
-@app.call
-def cin_validate(
-    cin_data: dict,
-    file_metadata: dict,
-    selected_rules: Optional[list[str]] = None,
-):
-    """
-    :param cin_data: eys are table names and values are CIN csv files.
-    :param file_metadata: contains collection year and local authority as strings.
-    :param selected_rules: array of rules the user has chosen. consists of rule codes as strings.
-
-    :return issue_report: issue locations in the data.
-    :return rule_defs: codes and descriptions of the rules that triggers issues in the data.
-    """
-    cin_data_file = cin_data["This year"][0]
-    filetext = cin_data_file.read().decode("utf-8")
-    root = ET.fromstring(filetext)
-
-    # fulltree = ET.parse("fake_data\\fake_CIN_data.xml")
-    # root = fulltree.getroot()
-
-    raw_data = cin_validator.convert_data(root)
-
-    # Send string-format data to the frontend.
-    cin_data_tables = {
-        table_name: table_df.to_json(orient="records")
-        for table_name, table_df in raw_data.items()
-    }
-
-    # Convert date columns to datetime format to enable comparison in rules.
-    data_files = cin_validator.process_data(raw_data)
-    # get rules to run based on specified year.
-    ruleset_registry = get_year_ruleset(file_metadata["collectionYear"])
-
-    # run validation
-    validator = cin_validator.CinValidator(data_files, ruleset_registry, selected_rules)
-
-    # make return data json-serialisable
-
-    # what the frontend will display
-    issue_report = validator.full_issue_df.to_json(orient="records")
-    multichild_issues = validator.multichild_issues.to_json(orient="records")
-
-    # what the user will download
-    user_report = validator.user_report.to_json(orient="records")
-
-    validation_results = {
-        "issue_locations": [issue_report],
-        "multichild_issues": [multichild_issues],
-        "data_tables": [cin_data_tables],
-        "user_report": [user_report],
-    }
-    return validation_results
+import datetime
+import json
+import logging
+import xml.etree.ElementTree as ET
+from typing import Optional
+
+from prpc_python import RpcApp
+
+from cin_validator import cin_validator
+from cin_validator.rules.ruleset_utils import get_year_ruleset
+
+logger = logging.getLogger(__name__)
+handler = logging.FileHandler(
+    datetime.datetime.now().strftime("lac validator --%d-%m-%Y %H.%M.%S.log")
+)
+
+f_format = logging.Formatter("%(asctime)s - %(levelname)s - % (message)s")
+handler.setFormatter(f_format)
+logger.addHandler(handler)
+
+app = RpcApp("validate_cin")
+
+
+@app.call
+def get_rules(collection_year: str) -> str:
+    """
+    :param str collection_year: validation year e.g "2023" for 2022/2023 validation rules.
+    :return rules_df: available rule codes and definitions according to chosen ruleset.
+    """
+    ruleset_registry = get_year_ruleset(collection_year)
+
+    rules = []
+    for _, rule in ruleset_registry.items():
+        rules.append(
+            {
+                "code": str(rule.code),
+                "description": str(rule.code) + " - " + str(rule.message),
+            }
+        )
+
+    return json.dumps(rules)
+
+
+@app.call
+def generate_tables(cin_data: dict) -> dict[str, dict]:
+    """
+    :param cin_data: files uploaded by user mapped to the field where files were uploaded.
+    :return cin_data_tables:  a dictionary of dataframes that has been converted to json.
+    """
+    # Only a single XML file representing the current year is accepted as an input by the tool.
+    cin_data_file = cin_data["This year"][0]
+    filetext = cin_data_file.read().decode("utf-8")
+    root = ET.fromstring(filetext)
+
+    data_files = cin_validator.convert_data(root)
+
+    # make data json-serialisable
+    cin_data_tables = {
+        table_name: table_df.to_json(orient="records")
+        for table_name, table_df in data_files.items()
+    }
+
+    return cin_data_tables
+
+
+@app.call
+def cin_validate(
+    cin_data: dict,
+    file_metadata: dict,
+    selected_rules: Optional[list[str]] = None,
+):
+    """
+    :param cin_data: eys are table names and values are CIN csv files.
+    :param file_metadata: contains collection year and local authority as strings.
+    :param selected_rules: array of rules the user has chosen. consists of rule codes as strings.
+
+    :return issue_report: issue locations in the data.
+    :return rule_defs: codes and descriptions of the rules that triggers issues in the data.
+    """
+    cin_data_file = cin_data["This year"][0]
+    filetext = cin_data_file.read().decode("utf-8")
+    root = ET.fromstring(filetext)
+
+    # fulltree = ET.parse("fake_data\\fake_CIN_data.xml")
+    # root = fulltree.getroot()
+
+    raw_data = cin_validator.convert_data(root)
+
+    # Send string-format data to the frontend.
+    cin_data_tables = {
+        table_name: table_df.to_json(orient="records")
+        for table_name, table_df in raw_data.items()
+    }
+
+    # Convert date columns to datetime format to enable comparison in rules.
+    data_files = cin_validator.process_data(raw_data)
+    # get rules to run based on specified year.
+    ruleset_registry = get_year_ruleset(file_metadata["collectionYear"])
+
+    # run validation
+    validator = cin_validator.CinValidator(data_files, ruleset_registry, selected_rules)
+
+    # make return data json-serialisable
+
+    # what the frontend will display
+    issue_report = validator.full_issue_df.to_json(orient="records")
+    multichild_issues = validator.multichild_issues.to_json(orient="records")
+
+    # what the user will download
+    user_report = validator.user_report.to_json(orient="records")
+
+    validation_results = {
+        "issue_locations": [issue_report],
+        "multichild_issues": [multichild_issues],
+        "data_tables": [cin_data_tables],
+        "user_report": [user_report],
+    }
+    return validation_results
```

### Comparing `csc_validator_be_cin-0.1.3/PKG-INFO` & `csc_validator_be_cin-0.1.4/README.md`

 * *Files 13% similar despite different names*

```diff
@@ -1,30 +1,7 @@
-Metadata-Version: 2.1
-Name: csc-validator-be-cin
-Version: 0.1.3
-Summary: Shared module for validating CIN census data using DfE rules.
-Home-page: https://github.com/data-to-insight/csc-validator-be-cin
-License: MIT
-Author: Tambe Tabitha
-Author-email: tambe.tabitha@socialfinance.org.uk>, Kaj Siebert <kaj.siebert@socialfinance.org.uk>, William Levack-Payne <william.levack-payne@eastsussex.gov.uk>, DatatoInsight's children's social care analyst community <datatoinsight.enquiries@gmail.com
-Requires-Python: >=3.9,<4.0
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.9
-Classifier: Programming Language :: Python :: 3.10
-Classifier: Programming Language :: Python :: 3.11
-Requires-Dist: click-log (>=0.4.0,<0.5.0)
-Requires-Dist: govuk-bank-holidays (>=0.13,<0.14)
-Requires-Dist: pandas (>=1.4.2,<2.0.0)
-Requires-Dist: prpc-python (>=0.9.2,<0.10.0)
-Requires-Dist: rich (>=13.5.3,<14.0.0)
-Requires-Dist: testfixtures (>=7.1.0,<8.0.0)
-Project-URL: Repository, https://github.com/data-to-insight/csc-validator-be-cin
-Description-Content-Type: text/markdown
-
 # CIN-validator
 The CIN validator is an open source, volunteer built tool that allows users to validate CIN census data year round via the command line, or using the browser based front end (URL HERE). It also provides a framework which other validation tools can easily be built on top of.
 
 The functions are documented using sphinx format so that a docs website can be auto-generated if need be. Also, there is an increased use of python type-hints as a form of intrinsic documentation. This does not apply to test functions as they neither receive nor return data, in the strict sense.
 More extensive documentation can be found here: https://data-to-insight.github.io/CIN-validator/
 
 ## Setup
@@ -43,26 +20,42 @@
 - To run rules on a file and select an instance of an error based on its ID:  
 `python -m cin_validator run <path to test data> -e "<ERROR_ID as string>"`
 - To convert a CIN XML file to it's respective CSV tables:  
 `python -m cin_validator xmltocsv <path to test data>`
 
 ## Yearly tool updates
 
-### update rule resources
+### Update rule resources
 - Run ` python get_uk_holidays.py` in the command line. This fetches the latest values of bank holidays into `cin_validator\england_holidates.py` (don't edit this file directly) for the rules that need them. Remember to convert \ to / if you are using a unix operating system.
 
-### update rules
+### Update rules
 - If any rules have been added or changed with respect to the previous year, create files for them in a rule folder named after the new validation year. For example, new or added rules for the 2023/24 validation year should be created in a folder named `cin2023_24`. Do not copy over rules that haven't changed.
 - The __init__.py file contains the code that pulls in rules from the previous year and modifies them to meet the current year's specification. Copy across that init file whenever a folder for a new collection_year is created. Change the import to the name of the previous year's folder. 
 - If the new specifications require that some rules are deleted, add their codes as strings to the `del_list` array in the current year's init file. Do not delete the rules manually. 
 - Any new rules or modified rules should be added by creating a file for each rule and writing the modified code or new code. Even for small modifications, create a new file for the rule in the year where the modification was made instead of going backwards into the previous years and editing the original file.
 - To run the modified set of rules from the command line interface, you can use the `-r` or `--ruleset` flag to specify the name of the rule folder that you wish to run. Otherwise, feel free to update the defaults of the commands so that they point to the new year's folder instead. For example, change `cin2022_23` to `cin2023_24`. 
 
-## make changes available to user
-- delete the `dist` folder completely.
+## Make changes available to user
+This part is a guide on how to update the frontend so that it reflects the changes that have been done in the backend.
+- Delete the `dist` folder completely.
+- Update the package version in the `pyproject.toml` file. (there is a section below to help you choose the new number.)
 - run `poetry install` (installs project dependencies) and then `poetry shell` (ensures project runs in controlled environment) in the command line. You might have already done this when updating the rules.
 - check that validation rules work as expected (pass) when you run `poetry python -m cin_validator test` in the command line.
 - Then run `poetry build` in the command line. You will see that this creates a new `dist` folder.
-- take the `.whl` file from the dist folder in this repo, go to the `public\bin\dist` location in the frontend repo, delete the cin...whl file in it and add this one.
-- Do a pull request to the frontend repo, containing your changes. When that is merged in, the tool will be updated automatically so that your rules updates from the backend (which were zipped up in the wheel file), are now publicly available.
+- Push the pyproject.toml change to github and do a pull request. 
+- When the version-number-change pull request is merged in, do a `release` by navigating to the release page from the right hand control bar on the repo homepage (click on `Releases` then `draft new release` in the top right hand corner)
+- The release tag is created by including a `v` before the version number which you put in the `pyproject.toml` file. For example, if you filled in `version = "0.1.3"` then on Github, write `v0.1.3` as your release tag.
+- Click on `generate release notes` at the top right of the main text box. Commit messages of all changes made since the last release will appear in the text box.
+- Create a release title that starts with a ddmmyyy pattern to indicate the date of the release and then you can write a few words to describe the changes made since the last release.
+- take the `.whl` file from the dist folder in this repo, go to the `public\bin\dist` location in the [frontend repo](https://github.com/data-to-insight/csc-validator-fe), delete the previous cin..`.whl` file in it and add this one.
+- Search for the former wheel name on the frontend repo and update all locations where the wheel file name is referenced so that they now point to the new wheel file name with updated version number. [Here is an example](https://github.com/data-to-insight/csc-validator-fe/pull/177/files).
+- Do a pull request to the frontend repo, containing your changes. 
+- When the frontend pull request is merged in, the live tool will be updated automatically. You can confirm by checking that the version number in the footer of the web app has changed.
 - You can watch the deployment process in the `Actions` tab on Github when your pull request is merged to the frontend.
 - All done !
+
+#### Notes about choosing version numbers
+When changes are rules updates (add/delete/modify) or bug fixes, only the last part of the version number should be updated (e.g `v0.1.9` becomes `v0.1.10`). 
+<br/>
+The middle number is only updated when new features have been added (the changes enable user functionality that was not previously available).<br/>
+Finally, the first part of the version number is changed when breaking changes are present (new version of tool is incompatible with previous version e.g when functions in the api, `rpc_main.py`, change.)
+Read more about [semantic versioning here](https://semver.org/).
```

