# Comparing `tmp/nemo2riva-2.15.1-py3-none-any.whl.zip` & `tmp/nemo2riva-2.9.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,38 +1,37 @@
-Zip file size: 33705 bytes, number of entries: 36
--rw-r--r--  2.0 unx      197 b- defN 24-May-16 19:41 nemo2riva/__init__.py
--rw-r--r--  2.0 unx     2340 b- defN 24-May-16 19:41 nemo2riva/args.py
--rw-r--r--  2.0 unx     5163 b- defN 24-May-16 19:41 nemo2riva/artifacts.py
--rw-r--r--  2.0 unx     3500 b- defN 24-May-16 19:41 nemo2riva/convert.py
--rw-r--r--  2.0 unx     6516 b- defN 24-May-16 19:41 nemo2riva/cookbook.py
--rw-r--r--  2.0 unx     8403 b- defN 24-May-16 19:41 nemo2riva/schema.py
--rw-r--r--  2.0 unx      177 b- defN 24-May-16 19:41 nemo2riva/cli/__init__.py
--rw-r--r--  2.0 unx     2932 b- defN 24-May-16 19:41 nemo2riva/cli/nemo2riva.py
--rw-r--r--  2.0 unx      742 b- defN 24-May-16 19:41 nemo2riva/patches/__init__.py
--rw-r--r--  2.0 unx      713 b- defN 24-May-16 19:41 nemo2riva/patches/ctc.py
--rw-r--r--  2.0 unx      532 b- defN 24-May-16 19:41 nemo2riva/patches/ctc_bpe.py
--rw-r--r--  2.0 unx     1017 b- defN 24-May-16 19:41 nemo2riva/patches/mtencdec.py
--rw-r--r--  2.0 unx      435 b- defN 24-May-16 19:41 nemo2riva/patches/tts/__init__.py
--rw-r--r--  2.0 unx     1281 b- defN 24-May-16 19:41 nemo2riva/patches/tts/fastpitch.py
--rw-r--r--  2.0 unx     5511 b- defN 24-May-16 19:41 nemo2riva/patches/tts/general.py
--rw-r--r--  2.0 unx    16949 b- defN 24-May-16 19:41 nemo2riva/patches/tts/radtts.py
--rw-r--r--  2.0 unx        0 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/__init__.py
--rw-rw-r--  2.0 unx      882 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/asr-scr-exported-encdecclsmodel.yaml
--rw-rw-r--  2.0 unx      888 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/asr-stt-exported-encdecctcmodel.yaml
--rw-rw-r--  2.0 unx     1138 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/asr-stt-exported-encdectcmodelbpe.yaml
--rw-rw-r--  2.0 unx     1186 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-isc-exported-bert.yaml
--rw-rw-r--  2.0 unx     1340 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml
--rw-rw-r--  2.0 unx     1362 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-mt-exported-megatronnmtmodel.yaml
--rw-rw-r--  2.0 unx     1209 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-pc-exported-bert.yaml
--rw-rw-r--  2.0 unx     1079 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-qa-exported-bert.yaml
--rw-rw-r--  2.0 unx     1177 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-tc-exported-bert.yaml
--rw-rw-r--  2.0 unx     1139 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/nlp-tkc-exported-bert.yaml
--rw-rw-r--  2.0 unx      800 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/tts-exported-fastpitchmodel.yaml
--rw-rw-r--  2.0 unx      882 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/tts-exported-hifiganmodel.yaml
--rw-rw-r--  2.0 unx      867 b- defN 24-May-16 19:41 nemo2riva/validation_schemas/tts-exported-radttsmodel.yaml
--rw-rw-r--  2.0 unx     1096 b- defN 24-May-16 20:24 nemo2riva-2.15.1.dist-info/LICENSE
--rw-r--r--  2.0 unx      483 b- defN 24-May-16 20:24 nemo2riva-2.15.1.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-May-16 20:24 nemo2riva-2.15.1.dist-info/WHEEL
--rw-r--r--  2.0 unx       54 b- defN 24-May-16 20:24 nemo2riva-2.15.1.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       10 b- defN 24-May-16 20:24 nemo2riva-2.15.1.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3422 b- defN 24-May-16 20:24 nemo2riva-2.15.1.dist-info/RECORD
-36 files, 75514 bytes uncompressed, 28059 bytes compressed:  62.8%
+Zip file size: 32675 bytes, number of entries: 35
+-rw-rw-r--  2.0 unx      197 b- defN 23-Jan-19 10:25 nemo2riva/__init__.py
+-rw-rw-r--  2.0 unx     1833 b- defN 23-Jan-19 10:25 nemo2riva/args.py
+-rw-r--r--  2.0 unx     5163 b- defN 23-Jan-20 05:04 nemo2riva/artifacts.py
+-rw-r--r--  2.0 unx     3288 b- defN 23-Jan-20 06:16 nemo2riva/convert.py
+-rw-r--r--  2.0 unx     6155 b- defN 23-Jan-20 06:16 nemo2riva/cookbook.py
+-rw-rw-r--  2.0 unx     7923 b- defN 23-Jan-19 10:25 nemo2riva/schema.py
+-rw-rw-r--  2.0 unx      177 b- defN 23-Jan-19 10:25 nemo2riva/cli/__init__.py
+-rw-rw-r--  2.0 unx     2932 b- defN 23-Jan-19 10:25 nemo2riva/cli/nemo2riva.py
+-rw-r--r--  2.0 unx      742 b- defN 23-Jan-20 06:16 nemo2riva/patches/__init__.py
+-rw-rw-r--  2.0 unx      713 b- defN 23-Jan-19 10:25 nemo2riva/patches/ctc.py
+-rw-rw-r--  2.0 unx      532 b- defN 23-Jan-19 10:25 nemo2riva/patches/ctc_bpe.py
+-rw-rw-r--  2.0 unx     1007 b- defN 23-Jan-19 10:25 nemo2riva/patches/mtencdec.py
+-rw-r--r--  2.0 unx      435 b- defN 23-Jan-20 06:16 nemo2riva/patches/tts/__init__.py
+-rw-r--r--  2.0 unx     6941 b- defN 23-Jan-20 06:16 nemo2riva/patches/tts/fastpitch.py
+-rw-r--r--  2.0 unx     3847 b- defN 23-Jan-19 10:25 nemo2riva/patches/tts/general.py
+-rw-r--r--  2.0 unx    13683 b- defN 23-Jan-20 06:16 nemo2riva/patches/tts/radtts.py
+-rw-rw-r--  2.0 unx      882 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/asr-scr-exported-encdecclsmodel.yaml
+-rw-rw-r--  2.0 unx      888 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/asr-stt-exported-encdecctcmodel.yaml
+-rw-rw-r--  2.0 unx     1138 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/asr-stt-exported-encdectcmodelbpe.yaml
+-rw-rw-r--  2.0 unx     1186 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/nlp-isc-exported-bert.yaml
+-rw-rw-r--  2.0 unx     1276 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml
+-rw-rw-r--  2.0 unx     1209 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/nlp-pc-exported-bert.yaml
+-rw-rw-r--  2.0 unx     1079 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/nlp-qa-exported-bert.yaml
+-rw-rw-r--  2.0 unx     1177 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/nlp-tc-exported-bert.yaml
+-rw-rw-r--  2.0 unx     1139 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/nlp-tkc-exported-bert.yaml
+-rw-rw-r--  2.0 unx      800 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/tts-exported-fastpitchmodel.yaml
+-rw-rw-r--  2.0 unx      882 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/tts-exported-hifiganmodel.yaml
+-rw-rw-r--  2.0 unx      867 b- defN 23-Jan-19 10:25 nemo2riva/validation_schemas/tts-exported-radttsmodel.yaml
+-rw-rw-r--  2.0 unx       10 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/DESCRIPTION.rst
+-rw-rw-r--  2.0 unx       55 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/entry_points.txt
+-rw-rw-r--  2.0 unx      705 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/metadata.json
+-rw-rw-r--  2.0 unx       10 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx       92 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/WHEEL
+-rw-rw-r--  2.0 unx      401 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/METADATA
+-rw-rw-r--  2.0 unx     3335 b- defN 23-Feb-13 05:16 nemo2riva-2.9.0.dist-info/RECORD
+35 files, 72699 bytes uncompressed, 27235 bytes compressed:  62.5%
```

## zipnote {}

```diff
@@ -42,17 +42,14 @@
 
 Filename: nemo2riva/patches/tts/general.py
 Comment: 
 
 Filename: nemo2riva/patches/tts/radtts.py
 Comment: 
 
-Filename: nemo2riva/validation_schemas/__init__.py
-Comment: 
-
 Filename: nemo2riva/validation_schemas/asr-scr-exported-encdecclsmodel.yaml
 Comment: 
 
 Filename: nemo2riva/validation_schemas/asr-stt-exported-encdecctcmodel.yaml
 Comment: 
 
 Filename: nemo2riva/validation_schemas/asr-stt-exported-encdectcmodelbpe.yaml
@@ -60,17 +57,14 @@
 
 Filename: nemo2riva/validation_schemas/nlp-isc-exported-bert.yaml
 Comment: 
 
 Filename: nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml
 Comment: 
 
-Filename: nemo2riva/validation_schemas/nlp-mt-exported-megatronnmtmodel.yaml
-Comment: 
-
 Filename: nemo2riva/validation_schemas/nlp-pc-exported-bert.yaml
 Comment: 
 
 Filename: nemo2riva/validation_schemas/nlp-qa-exported-bert.yaml
 Comment: 
 
 Filename: nemo2riva/validation_schemas/nlp-tc-exported-bert.yaml
@@ -84,26 +78,29 @@
 
 Filename: nemo2riva/validation_schemas/tts-exported-hifiganmodel.yaml
 Comment: 
 
 Filename: nemo2riva/validation_schemas/tts-exported-radttsmodel.yaml
 Comment: 
 
-Filename: nemo2riva-2.15.1.dist-info/LICENSE
+Filename: nemo2riva-2.9.0.dist-info/DESCRIPTION.rst
+Comment: 
+
+Filename: nemo2riva-2.9.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: nemo2riva-2.15.1.dist-info/METADATA
+Filename: nemo2riva-2.9.0.dist-info/metadata.json
 Comment: 
 
-Filename: nemo2riva-2.15.1.dist-info/WHEEL
+Filename: nemo2riva-2.9.0.dist-info/top_level.txt
 Comment: 
 
-Filename: nemo2riva-2.15.1.dist-info/entry_points.txt
+Filename: nemo2riva-2.9.0.dist-info/WHEEL
 Comment: 
 
-Filename: nemo2riva-2.15.1.dist-info/top_level.txt
+Filename: nemo2riva-2.9.0.dist-info/METADATA
 Comment: 
 
-Filename: nemo2riva-2.15.1.dist-info/RECORD
+Filename: nemo2riva-2.9.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## nemo2riva/args.py

```diff
@@ -22,28 +22,13 @@
         "--autocast",
         type=lambda x: bool(strtobool(x)),
         default=None,
         help="Override autocast in the schema : True|False",
     )
     parser.add_argument("--max-batch", type=int, default=None, help="Max batch size for model export")
     parser.add_argument("--max-dim", type=int, default=None, help="Max dimension(s) for model export")
-    parser.add_argument("--onnx-opset", type=int, default=16, help="ONNX opset for model export")
+    parser.add_argument("--onnx-opset", type=int, default=None, help="ONNX opset for model export")
     parser.add_argument("--device", default="cuda", help="Device to export for")
     parser.add_argument("--export-subnet", default=None, help="Export specified subnetwork/layer")
-    parser.add_argument(
-        "--cache-support",
-        type=lambda x: bool(strtobool(x)),
-        default=None,
-        help="[ deprecated ] cache support for models that support it"
-    )
-    parser.add_argument(
-        "--export-config",
-        metavar="KEY=VALUE",
-        nargs='+',
-        help="Set a number of key-value pairs to model.export_config dictionary "
-        "(do not put spaces before or after the = sign). "
-        "Note that values are always treated as strings.",
-    )
 
     args = parser.parse_args(argv)
-        
     return args
```

## nemo2riva/convert.py

```diff
@@ -8,15 +8,14 @@
 from dataclasses import dataclass
 from typing import Optional
 
 import torch
 from nemo.core import ModelPT
 from nemo.core.config.pytorch_lightning import TrainerConfig
 from nemo.utils import logging
-from omegaconf import OmegaConf
 from pytorch_lightning import Trainer
 
 from nemo2riva.artifacts import get_artifacts
 from nemo2riva.cookbook import export_model, save_archive
 from nemo2riva.schema import get_import_config, get_subnet, validate_archive
 
 
@@ -32,28 +31,25 @@
         riva_out = riva_out.split(".")
         riva_out[-2] += "-" + args.export_subnet
         riva_out = (".").join(riva_out)
 
     logging.info("Restoring NeMo model from '{}'".format(nemo_in))
     # Create a PL trainer object which is required for restoring Megatron models
     cfg_trainer = TrainerConfig(
-        accelerator='auto',
+        gpus=1,
+        accelerator="ddp",
         num_nodes=1,
-        devices=1,
         # Need to set the following two to False as ExpManager will take care of them differently.
         logger=False,
-        enable_checkpointing=False,
     )
-    cfg_trainer = OmegaConf.to_container(OmegaConf.create(cfg_trainer))
-    trainer = Trainer(**cfg_trainer)
+    trainer = Trainer(cfg_trainer)
 
     try:
-        with torch.inference_mode():
-            # Restore instance from .nemo file using generic model restore_from
-            model = ModelPT.restore_from(restore_path=nemo_in, trainer=trainer)
+        # Restore instance from .nemo file using generic model restore_from
+        model = ModelPT.restore_from(restore_path=nemo_in, trainer=trainer)
     except Exception as e:
         logging.error(
             "Failed to restore model from NeMo file : {}. Please make sure you have the latest NeMo package installed with [all] dependencies.".format(
                 nemo_in
             )
         )
         raise e
@@ -73,15 +69,15 @@
         logging.warning('Schema says encryption should be used, but no encryption key passed!')
 
     model.eval()
     with torch.no_grad():
         with warnings.catch_warnings():
             warnings.filterwarnings('ignore', category=UserWarning)
             # TODO: revisit export_subnet cli arg
-            patch_kwargs = {"import_config" : cfg}
+            patch_kwargs = {}
             if args.export_subnet:
                 patch_kwargs['export_subnet'] = args.export_subnet
             artifacts, manifest = get_artifacts(restore_path=nemo_in, model=model, passphrase=key, **patch_kwargs)
 
             for export_cfg in cfg.exports:
                 subnet = get_subnet(model, export_cfg.export_subnet)
                 export_model(
```

## nemo2riva/cookbook.py

```diff
@@ -46,21 +46,14 @@
         }
     elif cfg.export_format == "CKPT":
         format_meta = {"has_pytorch_checkpoint": True, "runtime": "PyTorch"}
     # TODO: use submodel sections
     metadata.update(format_meta)
     runtime = format_meta["runtime"]
     metadata.update({"runtime": runtime})
-    
-    if hasattr(model, "set_export_config"):
-        model.set_export_config(cfg.export_args)
-    else:
-        if cfg.export_args.get("cache_support", False) and hasattr(model, "encoder") and hasattr(model.encoder, "export_cache_support"):
-            model.encoder.export_cache_support = True
-            logging.info("Caching support is enabled.")
 
     with tempfile.TemporaryDirectory() as tmpdir:
         export_filename = cfg.export_file
         export_file = os.path.join(tmpdir, export_filename)
 
         if cfg.export_format in ["ONNX", "TS"]:
             # Export the model, get the descriptions.
@@ -86,15 +79,15 @@
 
                     input_example = model.input_module.input_example(**in_args)
                     _, descriptions = model.export(
                         export_file,
                         input_example=input_example,
                         check_trace=args.runtime_check,
                         onnx_opset_version=args.onnx_opset,
-                        verbose=bool(args.verbose),
+                        verbose=args.verbose,
                     )
                     del model
                 if cfg.export_format == 'ONNX':
                     o_list = os.listdir(tmpdir)
                     save_as_external_data = len(o_list) > 1
                     # fold-constants part
                     model_onnx = onnx.load_model(export_file)
```

## nemo2riva/schema.py

```diff
@@ -1,14 +1,14 @@
 # SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 # SPDX-License-Identifier: MIT
 
 import os
 import sys
 from dataclasses import dataclass
-from typing import List, Optional, Dict
+from typing import List, Optional
 
 import torch
 from eff.core import Archive
 from eff.validator import schema_validate_archive
 from nemo.package_info import __version__ as nemo_version
 from nemo.utils import logging
 from omegaconf import OmegaConf
@@ -27,16 +27,16 @@
     # Export format.
     export_subnet: str = ""
     export_format: str = "ONNX"
     export_file: str = "model_graph.onnx"
     encryption: Optional[str] = None
     autocast: bool = False
     max_dim: int = None
-    export_args: Optional[Dict[str,str]] = None
-    
+
+
 @dataclass
 class ImportConfig:
     """Default config model for the model that exports to ONNX."""
 
     exports = [None]
     # Encryption option.
     should_encrypt: bool = False
@@ -86,27 +86,14 @@
         conf.export_file = os.path.splitext(conf.export_file)[0] + "." + conf.export_format.lower()
 
     if conf.export_format not in supported_formats:
         raise Exception(
             "Format `{}` is invalid. Please pick one of the ({})".format(conf.export_format, supported_formats)
         )
 
-    # TODO: read from schema?
-    conf.export_args = {}
-    if args.export_config:
-        for key_value in args.export_config:
-            lst = key_value.split("=")
-            if len(lst) != 2:
-                raise Exception("Use correct format for --export_config: k=v")
-            k, v = lst
-            conf.export_args[k] = v
-
-    if args.cache_support:
-        conf.export_args.update({"cache_support": "True"})
-
     return conf
 
 
 def get_schema_key(model):
     key = model.cfg.target
     # normalize the key: remove extra qualifiers
     keylist = key.split('.')
```

## nemo2riva/patches/mtencdec.py

```diff
@@ -1,14 +1,14 @@
 # SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 # SPDX-License-Identifier: MIT
 
 import yaml
 
 
-def change_tokenizer_names(model, artifacts, **kwargs):
+def change_tokenizer_names(model, artifacts):
     if model.__class__.__name__ == 'MTEncDecModel':
 
         conf = yaml.safe_load(artifacts['model_config.yaml']['content'])
 
         enctok = conf['encoder_tokenizer']['tokenizer_model']
         if enctok not in artifacts:
             enctok = enctok.replace("nemo:", "")
```

## nemo2riva/patches/tts/fastpitch.py

```diff
@@ -1,26 +1,140 @@
 # SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 # SPDX-License-Identifier: MIT
 
 import nemo
+import torch
 import yaml
+from nemo.collections.tts.helpers.helpers import regulate_len
+from nemo.core.neural_types.elements import (
+    Index,
+    MelSpectrogramType,
+    RegressionValuesType,
+    TokenDurationType,
+    TokenIndex,
+    TokenLogDurationType,
+)
+from nemo.core.neural_types.neural_type import NeuralType
 from packaging.version import Version
 
+from nemo2riva.patches.tts.general import create_batch
+
+# Note: No need to mock as we don't support nemo2riva in our servicemaker container. Nemo2riva
+#       should be done inside the NeMo training container.
+# # fmt: off
+# # Need to mock pillow as we uninstall pillow in our docker
+# # All import pillow calls are from `import matplotlib` and since nemo2riva doesn't use matplotlib, we should be safe to just mock it
+# from mock import MagicMock
+# sys.modules["PIL"] = MagicMock()
+# sys.modules["PIL.PngImagePlugin"] = MagicMock()
+# # fmt: on
+
+
 def fastpitch_model_versioning(model, artifacts, **kwargs):
     # Riva supports some additional features over NeMo fastpitch models depending on the version
     # Namely, we need to patch in volume support and ragged batched support for lower NeMo versions
     try:
         nemo_version = Version(nemo.__version__)
     except NameError:
         # If can't find the nemo version, return without patching
         return None
     if model.__class__.__name__ == 'FastPitchModel':
-        # For NeMo version >= 1.11.0; set the relevant flags
-        model.export_config["enable_volume"] = True
-        model.export_config["enable_ragged_batches"] = True
+        if nemo_version < Version('1.11.0'):
+            # If nemo_version is less than 1.10, we need to manually add the volume updates
+            # and the ragged batch updates
+
+            # Patch model's _prepare_for_export()
+            def _prepare_for_export(self, **kwargs):
+                super(model.__class__, model)._prepare_for_export(**kwargs)
+
+                # Define input_types and output_types as required by export()
+                self._input_types = {
+                    "text": NeuralType(('T'), TokenIndex()),
+                    "pitch": NeuralType(('T'), RegressionValuesType()),
+                    "pace": NeuralType(('T')),
+                    "volume": NeuralType(('T'), optional=True),
+                    "batch_lengths": NeuralType(('B'), optional=True),
+                    "speaker": NeuralType(('B'), Index(), optional=True),
+                }
+                self._output_types = {
+                    "spect": NeuralType(('B', 'D', 'T_spec'), MelSpectrogramType()),
+                    "num_frames": NeuralType(('B'), TokenDurationType()),
+                    "durs_predicted": NeuralType(('B', 'T_text'), TokenDurationType()),
+                    "log_durs_predicted": NeuralType(('B', 'T_text'), TokenLogDurationType()),
+                    "pitch_predicted": NeuralType(('B', 'T_text'), RegressionValuesType()),
+                    "volume_aligned": NeuralType(('B', 'T_spec'), RegressionValuesType()),
+                }
+
+            model.__class__._prepare_for_export = _prepare_for_export
+
+            # Patch module's infer()
+            def forward_for_export(self, text, pitch, pace, volume, batch_lengths, speaker=None):
+                text, pitch, pace, volume = create_batch(
+                    text, pitch, pace, batch_lengths, padding_idx=self.fastpitch.encoder.padding_idx, volume=volume
+                )
+                try:
+                    return self.fastpitch.infer(text=text, pitch=pitch, pace=pace, volume=volume, speaker=speaker)
+                except TypeError as e:
+                    if 'volume' in str(e):
+                        # NeMo version <= 1.9.0 when we don't return volume
+                        base_return = self.fastpitch.infer(text=text, pitch=pitch, pace=pace, speaker=speaker)
+                        durs_predicted = base_return[2]
+                        volume_extended, _ = regulate_len(durs_predicted, volume.unsqueeze(-1), pace)
+                        volume_extended = volume_extended.squeeze(-1).float()
+                        return (*base_return, volume_extended)
+
+            model.__class__.forward_for_export = forward_for_export
+
+            # Patch module's input_example()
+            def input_example(self, max_batch=1, max_dim=44):
+                par = next(self.fastpitch.parameters())
+                sz = (max_batch * max_dim,)
+                inp = torch.randint(
+                    0, self.fastpitch.encoder.word_emb.num_embeddings, sz, device=par.device, dtype=torch.int64
+                )
+                pitch = torch.randn(sz, device=par.device, dtype=torch.float32) * 0.5
+                pace = torch.clamp(torch.randn(sz, device=par.device, dtype=torch.float32) * 0.1 + 1, min=0.01)
+
+                inputs = {'text': inp, 'pitch': pitch, 'pace': pace}
+
+                volume = torch.clamp(torch.randn(sz, device=par.device, dtype=torch.float32) * 0.1 + 1, min=0.01)
+                inputs['volume'] = volume
+                batch_lengths = torch.zeros((max_batch + 1), device=par.device, dtype=torch.int32)
+                left_over_size = sz[0]
+                batch_lengths[0] = 0
+                for i in range(1, max_batch):
+                    length = torch.randint(1, left_over_size - (max_batch - i), (1,), device=par.device)
+                    batch_lengths[i] = length + batch_lengths[i - 1]
+                    left_over_size -= length.detach().cpu().numpy()[0]
+                batch_lengths[-1] = left_over_size + batch_lengths[-2]
+
+                sum = 0
+                index = 1
+                while index < len(batch_lengths):
+                    sum += batch_lengths[index] - batch_lengths[index - 1]
+                    index += 1
+                assert sum == sz[0], f"sum: {sum}, sz: {sz[0]}, lengths:{batch_lengths}"
+                inputs['batch_lengths'] = batch_lengths
+
+                if self.fastpitch.speaker_emb is not None:
+                    inputs['speaker'] = torch.randint(
+                        0,
+                        self.fastpitch.speaker_emb.num_embeddings,
+                        (max_batch,),
+                        device=par.device,
+                        dtype=torch.int64,
+                    )
+
+                return (inputs,)
+
+            model.__class__.input_example = input_example
+        else:
+            # NeMo version >= 1.11.0; can just set the relevant flags
+            model.export_config["enable_volume"] = True
+            model.export_config["enable_ragged_batches"] = True
 
         # Patch the model config yaml to add the volume and ragged batch flags
         for art in artifacts:
             if art == 'model_config.yaml':
                 model_config = yaml.safe_load(artifacts['model_config.yaml']['content'])
                 model_config["export_config"] = {'enable_volume': True, 'enable_ragged_batches': True}
                 artifacts['model_config.yaml']['content'] = yaml.dump(model_config).encode()
```

## nemo2riva/patches/tts/general.py

```diff
@@ -1,12 +1,12 @@
 # SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 # SPDX-License-Identifier: MIT
 
 import logging
-from typing import Optional, Tuple
+from typing import Optional
 
 import torch
 
 check_ipa_support = True
 try:
     from nemo.collections.tts.torch.tts_tokenizers import IPATokenizer
 except Exception:
@@ -43,52 +43,14 @@
         if volume is not None:
             volumes[index - 1, :cur_seq_len] = volume[seq_start:seq_end]
 
         index += 1
 
     return texts, pitches, paces, volumes
 
-@torch.jit.script
-def batch_from_ragged(
-    text: torch.Tensor,
-    pitch: torch.Tensor,
-    pace: torch.Tensor,
-    batch_lengths: torch.Tensor,
-    padding_idx: int = -1,
-    volume: Optional[torch.Tensor] = None,
-) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
-    """ Same function as create_batch, but updated in NeMo #6020 for 1.17.0
-    """
-
-    batch_lengths = batch_lengths.to(dtype=torch.int64)
-    max_len = torch.max(batch_lengths[1:] - batch_lengths[:-1])
-
-    index = 1
-    num_batches = batch_lengths.shape[0] - 1
-    texts = torch.zeros(num_batches, max_len, dtype=torch.int64, device=text.device) + padding_idx
-    pitches = torch.ones(num_batches, max_len, dtype=torch.float32, device=text.device)
-    paces = torch.zeros(num_batches, max_len, dtype=torch.float32, device=text.device) + 1.0
-    volumes = torch.zeros(num_batches, max_len, dtype=torch.float32, device=text.device) + 1.0
-    lens = torch.zeros(num_batches, dtype=torch.int64, device=text.device)
-    last_index = index - 1
-    while index < batch_lengths.shape[0]:
-        seq_start = batch_lengths[last_index]
-        seq_end = batch_lengths[index]
-        cur_seq_len = seq_end - seq_start
-        lens[last_index] = cur_seq_len
-        texts[last_index, :cur_seq_len] = text[seq_start:seq_end]
-        pitches[last_index, :cur_seq_len] = pitch[seq_start:seq_end]
-        paces[last_index, :cur_seq_len] = pace[seq_start:seq_end]
-        if volume is not None:
-            volumes[last_index, :cur_seq_len] = volume[seq_start:seq_end]
-        last_index = index
-        index += 1
-
-    return texts, pitches, paces, volumes, lens
-
 
 def generate_vocab_mapping_arpabet(labels):
     mapping = []
     for idx, token in enumerate(labels):
         if not str.islower(token) and str.isalnum(token):
             # token is ARPABET token, need to be prepended with @
             token = '@' + token
@@ -98,15 +60,15 @@
             # since nemo preprocessing includes a .tolower
             mapping.append("{} {}".format(idx, token.upper()))
     return mapping
 
 
 def generate_vocab_mapping_ipa(labels):
     # Only support English IPA dict
-    VALID_NON_ALNUM_IPA_TOKENS = ['ˈ', 'ˌ', 'ː']
+    VALID_NON_ALNUM_IPA_TOKENS = ['ˈ', 'ˌ']
     mapping = []
     for idx, token in enumerate(labels):
         if token in VALID_NON_ALNUM_IPA_TOKENS or (str.isalnum(token) and str.islower(token)):
             # This is a phone
             token = '@' + token
         mapping.append("{} {}".format(idx, token))
     return mapping
```

## nemo2riva/patches/tts/radtts.py

```diff
@@ -1,235 +1,175 @@
 # SPDX-FileCopyrightText: Copyright (c) 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
 # SPDX-License-Identifier: MIT
 
 import random
 import nemo
 import torch
 import yaml
+from nemo.collections.tts.helpers.helpers import regulate_len
+from nemo.collections.tts.modules.radtts import RadTTSModule, adjust_f0, pad_dur, pad_energy_avg_and_f0
+from nemo.core.neural_types.elements import (
+    Index,
+    LengthsType,
+    MelSpectrogramType,
+    RegressionValuesType,
+    TokenDurationType,
+    TokenIndex,
+)
 from nemo.core.neural_types.neural_type import NeuralType
 from packaging.version import Version
 
-from nemo2riva.patches.tts.general import batch_from_ragged
+from nemo2riva.patches.tts.general import create_batch
+
 
 def radtts_model_versioning(model, artifacts, **kwargs):
     # Riva supports some additional features over NeMo radtts models depending on the version
     # Namely, we need to patch in
     # - pitch support
     # - pace support
     # - volume support
     # - ragged batching support. Not supported with torch backend, tracked as DLIS-4332
     try:
         nemo_version = Version(nemo.__version__)
     except NameError:
         # If can't find the nemo version, return without patching
         return None
-
-    # Don't override built-in format
-    # export_format is read from schemas, radtts is still currently torchscript in the schema
-    format_=kwargs['import_config'].exports[0].export_format
-    enable_ragged_batches = (format_ == "ONNX")
-
     if model.__class__.__name__ == 'RadTTSModel':
-        try:
-            # For NeMo < 1.17.0
-            from nemo.collections.tts.helpers.helpers import regulate_len
-        except ModuleNotFoundError as e:
-            # For NeMo >= 1.17.0
-            from nemo.collections.tts.parts.utils.helpers import regulate_len
-
-        from nemo.collections.tts.modules.radtts import RadTTSModule, adjust_f0, pad_dur, pad_energy_avg_and_f0
-        from nemo.core.neural_types.elements import (
-            Index,
-            LengthsType,
-            MelSpectrogramType,
-            RegressionValuesType,
-            TokenDurationType,
-            TokenIndex,
-        )
-        if nemo_version < Version('1.15.0'):
-            # RadTTS came in NeMo 1.11.0 but the export interafce was not stable until 1.15.0
-            # RadTTS will require NeMo >= 1.15.0
-            raise NotImplementedError(
-                "Nemo2riva obtained a RadTTS model, and the installed NeMo version was less than "
-                "1.15.0. Please update to nemo_toolkit['all']>=1.15.0"
-            )
-        elif nemo_version < Version('1.17.0') and not hasattr(model, "export_config"):
-            # We need to support NeMo 1.15, and NeMo 1.16. The patches are slightly different for input_example()
-            # We need to patch the model using 1.17.0's functions
-            using_v15 = (nemo_version < Version('1.16.0'))
-            if using_v15:
-                logging.warning(
-                    "Nemo2riva obtained a RadTTS model and the installed NeMo version was less "
-                    "than 1.16.0. Please consider updating to nemo_toolkit['all']>=1.16.0 as "
-                    "RadTTS has obtained various bugfixes in 1.16.0 and 1.17.0."
-                )
+        if nemo_version < Version('1.16.0'):
+            # If nemo_version is less than 1.16, we need to add all supports
+            # 1.16 is a placeholder, will finalize once these changes are merged into NeMo
 
             # Patch model's _prepare_for_export()
             def _prepare_for_export(self, **kwargs):
-                self.model.remove_norms()
                 super(model.__class__, model)._prepare_for_export(**kwargs)
-                tensor_shape = ('T') if enable_ragged_batches else ('B', 'T')
+
                 # Define input_types and output_types as required by export()
                 self._input_types = {
-                    "text": NeuralType(tensor_shape, TokenIndex()),
-                    "batch_lengths": NeuralType(('B')),
+                    "text": NeuralType(('B', 'T'), TokenIndex()),
+                    "lens": NeuralType(('B')),
+                    # "batch_lengths": NeuralType(('B'), LengthsType(), optional=True),
                     "speaker_id": NeuralType(('B'), Index()),
                     "speaker_id_text": NeuralType(('B'), Index()),
                     "speaker_id_attributes": NeuralType(('B'), Index()),
-                    "pitch": NeuralType(tensor_shape, RegressionValuesType()),
-                    "pace": NeuralType(tensor_shape),
+                    "pitch": NeuralType(('B', 'T'), RegressionValuesType()),
+                    "pace": NeuralType(('B', 'T')),
+                    "volume": NeuralType(('B', 'T'), optional=True),
                 }
                 self._output_types = {
                     "spect": NeuralType(('B', 'D', 'T_spec'), MelSpectrogramType()),
                     "num_frames": NeuralType(('B'), TokenDurationType()),
                     "durs_predicted": NeuralType(('B', 'T_text'), TokenDurationType()),
+                    "volume_aligned": NeuralType(('B', 'T_spec'), RegressionValuesType()),
                 }
-                self._input_types["volume"] = NeuralType(tensor_shape, optional=True)
-                self._output_types["volume_aligned"] = NeuralType(('B', 'T_spec'), RegressionValuesType())
 
             model.__class__._prepare_for_export = _prepare_for_export
 
-            # Patch model's forward_for_export()
+            # Patch module's infer()
             def forward_for_export(
+                # self, text, batch_lengths, speaker_id, speaker_id_text, speaker_id_attributes, pitch, pace, volume
                 self,
                 text,
-                batch_lengths,
+                lens,
                 speaker_id,
                 speaker_id_text,
                 speaker_id_attributes,
                 pitch,
                 pace,
                 volume,
             ):
-                if enable_ragged_batches:
-                    text, pitch, pace, volume, lens = batch_from_ragged(
-                        text, pitch, pace, batch_lengths=batch_lengths, padding_idx=self.tokenizer_pad, volume=volume,
-                    )
-                else:
-                    lens = batch_lengths.to(dtype=torch.int64)
+                # text, pitch, pace, volume = create_batch(
+                #     text, pitch, pace, batch_lengths, padding_idx=self.tokenizer.pad, volume=volume
+                # )
                 (mel, n_frames, dur, _, _) = self.model.infer(
                     speaker_id,
                     text,
                     speaker_id_text=speaker_id_text,
                     speaker_id_attributes=speaker_id_attributes,
-                    sigma=0.7,
-                    sigma_txt=0.7,
+                    sigma=0.0,
+                    sigma_txt=0.0,
                     sigma_f0=1.0,
                     sigma_energy=1.0,
                     f0_mean=0.0,
                     f0_std=0.0,
                     in_lens=lens,
                     pitch_shift=pitch,
                     pace=pace,
                 ).values()
                 volume_extended = volume
                 # Need to reshape as in infer patch
                 durs_predicted = dur.float()
                 truncated_length = torch.max(lens)
-                try:
-                    # Use NeMo 1.16's function signature if possible
-                    volume_extended, _ = regulate_len(
-                        durs_predicted,
-                        volume[:, :truncated_length].unsqueeze(-1),
-                        pace[:, :truncated_length],
-                        replicate_to_nearest_multiple=True,
-                        group_size=self.model.n_group_size,
-                        in_lens=lens,
-                    )
-                except TypeError as e:
-                    # Else, default to NeMo 1.15's function signature
-                    # TODO: This is actually 1.14's signature, maybe we can drop this if clause
-                    volume_extended, _ = regulate_len(
-                        durs_predicted,
-                        volume[:, :truncated_length].unsqueeze(-1),
-                        pace[:, :truncated_length]
-                    )
+                volume_extended, _ = regulate_len(
+                    durs_predicted, volume[:, :truncated_length].unsqueeze(-1), pace[:, :truncated_length]
+                )
                 volume_extended = volume_extended.squeeze(-1).float()
                 return mel.float(), n_frames, dur.float(), volume_extended
 
             model.__class__.forward_for_export = forward_for_export
 
-            # Patch module's infer()
             def infer(
                 self,
                 speaker_id,
                 text,
-                sigma=0.7,
-                sigma_txt=0.7,
-                sigma_f0=1.0,
-                sigma_energy=1.0,
+                sigma,
+                sigma_txt=0.8,
+                sigma_f0=0.8,
+                sigma_energy=0.8,
                 speaker_id_text=None,
                 speaker_id_attributes=None,
-                pace=None,
+                pace=1.0,
                 token_duration_max=100,
                 in_lens=None,
                 dur=None,
                 f0=None,
                 f0_mean=0.0,
                 f0_std=0.0,
                 energy_avg=None,
                 voiced_mask=None,
                 pitch_shift=None,
             ):
 
                 batch_size = text.shape[0]
+                n_tokens = text.shape[1]
                 if in_lens is None:
-                    in_lens = text.new_ones((batch_size,), dtype=torch.int64) * text.shape[1]
-                    txt_len_pad_removed = text.shape[1]
-                else:
-                    txt_len_pad_removed = torch.max(in_lens)
-                    # borisf : this should not be needed as long as we have properly formed input batch
-                    text = text[:, :txt_len_pad_removed]
-
+                    in_lens = text.new_ones((batch_size,), dtype=torch.int) * n_tokens
                 spk_vec = self.encode_speaker(speaker_id)
-
                 if speaker_id_text is None:
                     speaker_id_text = speaker_id
                 if speaker_id_attributes is None:
                     speaker_id_attributes = speaker_id
                 spk_vec_text = self.encode_speaker(speaker_id_text)
                 spk_vec_attributes = self.encode_speaker(speaker_id_attributes)
                 txt_enc, _ = self.encode_text(text, in_lens)
 
                 if dur is None:
                     # get token durations
                     dur = self.dur_pred_layer.infer(txt_enc, spk_vec_text, lens=in_lens)
                     dur = pad_dur(dur, txt_enc)
                     dur = dur[:, 0]
                     dur = dur.clamp(0, token_duration_max)
+                # text encoded removes padding tokens so shape of text_enc is changed
+                # need to adjust pace, pitch_shift to account for this
+                txt_len_pad_removed = torch.max(in_lens)
+                pace = pace[:, :txt_len_pad_removed]
+                pitch_shift = pitch_shift[:, :txt_len_pad_removed].unsqueeze(-1)
 
-                if pace is None:
-                    pace = txt_enc.new_ones((batch_size, txt_len_pad_removed))
-                else:
-                    pace = pace[:, :txt_len_pad_removed]
-
-                txt_enc_time_expanded, out_lens = regulate_len(
-                    dur,
-                    txt_enc.transpose(1, 2),
-                    pace,
-                    replicate_to_nearest_multiple=True,
-                    group_size=self.n_group_size,
-                    in_lens=in_lens,
-                )
+                txt_enc_time_expanded, out_lens = regulate_len(dur, txt_enc.transpose(1, 2), pace)
                 n_groups = torch.div(out_lens, self.n_group_size, rounding_mode='floor')
                 max_out_len = torch.max(out_lens)
 
                 txt_enc_time_expanded.transpose_(1, 2)
                 if voiced_mask is None:
                     if self.use_vpred_module:
                         # get logits
-                        voiced_mask = self.v_pred_module.infer(txt_enc_time_expanded, spk_vec_attributes, lens=out_lens)
-                        try:
-                            v_pred_threshold = self.v_pred_threshold
-                        except AttributeError as e:
-                            v_pred_threshold = 0.5
-                        voiced_mask_bool = torch.sigmoid(voiced_mask[:, 0]) > v_pred_threshold
+                        voiced_mask = self.v_pred_module.infer(
+                            txt_enc_time_expanded, spk_vec_attributes, lens=out_lens
+                        )
+                        voiced_mask_bool = torch.sigmoid(voiced_mask[:, 0]) > 0.5
                         voiced_mask = voiced_mask_bool.to(dur.dtype)
-                    else:
-                        voiced_mask_bool = None
                 else:
                     voiced_mask_bool = voiced_mask.bool()
 
                 ap_txt_enc_time_expanded = txt_enc_time_expanded
                 # voice mask augmentation only used for attribute prediction
                 if self.ap_use_voiced_embeddings:
                     ap_txt_enc_time_expanded = self.apply_voice_mask_to_text(txt_enc_time_expanded, voiced_mask)
@@ -237,124 +177,120 @@
                 f0_bias = 0
                 # unvoiced bias forward pass
                 if self.use_unvoiced_bias:
                     f0_bias = self.unvoiced_bias_module(txt_enc_time_expanded.permute(0, 2, 1))
                     f0_bias = -f0_bias[..., 0]
 
                 if f0 is None:
-                    f0 = self.infer_f0(ap_txt_enc_time_expanded, spk_vec_attributes, voiced_mask_bool, out_lens)[:, 0]
+                    n_f0_feature_channels = 2 if self.use_first_order_features else 1
+                    f0 = self.infer_f0(ap_txt_enc_time_expanded, spk_vec_attributes, voiced_mask_bool, out_lens)[
+                        :, 0
+                    ]
 
                 f0 = adjust_f0(f0, f0_mean, f0_std, voiced_mask_bool)
 
                 if energy_avg is None:
+                    n_energy_feature_channels = 2 if self.use_first_order_features else 1
                     energy_avg = self.infer_energy(ap_txt_enc_time_expanded, spk_vec, out_lens)[:, 0]
 
                 # replication pad, because ungrouping with different group sizes
                 # may lead to mismatched lengths
                 # FIXME: use replication pad
                 (energy_avg, f0) = pad_energy_avg_and_f0(energy_avg, f0, max_out_len)
 
+                pitch_shift_spec_len = 0
                 if pitch_shift is not None:
-                    pitch_shift_spec_len, _ = regulate_len(
-                        dur,
-                        pitch_shift[:, :txt_len_pad_removed].unsqueeze(-1),
-                        pace,
-                        replicate_to_nearest_multiple=True,
-                        group_size=self.n_group_size,
-                        in_lens=in_lens,
-                    )
-                    f0_bias = pitch_shift_spec_len.squeeze(-1) + f0_bias
+                    pitch_shift_spec_len, _ = regulate_len(dur, pitch_shift, pace)
+                    pitch_shift_spec_len = pitch_shift_spec_len.squeeze(-1)
 
                 context_w_spkvec = self.preprocess_context(
-                    txt_enc_time_expanded, spk_vec, out_lens, (f0 + f0_bias) * voiced_mask, energy_avg, assume_padded=True,
+                    txt_enc_time_expanded,
+                    spk_vec,
+                    out_lens,
+                    (f0 + f0_bias + pitch_shift_spec_len) * voiced_mask,
+                    energy_avg,
                 )
 
-                residual = txt_enc.new_zeros(batch_size, 80 * self.n_group_size, torch.max(n_groups))
-                if sigma > 0.0:
-                    residual = torch.normal(residual) * sigma
+                residual = (
+                    torch.normal(txt_enc.new_zeros(batch_size, 80 * self.n_group_size, torch.max(n_groups))) * sigma
+                )
 
                 # map from z sample to data
                 num_steps_to_exit = len(self.exit_steps)
-                split = num_steps_to_exit * self.n_early_size
-                mel = residual[:, split:]
-                residual = residual[:, :split]
+                remaining_residual, mel = torch.tensor_split(residual, [num_steps_to_exit * self.n_early_size,], dim=1)
 
                 for i, flow_step in enumerate(reversed(self.flows)):
                     curr_step = self.n_flows - i - 1
                     mel = flow_step(mel, context_w_spkvec, inverse=True, seq_lens=n_groups)
                     if num_steps_to_exit > 0 and curr_step == self.exit_steps[num_steps_to_exit - 1]:
                         # concatenate the next chunk of z
                         num_steps_to_exit = num_steps_to_exit - 1
-                        split = num_steps_to_exit * self.n_early_size
-                        residual_to_add = residual[:, split:]
-                        residual = residual[:, :split]
+                        remaining_residual, residual_to_add = torch.tensor_split(
+                            remaining_residual, [num_steps_to_exit * self.n_early_size,], dim=1
+                        )
                         mel = torch.cat((residual_to_add, mel), 1)
 
                 if self.n_group_size > 1:
                     mel = self.fold(mel)
 
                 return {'mel': mel, 'out_lens': out_lens, 'dur': dur, 'f0': f0, 'energy_avg': energy_avg}
+
             RadTTSModule.infer = infer
 
-            # Patch input_example()
+            # Patch module's input_example()
             def input_example(self, max_batch=1, max_dim=400):
                 par = next(self.parameters())
-                sz = (max_batch * max_dim,) if enable_ragged_batches else (max_batch, max_dim)
-                inp = torch.randint(32, 94, sz, device=par.device, dtype=torch.int64)
+                sz = (max_batch, max_dim)
+                # sz = (max_batch * max_dim,)
+                inp = torch.randint(0, 94, sz, device=par.device, dtype=torch.int64)
                 speaker = torch.randint(0, 1, (max_batch,), device=par.device, dtype=torch.int64)
                 pitch = torch.randn(sz, device=par.device, dtype=torch.float32) * 0.5
                 pace = torch.clamp(torch.randn(sz, device=par.device, dtype=torch.float32) * 0.1 + 1, min=0.01)
                 volume = torch.clamp(torch.randn(sz, device=par.device, dtype=torch.float32) * 0.1 + 1, min=0.01)
+                # batch_lengths = torch.zeros((max_batch + 1), device=par.device, dtype=torch.int32)
+                # left_over_size = sz[0]
+                # batch_lengths[0] = 0
+                # for i in range(1, max_batch):
+                #     length = torch.randint(1, left_over_size - (max_batch - i), (1,), device=par.device)
+                #     batch_lengths[i] = length + batch_lengths[i - 1]
+                #     left_over_size -= length.detach().cpu().numpy()[0]
+                # batch_lengths[-1] = left_over_size + batch_lengths[-2]
+                # sum = 0
+                # index = 1
+                # while index < len(batch_lengths):
+                #     sum += batch_lengths[index] - batch_lengths[index - 1]
+                #     index += 1
+                # assert sum == sz[0], f"sum: {sum}, sz: {sz[0]}, lengths:{batch_lengths}"
 
                 # TODO: Shouldn't hardcode but self.tokenizer isn't initlized yet so unsure how
                 # to get the pad_id
                 pad_id = 94
                 inp[inp == pad_id] = pad_id - 1 if pad_id > 0 else pad_id + 1
 
-                if enable_ragged_batches:
-                    batch_lengths = torch.zeros((max_batch + 1), device=device, dtype=torch.int32)
-                    left_over_size = sz[0]
-                    batch_lengths[0] = 0
-                    for i in range(1, max_batch):
-                        equal_len = (left_over_size - (max_batch - i)) // (max_batch - i)
-                        length = torch.randint(equal_len // 2, equal_len, (1,), device=device, dtype=torch.int32)
-                        batch_lengths[i] = length + batch_lengths[i - 1]
-                        left_over_size -= length.detach().cpu().numpy()[0]
-                    batch_lengths[-1] = left_over_size + batch_lengths[-2]
-
-                    sum = 0
-                    index = 1
-                    while index < len(batch_lengths):
-                        sum += batch_lengths[index] - batch_lengths[index - 1]
-                        index += 1
-                    assert sum == sz[0], f"sum: {sum}, sz: {sz[0]}, lengths:{batch_lengths}"
-                else:
-                    batch_lengths = torch.randint(max_dim // 2, max_dim, (max_batch,), device=device, dtype=torch.int32)
-                    batch_lengths[0] = max_dim
+                lens = []
+                for i, _ in enumerate(inp):
+                    len_i = random.randint(3, max_dim)
+                    lens.append(len_i)
+                    inp[i, len_i:] = pad_id
+                lens = torch.tensor(lens, device=par.device, dtype=torch.int)
 
                 inputs = {
                     'text': inp,
-                    'batch_lengths': batch_lengths,
+                    'lens': lens,
+                    # 'batch_lengths': batch_lengths,
                     'speaker_id': speaker,
                     'speaker_id_text': speaker,
                     'speaker_id_attributes': speaker,
                     'pitch': pitch,
                     'pace': pace,
                     'volume': volume,
                 }
                 return (inputs,)
 
-            if using_v15:
-                RadTTSModule.input_example = input_example
-            else:
-                model.__class__.input_example = input_example
-        else:
-            # NeMo version >= 1.17.0; can just set the relevant flags
-            model.export_config["enable_volume"] = True
-            model.export_config["enable_ragged_batches"] = enable_ragged_batches
+            RadTTSModule.input_example = input_example
 
     # Patch the model config yaml to add the volume and ragged batch flags
     for art in artifacts:
         if art == 'model_config.yaml':
             model_config = yaml.safe_load(artifacts['model_config.yaml']['content'])
-            model_config["export_config"] = {'enable_volume': True, 'enable_ragged_batches': enable_ragged_batches }
+            model_config["export_config"] = {'enable_volume': True, 'enable_ragged_batches': False}
             artifacts['model_config.yaml']['content'] = yaml.dump(model_config).encode()
```

## nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml

```diff
@@ -28,16 +28,13 @@
 # Functionality limited to yaml files (e.g. model_config.yaml).
 artifact_content:
   # List of files.
   - model_config.yaml:
     # List of sections.subsections. ... that are required.
     # (Optional `: True` instructs to check the presence of the file in indicated as leaf in the archive)
     - multilingual
-    - src_language
-    - tgt_language
     - encoder.num_layers
     - encoder.pre_ln
     - encoder_tokenizer.library
-    - encoder.hidden_size
     - decoder.num_layers
     - decoder.pre_ln
     - decoder_tokenizer.library
```

## Comparing `nemo2riva-2.15.1.dist-info/RECORD` & `nemo2riva-2.9.0.dist-info/RECORD`

 * *Files 18% similar despite different names*

```diff
@@ -1,36 +1,35 @@
-nemo2riva/__init__.py,sha256=k3PxkSmHDlhUR1cWZXo_drb_letEY5UrgTZTyLidz3s,197
-nemo2riva/args.py,sha256=-ptDvypTHCw5_9exdcfQVrj7VveMYPEls9rGCmMDg_c,2340
-nemo2riva/artifacts.py,sha256=tpcdMWzVwUf3f9HlJXQbB3vVORoMiv_O0-hrDKa56hA,5163
-nemo2riva/convert.py,sha256=f_1yfTBjCt9hmcta334dNeEV8lMWtIBgIkRckTQBwpY,3500
-nemo2riva/cookbook.py,sha256=aG_5gBUCWMdrZUac7uTWmAG2qLVEDiBlHj4uJlRkDKY,6516
-nemo2riva/schema.py,sha256=eQwZ9OM3ADyURvmB2YAtNJrz2Kla7koqEI5FBKBJKC0,8403
-nemo2riva/cli/__init__.py,sha256=KORxn-BUUbaUZO5ch1iStEY_gRSrtpHUwRBy4wnJMWg,177
-nemo2riva/cli/nemo2riva.py,sha256=QlijTb1_ryk9cfqbwEE2sn1P_8jobwsYXZSO_Zmab6g,2932
-nemo2riva/patches/__init__.py,sha256=oMmv_9_qRka0zX_u6kVxRqKnvrACpadeG6BGqv1y1iE,742
-nemo2riva/patches/ctc.py,sha256=YGjdLXHdw-MEwF6nej_nTyqmyuqh78Do3gICcNVMBcI,713
-nemo2riva/patches/ctc_bpe.py,sha256=NaYWuW0LoNdGQy6t4cqISw-S16ouacpM4q0ZdJVRPBk,532
-nemo2riva/patches/mtencdec.py,sha256=gOVz4OgJMe1mW4JDfsXsFAw3TWA8hKY39ZFkYMfzqPk,1017
-nemo2riva/patches/tts/__init__.py,sha256=6ysnn3Sf1I9aeLNiTyXmlxVMd-NoQcS93eXE2dPNvg0,435
-nemo2riva/patches/tts/fastpitch.py,sha256=O4CYqX3RuDlKBH1ZJraJbL3qeL6U_X7pMG5ly_WdqJE,1281
-nemo2riva/patches/tts/general.py,sha256=hfyHSYB8A7Cp_WoRh3urNKpYNBMPpj6W35VBCLFL_Yo,5511
-nemo2riva/patches/tts/radtts.py,sha256=VEE-Y-rIzwTocw2hJKsNsRYvw9WXvDRN5h5OUyTSp5E,16949
-nemo2riva/validation_schemas/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-nemo2riva/validation_schemas/asr-scr-exported-encdecclsmodel.yaml,sha256=i-N2pbaguWHweETvI7s1YzhDqnCxOIFJmNEFcS06km8,882
-nemo2riva/validation_schemas/asr-stt-exported-encdecctcmodel.yaml,sha256=3GVTWXffFQgXn08pxBJJjenvHHyllSM2ik6AUCa1sfo,888
-nemo2riva/validation_schemas/asr-stt-exported-encdectcmodelbpe.yaml,sha256=Q-SxsGnmxqGXZ4k-4IZPlWCK_UbFaVuo-0CCNAwVPGo,1138
-nemo2riva/validation_schemas/nlp-isc-exported-bert.yaml,sha256=PG5iUT9eOAZq7rfvwBrChGFYkTQlcz5HKEC0rp1JVC8,1186
-nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml,sha256=ThtC-k0XTabX_eJp2VVPldbNChRuRXlcLnN7bV6KDy0,1340
-nemo2riva/validation_schemas/nlp-mt-exported-megatronnmtmodel.yaml,sha256=tokSHo0YdtrvKiGSq6kABB7byME1iesDGe9f1cKdsTA,1362
-nemo2riva/validation_schemas/nlp-pc-exported-bert.yaml,sha256=s-SAhUhyNF7nS_VebPFSS3tXEnWBGNJkEgJOjFQOrgw,1209
-nemo2riva/validation_schemas/nlp-qa-exported-bert.yaml,sha256=QchfXIsrQfdAAc2DuyHYdviz2s6u4BvLFwBXYdI7P5M,1079
-nemo2riva/validation_schemas/nlp-tc-exported-bert.yaml,sha256=o41dq3HSdL8hkO0hwYvplqtNVqSPT0PLZfQeFMPN-EM,1177
-nemo2riva/validation_schemas/nlp-tkc-exported-bert.yaml,sha256=thGKTY7cMf7AVbVw3nOjz85E8dRpg8v5qq3GzsnBQr0,1139
-nemo2riva/validation_schemas/tts-exported-fastpitchmodel.yaml,sha256=cVFHH5rFDnjsOLzDuRTi-g4kpqPp5g7DCuXvYkjVjBA,800
-nemo2riva/validation_schemas/tts-exported-hifiganmodel.yaml,sha256=X-LMMAz7YtiLb0ce0t8WJOo7HtoT9FOYDi7gksLyEGA,882
-nemo2riva/validation_schemas/tts-exported-radttsmodel.yaml,sha256=91SPSQwq9KmtudijclTV93FI2-GA-sU7XvxQ7rTLvBI,867
-nemo2riva-2.15.1.dist-info/LICENSE,sha256=nAu1MzYxnBPQYaIkbupPPyFrrTHN6x_J_w_Y2DCN1UM,1096
-nemo2riva-2.15.1.dist-info/METADATA,sha256=l1CD9sVhEBcRWE7PMi_phmWbPjZkGXI14RV27ENyymA,483
-nemo2riva-2.15.1.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-nemo2riva-2.15.1.dist-info/entry_points.txt,sha256=GWR31xDmfeRlvP8hBTzGeQjo9VH-bE2gZVK-qHELTOM,54
-nemo2riva-2.15.1.dist-info/top_level.txt,sha256=YI6Ja9U6dVQPAASVAr-67bf2aRyjkT-qHvF3T_n5y6w,10
-nemo2riva-2.15.1.dist-info/RECORD,,
+nemo2riva/__init__.py,sha256=k3PxkSmHDlhUR1cWZXo_drb_letEY5UrgTZTyLidz3s,197
+nemo2riva/args.py,sha256=-GO8UEmhis3RvNw9HgUUgAZf1V2g7eilp6dsBQZ4LPE,1833
+nemo2riva/artifacts.py,sha256=tpcdMWzVwUf3f9HlJXQbB3vVORoMiv_O0-hrDKa56hA,5163
+nemo2riva/convert.py,sha256=TopxowpJwhFs4mbILJBQKJe_W_h5ysJQranjZdFb30M,3288
+nemo2riva/cookbook.py,sha256=wpM3hz0zI1lClMMrcnSzZzbqlD94H4S3oWGJ4UNnCtc,6155
+nemo2riva/schema.py,sha256=wkdLFfbJZfCd0TaxS_7LrgmMhzGXuk0MLnua64XHIDA,7923
+nemo2riva/cli/__init__.py,sha256=KORxn-BUUbaUZO5ch1iStEY_gRSrtpHUwRBy4wnJMWg,177
+nemo2riva/cli/nemo2riva.py,sha256=QlijTb1_ryk9cfqbwEE2sn1P_8jobwsYXZSO_Zmab6g,2932
+nemo2riva/patches/__init__.py,sha256=oMmv_9_qRka0zX_u6kVxRqKnvrACpadeG6BGqv1y1iE,742
+nemo2riva/patches/ctc.py,sha256=YGjdLXHdw-MEwF6nej_nTyqmyuqh78Do3gICcNVMBcI,713
+nemo2riva/patches/ctc_bpe.py,sha256=NaYWuW0LoNdGQy6t4cqISw-S16ouacpM4q0ZdJVRPBk,532
+nemo2riva/patches/mtencdec.py,sha256=m9v_0EazEcNZpjumvJZj4BKxtxeMN6lwNaiYoD8BIzA,1007
+nemo2riva/patches/tts/__init__.py,sha256=6ysnn3Sf1I9aeLNiTyXmlxVMd-NoQcS93eXE2dPNvg0,435
+nemo2riva/patches/tts/fastpitch.py,sha256=GF0oztZtF2N53SAwJSm6TLfDQsBSFXJ9XqB7nXVOUtU,6941
+nemo2riva/patches/tts/general.py,sha256=TfihjcsK0orWD6OcaD8Qiqpx1uOP3KSL2wDRVBvCPXo,3847
+nemo2riva/patches/tts/radtts.py,sha256=bSExO18VeL6ZEGE9lPh5ynP8pAEwVSwuDSdeNzG0ulw,13683
+nemo2riva/validation_schemas/asr-scr-exported-encdecclsmodel.yaml,sha256=i-N2pbaguWHweETvI7s1YzhDqnCxOIFJmNEFcS06km8,882
+nemo2riva/validation_schemas/asr-stt-exported-encdecctcmodel.yaml,sha256=3GVTWXffFQgXn08pxBJJjenvHHyllSM2ik6AUCa1sfo,888
+nemo2riva/validation_schemas/asr-stt-exported-encdectcmodelbpe.yaml,sha256=Q-SxsGnmxqGXZ4k-4IZPlWCK_UbFaVuo-0CCNAwVPGo,1138
+nemo2riva/validation_schemas/nlp-isc-exported-bert.yaml,sha256=PG5iUT9eOAZq7rfvwBrChGFYkTQlcz5HKEC0rp1JVC8,1186
+nemo2riva/validation_schemas/nlp-mt-exported-encdecmtmodel.yaml,sha256=F7umz-mrN8AqalkS6OGjXUmG-jSmfQA-J1EfbGkrBQE,1276
+nemo2riva/validation_schemas/nlp-pc-exported-bert.yaml,sha256=s-SAhUhyNF7nS_VebPFSS3tXEnWBGNJkEgJOjFQOrgw,1209
+nemo2riva/validation_schemas/nlp-qa-exported-bert.yaml,sha256=QchfXIsrQfdAAc2DuyHYdviz2s6u4BvLFwBXYdI7P5M,1079
+nemo2riva/validation_schemas/nlp-tc-exported-bert.yaml,sha256=o41dq3HSdL8hkO0hwYvplqtNVqSPT0PLZfQeFMPN-EM,1177
+nemo2riva/validation_schemas/nlp-tkc-exported-bert.yaml,sha256=thGKTY7cMf7AVbVw3nOjz85E8dRpg8v5qq3GzsnBQr0,1139
+nemo2riva/validation_schemas/tts-exported-fastpitchmodel.yaml,sha256=cVFHH5rFDnjsOLzDuRTi-g4kpqPp5g7DCuXvYkjVjBA,800
+nemo2riva/validation_schemas/tts-exported-hifiganmodel.yaml,sha256=X-LMMAz7YtiLb0ce0t8WJOo7HtoT9FOYDi7gksLyEGA,882
+nemo2riva/validation_schemas/tts-exported-radttsmodel.yaml,sha256=91SPSQwq9KmtudijclTV93FI2-GA-sU7XvxQ7rTLvBI,867
+nemo2riva-2.9.0.dist-info/DESCRIPTION.rst,sha256=OCTuuN6LcWulhHS3d5rfjdsQtW22n7HENFRh6jC6ego,10
+nemo2riva-2.9.0.dist-info/METADATA,sha256=-O7c8sjjrf25UN0KZgwH9ZsK0lqjaOeYVvx9NPDPbBo,401
+nemo2riva-2.9.0.dist-info/RECORD,,
+nemo2riva-2.9.0.dist-info/WHEEL,sha256=8Lm45v9gcYRm70DrgFGVe4WsUtUMi1_0Tso1hqPGMjA,92
+nemo2riva-2.9.0.dist-info/entry_points.txt,sha256=75yOjD9m_irFDfiHryeMRh5-x8s9n7_1_LPXfzB5hEY,55
+nemo2riva-2.9.0.dist-info/metadata.json,sha256=kj2zeXg8clSM8UuzL_ndbupW-n7TkpHa4DHlj3OL1f8,705
+nemo2riva-2.9.0.dist-info/top_level.txt,sha256=YI6Ja9U6dVQPAASVAr-67bf2aRyjkT-qHvF3T_n5y6w,10
```

