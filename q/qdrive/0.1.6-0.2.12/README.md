# Comparing `tmp/qdrive-0.1.6-py3-none-any.whl.zip` & `tmp/qdrive-0.2.12-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,40 +1,40 @@
-Zip file size: 35592 bytes, number of entries: 38
--rw-r--r--  2.0 unx      169 b- defN 24-Mar-13 14:16 qdrive/__init__.py
+Zip file size: 35761 bytes, number of entries: 38
+-rw-r--r--  2.0 unx      232 b- defN 24-May-09 09:06 qdrive/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/dataset/__init__.py
--rw-r--r--  2.0 unx     2267 b- defN 24-Apr-04 08:36 qdrive/dataset/dataset.py
--rw-r--r--  2.0 unx     5044 b- defN 24-Apr-16 19:00 qdrive/dataset/file_manager.py
+-rw-r--r--  2.0 unx     2496 b- defN 24-May-09 08:58 qdrive/dataset/dataset.py
+-rw-r--r--  2.0 unx     5038 b- defN 24-May-13 07:58 qdrive/dataset/file_manager.py
 -rw-r--r--  2.0 unx     3995 b- defN 24-Apr-04 09:44 qdrive/dataset/files/HDF5.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/dataset/files/__init__.py
 -rw-r--r--  2.0 unx      929 b- defN 23-Dec-13 10:03 qdrive/dataset/files/file.py
 -rw-r--r--  2.0 unx     3213 b- defN 24-Apr-04 09:51 qdrive/dataset/files/file_mgr_single.py
--rw-r--r--  2.0 unx     3288 b- defN 23-Dec-13 10:03 qdrive/dataset/files/json.py
+-rw-r--r--  2.0 unx     3372 b- defN 24-May-09 07:44 qdrive/dataset/files/json.py
 -rw-r--r--  2.0 unx     2256 b- defN 23-Dec-13 10:03 qdrive/dataset/files/numpy.py
 -rw-r--r--  2.0 unx      222 b- defN 23-Dec-13 10:03 qdrive/dataset/files/utility.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/measurement/__init__.py
--rw-r--r--  2.0 unx     9638 b- defN 24-Apr-16 18:58 qdrive/measurement/data_collector.py
+-rw-r--r--  2.0 unx     9652 b- defN 24-May-13 08:15 qdrive/measurement/data_collector.py
 -rw-r--r--  2.0 unx     1989 b- defN 24-Mar-05 14:29 qdrive/measurement/data_collector_var.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/measurement/HDF5_collector/__init__.py
--rw-r--r--  2.0 unx     4062 b- defN 24-Apr-08 16:46 qdrive/measurement/HDF5_collector/ds_cache.py
--rw-r--r--  2.0 unx     4659 b- defN 24-Apr-08 16:52 qdrive/measurement/HDF5_collector/h5_cache.py
+-rw-r--r--  2.0 unx     4112 b- defN 24-May-13 08:20 qdrive/measurement/HDF5_collector/ds_cache.py
+-rw-r--r--  2.0 unx     4883 b- defN 24-May-13 08:24 qdrive/measurement/HDF5_collector/h5_cache.py
 -rw-r--r--  2.0 unx     5788 b- defN 24-Apr-17 08:05 qdrive/measurement/HDF5_collector/h5_dependency_builder.py
--rw-r--r--  2.0 unx     2719 b- defN 24-Apr-08 07:32 qdrive/measurement/HDF5_collector/h5_writer.py
--rw-r--r--  2.0 unx     5648 b- defN 24-Apr-09 09:21 qdrive/measurement/HDF5_collector/h5_writer_container.py
+-rw-r--r--  2.0 unx     2693 b- defN 24-May-13 08:23 qdrive/measurement/HDF5_collector/h5_writer.py
+-rw-r--r--  2.0 unx     5649 b- defN 24-May-13 08:29 qdrive/measurement/HDF5_collector/h5_writer_container.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/measurement/utility/__init__.py
 -rw-r--r--  2.0 unx       18 b- defN 23-Dec-13 10:03 qdrive/measurement/utility/irregular_ds_conversion.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/testing/__init__.py
 -rw-r--r--  2.0 unx     1595 b- defN 23-Dec-13 10:03 qdrive/testing/core_tools_test.py
 -rw-r--r--  2.0 unx     1034 b- defN 23-Dec-13 10:03 qdrive/testing/create_dataset.py
 -rw-r--r--  2.0 unx     6271 b- defN 23-Dec-13 10:03 qdrive/testing/dataset_file_feature_overview.py
 -rw-r--r--  2.0 unx      214 b- defN 23-Dec-13 10:03 qdrive/testing/interfaces_dataset.py
 -rw-r--r--  2.0 unx      635 b- defN 24-Feb-29 15:23 qdrive/testing/measurement_with_qdrive.py
 -rw-r--r--  2.0 unx     6360 b- defN 23-Dec-13 10:03 qdrive/testing/qcodes_test_param.py
 -rw-r--r--  2.0 unx     1105 b- defN 23-Dec-13 10:03 qdrive/testing/qdrive_dataset_test.py
 -rw-r--r--  2.0 unx     2181 b- defN 23-Dec-13 10:03 qdrive/testing/test.py
 -rw-r--r--  2.0 unx        0 b- defN 23-Dec-13 10:03 qdrive/utility/__init__.py
--rw-r--r--  2.0 unx    16695 b- defN 24-Apr-22 11:49 qdrive-0.1.6.dist-info/LICENCE
--rw-r--r--  2.0 unx      670 b- defN 24-Apr-22 11:49 qdrive-0.1.6.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-22 11:49 qdrive-0.1.6.dist-info/WHEEL
--rw-r--r--  2.0 unx        7 b- defN 24-Apr-22 11:49 qdrive-0.1.6.dist-info/top_level.txt
--rw-r--r--  2.0 unx        1 b- defN 23-Dec-13 12:27 qdrive-0.1.6.dist-info/zip-safe
--rw-rw-r--  2.0 unx     3402 b- defN 24-Apr-22 11:49 qdrive-0.1.6.dist-info/RECORD
-38 files, 96166 bytes uncompressed, 30030 bytes compressed:  68.8%
+-rw-r--r--  2.0 unx    16695 b- defN 24-May-17 11:19 qdrive-0.2.12.dist-info/LICENCE
+-rw-r--r--  2.0 unx      671 b- defN 24-May-17 11:19 qdrive-0.2.12.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-May-17 11:19 qdrive-0.2.12.dist-info/WHEEL
+-rw-r--r--  2.0 unx        7 b- defN 24-May-17 11:19 qdrive-0.2.12.dist-info/top_level.txt
+-rw-r--r--  2.0 unx        1 b- defN 23-Dec-13 12:27 qdrive-0.2.12.dist-info/zip-safe
+-rw-rw-r--  2.0 unx     3408 b- defN 24-May-17 11:19 qdrive-0.2.12.dist-info/RECORD
+38 files, 96806 bytes uncompressed, 30187 bytes compressed:  68.8%
```

## zipnote {}

```diff
@@ -90,26 +90,26 @@
 
 Filename: qdrive/testing/test.py
 Comment: 
 
 Filename: qdrive/utility/__init__.py
 Comment: 
 
-Filename: qdrive-0.1.6.dist-info/LICENCE
+Filename: qdrive-0.2.12.dist-info/LICENCE
 Comment: 
 
-Filename: qdrive-0.1.6.dist-info/METADATA
+Filename: qdrive-0.2.12.dist-info/METADATA
 Comment: 
 
-Filename: qdrive-0.1.6.dist-info/WHEEL
+Filename: qdrive-0.2.12.dist-info/WHEEL
 Comment: 
 
-Filename: qdrive-0.1.6.dist-info/top_level.txt
+Filename: qdrive-0.2.12.dist-info/top_level.txt
 Comment: 
 
-Filename: qdrive-0.1.6.dist-info/zip-safe
+Filename: qdrive-0.2.12.dist-info/zip-safe
 Comment: 
 
-Filename: qdrive-0.1.6.dist-info/RECORD
+Filename: qdrive-0.2.12.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## qdrive/__init__.py

```diff
@@ -1,7 +1,8 @@
 from etiket_client import login, logout
 from etiket_client.GUI.app import launch_GUI as l_GUI
+from etiket_client.settings.user_settings import user_settings
 
 def launch_GUI():
     l_GUI()
 
 from qdrive.dataset.dataset import dataset
```

## qdrive/dataset/dataset.py

```diff
@@ -1,47 +1,51 @@
 from etiket_client.python_api.dataset_model.dataset import dataset_model
-from etiket_client.python_api.dataset import dataset_read, dataset_create, DatasetCreate
+from etiket_client.python_api.dataset import dataset_read_raw, dataset_create_raw, DatasetCreate
 from etiket_client.python_api.scopes import get_scopes
 from etiket_client.python_api.dataset_model.files import FileStatusLocal
 
 from etiket_client.settings.user_settings import user_settings
 
 from qdrive.dataset.file_manager import file_manager
 from qdrive.dataset.files.file_mgr_single import file_mgr_single
 
 import uuid, datetime, typing
 
 
 class dataset(dataset_model):
-    def __init__(self, uuid : 'uuid.UUID | str'):
-        ds_mod = dataset_read(uuid)
-        super().__init__(ds_mod._l_ds, ds_mod._r_ds)
+    def __init__(self, ds_uuid : 'uuid.UUID | str'):
+        l_ds, r_ds = dataset_read_raw(ds_uuid)
+        super().__init__(l_ds, r_ds, user_settings.verbose)
         self.__files = file_manager(self, self.files)
         
     @classmethod
     def create(cls, name, description = None, scope_name = None):
         if scope_name is None:
-            scope_uuid=user_settings.current_scope
+            try:
+                scope_uuid=uuid.UUID(user_settings.current_scope)
+            except Exception as exc:
+                raise ValueError("No scope provided and no default scope set. Please provide a scope.") from exc
         else:
             scope_uuid = None
             scopes = get_scopes()
             for scope in scopes:
                 if scope.name == scope_name:
                     scope_uuid = scope.uuid
+        
             if scope_uuid == None:
                 raise ValueError(f"Scope '{scope_name}' does not exist ): .")
         
         datasetCreate = DatasetCreate(uuid=uuid.uuid4(), collected=datetime.datetime.now(),
                                       name=name, creator=user_settings.user_name,
                                       description=description, keywords=[],
                                       ranking= 0, synchronized=False,
                                       scope_uuid=scope_uuid)
-        ds_mod = dataset_create(datasetCreate)
+        l_ds = dataset_create_raw(datasetCreate)
         ds = cls.__new__(cls)
-        super(type(ds), ds).__init__(ds_mod._l_ds, ds_mod._r_ds)
+        super(type(ds), ds).__init__(l_ds, None, user_settings.verbose)
         ds.__files = file_manager(ds, ds.files)
         return ds
     
     def __iter__(self):
         return iter(self.__files)
         
     def __getitem__(self, item) -> typing.Type[file_mgr_single]:
```

## qdrive/dataset/file_manager.py

```diff
@@ -69,15 +69,15 @@
             elif isinstance(value, (xarray.Dataset, xarray.DataArray)):
                 fname = f'{item_name}.hdf5'
                 destination = fpath + fname
                 value.to_netcdf(destination)
                 file_type = FileType.HDF5_NETCDF
                 generator = f"xarray.{xarray.__version__}"
             else: 
-                raise ValueError(f"Assignement of the type {file_type(value)} is not supported.")
+                raise ValueError(f"Assignment of the type {type(value)} is not supported.")
             
             self._add_new_file(item_name, destination, file_type, generator)
         else:
             self.file_obj[item_name].update(value)
     
     def __load_file(self, file : file_object):
         if file.current.type is FileType.HDF5_NETCDF or file.current.type is FileType.HDF5_CACHE:
```

## qdrive/dataset/files/json.py

```diff
@@ -1,24 +1,28 @@
 from qdrive.dataset.files.file_mgr_single import file_mgr_single
 from qdrive.dataset.files.utility import is_scalar, is_iterable
 
-import json
+import json, copy
 
 class JSON_file(file_mgr_single):
     def __init__(self, file_info):
         super().__init__(file_info)
         
     @property
     def raw(self):
         if self.object_handle == None:
             with open(self.file_obj.current.path) as _json_file:
                 self.object_handle = json.load(_json_file)
             self.local_handle =  self.object_handle
         return self.object_handle
     
+    @property
+    def json(self):
+        return copy.deepcopy(self.raw)
+    
     def __getitem__(self, key):
         self.__load()
         if is_iterable(self.local_handle):
             obj_slice = self.local_handle[key]
             return self.__create_from_self(obj_slice)
         else :
             raise ValueError(f"object of the type {type(self.raw)} cannot be accessed using this operator.")
```

## qdrive/measurement/data_collector.py

```diff
@@ -1,42 +1,42 @@
-import os
+from typing import List, Any
+from pathlib import Path
+
+import time, h5py, uuid, dataclasses, os
+import qcodes as qc
+
 from etiket_client.python_api.dataset_model.files import FileType, generate_version_id, FileStatusLocal
 from etiket_client.settings.folders import create_file_dir
 
 from qdrive.measurement.data_collector_var import set_var_static, set_var_dynamic, get_var
 from qdrive.measurement.HDF5_collector.ds_cache import ds_cache
 from qdrive.measurement.HDF5_collector.h5_writer_container import h5_writer_container
 from qdrive.measurement.HDF5_collector.h5_dependency_builder import H5_dependency_builder, NETCDF4_reference_list_builder
 
-from typing import List
-from pathlib import Path
-
 
-import qcodes as qc
-import time, h5py, uuid, dataclasses
 
 # TODO fix naming clashes
 @dataclasses.dataclass
 class data_collection:
-    parameter : any
+    parameter : Any
     get_var : ds_cache
     set_var_static : List[ds_cache]
     set_var_dynamic : List[ds_cache]
     dependency_builder : H5_dependency_builder
     param_idx : int
 
     def add_data(self, data):
-            if self.parameter in data.keys():
-                for data_saver_dynamic in self.set_var_dynamic:
-                    data_saver_dynamic.add_result(data[data_saver_dynamic.var_info.parameter])
-
-                if issubclass(self.parameter.__class__, qc.parameters.MultiParameter) : 
-                    self.get_var.add_result(data[self.parameter][self.param_idx])
-                else:
-                    self.get_var.add_result(data[self.parameter])
+        if self.parameter in data.keys():
+            for data_saver_dynamic in self.set_var_dynamic:
+                data_saver_dynamic.add_result(data[data_saver_dynamic.var_info.parameter])
+
+            if issubclass(self.parameter.__class__, qc.parameters.MultiParameter) : 
+                self.get_var.add_result(data[self.parameter][self.param_idx])
+            else:
+                self.get_var.add_result(data[self.parameter])
 
     def save(self):
         self.dependency_builder.rebuild() #only writes when needed.
         for preprocessor in [self.get_var] + self.set_var_static + self.set_var_dynamic:
             preprocessor.write()
 
     def complete(self):
@@ -47,17 +47,17 @@
     def __init__(self, dataset, dtype = FileType.HDF5_NETCDF):
         self.dataset = dataset
         self.measurement_name = None
         h5_file = self.__create_hdf5_file(dtype)
         self.HDF5_writers = h5_writer_container(h5_file)
         self.ds_collections : List[data_collection] = []
         self.last_write = time.time()
-        self.write_every = 0.2 #200ms
+        self.write_every = 0.1 #100ms
         
-        self.firstWriteHappened = False
+        self.first_write_happened = False
     
     def __create_hdf5_file(self, dtype, name = "measurement") -> 'h5py.File':
         self.measurement_name = name
         if name in self.dataset.files.keys():
             raise ValueError("Already a measurement present in this dataset. Please start a new one.")
         
         fname = f'{name}.hdf5'
@@ -69,38 +69,38 @@
         
         self.lock_file = os.path.dirname(self.dataset[name].path) + "/.lock"
         os.close(os.open(self.lock_file, os.O_CREAT | os.O_EXCL | os.O_RDWR))
         hdf5_file = h5py.File(self.dataset[name].path, 'w', locking=False, libver='v112')
         return hdf5_file
     
     def __add__(self, other : List[data_collection]):
-        if self.firstWriteHappened:
+        if self.first_write_happened:
             raise ValueError("Cannot add to a data collector after the first write has happened.")
         self.ds_collections += other
         return self
 
     def _enable_swmr(self):
-        if self.firstWriteHappened == False:
+        if self.first_write_happened is False:
             # this was a quick fix, putting this here, in swmr mode, no new attributes can be created
             # this is supposed to be fixed with VDF SWMR mode (aka SWMR 2.0), but the implementation is not yet in the H5 library (lack of money :/).
             NETCDF4_reference_list_builder(self.HDF5_writers.h5_file ,self.ds_collections)
             self.HDF5_writers.h5_file.swmr_mode = True
-            self.firstWriteHappened = True
+            self.first_write_happened = True
             os.remove(self.lock_file)
             
     @property
     def size(self):
         return len(self.ds_collections)
 
     def add_data(self, data):
         self._enable_swmr()
         
-        for collelection in self.ds_collections:
-            if collelection.parameter in data.keys():
-                collelection.add_data(data)
+        for collection in self.ds_collections:
+            if collection.parameter in data.keys():
+                collection.add_data(data)
         
         if self.last_write + self.write_every < time.time():
             self.__save()
             self.last_write = time.time()
 
     def __save(self): #this happens automatically when data is added.
         for collection in self.ds_collections:
@@ -122,40 +122,40 @@
 
 def get_var_to_get_mgr(get_vars : 'get_var | List[get_var]', collector) -> List[data_collection]:
     if not isinstance(get_vars, list):
         get_vars = [get_vars]
     
     ds_collections = []
     
-    for i, get_var in enumerate(get_vars):
-        get_var_cache = ds_cache(collector.HDF5_writers, get_var, get_var.ndim, 0)
+    for i, get_variable in enumerate(get_vars):
+        get_var_cache = ds_cache(collector.HDF5_writers, get_variable, get_variable.ndim, 0)
         set_var_static_cache = []
         
-        for stat_var in get_var.set_vars_static:
+        for stat_var in get_variable.set_vars_static:
             data_pre = ds_cache(collector.HDF5_writers, stat_var, 1, 0)
             set_var_static_cache.append(data_pre)
             
         set_var_dynamic_cache = []
-        for j, set_vars_dynamic in enumerate(get_var.set_vars_dynamic):
+        for j, set_vars_dynamic in enumerate(get_variable.set_vars_dynamic):
             data_pre = ds_cache(collector.HDF5_writers, set_vars_dynamic,
-                                get_var.ndim, get_var.ndim-j-1)
+                                get_variable.ndim, get_variable.ndim-j-1)
             set_var_dynamic_cache.append(data_pre)
 
         if len(set_var_dynamic_cache) > 1:
             for j in range(len(set_var_dynamic_cache)-1):
                 for dyn_cache in set_var_dynamic_cache[j+1:]:
                     set_var_dynamic_cache[j].add_child(dyn_cache)
                 set_var_dynamic_cache[j].add_child(get_var_cache)
         
         # ensure that the dataset contains the right linkage.
         dep_builder = H5_dependency_builder(get_var_cache, set_var_dynamic_cache + set_var_static_cache)
         
         ds_collections.append(
                 data_collection(
-                    get_var.parameter, get_var_cache, set_var_static_cache,
+                    get_variable.parameter, get_var_cache, set_var_static_cache,
                     set_var_dynamic_cache, dep_builder, i))
         
     return ds_collections
 
 # TODO intergrate in data_collector.
 # TODO check qcodes multiparameter with multiple setpoint allowed formats.
 def from_QCoDeS_parameter(parameter, dependencies, writer_collection) -> List[data_collection]:
```

## qdrive/measurement/HDF5_collector/ds_cache.py

```diff
@@ -11,17 +11,18 @@
 class IRREGULAR_DATASET_EXCEPTION(Exception):
     pass
 
 # TODO :: find a better name for this class
 # TODO :: check if flat cache really needed?
 class ds_cache:
     '''
-    Respresents the cache of a single variable of a dataset (e.g. a setpoint or getter).
+    Represents the cache of a single variable of a dataset (e.g. a setpoint or getter).
     Multiple ds_caches can be linked to a single h5_writer, i.e. to avoid storing the same setpoints twice.
     When a divergence between different setpoints occurs, new h5_writers are automatically constructed (i.e. BRANCH_DETECTED_EXCEPTION)
+    -- this only happens when SWMR is not enabled.
     '''
     def __init__(self, data_collection : 'h5_writer_container',
                  var_info : 'get_var | set_var_dynamic | set_var_static', ndim, nth_dim):
         self.ndim = ndim
         self.nth_dim = nth_dim
         self.var_info = var_info
         self.data_collection = data_collection
```

## qdrive/measurement/HDF5_collector/h5_cache.py

```diff
@@ -129,11 +129,21 @@
         self.cache = data
         self.cursor = list(data.shape)
         self.n_writes = 1
 
     @property 
     def shape(self):
         return self.cache.shape
+    
+    @property
+    def size(self):
+        return np.prod(self.shape)
 
+    def add_result(self, index, result):
+        raise NotImplementedError
+
+    def increase_index(self, dim):
+        raise NotImplementedError
+    
     @staticmethod
     def from_cache(cache, n_writes):
         raise NotImplementedError
```

## qdrive/measurement/HDF5_collector/h5_writer.py

```diff
@@ -1,14 +1,13 @@
 import h5py as h5
 import numpy as np
 
 from qdrive.measurement.HDF5_collector.h5_cache import H5_static_cache, h5_dynamic_cache
 
 
-# TODO add cursor to HDF5
 class h5_writer:
     def __init__(self, cache : 'h5_dynamic_cache | H5_static_cache', dataset : 'h5.Dataset', var_info, ds_collection):
         self.cache = cache
         self.dataset = dataset
         self.var_info = var_info
         self.writer_collection = ds_collection
```

## qdrive/measurement/HDF5_collector/h5_writer_container.py

```diff
@@ -80,15 +80,15 @@
     chunk_size[-1] = 1000
 
     if isinstance(var_info, get_var):
         size_result_shape = 1
         for i in result_shape:
             size_result_shape *= i
         
-        # Recomended size between 10KB-1MB
+        # Recommended size between 10KB-1MB
         if size_result_shape*64 < 64e3:
             chunk_size[var_info.ndim-1] = int(1e3/size_result_shape)
             chunk_size[var_info.ndim:] = result_shape 
         elif size_result_shape*64 < 1e6:
             chunk_size[var_info.ndim:] = result_shape 
         else:  # expected large dataset, so we also take big chunks.
             n_chunks = np.ceil(size_result_shape*64/1e6)
```

## Comparing `qdrive-0.1.6.dist-info/LICENCE` & `qdrive-0.2.12.dist-info/LICENCE`

 * *Files identical despite different names*

## Comparing `qdrive-0.1.6.dist-info/METADATA` & `qdrive-0.2.12.dist-info/METADATA`

 * *Files 14% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: qdrive
-Version: 0.1.6
+Version: 0.2.12
 Summary: Qdrive dataset library
 Author: QDrive team
 Requires-Python: >=3.7
 License-File: LICENCE
 Requires-Dist: PyYAML >=6.0.0
 Requires-Dist: platformdirs >=4.0.0
 Requires-Dist: numpy >=1.16.0
```

## Comparing `qdrive-0.1.6.dist-info/RECORD` & `qdrive-0.2.12.dist-info/RECORD`

 * *Files 16% similar despite different names*

```diff
@@ -1,38 +1,38 @@
-qdrive/__init__.py,sha256=QI4t7cciTFzcGkkXsgQvhs7090V2AUHyd5_tD4-W1IE,169
+qdrive/__init__.py,sha256=7P5UbyRbVZVGreZvOkKFztdh7LTB3mLAwBDDNfhrrj4,232
 qdrive/dataset/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-qdrive/dataset/dataset.py,sha256=fJW8uxQ3DhRnWWiUGmreWQlau5b6D9zSrAuqzIu8zAM,2267
-qdrive/dataset/file_manager.py,sha256=BSSQYy-iVWM40lQwahi1GYoYn5YcNSvVmVmJu4umasQ,5044
+qdrive/dataset/dataset.py,sha256=spoWQqpm0j1RdXcEi7vUvueUWdEtJ5SYY77ZFX_ONe8,2496
+qdrive/dataset/file_manager.py,sha256=l_t0cjRbUACiu5KflF0HMbVtzUSRt3cpwmp4sf0GWNc,5038
 qdrive/dataset/files/HDF5.py,sha256=20nYipbsqqIoE6rN3xxsQS2mL4FKBSX8LyA4bE2ePlI,3995
 qdrive/dataset/files/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 qdrive/dataset/files/file.py,sha256=qz6n1_b4wvUovMF3UGj7JpvfDP8sndegD3OSfZWOjEg,929
 qdrive/dataset/files/file_mgr_single.py,sha256=XW1NsmLWX6bn6EKVF8MwO4icVgEPKxClMOeL880B-IY,3213
-qdrive/dataset/files/json.py,sha256=j-3hIUoUzksUXPB2QSAOiVEUCYULQ5cRRFlIaUEu2wU,3288
+qdrive/dataset/files/json.py,sha256=jYSJ6px9of3fqa0xWekOa7eg7M93jW1BvZaTVzt5Iu4,3372
 qdrive/dataset/files/numpy.py,sha256=YhMY4H1F0oXcVV1j8GTWhbDDQSQzjuTdGZSPs5fnKa4,2256
 qdrive/dataset/files/utility.py,sha256=VO-zIhQJqPXjaWKWAT-maITiOVikXS6TLImFblnVQcc,222
 qdrive/measurement/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-qdrive/measurement/data_collector.py,sha256=CILt3qz21eUyn_w70FZIDfy8HSiSSUNe1TtnZcmhPV0,9638
+qdrive/measurement/data_collector.py,sha256=UwYdQHyuykyyCDxMRpzMgEQlTxjkKcmhdxjjwwb-kjQ,9652
 qdrive/measurement/data_collector_var.py,sha256=MhP-fgG9qUXWBnJS0NfzHvjK-nT8zu1aOZyYMneMKd8,1989
 qdrive/measurement/HDF5_collector/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-qdrive/measurement/HDF5_collector/ds_cache.py,sha256=nbWSAzVvBLUBgKBogbqtmPuB0oMcxnCnkKoKk5dJDl8,4062
-qdrive/measurement/HDF5_collector/h5_cache.py,sha256=5X8pIa3I79L5NTyL5LlaTOuXZ7rY6PRDqAnS93X47Iw,4659
+qdrive/measurement/HDF5_collector/ds_cache.py,sha256=jiZFKY1luPagH86zB1C3-G68LHjgf59rW3uXZpt_8b0,4112
+qdrive/measurement/HDF5_collector/h5_cache.py,sha256=CWoYu7iuJz8v2nQWhhvVikaCO99mZq4Kbo9PavBy5w8,4883
 qdrive/measurement/HDF5_collector/h5_dependency_builder.py,sha256=ZluDA9OaMiVn_UIeeLDw_V9FaxKiYSAPGsLIp3eRVQc,5788
-qdrive/measurement/HDF5_collector/h5_writer.py,sha256=W_0U6KviaPRoZzvQGrmgEK9T-SRaH0IP8s3wDZ4sPKI,2719
-qdrive/measurement/HDF5_collector/h5_writer_container.py,sha256=-Nun2csSDoTmM4hNWMwEAsbP84eVWpQzMgjX-qmgLuM,5648
+qdrive/measurement/HDF5_collector/h5_writer.py,sha256=u6XWTGIZTGXRf99yXEeUYi6RKC6aYNvQ4ugAqdFigw8,2693
+qdrive/measurement/HDF5_collector/h5_writer_container.py,sha256=KFSlWBXKU0oNtYSDP_8yq2fvpt03jHwt2vBd4M6cZQ8,5649
 qdrive/measurement/utility/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 qdrive/measurement/utility/irregular_ds_conversion.py,sha256=bxFYHbK0SHqq9uuHBKmsvonN3RzN5GUiEcGoOLxw794,18
 qdrive/testing/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 qdrive/testing/core_tools_test.py,sha256=CX2SVZr0iFuEyI1trRuevpE0QIempdIhKCtvq_2DfkA,1595
 qdrive/testing/create_dataset.py,sha256=_X0rUdEjWE5WmrDzEifrs7DUM8TSB7gj94GjP2-p_pk,1034
 qdrive/testing/dataset_file_feature_overview.py,sha256=GQBka3vPO57bY9t5vtUsMWqeO-4WqY3IJcYFsBBlULg,6271
 qdrive/testing/interfaces_dataset.py,sha256=zJEG8EVx7Rf6Bu5upmBCK8rrdNanB3jIKe0rW-NF2aM,214
 qdrive/testing/measurement_with_qdrive.py,sha256=FOKDWqD11XmD8dXBvTZFZfweT-JR6st8ltT9fOkSQTI,635
 qdrive/testing/qcodes_test_param.py,sha256=YF1AW-qpVhBKEgxQxnODOU_taijtHsM-r-u6H7wWle8,6360
 qdrive/testing/qdrive_dataset_test.py,sha256=AFhbgJONRj-lRsIEI_L6zeMHLCepMyvtIms-dAeMzIU,1105
 qdrive/testing/test.py,sha256=QbMylU_a80YIqPzpM_-eVvOrbYn1jQYQrMeEDWS4bcA,2181
 qdrive/utility/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-qdrive-0.1.6.dist-info/LICENCE,sha256=BNXChWe7aLPGR3QkVckAkeLqK2cI2idnmInh-A3YOO0,16695
-qdrive-0.1.6.dist-info/METADATA,sha256=iOYNvotUc9-8lD5j68UJlPnvMbyiXZcRle4MA7p2tDk,670
-qdrive-0.1.6.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-qdrive-0.1.6.dist-info/top_level.txt,sha256=B1Ij35CV2H-FfDMctSIRLfZ9EIU_GshRACjkLDpc4I8,7
-qdrive-0.1.6.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
-qdrive-0.1.6.dist-info/RECORD,,
+qdrive-0.2.12.dist-info/LICENCE,sha256=BNXChWe7aLPGR3QkVckAkeLqK2cI2idnmInh-A3YOO0,16695
+qdrive-0.2.12.dist-info/METADATA,sha256=Cduk9uThk-GqJo02WWzU9maA9VwqXaUzb-ZBNzYQquI,671
+qdrive-0.2.12.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+qdrive-0.2.12.dist-info/top_level.txt,sha256=B1Ij35CV2H-FfDMctSIRLfZ9EIU_GshRACjkLDpc4I8,7
+qdrive-0.2.12.dist-info/zip-safe,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
+qdrive-0.2.12.dist-info/RECORD,,
```

